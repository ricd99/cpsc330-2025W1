Search.setIndex({"alltitles": {"": [[37, "id1"]], "(Optional) Evaluation": [[34, "optional-evaluation"], [53, "optional-evaluation"], [77, "optional-evaluation"]], "(Optional) Example 1: Optimization bias": [[22, "optional-example-1-optimization-bias"], [65, "optional-example-1-optimization-bias"]], "(Optional) Example 2: Optimization bias": [[22, "optional-example-2-optimization-bias"], [65, "optional-example-2-optimization-bias"]], "(Optional) Fancier methods": [[22, "optional-fancier-methods"], [41, "optional-fancier-methods"], [65, "optional-fancier-methods"]], "(Optional) Fitting in boosted regression trees.": [[44, "optional-fitting-in-boosted-regression-trees"], [68, "optional-fitting-in-boosted-regression-trees"]], "(Optional) Forward or backward selection": [[27, "optional-forward-or-backward-selection"], [81, "optional-forward-or-backward-selection"]], "(Optional) Given customer has been here n months, what\u2019s the outlook?": [[53, "optional-given-customer-has-been-here-n-months-what-s-the-outlook"], [77, "optional-given-customer-has-been-here-n-months-what-s-the-outlook"]], "(Optional) How does training work in neural networks? (High-Level)": [[32, "optional-how-does-training-work-in-neural-networks-high-level"], [75, "optional-how-does-training-work-in-neural-networks-high-level"]], "(Optional) Learn JupyterLab and Python": [[11, "optional-learn-jupyterlab-and-python"]], "(Optional) Parametric vs non parametric": [[16, "optional-parametric-vs-non-parametric"], [61, "optional-parametric-vs-non-parametric"]], "(Optional) Prediction in boosted regression trees": [[44, "optional-prediction-in-boosted-regression-trees"], [68, "optional-prediction-in-boosted-regression-trees"]], "(Optional) Problems with feature selection": [[27, "optional-problems-with-feature-selection"], [81, "optional-problems-with-feature-selection"]], "(Optional) Search and score": [[27, "optional-search-and-score"], [81, "optional-search-and-score"]], "(Optional) Searching for optimal parameters with successive halving\u00b6": [[22, "optional-searching-for-optimal-parameters-with-successive-halving"], [41, "optional-searching-for-optimal-parameters-with-successive-halving"], [65, "optional-searching-for-optimal-parameters-with-successive-halving"]], "(Optional) Setting up a directory structure and environment": [[56, "optional-setting-up-a-directory-structure-and-environment"], [57, "optional-setting-up-a-directory-structure-and-environment"], [79, "optional-setting-up-a-directory-structure-and-environment"]], "(Optional) Some more details": [[42, "optional-some-more-details"], [66, "optional-some-more-details"]], "(Supervised) machine learning: popular definition": [[13, "supervised-machine-learning-popular-definition"], [58, "supervised-machine-learning-popular-definition"]], "(iClicker) Exercise 14.1": [[70, "id1"]], "(iClicker) Exercise 20.1": [[77, "iclicker-exercise-20-1"]], "(iClicker) Exercise 20.2": [[77, "iclicker-exercise-20-2"]], "(iClicker) Exercise 21.1": [[34, "iclicker-exercise-21-1"]], "(iClicker) Exercise 21.2": [[34, "iclicker-exercise-21-2"]], "(iClicker) Exercise 4.1": [[16, "iclicker-exercise-4-1"], [61, "iclicker-exercise-4-1"]], "(iClicker) Exercise 4.2": [[16, "iclicker-exercise-4-2"], [61, "iclicker-exercise-4-2"]], "(iClicker) Exercise 5.1": [[18, "iclicker-exercise-5-1"], [62, "iclicker-exercise-5-1"]], "(iClicker) Exercise 5.2": [[18, "iclicker-exercise-5-2"], [62, "iclicker-exercise-5-2"]], "(iClicker) Exercise 5.3": [[18, "iclicker-exercise-5-3"], [62, "iclicker-exercise-5-3"]], "(iClicker) Exercise 6.1": [[19, "iclicker-exercise-6-1"], [63, "iclicker-exercise-6-1"]], "(iClicker) Exercise 6.2": [[19, "iclicker-exercise-6-2"], [63, "iclicker-exercise-6-2"]], "(iClicker) Exercise 7.1": [[21, "iclicker-exercise-7-1"], [64, "iclicker-exercise-7-1"]], "(iClicker) Exercise 7.2": [[21, "iclicker-exercise-7-2"], [64, "iclicker-exercise-7-2"]], "(iClicker) Exercise 7.3": [[21, "iclicker-exercise-7-3"]], "(iClicker) Exercise 8.1": [[22, "iclicker-exercise-8-1"], [65, "iclicker-exercise-8-1"]], "(iClicker) Midterm poll": [[71, "iclicker-midterm-poll"]], "15.1 Select all of the following statements which are True (iClicker)": [[28, "select-all-of-the-following-statements-which-are-true-iclicker"]], "15.2 Select all of the following statements which are True (iClicker)": [[28, "id1"]], "15.3 Select all of the following statements which are True (iClicker)": [[28, "id3"]], "16.1 Select all of the following statements which are True (iClicker)": [[29, "select-all-of-the-following-statements-which-are-true-iclicker"]], "16.2 Select all of the following statements which are True (iClicker)": [[29, "id2"]], "16.3 Select all of the following statements which are True": [[29, "select-all-of-the-following-statements-which-are-true"], [72, "select-all-of-the-following-statements-which-are-true"]], "330 vs. 340": [[79, "vs-340"]], "<font color='red'>Question 10</font>": [[88, "question-10"], [94, "question-10"]], "<font color='red'>Question 1</font>": [[85, "question-1"], [86, "question-1"], [88, "question-1"], [90, "question-1"], [91, "question-1"], [92, "question-1"], [94, "question-1"], [96, "question-1"]], "<font color='red'>Question 2</font>": [[85, "question-2"], [88, "question-2"], [90, "question-2"], [91, "question-2"], [94, "question-2"], [96, "question-2"]], "<font color='red'>Question 3: Baseline model</font>": [[86, "question-3-baseline-model"], [92, "question-3-baseline-model"]], "<font color='red'>Question 3</font>": [[85, "question-3"], [88, "question-3"], [90, "question-3"], [91, "question-3"], [94, "question-3"], [96, "question-3"]], "<font color='red'>Question 4: Decision tree</font>": [[86, "question-4-decision-tree"], [92, "question-4-decision-tree"]], "<font color='red'>Question 4</font>": [[85, "question-4"], [88, "question-4"], [90, "question-4"], [91, "question-4"], [94, "question-4"], [96, "question-4"]], "<font color='red'>Question 5: Cross-validation</font>": [[86, "question-5-cross-validation"]], "<font color='red'>Question 5: Hyperparameter tuning</font>": [[86, "question-5-hyperparameter-tuning"], [92, "question-5-hyperparameter-tuning"]], "<font color='red'>Question 5</font>": [[88, "question-5"], [90, "question-5"], [94, "question-5"], [96, "question-5"]], "<font color='red'>Question 6: Cross-validation</font>": [[92, "question-6-cross-validation"]], "<font color='red'>Question 6: Hyperparameters playground</font>": [[86, "question-6-hyperparameters-playground"], [92, "question-6-hyperparameters-playground"]], "<font color='red'>Question 6</font>": [[88, "question-6"], [90, "question-6"], [94, "question-6"], [96, "question-6"]], "<font color='red'>Question 7</font>": [[88, "question-7"], [94, "question-7"]], "<font color='red'>Question 8</font>": [[88, "question-8"], [94, "question-8"]], "<font color='red'>Question 9</font>": [[88, "question-9"], [94, "question-9"]], "<font color='red'>Recap Questions</font>": [[85, "recap-questions"], [91, "recap-questions"]], "<font color='red'>Recap/comprehension questions</font>": [[87, "recap-comprehension-questions"], [93, "recap-comprehension-questions"]], "A few comments on PR curve": [[23, "a-few-comments-on-pr-curve"], [42, "a-few-comments-on-pr-curve"], [66, "a-few-comments-on-pr-curve"]], "A few comments on clustering evaluation": [[29, "a-few-comments-on-clustering-evaluation"], [72, "a-few-comments-on-clustering-evaluation"]], "A simple model of language": [[31, "a-simple-model-of-language"], [50, "a-simple-model-of-language"], [74, "a-simple-model-of-language"]], "AP score": [[23, "ap-score"], [42, "ap-score"], [66, "ap-score"]], "AP vs. F1-score": [[23, "ap-vs-f1-score"], [42, "ap-vs-f1-score"], [66, "ap-vs-f1-score"]], "API on the localhost": [[56, "api-on-the-localhost"], [57, "api-on-the-localhost"], [79, "api-on-the-localhost"]], "AUC or AP?": [[23, "auc-or-ap"]], "About this course": [[13, "about-this-course"]], "About this document": [[9, "about-this-document"]], "Academic concessions": [[98, "academic-concessions"]], "Accessing homework assignments": [[8, "accessing-homework-assignments"]], "Accessing learned parameters": [[21, "accessing-learned-parameters"], [64, "accessing-learned-parameters"]], "Activity": [[13, "activity"], [27, "activity"]], "Activity (~4 mins)": [[45, "activity-4-mins"]], "Activity (~5 mins)": [[26, "activity-5-mins"], [26, "id3"], [69, "activity-5-mins"], [69, "id3"]], "Activity: Context and word meaning": [[51, "activity-context-and-word-meaning"]], "Activity: Discuss the following questions in your group": [[15, "activity-discuss-the-following-questions-in-your-group"]], "Activity: How can you measure quality of the data? (~3 mins)": [[70, "activity-how-can-you-measure-quality-of-the-data-3-mins"]], "Activity: explaining GridSearchCV (15 min)": [[35, "activity-explaining-gridsearchcv-15-min"], [55, "activity-explaining-gridsearchcv-15-min"], [78, "activity-explaining-gridsearchcv-15-min"]], "Activity: interpretation of results": [[28, "activity-interpretation-of-results"]], "Adding/removing columns with [] and drop()": [[9, "adding-removing-columns-with-and-drop"]], "Adding/removing rows with [] and drop()": [[9, "adding-removing-rows-with-and-drop"]], "Additional sources": [[26, "additional-sources"]], "Additional submission instructions": [[8, "additional-submission-instructions"]], "Addressing class imbalance": [[66, "addressing-class-imbalance"]], "Advantages of RandomizedSearchCV": [[22, "advantages-of-randomizedsearchcv"], [22, "id1"], [41, "advantages-of-randomizedsearchcv"], [41, "id1"], [65, "advantages-of-randomizedsearchcv"], [65, "id1"]], "Alternative and more compact syntax: make_pipeline": [[17, "alternative-and-more-compact-syntax-make-pipeline"], [18, "alternative-and-more-compact-syntax-make-pipeline"], [62, "alternative-and-more-compact-syntax-make-pipeline"]], "Alternative methods for scaling": [[17, "alternative-methods-for-scaling"], [39, "alternative-methods-for-scaling"]], "Alternative terminology for examples, features, targets, and training": [[14, "alternative-terminology-for-examples-features-targets-and-training"], [59, "alternative-terminology-for-examples-features-targets-and-training"]], "An effective strategy": [[25, "an-effective-strategy"], [44, "an-effective-strategy"], [68, "an-effective-strategy"]], "An example of a bootstrap samples": [[25, "an-example-of-a-bootstrap-samples"], [68, "an-example-of-a-bootstrap-samples"]], "An introduction to Grid Search": [[35, "an-introduction-to-grid-search"], [55, "an-introduction-to-grid-search"], [78, "an-introduction-to-grid-search"]], "Analogy-based algorithms in practice": [[61, "analogy-based-algorithms-in-practice"]], "Analogy-based models": [[61, "analogy-based-models"]], "Appendix A: Lecture 09": [[80, null]], "Appendix A: Lecture 13": [[81, null]], "Appendix C: Basic text preprocessing [video]": [[82, null]], "Appendix D: Multi-class, meta-strategies": [[83, null]], "Applying feature transformations": [[24, "applying-feature-transformations"], [35, "applying-feature-transformations"], [43, "applying-feature-transformations"], [54, "applying-feature-transformations"], [55, "applying-feature-transformations"], [67, "applying-feature-transformations"], [78, "applying-feature-transformations"]], "Applying functions to a dataframe with df.apply() and df.applymap()": [[9, "applying-functions-to-a-dataframe-with-df-apply-and-df-applymap"]], "Approach 1: Only consider the examples where \u201cChurn\u201d=Yes": [[34, "approach-1-only-consider-the-examples-where-churn-yes"], [77, "approach-1-only-consider-the-examples-where-churn-yes"]], "Approach 2: Assume everyone churns right now": [[34, "approach-2-assume-everyone-churns-right-now"], [77, "approach-2-assume-everyone-churns-right-now"]], "Approach 3: Survival analysis": [[34, "approach-3-survival-analysis"], [77, "approach-3-survival-analysis"]], "Approach from all angles": [[35, "approach-from-all-angles"], [55, "approach-from-all-angles"], [78, "approach-from-all-angles"]], "Are we doing better with class_weight=\"balanced\"?": [[66, "are-we-doing-better-with-class-weight-balanced"]], "Area under the curve (AUC)": [[23, "area-under-the-curve-auc"], [42, "area-under-the-curve-auc"], [66, "area-under-the-curve-auc"]], "Assessing on the test set": [[37, "assessing-on-the-test-set"]], "Assignments": [[98, "assignments"]], "Attention": [[14, null], [14, null], [16, null], [59, null], [59, null], [59, null], [61, null]], "Attribution": [[35, "attribution"], [55, "attribution"], [78, "attribution"]], "Automated hyperparameter optimization": [[22, "automated-hyperparameter-optimization"], [22, "id3"], [65, "automated-hyperparameter-optimization"], [65, "id3"]], "Averaging": [[25, "averaging"], [44, "averaging"], [68, "averaging"]], "Averaging simulation": [[88, "averaging-simulation"], [94, "averaging-simulation"]], "Bad range for hyperparameters": [[22, "bad-range-for-hyperparameters"], [41, "bad-range-for-hyperparameters"], [65, "bad-range-for-hyperparameters"]], "Bag of words (BOW) representation": [[19, "bag-of-words-bow-representation"], [63, "bag-of-words-bow-representation"]], "Baseline": [[23, "baseline"], [26, "baseline"], [42, "baseline"], [45, "baseline"], [66, "baseline"], [69, "baseline"]], "Baseline Approaches": [[30, "baseline-approaches"], [49, "baseline-approaches"], [73, "baseline-approaches"]], "Baseline model": [[15, "baseline-model"], [37, "baseline-model"]], "Baselines": [[14, "baselines"], [25, "baselines"], [44, "baselines"], [59, "baselines"], [68, "baselines"]], "Baselines [video]": [[14, "baselines-video"], [59, "baselines-video"]], "Basic text preprocessing [video]": [[51, "basic-text-preprocessing-video"]], "Better features usually help more than a better model.": [[27, "better-features-usually-help-more-than-a-better-model"], [70, "better-features-usually-help-more-than-a-better-model"]], "Beyond error rate in recommendation systems": [[30, "beyond-error-rate-in-recommendation-systems"], [49, "beyond-error-rate-in-recommendation-systems"], [73, "beyond-error-rate-in-recommendation-systems"]], "Beyond words: sentence embeddings": [[31, "beyond-words-sentence-embeddings"], [50, "beyond-words-sentence-embeddings"], [74, "beyond-words-sentence-embeddings"]], "Bias vs variance tradeoff": [[15, "bias-vs-variance-tradeoff"], [60, "bias-vs-variance-tradeoff"]], "Big picture and datasets": [[14, "big-picture-and-datasets"], [59, "big-picture-and-datasets"]], "Big picture and motivation": [[15, "big-picture-and-motivation"], [60, "big-picture-and-motivation"]], "Books": [[1, "books"]], "Bottom-up explanations": [[35, "bottom-up-explanations"], [55, "bottom-up-explanations"], [78, "bottom-up-explanations"]], "Break (5 min)": [[9, "break-5-min"], [13, "break-5-min"], [14, "break-5-min"], [15, "break-5-min"], [16, "break-5-min"], [19, "break-5-min"], [32, "break-5-min"], [34, "break-5-min"], [35, "break-5-min"], [50, "break-5-min"], [51, "break-5-min"], [55, "break-5-min"], [59, "break-5-min"], [60, "break-5-min"], [61, "break-5-min"], [62, "break-5-min"], [63, "break-5-min"], [70, "break-5-min"], [74, "break-5-min"], [75, "break-5-min"], [77, "break-5-min"], [78, "break-5-min"]], "Break (~15 min)": [[79, "break-15-min"]], "Broadcasting in numpy": [[9, "broadcasting-in-numpy"]], "Building a model": [[56, "building-a-model"], [57, "building-a-model"], [79, "building-a-model"]], "Building a supervise machine learning model": [[13, "building-a-supervise-machine-learning-model"], [58, "building-a-supervise-machine-learning-model"]], "Building and deploying a web app": [[56, "building-and-deploying-a-web-app"], [57, "building-and-deploying-a-web-app"], [79, "building-and-deploying-a-web-app"]], "Building decision trees with sklearn": [[14, "building-decision-trees-with-sklearn"], [59, "building-decision-trees-with-sklearn"]], "Building user profiles": [[30, "building-user-profiles"], [49, "building-user-profiles"], [73, "building-user-profiles"]], "CPSC 330 Documents": [[3, null]], "CPSC 330 Python notes": [[9, null]], "CPSC 330 grading policies": [[7, null]], "CPSC 330 vs. 340": [[13, "cpsc-330-vs-340"]], "CPSC 330 vs. CPSC 340": [[2, null]], "Can I attend lectures from a different section?": [[5, "can-i-attend-lectures-from-a-different-section"]], "Can I audit the class?": [[5, "can-i-audit-the-class"]], "Can I use generative AI in this course?": [[5, "can-i-use-generative-ai-in-this-course"]], "Can we learn without targets?": [[28, "can-we-learn-without-targets"], [71, "can-we-learn-without-targets"]], "Can we use this feature in the model?": [[18, "can-we-use-this-feature-in-the-model"], [62, "can-we-use-this-feature-in-the-model"]], "Cases where it\u2019s OK to break the golden rule": [[19, "cases-where-it-s-ok-to-break-the-golden-rule"], [63, "cases-where-it-s-ok-to-break-the-golden-rule"]], "CatBoost": [[25, "catboost"], [44, "catboost"], [68, "catboost"]], "Categorical features": [[17, "categorical-features"], [26, "categorical-features"], [39, "categorical-features"], [45, "categorical-features"], [69, "categorical-features"]], "Categorical features [video]": [[18, "categorical-features-video"], [62, "categorical-features-video"]], "Categorical features with only two possible categories": [[19, "categorical-features-with-only-two-possible-categories"], [63, "categorical-features-with-only-two-possible-categories"]], "Censoring and survival analysis": [[34, "censoring-and-survival-analysis"], [77, "censoring-and-survival-analysis"]], "Centre for Accessibility (CfA) Exam Accommodations": [[98, "centre-for-accessibility-cfa-exam-accommodations"]], "Changing the training procedure": [[66, "changing-the-training-procedure"]], "Characters in this course?": [[13, "characters-in-this-course"], [58, "characters-in-this-course"]], "Checklist for you before next class": [[13, "checklist-for-you-before-next-class"]], "Choosing K [video]": [[28, "choosing-k-video"], [71, "choosing-k-video"]], "Choosing n_neighbors": [[16, "choosing-n-neighbors"], [61, "choosing-n-neighbors"]], "Citing sources": [[8, "citing-sources"]], "Class imbalance in training sets": [[66, "class-imbalance-in-training-sets"]], "Class meetings": [[98, "class-meetings"]], "Classification report": [[23, "classification-report"], [42, "classification-report"]], "Classification vs. Regression": [[14, "classification-vs-regression"], [59, "classification-vs-regression"]], "Classification with KNeighborsClassifier": [[38, "classification-with-kneighborsclassifier"]], "Clustering": [[84, "clustering"]], "Clustering Activity (~5 mins)": [[28, "clustering-activity-5-mins"], [71, "clustering-activity-5-mins"]], "Clustering motivation [video]": [[28, "clustering-motivation-video"], [71, "clustering-motivation-video"]], "Clustering with K-Means": [[89, "clustering-with-k-means"], [95, "clustering-with-k-means"]], "Clustering: Input and (possible) output": [[28, "clustering-input-and-possible-output"], [71, "clustering-input-and-possible-output"]], "Code of conduct": [[98, "code-of-conduct"]], "Coefficients and intercept": [[21, "coefficients-and-intercept"], [64, "coefficients-and-intercept"]], "ColumnTransformer example": [[19, "columntransformer-example"], [63, "columntransformer-example"]], "ColumnTransformer on the California housing dataset": [[63, "columntransformer-on-the-california-housing-dataset"], [87, "columntransformer-on-the-california-housing-dataset"], [93, "columntransformer-on-the-california-housing-dataset"]], "ColumnTransformer: Transformed data": [[19, "columntransformer-transformed-data"], [63, "columntransformer-transformed-data"]], "Coming up \u2026": [[15, "coming-up"], [60, "coming-up"]], "Coming up:": [[16, "coming-up"], [61, "coming-up"]], "Common applications": [[28, "common-applications"], [71, "common-applications"]], "Common architectures": [[31, "common-architectures"], [50, "common-architectures"], [74, "common-architectures"]], "Common preprocessing techniques": [[18, "common-preprocessing-techniques"], [62, "common-preprocessing-techniques"]], "Communication": [[84, "communication"]], "Communications": [[13, "communications"]], "Completing the utility matrix with content-based filtering": [[30, "completing-the-utility-matrix-with-content-based-filtering"], [49, "completing-the-utility-matrix-with-content-based-filtering"], [73, "completing-the-utility-matrix-with-content-based-filtering"]], "Components of a linear classifier": [[21, "components-of-a-linear-classifier"], [64, "components-of-a-linear-classifier"]], "Concepts then labels, not the other way around": [[35, "concepts-then-labels-not-the-other-way-around"], [55, "concepts-then-labels-not-the-other-way-around"], [78, "concepts-then-labels-not-the-other-way-around"]], "Concepts we revised in this demo": [[37, "concepts-we-revised-in-this-demo"]], "Conclusion & farewell": [[79, "conclusion-farewell"]], "Confidence and predict_proba (20 min)": [[35, "confidence-and-predict-proba-20-min"], [55, "confidence-and-predict-proba-20-min"], [78, "confidence-and-predict-proba-20-min"]], "Confusing and perhaps misleading visualization of results": [[35, "confusing-and-perhaps-misleading-visualization-of-results"], [54, "confusing-and-perhaps-misleading-visualization-of-results"], [55, "confusing-and-perhaps-misleading-visualization-of-results"], [78, "confusing-and-perhaps-misleading-visualization-of-results"]], "Confusion matrix": [[23, "confusion-matrix"], [42, "confusion-matrix"]], "Confusion matrix and related metrics": [[66, "confusion-matrix-and-related-metrics"]], "Confusion matrix with cross-validation": [[23, "confusion-matrix-with-cross-validation"], [42, "confusion-matrix-with-cross-validation"], [66, "confusion-matrix-with-cross-validation"]], "Cons of k-NNs for supervised learning": [[16, "cons-of-k-nns-for-supervised-learning"], [61, "cons-of-k-nns-for-supervised-learning"]], "Content-based filtering": [[30, "content-based-filtering"], [49, "content-based-filtering"], [73, "content-based-filtering"]], "Convenient make_column_transformer syntax": [[19, "convenient-make-column-transformer-syntax"], [63, "convenient-make-column-transformer-syntax"]], "Convolutional Neural Networks (CNNs) (high level)": [[32, "convolutional-neural-networks-cnns-high-level"], [75, "convolutional-neural-networks-cnns-high-level"]], "Course Learning Objectives": [[12, null]], "Course co-ordinator": [[1, "course-co-ordinator"], [98, "course-co-ordinator"]], "Course description": [[98, "course-description"]], "Course format": [[13, "course-format"]], "Course review / conclusion (~20 min)": [[79, "course-review-conclusion-20-min"]], "Course website": [[13, "course-website"]], "Cox proportional hazards model": [[34, "cox-proportional-hazards-model"], [53, "cox-proportional-hazards-model"], [77, "cox-proportional-hazards-model"]], "Create X and y": [[14, "create-x-and-y"], [59, "create-x-and-y"]], "Create a classifier object": [[14, "create-a-classifier-object"], [59, "create-a-classifier-object"]], "Create a column transformer": [[19, "create-a-column-transformer"], [63, "create-a-column-transformer"]], "Creating train_df and test_df": [[60, "creating-train-df-and-test-df"]], "Creating utility matrix": [[30, "creating-utility-matrix"], [49, "creating-utility-matrix"], [73, "creating-utility-matrix"]], "Credit": [[11, "credit"]], "Cross validation with different metrics": [[23, "cross-validation-with-different-metrics"], [42, "cross-validation-with-different-metrics"]], "Cross-validation": [[33, "cross-validation"], [37, "cross-validation"], [52, "cross-validation"], [76, "cross-validation"], [76, "id4"]], "Cross-validation [video]": [[15, "cross-validation-video"], [60, "cross-validation-video"]], "Cross-validation to the rescue!!": [[15, "cross-validation-to-the-rescue"], [60, "cross-validation-to-the-rescue"]], "Cross-validation using scikit-learn": [[60, "cross-validation-using-scikit-learn"]], "Cross-validation using scikit-learn on housing data": [[15, "cross-validation-using-scikit-learn-on-housing-data"]], "Curse of dimensionality": [[16, "curse-of-dimensionality"], [61, "curse-of-dimensionality"]], "Customer churn": [[34, "customer-churn"], [77, "customer-churn"]], "Customer segmentation": [[28, "customer-segmentation"], [71, "customer-segmentation"]], "DBSCAN": [[48, "dbscan"]], "DBSCAN [video]": [[29, "dbscan-video"], [72, "dbscan-video"]], "DBSCAN introduction": [[29, "dbscan-introduction"], [72, "dbscan-introduction"]], "DBSCAN: failure cases": [[29, "dbscan-failure-cases"], [29, "id1"], [72, "dbscan-failure-cases"], [72, "id1"]], "Data": [[19, "data"], [21, "data"], [25, "data"], [26, "data"], [26, "id1"], [44, "data"], [45, "data"], [45, "id1"], [53, "data"], [63, "data"], [64, "data"], [68, "data"], [69, "data"], [69, "id1"], [80, "data"]], "Data Splitting [video]": [[15, "data-splitting-video"], [60, "data-splitting-video"]], "Data and main approaches": [[30, "data-and-main-approaches"], [73, "data-and-main-approaches"]], "Data and splitting": [[17, "data-and-splitting"], [39, "data-and-splitting"]], "Data exploration": [[28, "data-exploration"], [71, "data-exploration"]], "Data splitting": [[37, "data-splitting"], [86, "data-splitting"], [92, "data-splitting"]], "Dataframe summaries": [[9, "dataframe-summaries"]], "Dataset": [[32, "dataset"], [35, "dataset"], [54, "dataset"], [55, "dataset"], [75, "dataset"], [78, "dataset"]], "Dataset [video]": [[24, "dataset-video"], [43, "dataset-video"], [67, "dataset-video"]], "Dataset for demonstration": [[23, "dataset-for-demonstration"], [42, "dataset-for-demonstration"], [66, "dataset-for-demonstration"]], "Dataset, splitting, and baseline": [[18, "dataset-splitting-and-baseline"], [62, "dataset-splitting-and-baseline"]], "Datasets": [[8, "datasets"]], "Dealing with class imbalance [video]": [[66, "dealing-with-class-imbalance-video"]], "Dealing with unknown categories": [[19, "dealing-with-unknown-categories"], [63, "dealing-with-unknown-categories"]], "Decision boundaries playground": [[38, "decision-boundaries-playground"]], "Decision boundary": [[14, "decision-boundary"], [59, "decision-boundary"]], "Decision boundary for max_depth=1": [[14, "decision-boundary-for-max-depth-1"], [59, "decision-boundary-for-max-depth-1"]], "Decision boundary for max_depth=2": [[14, "decision-boundary-for-max-depth-2"], [59, "decision-boundary-for-max-depth-2"]], "Decision boundary for max_depth=5": [[14, "decision-boundary-for-max-depth-5"], [59, "decision-boundary-for-max-depth-5"]], "Decision boundary of SVMs": [[16, "decision-boundary-of-svms"], [61, "decision-boundary-of-svms"]], "Decision boundary of logistic regression": [[21, "decision-boundary-of-logistic-regression"], [64, "decision-boundary-of-logistic-regression"]], "Decision tree algorithm": [[14, "decision-tree-algorithm"], [59, "decision-tree-algorithm"]], "Decision tree feature importances": [[26, "decision-tree-feature-importances"], [45, "decision-tree-feature-importances"], [69, "decision-tree-feature-importances"]], "Decision tree for regression problems": [[14, "decision-tree-for-regression-problems"], [59, "decision-tree-for-regression-problems"]], "Decision tree model": [[15, "decision-tree-model"], [37, "decision-tree-model"]], "Decision tree with max_depth=1": [[14, "decision-tree-with-max-depth-1"], [59, "decision-tree-with-max-depth-1"]], "Decision tree with max_depth=3": [[14, "decision-tree-with-max-depth-3"], [59, "decision-tree-with-max-depth-3"]], "Decision trees [video]": [[14, "decision-trees-video"], [59, "decision-trees-video"]], "Decision trees with continuous features": [[14, "decision-trees-with-continuous-features"], [59, "decision-trees-with-continuous-features"]], "DecisionTreeClassifier baseline": [[25, "decisiontreeclassifier-baseline"], [44, "decisiontreeclassifier-baseline"], [68, "decisiontreeclassifier-baseline"]], "DecisionTreeClassifier on quiz2 grade prediction toy dataset": [[14, "decisiontreeclassifier-on-quiz2-grade-prediction-toy-dataset"], [59, "decisiontreeclassifier-on-quiz2-grade-prediction-toy-dataset"]], "Decisions involve a few key pieces": [[55, "decisions-involve-a-few-key-pieces"], [78, "decisions-involve-a-few-key-pieces"]], "Decreasing the threshold": [[23, "decreasing-the-threshold"], [42, "decreasing-the-threshold"], [66, "decreasing-the-threshold"]], "Deep learning": [[33, "deep-learning"], [52, "deep-learning"], [76, "deep-learning"]], "Deep learning software": [[32, "deep-learning-software"], [75, "deep-learning-software"]], "Deliverable due dates (tentative)": [[1, "deliverable-due-dates-tentative"]], "Demo": [[15, "demo"]], "Demo of creating a new web service": [[56, "demo-of-creating-a-new-web-service"], [57, "demo-of-creating-a-new-web-service"], [79, "demo-of-creating-a-new-web-service"]], "Demo of feature engineering with numeric features": [[27, "demo-of-feature-engineering-with-numeric-features"], [46, "demo-of-feature-engineering-with-numeric-features"], [70, "demo-of-feature-engineering-with-numeric-features"]], "Demo: A more complicated dataset": [[52, "demo-a-more-complicated-dataset"], [76, "demo-a-more-complicated-dataset"]], "Demo: Deploying moment classification model": [[56, "demo-deploying-moment-classification-model"], [57, "demo-deploying-moment-classification-model"], [79, "demo-deploying-moment-classification-model"]], "Demo: Model interpretation of linear classifiers": [[20, "demo-model-interpretation-of-linear-classifiers"], [40, "demo-model-interpretation-of-linear-classifiers"]], "Dendrogram": [[29, "dendrogram"], [72, "dendrogram"]], "Deploying the API on a server (not covered)": [[56, "deploying-the-api-on-a-server-not-covered"], [57, "deploying-the-api-on-a-server-not-covered"], [79, "deploying-the-api-on-a-server-not-covered"]], "Deployment (Not examinable)": [[84, "deployment-not-examinable"]], "Difference between Statistics and Machine Learning": [[79, "difference-between-statistics-and-machine-learning"]], "Different models": [[26, "different-models"], [45, "different-models"], [69, "different-models"]], "Different range for hyperparameters yields better results!": [[22, "different-range-for-hyperparameters-yields-better-results"], [41, "different-range-for-hyperparameters-yields-better-results"], [65, "different-range-for-hyperparameters-yields-better-results"]], "Different scoring functions with cross_validate": [[24, "different-scoring-functions-with-cross-validate"], [43, "different-scoring-functions-with-cross-validate"], [67, "different-scoring-functions-with-cross-validate"]], "Dimensions in ML problems": [[16, "dimensions-in-ml-problems"], [61, "dimensions-in-ml-problems"]], "Discuss the following questions in your group": [[15, "discuss-the-following-questions-in-your-group"]], "Discussion": [[56, "discussion"], [57, "discussion"], [79, "discussion"]], "Discussion question": [[31, "discussion-question"], [51, "discussion-question"], [74, "discussion-question"]], "Discussion questions": [[17, "discussion-questions"]], "Discussion questions:": [[35, "discussion-questions"], [55, "discussion-questions"], [78, "discussion-questions"]], "Distance between feature vectors": [[16, "distance-between-feature-vectors"], [61, "distance-between-feature-vectors"]], "Distributional hypothesis": [[31, "distributional-hypothesis"], [50, "distributional-hypothesis"], [74, "distributional-hypothesis"]], "Do we actually want to use certain features for prediction?": [[63, "do-we-actually-want-to-use-certain-features-for-prediction"]], "Do we have class imbalance?": [[25, "do-we-have-class-imbalance"], [26, "do-we-have-class-imbalance"], [44, "do-we-have-class-imbalance"], [45, "do-we-have-class-imbalance"], [68, "do-we-have-class-imbalance"], [69, "do-we-have-class-imbalance"]], "Do we have correlated features?": [[26, "do-we-have-correlated-features"], [45, "do-we-have-correlated-features"], [69, "do-we-have-correlated-features"]], "Document clustering": [[28, "document-clustering"], [71, "document-clustering"]], "Domain-specific transformations": [[27, "domain-specific-transformations"], [70, "domain-specific-transformations"]], "Dummy Classifier": [[17, "dummy-classifier"], [39, "dummy-classifier"]], "Dummy model": [[38, "dummy-model"]], "DummyClassifier": [[14, "dummyclassifier"], [34, "dummyclassifier"], [52, "dummyclassifier"], [59, "dummyclassifier"], [76, "dummyclassifier"], [77, "dummyclassifier"]], "DummyClassifier baseline": [[25, "dummyclassifier-baseline"], [44, "dummyclassifier-baseline"], [68, "dummyclassifier-baseline"]], "DummyClassifier on quiz2 grade prediction toy dataset": [[14, "dummyclassifier-on-quiz2-grade-prediction-toy-dataset"], [59, "dummyclassifier-on-quiz2-grade-prediction-toy-dataset"]], "DummyRegressor": [[14, "dummyregressor"], [24, "dummyregressor"], [43, "dummyregressor"], [59, "dummyregressor"], [67, "dummyregressor"]], "EDA": [[18, "eda"], [23, "eda"], [24, "eda"], [42, "eda"], [43, "eda"], [62, "eda"], [66, "eda"], [67, "eda"], [89, "eda"], [95, "eda"]], "EDA: Exploratory Data Analysis": [[86, "eda-exploratory-data-analysis"], [92, "eda-exploratory-data-analysis"]], "Encoding text data": [[19, "encoding-text-data"], [63, "encoding-text-data"]], "Encoding time as a number": [[52, "encoding-time-as-a-number"], [76, "encoding-time-as-a-number"]], "Encoding time of day as a categorical feature": [[33, "encoding-time-of-day-as-a-categorical-feature"], [76, "encoding-time-of-day-as-a-categorical-feature"]], "Ensemble models": [[25, "ensemble-models"]], "Ensembles": [[84, "ensembles"]], "Equally good": [[35, "equally-good"], [54, "equally-good"], [55, "equally-good"], [78, "equally-good"]], "Errors when creating course environment": [[11, "errors-when-creating-course-environment"]], "Ethics": [[84, "ethics"]], "Euclidean distance": [[16, "euclidean-distance"], [61, "euclidean-distance"]], "Evaluating DBSCAN clusters": [[29, "evaluating-dbscan-clusters"], [72, "evaluating-dbscan-clusters"]], "Evaluation": [[30, "evaluation"], [30, "id2"], [49, "evaluation"], [49, "id3"], [73, "evaluation"], [73, "id4"]], "Evaluation metrics": [[84, "evaluation-metrics"]], "Evaluation metrics for binary classification: Motivation": [[23, "evaluation-metrics-for-binary-classification-motivation"], [42, "evaluation-metrics-for-binary-classification-motivation"], [66, "evaluation-metrics-for-binary-classification-motivation"]], "Evaluation metrics for multi-class classification": [[80, "evaluation-metrics-for-multi-class-classification"]], "Evalution metrics overview": [[42, "evalution-metrics-overview"]], "Examining learned coefficients": [[20, "examining-learned-coefficients"], [40, "examining-learned-coefficients"]], "Examining the preprocessed data": [[24, "examining-the-preprocessed-data"], [35, "examining-the-preprocessed-data"], [43, "examining-the-preprocessed-data"], [54, "examining-the-preprocessed-data"], [55, "examining-the-preprocessed-data"], [67, "examining-the-preprocessed-data"], [78, "examining-the-preprocessed-data"]], "Examining the vocabulary": [[20, "examining-the-vocabulary"], [40, "examining-the-vocabulary"]], "Example": [[21, "example"], [25, "example"], [44, "example"], [64, "example"], [68, "example"]], "Example 1": [[35, "example-1"]], "Example 1: Predicting whether a patient has a liver disease or not": [[13, "example-1-predicting-whether-a-patient-has-a-liver-disease-or-not"], [58, "example-1-predicting-whether-a-patient-has-a-liver-disease-or-not"]], "Example 1: What is \u201ccorrect\u201d grouping?": [[28, "example-1-what-is-correct-grouping"], [71, "example-1-what-is-correct-grouping"]], "Example 1: quiz 2 grade prediction": [[14, "example-1-quiz-2-grade-prediction"], [59, "example-1-quiz-2-grade-prediction"]], "Example 2": [[35, "example-2"]], "Example 2: Predicting country using the longitude and latitude": [[59, "example-2-predicting-country-using-the-longitude-and-latitude"]], "Example 2: Predicting the label of a given image": [[13, "example-2-predicting-the-label-of-a-given-image"], [58, "example-2-predicting-the-label-of-a-given-image"]], "Example 3": [[35, "example-3"]], "Example 3: Predicting sentiment expressed in a movie review": [[13, "example-3-predicting-sentiment-expressed-in-a-movie-review"], [58, "example-3-predicting-sentiment-expressed-in-a-movie-review"]], "Example 4: Predicting housing prices": [[13, "example-4-predicting-housing-prices"], [58, "example-4-predicting-housing-prices"]], "Example showing how can we interpret coefficients of scaled features.": [[26, "example-showing-how-can-we-interpret-coefficients-of-scaled-features"], [45, "example-showing-how-can-we-interpret-coefficients-of-scaled-features"], [69, "example-showing-how-can-we-interpret-coefficients-of-scaled-features"]], "Example: Is \u201cRelevance\u201d clearly defined?": [[27, "example-is-relevance-clearly-defined"], [81, "example-is-relevance-clearly-defined"]], "Example: Predict whether a message is spam or not": [[13, "example-predict-whether-a-message-is-spam-or-not"], [58, "example-predict-whether-a-message-is-spam-or-not"]], "Example: Sentiment analysis using a pretrained model": [[31, "example-sentiment-analysis-using-a-pretrained-model"], [50, "example-sentiment-analysis-using-a-pretrained-model"], [74, "example-sentiment-analysis-using-a-pretrained-model"]], "Example: Supervised vs unsupervised learning": [[28, "example-supervised-vs-unsupervised-learning"], [71, "example-supervised-vs-unsupervised-learning"]], "Example: Tabular data for grade prediction": [[14, "example-tabular-data-for-grade-prediction"], [59, "example-tabular-data-for-grade-prediction"]], "Example: Tabular data for the housing price prediction": [[59, "example-tabular-data-for-the-housing-price-prediction"]], "Example: class_weight parameter of sklearn LogisticRegression": [[66, "example-class-weight-parameter-of-sklearn-logisticregression"]], "Example: k-nearest neighbours on the Spotify dataset": [[18, "example-k-nearest-neighbours-on-the-spotify-dataset"], [62, "example-k-nearest-neighbours-on-the-spotify-dataset"]], "Examples": [[13, "examples"], [58, "examples"]], "Exercise - Features and targets": [[14, "exercise-features-and-targets"]], "Exercise 17.1 Select all of the following statements which are True (iClicker)": [[30, "exercise-17-1-select-all-of-the-following-statements-which-are-true-iclicker"]], "Exercise 17.2 Select all of the following statements which are True (iClicker)": [[30, "exercise-17-2-select-all-of-the-following-statements-which-are-true-iclicker"]], "Exercise 2.1 Select all of the following statements which are examples of supervised machine learning": [[59, "exercise-2-1-select-all-of-the-following-statements-which-are-examples-of-supervised-machine-learning"]], "Exercise 2.4": [[59, "exercise-2-4"]], "Exercise 8.2": [[22, "exercise-8-2"], [65, "exercise-8-2"]], "Exercise: Predicting country using the longitude and latitude": [[85, "exercise-predicting-country-using-the-longitude-and-latitude"], [91, "exercise-predicting-country-using-the-longitude-and-latitude"]], "Exhaustive grid search: sklearn.model_selection.GridSearchCV": [[22, "exhaustive-grid-search-sklearn-model-selection-gridsearchcv"], [41, "exhaustive-grid-search-sklearn-model-selection-gridsearchcv"], [65, "exhaustive-grid-search-sklearn-model-selection-gridsearchcv"]], "Explaining a prediction": [[26, "explaining-a-prediction"], [45, "explaining-a-prediction"], [69, "explaining-a-prediction"]], "Explanation 1": [[35, "explanation-1"], [55, "explanation-1"], [78, "explanation-1"]], "Explanation 2": [[35, "explanation-2"], [55, "explanation-2"], [78, "explanation-2"]], "Exploratory Data Analysis": [[15, "exploratory-data-analysis"], [37, "exploratory-data-analysis"]], "Exploratory data analysis": [[17, "exploratory-data-analysis"], [39, "exploratory-data-analysis"], [52, "exploratory-data-analysis"], [76, "exploratory-data-analysis"], [90, "exploratory-data-analysis"], [96, "exploratory-data-analysis"]], "Extracting BOW features using scikit-learn": [[19, "extracting-bow-features-using-scikit-learn"], [63, "extracting-bow-features-using-scikit-learn"]], "Extracting date and time information": [[33, "extracting-date-and-time-information"], [76, "extracting-date-and-time-information"]], "F1-score": [[23, "f1-score"], [42, "f1-score"]], "Faster method: vectorize the loop over rows": [[9, "faster-method-vectorize-the-loop-over-rows"]], "Fastest method: broadcasting": [[9, "fastest-method-broadcasting"]], "Feature crosses for one-hot encoded features": [[27, "feature-crosses-for-one-hot-encoded-features"], [46, "feature-crosses-for-one-hot-encoded-features"], [70, "feature-crosses-for-one-hot-encoded-features"]], "Feature engineering": [[33, "feature-engineering"], [52, "feature-engineering"], [76, "feature-engineering"]], "Feature engineering and selection": [[84, "feature-engineering-and-selection"]], "Feature engineering for date/time columns": [[33, "feature-engineering-for-date-time-columns"], [76, "feature-engineering-for-date-time-columns"]], "Feature engineering: Encoding date/time as feature(s)": [[52, "feature-engineering-encoding-date-time-as-feature-s"], [76, "feature-engineering-encoding-date-time-as-feature-s"]], "Feature engineering: Motivation": [[27, "feature-engineering-motivation"], [70, "feature-engineering-motivation"]], "Feature importances": [[26, "feature-importances"], [45, "feature-importances"], [69, "feature-importances"], [84, "feature-importances"]], "Feature importances in linear models": [[26, "feature-importances-in-linear-models"], [26, "id2"], [45, "feature-importances-in-linear-models"], [45, "id2"], [69, "feature-importances-in-linear-models"], [69, "id2"]], "Feature interactions and feature crosses": [[27, "feature-interactions-and-feature-crosses"], [46, "feature-interactions-and-feature-crosses"], [70, "feature-interactions-and-feature-crosses"]], "Feature names of transformed data": [[24, "feature-names-of-transformed-data"], [43, "feature-names-of-transformed-data"], [67, "feature-names-of-transformed-data"]], "Feature selection: Introduction and motivation": [[27, "feature-selection-introduction-and-motivation"], [46, "feature-selection-introduction-and-motivation"], [70, "feature-selection-introduction-and-motivation"]], "Feature transformations and the golden rule": [[18, "feature-transformations-and-the-golden-rule"], [62, "feature-transformations-and-the-golden-rule"]], "Feature types": [[24, "feature-types"], [24, "id1"], [35, "feature-types"], [43, "feature-types"], [43, "id1"], [54, "feature-types"], [55, "feature-types"], [67, "feature-types"], [67, "id1"], [78, "feature-types"]], "Feature vectors": [[61, "feature-vectors"]], "Figures": [[8, "figures"]], "Filtering a dataframe with [] and df.query()": [[9, "filtering-a-dataframe-with-and-df-query"]], "Final comments and summary": [[22, "final-comments-and-summary"], [30, "final-comments-and-summary"], [49, "final-comments-and-summary"], [65, "final-comments-and-summary"], [73, "final-comments-and-summary"]], "Final comments, summary, and reflection": [[14, "final-comments-summary-and-reflection"], [28, "final-comments-summary-and-reflection"], [29, "final-comments-summary-and-reflection"], [59, "final-comments-summary-and-reflection"], [71, "final-comments-summary-and-reflection"], [72, "final-comments-summary-and-reflection"]], "Final exam": [[98, "final-exam"]], "Final exam preparation: guiding questions": [[84, null]], "Final note": [[86, "final-note"], [92, "final-note"]], "Final remarks": [[33, "final-remarks"], [52, "final-remarks"], [76, "final-remarks"]], "Finding the distances to a query point": [[16, "finding-the-distances-to-a-query-point"], [61, "finding-the-distances-to-a-query-point"]], "Finding the nearest neighbour": [[16, "finding-the-nearest-neighbour"], [61, "finding-the-nearest-neighbour"]], "First deliverables": [[13, "first-deliverables"]], "Forecasting further into the future": [[33, "forecasting-further-into-the-future"], [76, "forecasting-further-into-the-future"]], "Forecasting further into the future on a retail dataset": [[33, "forecasting-further-into-the-future-on-a-retail-dataset"], [76, "forecasting-further-into-the-future-on-a-retail-dataset"]], "Formulating the problem of recommender systems": [[30, "formulating-the-problem-of-recommender-systems"], [49, "formulating-the-problem-of-recommender-systems"], [73, "formulating-the-problem-of-recommender-systems"]], "Frequently Asked Questions": [[5, null]], "From Markov models to meaning": [[31, "from-markov-models-to-meaning"], [50, "from-markov-models-to-meaning"], [74, "from-markov-models-to-meaning"]], "From word prediction to transformers": [[31, "from-word-prediction-to-transformers"], [50, "from-word-prediction-to-transformers"], [74, "from-word-prediction-to-transformers"]], "GB better than RF": [[35, "gb-better-than-rf"], [54, "gb-better-than-rf"], [55, "gb-better-than-rf"], [78, "gb-better-than-rf"]], "Garbage in, garbage out.": [[27, "garbage-in-garbage-out"], [70, "garbage-in-garbage-out"]], "Gaussian distribution": [[41, "gaussian-distribution"], [65, "gaussian-distribution"]], "General advice on finding relevant features": [[27, "general-advice-on-finding-relevant-features"], [70, "general-advice-on-finding-relevant-features"]], "General guidelines": [[7, "general-guidelines"]], "General idea": [[25, "general-idea"], [44, "general-idea"], [68, "general-idea"]], "General idea of k-nearest neighbours algorithm": [[16, "general-idea-of-k-nearest-neighbours-algorithm"], [61, "general-idea-of-k-nearest-neighbours-algorithm"]], "General idea of search and score methods": [[27, "general-idea-of-search-and-score-methods"], [81, "general-idea-of-search-and-score-methods"]], "General questions": [[4, "general-questions"]], "Generalization [video]": [[15, "generalization-video"], [60, "generalization-video"]], "Generalization: Fundamental goal of ML": [[15, "generalization-fundamental-goal-of-ml"], [60, "generalization-fundamental-goal-of-ml"]], "Generalizing to more features": [[21, "generalizing-to-more-features"], [64, "generalizing-to-more-features"]], "Generalizing to unseen data": [[60, "generalizing-to-unseen-data"]], "Geometric view of tabular data and dimensions": [[16, "geometric-view-of-tabular-data-and-dimensions"], [61, "geometric-view-of-tabular-data-and-dimensions"]], "Git and GitHub: Getting Started": [[6, null]], "Global average baseline": [[30, "global-average-baseline"], [49, "global-average-baseline"], [73, "global-average-baseline"]], "Golden rule violation: Example 1": [[60, "golden-rule-violation-example-1"]], "Golden rule violation: Example 2": [[60, "golden-rule-violation-example-2"]], "Grades": [[13, "grades"]], "Gradient boosted trees [video]": [[25, "gradient-boosted-trees-video"], [44, "gradient-boosted-trees-video"], [68, "gradient-boosted-trees-video"]], "Gradient boosting in sklearn": [[25, "gradient-boosting-in-sklearn"], [44, "gradient-boosting-in-sklearn"], [68, "gradient-boosting-in-sklearn"]], "Grading concerns: time limit": [[7, "grading-concerns-time-limit"]], "Grading scheme": [[98, "grading-scheme"]], "Grading-related questions": [[4, "grading-related-questions"]], "Handling class imbalance by changing the data": [[80, "handling-class-imbalance-by-changing-the-data"]], "Handling imbalance": [[66, "handling-imbalance"]], "Here is the workflow we\u2019ll generally follow.": [[15, "here-is-the-workflow-we-ll-generally-follow"], [60, "here-is-the-workflow-we-ll-generally-follow"]], "Hierarchical clustering": [[48, "hierarchical-clustering"]], "Hierarchical clustering [video]": [[29, "hierarchical-clustering-video"], [72, "hierarchical-clustering-video"]], "Homework info & submission guidelines": [[8, null]], "How are we making predictions?": [[21, "how-are-we-making-predictions"], [64, "how-are-we-making-predictions"]], "How can we avoid violating golden rule?": [[15, "how-can-we-avoid-violating-golden-rule"], [60, "how-can-we-avoid-violating-golden-rule"]], "How can we get feature importances for non sklearn models?": [[45, "how-can-we-get-feature-importances-for-non-sklearn-models"], [69, "how-can-we-get-feature-importances-for-non-sklearn-models"]], "How do I submit homework assignments?": [[5, "how-do-i-submit-homework-assignments"]], "How do they work?": [[25, "how-do-they-work"], [44, "how-do-they-work"], [68, "how-do-they-work"]], "How do we carry out feature selection?": [[27, "how-do-we-carry-out-feature-selection"], [46, "how-do-we-carry-out-feature-selection"], [70, "how-do-we-carry-out-feature-selection"]], "How does fit work?": [[14, "how-does-fit-work"], [59, "how-does-fit-work"], [59, "id2"]], "How does it work?": [[29, "how-does-it-work"], [35, "how-does-it-work"], [55, "how-does-it-work"], [72, "how-does-it-work"], [78, "how-does-it-work"]], "How does logistic regression calculate these probabilities?": [[21, "how-does-logistic-regression-calculate-these-probabilities"], [64, "how-does-logistic-regression-calculate-these-probabilities"]], "How does predict work?": [[14, "how-does-predict-work"], [59, "how-does-predict-work"]], "How does this course overlap with CPSC 340?": [[5, "how-does-this-course-overlap-with-cpsc-340"]], "How to approximate generalization error?": [[15, "how-to-approximate-generalization-error"], [60, "how-to-approximate-generalization-error"]], "How to ask for help": [[4, null]], "How to carry out cross-validation?": [[18, "how-to-carry-out-cross-validation"], [62, "how-to-carry-out-cross-validation"]], "How to choose n_neighbors?": [[16, "how-to-choose-n-neighbors"], [61, "how-to-choose-n-neighbors"]], "How to do it properly? Enter sklearn pipelines!!": [[17, "how-to-do-it-properly-enter-sklearn-pipelines"]], "How to pick a model that would generalize better?": [[15, "how-to-pick-a-model-that-would-generalize-better"], [60, "how-to-pick-a-model-that-would-generalize-better"]], "How to submit": [[8, "how-to-submit"]], "How would you do it properly? Enter sklearn pipelines!!": [[39, "how-would-you-do-it-properly-enter-sklearn-pipelines"]], "Hyperparameter alpha of Ridge": [[21, "hyperparameter-alpha-of-ridge"], [64, "hyperparameter-alpha-of-ridge"]], "Hyperparameter optimization": [[15, "hyperparameter-optimization"], [37, "hyperparameter-optimization"], [84, "hyperparameter-optimization"]], "Hyperparameter optimization motivation": [[65, "hyperparameter-optimization-motivation"]], "Hyperparameter optimization motivation (video)": [[22, "hyperparameter-optimization-motivation-video"]], "Hyperparameter tuning for the number of clusters": [[28, "hyperparameter-tuning-for-the-number-of-clusters"], [71, "hyperparameter-tuning-for-the-number-of-clusters"]], "Hyperparameters of SVM": [[16, "hyperparameters-of-svm"], [61, "hyperparameters-of-svm"]], "Hyperparameters: the problem": [[22, "hyperparameters-the-problem"], [65, "hyperparameters-the-problem"]], "Identify the transformations we want to apply": [[19, "identify-the-transformations-we-want-to-apply"], [63, "identify-the-transformations-we-want-to-apply"]], "Image classification using KNNs and SVM RBF": [[38, "image-classification-using-knns-and-svm-rbf"]], "Importance of scaling": [[21, "importance-of-scaling"], [64, "importance-of-scaling"]], "Important hyperparameters": [[25, "important-hyperparameters"], [44, "important-hyperparameters"], [68, "important-hyperparameters"]], "Important hyperparameters of CountVectorizer": [[19, "important-hyperparameters-of-countvectorizer"], [63, "important-hyperparameters-of-countvectorizer"]], "Important links": [[1, "important-links"]], "Important points to remember": [[28, "important-points-to-remember"], [71, "important-points-to-remember"]], "Imports": [[13, "imports"], [14, "imports"], [15, "imports"], [16, "imports"], [17, "imports"], [18, "imports"], [19, "imports"], [21, "imports"], [22, "imports"], [23, "imports"], [24, "imports"], [25, "imports"], [26, "imports"], [27, "imports"], [28, "imports"], [29, "imports"], [30, "imports"], [31, "imports"], [32, "imports"], [33, "imports"], [34, "imports"], [35, "imports"], [37, "imports"], [38, "imports"], [39, "imports"], [40, "imports"], [41, "imports"], [42, "imports"], [43, "imports"], [44, "imports"], [45, "imports"], [46, "imports"], [49, "imports"], [50, "imports"], [51, "imports"], [52, "imports"], [53, "imports"], [54, "imports"], [55, "imports"], [56, "imports"], [57, "imports"], [58, "imports"], [59, "imports"], [60, "imports"], [61, "imports"], [62, "imports"], [63, "imports"], [64, "imports"], [65, "imports"], [66, "imports"], [67, "imports"], [68, "imports"], [69, "imports"], [70, "imports"], [71, "imports"], [72, "imports"], [73, "imports"], [74, "imports"], [75, "imports"], [76, "imports"], [77, "imports"], [78, "imports"], [79, "imports"], [84, "imports"], [85, "imports"], [86, "imports"], [90, "imports"], [91, "imports"], [92, "imports"], [96, "imports"]], "Imports and LO": [[22, "imports-and-lo"], [24, "imports-and-lo"], [32, "imports-and-lo"], [33, "imports-and-lo"], [65, "imports-and-lo"], [67, "imports-and-lo"], [75, "imports-and-lo"], [76, "imports-and-lo"]], "Imports and LOs": [[66, "imports-and-los"], [79, "imports-and-los"]], "Imports and learning outcomes": [[28, "imports-and-learning-outcomes"], [71, "imports-and-learning-outcomes"]], "Imports, Announcements, LOs": [[59, "imports-announcements-los"]], "Imports, Announcements, and LO": [[19, "imports-announcements-and-lo"], [21, "imports-announcements-and-lo"], [63, "imports-announcements-and-lo"], [64, "imports-announcements-and-lo"]], "Imports, LOs": [[15, "imports-los"], [18, "imports-los"], [26, "imports-los"], [45, "imports-los"], [60, "imports-los"], [62, "imports-los"], [69, "imports-los"]], "Imports, announcements, LOs": [[25, "imports-announcements-los"], [68, "imports-announcements-los"]], "Imports, announcements, and LOs": [[16, "imports-announcements-and-los"], [61, "imports-announcements-and-los"]], "Imputation": [[18, "imputation"], [62, "imputation"]], "Imputation and scaling [video]": [[18, "imputation-and-scaling-video"], [62, "imputation-and-scaling-video"]], "Incorporating ordinal feature class_attendance": [[19, "incorporating-ordinal-feature-class-attendance"], [63, "incorporating-ordinal-feature-class-attendance"]], "Incorporating text features": [[17, "incorporating-text-features"], [39, "incorporating-text-features"]], "Increasing the threshold": [[23, "increasing-the-threshold"], [42, "increasing-the-threshold"], [66, "increasing-the-threshold"]], "Indexing Dataframes": [[9, "indexing-dataframes"]], "Indexing cheatsheet": [[9, "indexing-cheatsheet"]], "Inertia": [[28, "inertia"], [71, "inertia"]], "Initial analysis, EDA, preprocessing": [[79, "initial-analysis-eda-preprocessing"]], "Initialization of K-Means": [[28, "initialization-of-k-means"], [71, "initialization-of-k-means"]], "Inject randomness in the classifier construction": [[25, "inject-randomness-in-the-classifier-construction"], [44, "inject-randomness-in-the-classifier-construction"], [68, "inject-randomness-in-the-classifier-construction"]], "Input data": [[13, "input-data"], [58, "input-data"]], "Input features X and target y": [[58, "input-features-x-and-target-y"]], "Input: features X and target y": [[13, "input-features-x-and-target-y"]], "Install VS Code": [[11, "install-vs-code"]], "Instructional Material": [[0, "instructional-material"]], "Instructors": [[1, "instructors"]], "Interesting to you != useful to the reader (aka it\u2019s not about you)": [[35, "interesting-to-you-useful-to-the-reader-aka-it-s-not-about-you"], [55, "interesting-to-you-useful-to-the-reader-aka-it-s-not-about-you"], [78, "interesting-to-you-useful-to-the-reader-aka-it-s-not-about-you"]], "Interim summary": [[23, "interim-summary"], [26, "interim-summary"], [27, "interim-summary"], [33, "interim-summary"], [42, "interim-summary"], [45, "interim-summary"], [46, "interim-summary"], [66, "interim-summary"], [69, "interim-summary"], [70, "interim-summary"], [76, "interim-summary"]], "Interpretation of coefficients": [[21, "interpretation-of-coefficients"], [64, "interpretation-of-coefficients"]], "Interpretation of coefficients in linear models": [[21, "interpretation-of-coefficients-in-linear-models"], [64, "interpretation-of-coefficients-in-linear-models"]], "Interpreting coefficients of numeric features": [[26, "interpreting-coefficients-of-numeric-features"], [45, "interpreting-coefficients-of-numeric-features"], [69, "interpreting-coefficients-of-numeric-features"]], "Introduction": [[29, "introduction"], [72, "introduction"], [84, "introduction"]], "Introduction to NLP": [[84, "introduction-to-nlp"]], "Introduction to computer vision": [[32, "introduction-to-computer-vision"], [75, "introduction-to-computer-vision"]], "Introduction to large language models": [[31, "introduction-to-large-language-models"], [50, "introduction-to-large-language-models"], [74, "introduction-to-large-language-models"]], "Introduction to neural networks": [[32, "introduction-to-neural-networks"], [75, "introduction-to-neural-networks"]], "Introduction to pandas": [[9, "introduction-to-pandas"]], "Introduction to unsupervised learning": [[28, "introduction-to-unsupervised-learning"], [71, "introduction-to-unsupervised-learning"]], "Intuition of regression trees": [[37, "intuition-of-regression-trees"]], "Is stratifying a good idea?": [[66, "is-stratifying-a-good-idea"]], "Is this a realistic representation of text data?": [[19, "is-this-a-realistic-representation-of-text-data"], [63, "is-this-a-realistic-representation-of-text-data"]], "Is this misleading?": [[35, "is-this-misleading"], [55, "is-this-misleading"], [78, "is-this-misleading"]], "Is \u201cRelevance\u201d clearly defined?": [[27, "is-relevance-clearly-defined"], [27, "id1"], [27, "id2"], [27, "id3"], [27, "id4"], [27, "id5"], [27, "id6"], [81, "is-relevance-clearly-defined"], [81, "id1"], [81, "id2"], [81, "id3"], [81, "id4"], [81, "id5"], [81, "id6"]], "I\u2019m on the waitlist. How likely am I to get into this course?": [[5, "i-m-on-the-waitlist-how-likely-am-i-to-get-into-this-course"]], "K-Means algorithm": [[28, "k-means-algorithm"], [71, "k-means-algorithm"]], "K-Means clustering [video]": [[28, "k-means-clustering-video"], [71, "k-means-clustering-video"]], "K-Means example": [[28, "k-means-example"], [71, "k-means-example"]], "K-Means limitations": [[29, "k-means-limitations"], [72, "k-means-limitations"]], "K-Means limitations: Shape of K-Means clusters": [[29, "k-means-limitations-shape-of-k-means-clusters"], [72, "k-means-limitations-shape-of-k-means-clusters"]], "K-Means recap": [[29, "k-means-recap"], [72, "k-means-recap"]], "K-Means: failure case 1": [[29, "k-means-failure-case-1"], [72, "k-means-failure-case-1"]], "K-Means: failure case 2": [[29, "k-means-failure-case-2"], [72, "k-means-failure-case-2"]], "K-Means: failure case 3": [[29, "k-means-failure-case-3"], [72, "k-means-failure-case-3"]], "Kaplan-Meier survival curve": [[34, "kaplan-meier-survival-curve"], [53, "kaplan-meier-survival-curve"], [77, "kaplan-meier-survival-curve"]], "Key point": [[26, "key-point"], [45, "key-point"], [69, "key-point"]], "LDA topics in social media": [[31, "lda-topics-in-social-media"], [50, "lda-topics-in-social-media"], [51, "lda-topics-in-social-media"], [74, "lda-topics-in-social-media"]], "LICENSE": [[0, null]], "Labeled vs. Unlabeled data": [[28, "labeled-vs-unlabeled-data"], [71, "labeled-vs-unlabeled-data"]], "Lag-based features": [[33, "lag-based-features"], [52, "lag-based-features"], [76, "lag-based-features"], [76, "id5"], [90, "lag-based-features"], [96, "lag-based-features"]], "Land acknowledgement": [[98, "land-acknowledgement"]], "Language model": [[31, "language-model"], [50, "language-model"], [74, "language-model"]], "Language models activity": [[31, "language-models-activity"], [50, "language-models-activity"], [74, "language-models-activity"]], "Large datasets solve many of these problems": [[22, "large-datasets-solve-many-of-these-problems"], [65, "large-datasets-solve-many-of-these-problems"]], "Late submissions": [[8, "late-submissions"]], "Learned coefficients associated with all features": [[21, "learned-coefficients-associated-with-all-features"], [64, "learned-coefficients-associated-with-all-features"]], "Learned model": [[37, "learned-model"]], "Learning git": [[6, "learning-git"]], "Learning objectives": [[31, "learning-objectives"], [32, "learning-objectives"], [33, "learning-objectives"], [34, "learning-objectives"], [35, "learning-objectives"], [74, "learning-objectives"], [75, "learning-objectives"], [76, "learning-objectives"], [77, "learning-objectives"], [78, "learning-objectives"], [79, "learning-objectives"]], "Learning outcomes": [[13, "learning-outcomes"], [14, "learning-outcomes"], [15, "learning-outcomes"], [16, "learning-outcomes"], [18, "learning-outcomes"], [19, "learning-outcomes"], [21, "learning-outcomes"], [22, "learning-outcomes"], [24, "learning-outcomes"], [26, "learning-outcomes"], [27, "learning-outcomes"], [28, "learning-outcomes"], [29, "learning-outcomes"], [58, "learning-outcomes"], [59, "learning-outcomes"], [60, "learning-outcomes"], [61, "learning-outcomes"], [62, "learning-outcomes"], [63, "learning-outcomes"], [64, "learning-outcomes"], [65, "learning-outcomes"], [66, "learning-outcomes"], [67, "learning-outcomes"], [69, "learning-outcomes"], [70, "learning-outcomes"], [71, "learning-outcomes"], [72, "learning-outcomes"]], "Learning outcomes <a name=\"lo\"></a>": [[30, "learning-outcomes"], [73, "learning-outcomes"]], "Least confident cases": [[21, "least-confident-cases"], [64, "least-confident-cases"]], "Lecture 10: Class demo": [[43, null]], "Lecture 10: Regression metrics": [[24, null], [67, null]], "Lecture 11: Ensembles": [[25, null], [44, null], [68, null]], "Lecture 12: Class demo": [[45, null]], "Lecture 12: Feature importances and model transparency": [[26, null], [69, null]], "Lecture 13: Class demo": [[46, null]], "Lecture 13: Feature engineering and feature selection": [[27, null], [70, null]], "Lecture 14: K-Means Clustering": [[28, null], [71, null]], "Lecture 15: Class demo": [[48, null]], "Lecture 15: Clustering class demo": [[47, null]], "Lecture 15: More Clustering": [[72, null]], "Lecture 16: Class demo": [[49, null]], "Lecture 16: More Clustering": [[29, null]], "Lecture 16: Recommender Systems": [[30, null], [73, null]], "Lecture 17: Class demo": [[50, null]], "Lecture 17: Introduction to natural language processing": [[31, null], [74, null]], "Lecture 18: Class demo": [[51, null]], "Lecture 18: Multi-class classification and introduction to computer vision": [[32, null], [75, null]], "Lecture 19: Class demo": [[52, null]], "Lecture 19: Time series": [[33, null], [76, null]], "Lecture 1: Course Introduction": [[13, null], [58, null]], "Lecture 20: Class demo": [[53, null]], "Lecture 20: Survival analysis": [[34, null], [77, null]], "Lecture 21: Class demo (Based on the lecture notes)": [[54, null]], "Lecture 21: Communication": [[35, null], [78, null]], "Lecture 22: Class demo (Based on the lecture notes)": [[55, null]], "Lecture 23: Class demo (Based on the lecture notes)": [[56, null]], "Lecture 23: Deployment and conclusion": [[79, null]], "Lecture 24: Class demo (Based on the lecture notes)": [[57, null]], "Lecture 2: Terminology, Baselines, Decision Trees": [[14, null], [59, null]], "Lecture 3: ML Fundamentals Class Demo": [[37, null]], "Lecture 3: Machine Learning Fundamentals": [[15, null], [60, null]], "Lecture 4: Class demo": [[38, null]], "Lecture 4: k-Nearest Neighbours and SVM RBFs": [[16, null], [61, null]], "Lecture 5 and 6: Class demo": [[17, null], [39, null]], "Lecture 5: Preprocessing and sklearn pipelines": [[18, null], [62, null]], "Lecture 6: sklearn ColumnTransformer and Text Features": [[19, null], [63, null]], "Lecture 7: Class demo": [[20, null]], "Lecture 7: Linear Models": [[21, null], [64, null]], "Lecture 8: Hyperparameter Optimization and Optimization Bias": [[22, null], [65, null]], "Lecture 9: Class demo": [[23, null], [42, null]], "Lecture 9: Classification metrics": [[66, null]], "Lecture and homework format: Jupyter notebooks": [[13, "lecture-and-homework-format-jupyter-notebooks"]], "Lecture learning objectives": [[25, "lecture-learning-objectives"], [68, "lecture-learning-objectives"]], "Lecture plan and learning outcomes": [[29, "lecture-plan-and-learning-outcomes"], [72, "lecture-plan-and-learning-outcomes"]], "Lecture recordings": [[98, "lecture-recordings"]], "Lecture schedule (tentative)": [[1, "lecture-schedule-tentative"]], "Lecture style": [[13, "lecture-style"]], "Lectures 7: Class demo": [[40, null]], "Lectures 8: Class demo": [[41, null]], "Let\u2019s cluster images!!": [[47, "let-s-cluster-images"]], "Let\u2019s do it on our housing data": [[18, "let-s-do-it-on-our-housing-data"], [62, "let-s-do-it-on-our-housing-data"]], "Let\u2019s examine the transformed data": [[19, "let-s-examine-the-transformed-data"], [63, "let-s-examine-the-transformed-data"]], "Let\u2019s explore SVM RBFs": [[16, "let-s-explore-svm-rbfs"], [61, "let-s-explore-svm-rbfs"]], "Let\u2019s first run our baseline model DummyRegressor": [[18, "let-s-first-run-our-baseline-model-dummyregressor"], [62, "let-s-first-run-our-baseline-model-dummyregressor"]], "Let\u2019s identify feature types": [[26, "let-s-identify-feature-types"], [45, "let-s-identify-feature-types"], [69, "let-s-identify-feature-types"]], "Let\u2019s look at all the scores at once": [[23, "let-s-look-at-all-the-scores-at-once"], [42, "let-s-look-at-all-the-scores-at-once"], [66, "let-s-look-at-all-the-scores-at-once"]], "Let\u2019s separate X and y": [[24, "let-s-separate-x-and-y"], [26, "let-s-separate-x-and-y"], [35, "let-s-separate-x-and-y"], [43, "let-s-separate-x-and-y"], [45, "let-s-separate-x-and-y"], [54, "let-s-separate-x-and-y"], [55, "let-s-separate-x-and-y"], [67, "let-s-separate-x-and-y"], [69, "let-s-separate-x-and-y"], [78, "let-s-separate-x-and-y"]], "Let\u2019s start with a recap": [[16, "let-s-start-with-a-recap"]], "Let\u2019s talk about GenAI": [[13, "let-s-talk-about-genai"]], "Let\u2019s try KNN on this data": [[17, "let-s-try-knn-on-this-data"], [39, "let-s-try-knn-on-this-data"]], "Let\u2019s try a linear model: Ridge": [[24, "let-s-try-a-linear-model-ridge"], [43, "let-s-try-a-linear-model-ridge"], [67, "let-s-try-a-linear-model-ridge"]], "Let\u2019s try cross-validation with our pipeline": [[17, "let-s-try-cross-validation-with-our-pipeline"], [18, "let-s-try-cross-validation-with-our-pipeline"], [62, "let-s-try-cross-validation-with-our-pipeline"]], "License": [[1, "license"]], "LightGBM": [[25, "lightgbm"], [44, "lightgbm"], [68, "lightgbm"]], "Limitations of linear models": [[21, "limitations-of-linear-models"], [64, "limitations-of-linear-models"]], "Linear SVM": [[21, "linear-svm"], [64, "linear-svm"]], "Linear models [video]": [[21, "linear-models-video"], [64, "linear-models-video"]], "Linear regression": [[21, "linear-regression"], [64, "linear-regression"]], "Lists of resources": [[10, "lists-of-resources"]], "Loading our saved model": [[56, "loading-our-saved-model"], [57, "loading-our-saved-model"], [79, "loading-our-saved-model"]], "Logistic regression [video]": [[21, "logistic-regression-video"], [64, "logistic-regression-video"]], "Logistic regression intuition": [[21, "logistic-regression-intuition"], [64, "logistic-regression-intuition"]], "Logistic regression on the cities data": [[21, "logistic-regression-on-the-cities-data"], [64, "logistic-regression-on-the-cities-data"]], "LogisticRegression": [[34, "logisticregression"], [52, "logisticregression"], [76, "logisticregression"], [77, "logisticregression"]], "MAPE": [[24, "mape"], [43, "mape"], [67, "mape"]], "ML and decision-making (5 min)": [[55, "ml-and-decision-making-5-min"], [78, "ml-and-decision-making-5-min"]], "ML fairness activity": [[66, "ml-fairness-activity"]], "ML fundamentals": [[84, "ml-fundamentals"]], "Machine learning workflow": [[13, "machine-learning-workflow"], [23, "machine-learning-workflow"], [42, "machine-learning-workflow"], [66, "machine-learning-workflow"]], "Macro average and weighted average": [[80, "macro-average-and-weighted-average"]], "Magnitude of the coefficients": [[21, "magnitude-of-the-coefficients"], [64, "magnitude-of-the-coefficients"]], "Main hyperparameter of logistic regression": [[21, "main-hyperparameter-of-logistic-regression"], [64, "main-hyperparameter-of-logistic-regression"]], "Main hyperparameters": [[21, "main-hyperparameters"], [64, "main-hyperparameters"]], "Main issues in ML-related communication": [[35, "main-issues-in-ml-related-communication"], [55, "main-issues-in-ml-related-communication"], [78, "main-issues-in-ml-related-communication"]], "Manual hyperparameter optimization": [[22, "manual-hyperparameter-optimization"], [65, "manual-hyperparameter-optimization"]], "Mean intra-cluster distance (a)": [[28, "mean-intra-cluster-distance-a"], [71, "mean-intra-cluster-distance-a"]], "Mean nearest-cluster distance (b)": [[28, "mean-nearest-cluster-distance-b"], [71, "mean-nearest-cluster-distance-b"]], "Mean squared error (MSE)": [[24, "mean-squared-error-mse"], [43, "mean-squared-error-mse"], [67, "mean-squared-error-mse"]], "Measuring similarity between vectors": [[31, "measuring-similarity-between-vectors"], [74, "measuring-similarity-between-vectors"]], "Meet Eva (a fictitious persona)!": [[13, "meet-eva-a-fictitious-persona"], [58, "meet-eva-a-fictitious-persona"]], "Method 1: The Elbow method": [[28, "method-1-the-elbow-method"], [71, "method-1-the-elbow-method"]], "Method 2: The Silhouette method": [[28, "method-2-the-silhouette-method"], [71, "method-2-the-silhouette-method"]], "Midterm": [[98, "midterm"]], "Misc": [[1, "misc"], [10, "misc"]], "Miscellaneous comments on content-based filtering": [[30, "miscellaneous-comments-on-content-based-filtering"], [49, "miscellaneous-comments-on-content-based-filtering"], [73, "miscellaneous-comments-on-content-based-filtering"]], "Model building": [[24, "model-building"], [43, "model-building"], [67, "model-building"], [79, "model-building"]], "Model building on the dataset": [[20, "model-building-on-the-dataset"], [40, "model-building-on-the-dataset"]], "Model complexity and training error": [[15, "model-complexity-and-training-error"], [60, "model-complexity-and-training-error"]], "Model deployment": [[56, "model-deployment"], [57, "model-deployment"], [79, "model-deployment"], [79, "id1"]], "Model interpretability beyond linear models": [[45, "model-interpretability-beyond-linear-models"], [69, "model-interpretability-beyond-linear-models"]], "Model interpretability beyond linear models (video)": [[26, "model-interpretability-beyond-linear-models-video"]], "Model predictions on unseen data": [[13, "model-predictions-on-unseen-data"], [58, "model-predictions-on-unseen-data"]], "Model transparency and interpretation": [[79, "model-transparency-and-interpretation"]], "Model-based selection": [[27, "model-based-selection"], [46, "model-based-selection"], [70, "model-based-selection"]], "Modeling": [[17, "modeling"], [39, "modeling"]], "More comments on tackling class imbalance": [[24, "more-comments-on-tackling-class-imbalance"], [67, "more-comments-on-tackling-class-imbalance"]], "More details": [[15, "more-details"]], "More details on DBSCAN": [[29, "more-details-on-dbscan"], [72, "more-details-on-dbscan"]], "More on feature transformations": [[19, "more-on-feature-transformations"], [63, "more-on-feature-transformations"]], "More on k-NNs [video]": [[16, "more-on-k-nns-video"], [61, "more-on-k-nns-video"]], "More terminology [video]": [[14, "more-terminology-video"], [59, "more-terminology-video"]], "More than one ordinal columns?": [[19, "more-than-one-ordinal-columns"], [63, "more-than-one-ordinal-columns"]], "Most confident cases": [[21, "most-confident-cases"], [64, "most-confident-cases"]], "Most negative review": [[20, "most-negative-review"], [40, "most-negative-review"]], "Most positive review": [[20, "most-positive-review"], [40, "most-positive-review"]], "Motivating example": [[21, "motivating-example"], [64, "motivating-example"]], "Motivation": [[22, "motivation"], [31, "motivation"], [33, "motivation"], [35, "motivation"], [50, "motivation"], [55, "motivation"], [65, "motivation"], [74, "motivation"], [76, "motivation"], [78, "motivation"]], "Motivation [video]": [[25, "motivation-video"], [68, "motivation-video"]], "Motivation and big picture [video]": [[18, "motivation-and-big-picture-video"], [62, "motivation-and-big-picture-video"]], "Motivation and context": [[51, "motivation-and-context"]], "Motivation and distances [video]": [[16, "motivation-and-distances-video"], [61, "motivation-and-distances-video"]], "Movie features": [[30, "movie-features"], [49, "movie-features"], [73, "movie-features"]], "Multi-class classification": [[32, "multi-class-classification"], [75, "multi-class-classification"]], "Multiclass classification and computer vision": [[84, "multiclass-classification-and-computer-vision"]], "Multiple transformations in a transformer": [[19, "multiple-transformations-in-a-transformer"], [63, "multiple-transformations-in-a-transformer"]], "NLP pipelines before and after LLMs": [[31, "nlp-pipelines-before-and-after-llms"], [50, "nlp-pipelines-before-and-after-llms"], [74, "nlp-pipelines-before-and-after-llms"]], "NOTE:": [[9, "note"]], "Neural networks example and terminology": [[32, "neural-networks-example-and-terminology"], [75, "neural-networks-example-and-terminology"]], "New ideas in small chunks": [[35, "new-ideas-in-small-chunks"], [55, "new-ideas-in-small-chunks"], [78, "new-ideas-in-small-chunks"]], "No-loop method: make them the same size, and multiply element-wise": [[9, "no-loop-method-make-them-the-same-size-and-multiply-element-wise"]], "Note": [[33, null], [60, null], [60, null], [76, null]], "Number of trees and fundamental trade-off": [[25, "number-of-trees-and-fundamental-trade-off"], [44, "number-of-trees-and-fundamental-trade-off"], [68, "number-of-trees-and-fundamental-trade-off"]], "Numpy array shapes": [[9, "numpy-array-shapes"]], "Numpy arrays": [[9, "numpy-arrays"]], "OHE with many categories": [[63, "ohe-with-many-categories"]], "Object detection": [[32, "object-detection"], [75, "object-detection"]], "Observations": [[23, "observations"], [42, "observations"], [66, "observations"]], "One Vs. One approach": [[83, "one-vs-one-approach"]], "One Vs. One prediction": [[83, "one-vs-one-prediction"]], "One vs. Rest": [[83, "one-vs-rest"]], "One-hot encoding (OHE)": [[18, "one-hot-encoding-ohe"], [62, "one-hot-encoding-ohe"]], "One-hot encoding of the month": [[52, "one-hot-encoding-of-the-month"], [76, "one-hot-encoding-of-the-month"]], "One-hot encoding seasons": [[52, "one-hot-encoding-seasons"], [76, "one-hot-encoding-seasons"]], "OneHotEncoder and sparse features": [[19, "onehotencoder-and-sparse-features"], [63, "onehotencoder-and-sparse-features"]], "Online courses": [[1, "online-courses"], [10, "online-courses"]], "Open the repo in VS Code": [[11, "open-the-repo-in-vs-code"]], "Operating point": [[23, "operating-point"], [42, "operating-point"], [66, "operating-point"]], "Optimization bias of hyper-parameter learning": [[22, "optimization-bias-of-hyper-parameter-learning"], [65, "optimization-bias-of-hyper-parameter-learning"]], "Optimization bias of parameter learning": [[22, "optimization-bias-of-parameter-learning"], [65, "optimization-bias-of-parameter-learning"]], "Optimization bias on the Spotify dataset": [[22, "optimization-bias-on-the-spotify-dataset"], [65, "optimization-bias-on-the-spotify-dataset"]], "Optimization bias/Overfitting of the validation set": [[65, "optimization-bias-overfitting-of-the-validation-set"]], "Optimization bias/Overfitting of the validation set (video)": [[22, "optimization-bias-overfitting-of-the-validation-set-video"]], "Option 1: GitHub Desktop (easiest)": [[6, "option-1-github-desktop-easiest"]], "Option 2: Command-line Git (recommended)": [[6, "option-2-command-line-git-recommended"]], "Option A (recommended): Miniforge": [[11, "option-a-recommended-miniforge"]], "Option B: Miniconda": [[11, "option-b-miniconda"]], "Optional readings and resources": [[22, "optional-readings-and-resources"], [65, "optional-readings-and-resources"]], "Ordinal encoding (occasionally recommended)": [[18, "ordinal-encoding-occasionally-recommended"], [62, "ordinal-encoding-occasionally-recommended"]], "Ordinal features": [[17, "ordinal-features"], [26, "ordinal-features"], [39, "ordinal-features"], [45, "ordinal-features"], [69, "ordinal-features"]], "Other applications": [[28, "other-applications"], [71, "other-applications"]], "Other approaches / what did we not cover?": [[34, "other-approaches-what-did-we-not-cover"], [53, "other-approaches-what-did-we-not-cover"], [77, "other-approaches-what-did-we-not-cover"]], "Other commonly used preprocessing steps": [[51, "other-commonly-used-preprocessing-steps"], [82, "other-commonly-used-preprocessing-steps"]], "Other possible preprocessing?": [[24, "other-possible-preprocessing"], [43, "other-possible-preprocessing"], [67, "other-possible-preprocessing"]], "Other software package": [[33, "other-software-package"], [52, "other-software-package"], [76, "other-software-package"]], "Other tools for preprocessing": [[51, "other-tools-for-preprocessing"], [82, "other-tools-for-preprocessing"]], "Other typical NLP tasks": [[51, "other-typical-nlp-tasks"], [82, "other-typical-nlp-tasks"]], "Other useful arguments of KNeighborsClassifier": [[16, "other-useful-arguments-of-kneighborsclassifier"], [61, "other-useful-arguments-of-kneighborsclassifier"]], "Other ways to search": [[27, "other-ways-to-search"], [46, "other-ways-to-search"], [81, "other-ways-to-search"]], "Our typical supervised learning set up is as follows:": [[60, "our-typical-supervised-learning-set-up-is-as-follows"]], "Outline": [[85, "outline"], [86, "outline"], [87, "outline"], [88, "outline"], [89, "outline"], [90, "outline"], [91, "outline"], [92, "outline"], [93, "outline"], [94, "outline"], [95, "outline"], [96, "outline"]], "Over confident cases": [[21, "over-confident-cases"], [64, "over-confident-cases"]], "Overfitting": [[15, "overfitting"], [60, "overfitting"]], "Overfitting of the validation data": [[22, "overfitting-of-the-validation-data"], [65, "overfitting-of-the-validation-data"]], "Overfitting of the validation error": [[22, "overfitting-of-the-validation-error"], [65, "overfitting-of-the-validation-error"]], "Oversampling": [[80, "oversampling"]], "Overview": [[16, "overview"], [61, "overview"]], "POSIX time feature": [[33, "posix-time-feature"], [76, "posix-time-feature"]], "PR curves for logistic regression and SVC": [[23, "pr-curves-for-logistic-regression-and-svc"], [42, "pr-curves-for-logistic-regression-and-svc"], [66, "pr-curves-for-logistic-regression-and-svc"]], "Pandas DataFrames": [[9, "pandas-dataframes"]], "Pandas Series": [[9, "pandas-series"]], "Parameters": [[14, "parameters"], [59, "parameters"]], "Parameters and hyperparameters: Summary": [[14, "parameters-and-hyperparameters-summary"], [59, "parameters-and-hyperparameters-summary"]], "Parsing datetimes": [[52, "parsing-datetimes"], [76, "parsing-datetimes"], [90, "parsing-datetimes"], [96, "parsing-datetimes"]], "Part 1": [[84, "part-1"]], "Part 2": [[84, "part-2"]], "Passing probability distributions to random search": [[22, "passing-probability-distributions-to-random-search"], [41, "passing-probability-distributions-to-random-search"], [65, "passing-probability-distributions-to-random-search"]], "Pause!": [[17, "pause"]], "Permutation importances": [[45, "permutation-importances"]], "Piazza-specific Q&A guidelines": [[4, "piazza-specific-q-a-guidelines"]], "Pipelines": [[18, "pipelines"], [62, "pipelines"]], "Playground": [[61, "playground"]], "Playground (in tutorial)": [[16, "playground-in-tutorial"]], "Plotting with matplotlib": [[9, "plotting-with-matplotlib"]], "Practice exercises": [[14, "practice-exercises"], [59, "practice-exercises"]], "Precision": [[23, "precision"], [42, "precision"]], "Precision and recall: toy example": [[23, "precision-and-recall-toy-example"], [42, "precision-and-recall-toy-example"], [66, "precision-and-recall-toy-example"]], "Precision, recall, f1 score": [[23, "precision-recall-f1-score"], [42, "precision-recall-f1-score"], [66, "precision-recall-f1-score"]], "Precision-recall curve": [[23, "precision-recall-curve"], [23, "id1"], [42, "precision-recall-curve"], [42, "id1"], [66, "precision-recall-curve"], [66, "id1"]], "Precision/Recall tradeoff": [[23, "precision-recall-tradeoff"], [42, "precision-recall-tradeoff"], [66, "precision-recall-tradeoff"]], "Predicting on unseen data using the trained model": [[13, "predicting-on-unseen-data-using-the-trained-model"], [58, "predicting-on-unseen-data-using-the-trained-model"]], "Predicting probability scores [video]": [[21, "predicting-probability-scores-video"], [64, "predicting-probability-scores-video"]], "Predicting with learned weights": [[21, "predicting-with-learned-weights"], [64, "predicting-with-learned-weights"]], "Prediction": [[34, "prediction"], [53, "prediction"], [77, "prediction"]], "Prediction of linear regression": [[21, "prediction-of-linear-regression"], [64, "prediction-of-linear-regression"]], "Prediction with learned parameters": [[21, "prediction-with-learned-parameters"], [64, "prediction-with-learned-parameters"]], "Predictions": [[32, "predictions"], [75, "predictions"]], "Preferences in LogisticRegression": [[35, "preferences-in-logisticregression"], [55, "preferences-in-logisticregression"], [78, "preferences-in-logisticregression"]], "Preparation": [[8, "preparation"]], "Preprocessing": [[19, "preprocessing"], [52, "preprocessing"], [63, "preprocessing"], [76, "preprocessing"], [84, "preprocessing"], [89, "preprocessing"], [90, "preprocessing"], [95, "preprocessing"], [96, "preprocessing"]], "Preprocessing the targets?": [[19, "preprocessing-the-targets"], [63, "preprocessing-the-targets"]], "Prevalence of ML": [[13, "prevalence-of-ml"], [58, "prevalence-of-ml"]], "Principles of effective communication": [[35, "principles-of-effective-communication"], [55, "principles-of-effective-communication"], [78, "principles-of-effective-communication"]], "Principles of good explanations (~15 min)": [[35, "principles-of-good-explanations-15-min"], [55, "principles-of-good-explanations-15-min"], [78, "principles-of-good-explanations-15-min"]], "Problem formulation": [[30, "problem-formulation"], [73, "problem-formulation"]], "Problem: Different transformations on different columns": [[18, "problem-different-transformations-on-different-columns"], [62, "problem-different-transformations-on-different-columns"]], "Problems with exhaustive grid search": [[22, "problems-with-exhaustive-grid-search"], [41, "problems-with-exhaustive-grid-search"], [65, "problems-with-exhaustive-grid-search"]], "Problems with single train/validation split": [[15, "problems-with-single-train-validation-split"], [60, "problems-with-single-train-validation-split"]], "Pros of k-NNs for supervised learning": [[16, "pros-of-k-nns-for-supervised-learning"], [61, "pros-of-k-nns-for-supervised-learning"]], "Pros, cons, parameters and hyperparameters of different ML models": [[84, "pros-cons-parameters-and-hyperparameters-of-different-ml-models"]], "Python requirements/resources": [[13, "python-requirements-resources"]], "Python resources": [[10, "python-resources"]], "Question": [[16, "question"], [61, "question"]], "Question for you": [[29, "question-for-you"], [72, "question-for-you"]], "Question for you to ponder on": [[20, "question-for-you-to-ponder-on"], [40, "question-for-you-to-ponder-on"]], "Questions for class discussion": [[30, "questions-for-class-discussion"], [73, "questions-for-class-discussion"]], "Questions for class discussion (hyperparameter optimization)": [[22, "questions-for-class-discussion-hyperparameter-optimization"], [65, "questions-for-class-discussion-hyperparameter-optimization"]], "Quick recap": [[61, "quick-recap"]], "Quick start (TL;DR)": [[11, "quick-start-tl-dr"]], "RF better than GB": [[35, "rf-better-than-gb"], [54, "rf-better-than-gb"], [55, "rf-better-than-gb"], [78, "rf-better-than-gb"]], "RFE algorithm": [[27, "rfe-algorithm"], [46, "rfe-algorithm"], [70, "rfe-algorithm"]], "R^2 (not in detail)": [[24, "r-2-not-in-detail"], [43, "r-2-not-in-detail"], [67, "r-2-not-in-detail"]], "Random forest feature importances": [[26, "random-forest-feature-importances"], [45, "random-forest-feature-importances"], [69, "random-forest-feature-importances"]], "Random forests": [[25, "random-forests"], [44, "random-forests"], [68, "random-forests"]], "Random forests: number of trees (n_estimators) and the fundamental tradeoff": [[25, "random-forests-number-of-trees-n-estimators-and-the-fundamental-tradeoff"], [44, "random-forests-number-of-trees-n-estimators-and-the-fundamental-tradeoff"], [68, "random-forests-number-of-trees-n-estimators-and-the-fundamental-tradeoff"]], "RandomForestClassifier": [[25, "randomforestclassifier"], [34, "randomforestclassifier"], [44, "randomforestclassifier"], [68, "randomforestclassifier"], [77, "randomforestclassifier"]], "Randomized hyperparameter search": [[22, "randomized-hyperparameter-search"], [41, "randomized-hyperparameter-search"], [65, "randomized-hyperparameter-search"]], "Range of C": [[22, "range-of-c"], [41, "range-of-c"], [65, "range-of-c"]], "Raw scores": [[21, "raw-scores"], [64, "raw-scores"]], "Reading from .csv": [[9, "reading-from-csv"]], "Reading from other formats": [[9, "reading-from-other-formats"]], "Reading from url": [[9, "reading-from-url"]], "Reading the data": [[14, "reading-the-data"], [59, "reading-the-data"]], "Real boundary between Canada and USA": [[59, "real-boundary-between-canada-and-usa"], [85, "real-boundary-between-canada-and-usa"], [91, "real-boundary-between-canada-and-usa"]], "Reasonable grading concerns": [[7, "reasonable-grading-concerns"]], "Recall": [[23, "recall"], [42, "recall"]], "Recap": [[34, "recap"], [55, "recap"], [77, "recap"], [78, "recap"]], "Recap and motivation [video]": [[29, "recap-and-motivation-video"], [72, "recap-and-motivation-video"]], "Recap: Supervised machine learning": [[14, "recap-supervised-machine-learning"], [59, "recap-supervised-machine-learning"]], "Receiver Operating Characteristic (ROC) curve": [[23, "receiver-operating-characteristic-roc-curve"], [42, "receiver-operating-characteristic-roc-curve"], [66, "receiver-operating-characteristic-roc-curve"]], "Recipe to approach a supervised learning problem with tabular data": [[79, "recipe-to-approach-a-supervised-learning-problem-with-tabular-data"]], "Recommended browser": [[13, "recommended-browser"]], "Recommender systems": [[84, "recommender-systems"]], "Recommender systems intro and motivation": [[30, "recommender-systems-intro-and-motivation"], [73, "recommender-systems-intro-and-motivation"]], "Recommender systems problem": [[30, "recommender-systems-problem"], [73, "recommender-systems-problem"]], "Recursive feature elimination (RFE)": [[27, "recursive-feature-elimination-rfe"], [46, "recursive-feature-elimination-rfe"], [70, "recursive-feature-elimination-rfe"]], "Reference Material": [[1, "reference-material"]], "Reference material": [[10, null]], "References": [[34, "references"], [53, "references"], [77, "references"]], "Registration": [[98, "registration"]], "Registration, waitlist and prerequisites": [[13, "registration-waitlist-and-prerequisites"]], "Regression scoring functions": [[24, "regression-scoring-functions"], [43, "regression-scoring-functions"], [67, "regression-scoring-functions"]], "Regression with k-nearest neighbours (k-NNs)": [[16, "regression-with-k-nearest-neighbours-k-nns"], [61, "regression-with-k-nearest-neighbours-k-nns"]], "Relation of C and the fundamental trade-off": [[16, "relation-of-c-and-the-fundamental-trade-off"], [61, "relation-of-c-and-the-fundamental-trade-off"]], "Relation of gamma and the fundamental trade-off": [[16, "relation-of-gamma-and-the-fundamental-trade-off"], [61, "relation-of-gamma-and-the-fundamental-trade-off"]], "Relevant companion materials": [[10, "relevant-companion-materials"]], "Relevant papers": [[25, "relevant-papers"], [44, "relevant-papers"], [68, "relevant-papers"]], "Relevant papers and resources": [[66, "relevant-papers-and-resources"]], "Relevant resources": [[27, "relevant-resources"], [70, "relevant-resources"]], "Reminder": [[30, "reminder"], [49, "reminder"], [73, "reminder"]], "Renaming columns with df.rename()": [[9, "renaming-columns-with-df-rename"]], "Render set-up (I already did these):": [[56, "render-set-up-i-already-did-these"], [57, "render-set-up-i-already-did-these"], [79, "render-set-up-i-already-did-these"]], "Report format": [[8, "report-format"]], "Requirements (I already did these)": [[79, "requirements-i-already-did-these"]], "Resources": [[28, "resources"], [29, "resources"], [30, "resources"], [49, "resources"], [71, "resources"], [72, "resources"], [73, "resources"]], "Reuse your running examples": [[35, "reuse-your-running-examples"], [55, "reuse-your-running-examples"], [78, "reuse-your-running-examples"]], "Ridge": [[21, "ridge"], [64, "ridge"]], "Ridge on the California housing dataset": [[21, "ridge-on-the-california-housing-dataset"], [64, "ridge-on-the-california-housing-dataset"]], "RidgeCV": [[24, "ridgecv"], [43, "ridgecv"], [67, "ridgecv"]], "Root mean squared error or RMSE": [[24, "root-mean-squared-error-or-rmse"], [43, "root-mean-squared-error-or-rmse"], [67, "root-mean-squared-error-or-rmse"]], "Running notebooks": [[11, "running-notebooks"]], "SHAP  (SHapley Additive exPlanations) introduction": [[26, "shap-shapley-additive-explanations-introduction"], [45, "shap-shapley-additive-explanations-introduction"], [69, "shap-shapley-additive-explanations-introduction"]], "SHAP plots": [[26, "shap-plots"], [45, "shap-plots"], [69, "shap-plots"]], "SMOTE idea": [[80, "smote-idea"]], "SMOTE: Synthetic Minority Over-sampling Technique": [[80, "smote-synthetic-minority-over-sampling-technique"]], "SVM Regressor": [[16, "svm-regressor"], [61, "svm-regressor"]], "Saving the model": [[56, "saving-the-model"], [57, "saving-the-model"], [79, "saving-the-model"]], "Saving time and scaling products": [[13, "saving-time-and-scaling-products"], [58, "saving-time-and-scaling-products"]], "Scaling": [[18, "scaling"], [62, "scaling"]], "Scaling using scikit-learn\u2019s StandardScaler": [[18, "scaling-using-scikit-learn-s-standardscaler"], [62, "scaling-using-scikit-learn-s-standardscaler"]], "Search over multiple hyperparameters": [[16, "search-over-multiple-hyperparameters"], [61, "search-over-multiple-hyperparameters"]], "Seasonality and trends": [[33, "seasonality-and-trends"], [76, "seasonality-and-trends"]], "Section 102": [[36, null]], "Select all of the following statements which are True (iClicker)": [[13, "select-all-of-the-following-statements-which-are-true-iclicker"], [49, "select-all-of-the-following-statements-which-are-true-iclicker"], [71, "select-all-of-the-following-statements-which-are-true-iclicker"], [71, "id1"], [71, "id3"], [72, "select-all-of-the-following-statements-which-are-true-iclicker"], [72, "id2"], [73, "select-all-of-the-following-statements-which-are-true-iclicker"], [73, "id3"]], "Select the correct environment": [[11, "select-the-correct-environment"]], "Sending a request to the API": [[56, "sending-a-request-to-the-api"], [57, "sending-a-request-to-the-api"], [79, "sending-a-request-to-the-api"]], "Setting up your coding environment": [[11, null]], "Setting up your computer for the course": [[13, "setting-up-your-computer-for-the-course"]], "Short posts/articles": [[10, "short-posts-articles"]], "Sigmoid vs. Softmax": [[32, "sigmoid-vs-softmax"], [75, "sigmoid-vs-softmax"]], "Sign of the coefficients": [[21, "sign-of-the-coefficients"], [64, "sign-of-the-coefficients"]], "Silhouette distance for a sample": [[28, "silhouette-distance-for-a-sample"], [71, "silhouette-distance-for-a-sample"]], "Similarity between examples": [[16, "similarity-between-examples"], [61, "similarity-between-examples"]], "Simple train/test split": [[15, "simple-train-test-split"], [60, "simple-train-test-split"]], "SimpleFeature correlations": [[26, "simplefeature-correlations"], [69, "simplefeature-correlations"]], "Single validation set": [[37, "single-validation-set"]], "Slowest method: nested loop": [[9, "slowest-method-nested-loop"]], "Software": [[0, "software"]], "Solution": [[25, "solution"]], "Some important hyperparameters:": [[25, "some-important-hyperparameters"], [44, "some-important-hyperparameters"], [68, "some-important-hyperparameters"]], "Some key takeaways": [[79, "some-key-takeaways"]], "Some quotes on feature engineering": [[27, "some-quotes-on-feature-engineering"], [70, "some-quotes-on-feature-engineering"]], "Some terminology related to trees": [[14, "some-terminology-related-to-trees"], [59, "some-terminology-related-to-trees"]], "Some ways to pick hyperparameters:": [[22, "some-ways-to-pick-hyperparameters"], [65, "some-ways-to-pick-hyperparameters"]], "Sorting a dataframe with df.sort_values()": [[9, "sorting-a-dataframe-with-df-sort-values"]], "Spam/non spam toy example": [[19, "spam-non-spam-toy-example"], [63, "spam-non-spam-toy-example"]], "Specific questions": [[4, "specific-questions"]], "Stacking": [[25, "stacking"], [44, "stacking"], [68, "stacking"], [88, "stacking"], [94, "stacking"]], "Step 0: EDA": [[87, "step-0-eda"]], "Step 1": [[87, "step-1"], [93, "step-1"]], "Step 1: Install Git": [[6, "step-1-install-git"], [11, "step-1-install-git"]], "Step 2": [[87, "step-2"], [93, "step-2"]], "Step 2: Install Python and Conda": [[11, "step-2-install-python-and-conda"]], "Step 2: Testing your Git installation": [[6, "step-2-testing-your-git-installation"]], "Step 3": [[87, "step-3"], [93, "step-3"]], "Step 3: Authenticating with GitHub (important!)": [[6, "step-3-authenticating-with-github-important"]], "Step 3: Verify installation": [[11, "step-3-verify-installation"]], "Step 4": [[87, "step-4"], [93, "step-4"]], "Step 4: Configure conda-forge (Miniconda only)": [[11, "step-4-configure-conda-forge-miniconda-only"]], "Step 5": [[87, "step-5"], [93, "step-5"]], "Step 5: Create the course environment": [[11, "step-5-create-the-course-environment"]], "Step 6: Using VS Code (alternative to JupyterLab)": [[11, "step-6-using-vs-code-alternative-to-jupyterlab"]], "Step 7: Troubleshooting": [[11, "step-7-troubleshooting"]], "Steps to train a classifier using sklearn": [[14, "steps-to-train-a-classifier-using-sklearn"], [59, "steps-to-train-a-classifier-using-sklearn"]], "Stratified Splits": [[66, "stratified-splits"]], "Strengths and weaknesses": [[25, "strengths-and-weaknesses"], [44, "strengths-and-weaknesses"], [68, "strengths-and-weaknesses"]], "Strengths of linear models": [[21, "strengths-of-linear-models"], [64, "strengths-of-linear-models"]], "Study tips": [[84, "study-tips"]], "Submitting on Gradescope": [[8, "submitting-on-gradescope"]], "Summary": [[13, "summary"], [16, "summary"], [25, "summary"], [31, "summary"], [32, "summary"], [34, "summary"], [44, "summary"], [50, "summary"], [51, "summary"], [53, "summary"], [58, "summary"], [61, "summary"], [68, "summary"], [74, "summary"], [75, "summary"], [77, "summary"]], "Summary and reflection": [[15, "summary-and-reflection"], [60, "summary-and-reflection"]], "Summary of linear models": [[21, "summary-of-linear-models"], [64, "summary-of-linear-models"]], "Summary of train, validation, test, and deployment data": [[15, "summary-of-train-validation-test-and-deployment-data"], [60, "summary-of-train-validation-test-and-deployment-data"]], "Summary: Pros and cons": [[29, "summary-pros-and-cons"], [72, "summary-pros-and-cons"]], "Supervised approach to rating prediction": [[30, "supervised-approach-to-rating-prediction"], [49, "supervised-approach-to-rating-prediction"], [73, "supervised-approach-to-rating-prediction"]], "Supervised learning": [[28, "supervised-learning"], [71, "supervised-learning"]], "Supervised learning (Reminder)": [[59, "supervised-learning-reminder"]], "Supervised learning vs. Unsupervised learning": [[14, "supervised-learning-vs-unsupervised-learning"], [59, "supervised-learning-vs-unsupervised-learning"]], "Supervised machine learning": [[13, "supervised-machine-learning"], [58, "supervised-machine-learning"]], "Supervised machine learning workflow": [[58, "supervised-machine-learning-workflow"]], "Support Vector Machines (SVMs) with RBF kernel [video]": [[16, "support-vector-machines-svms-with-rbf-kernel-video"], [61, "support-vector-machines-svms-with-rbf-kernel-video"]], "Support vectors": [[16, "support-vectors"], [61, "support-vectors"]], "Survival analysis": [[84, "survival-analysis"]], "Survival plots": [[34, "survival-plots"], [53, "survival-plots"], [77, "survival-plots"]], "Syllabus": [[1, "syllabus"], [1, "id1"], [98, null]], "TAs": [[1, "tas"], [98, "tas"]], "Tabular data": [[14, "tabular-data"], [59, "tabular-data"]], "Take-home message": [[29, "take-home-message"], [72, "take-home-message"]], "Teaching Team": [[98, "teaching-team"]], "Terminology [video]": [[14, "terminology-video"], [59, "terminology-video"]], "Text representations and word embeddings": [[31, "text-representations-and-word-embeddings"], [50, "text-representations-and-word-embeddings"], [74, "text-representations-and-word-embeddings"]], "The Netflix prize": [[25, "the-netflix-prize"], [68, "the-netflix-prize"]], "The __ syntax": [[22, "the-syntax"], [41, "the-syntax"], [65, "the-syntax"]], "The best features may be dependent on the model you use.": [[70, "the-best-features-may-be-dependent-on-the-model-you-use"]], "The dataset": [[88, "the-dataset"], [89, "the-dataset"], [94, "the-dataset"], [95, "the-dataset"]], "The golden rule <a name=\"4\"></a>": [[15, "the-golden-rule"], [60, "the-golden-rule"]], "The random forests classifier": [[25, "the-random-forests-classifier"], [44, "the-random-forests-classifier"], [68, "the-random-forests-classifier"]], "The sigmoid function": [[21, "the-sigmoid-function"], [64, "the-sigmoid-function"]], "The teaching team": [[1, "the-teaching-team"]], "The \u201cfundamental tradeoff\u201d of supervised learning:": [[15, "the-fundamental-tradeoff-of-supervised-learning"], [60, "the-fundamental-tradeoff-of-supervised-learning"]], "The \u201cperfect\u201d spaghetti sauce": [[28, "the-perfect-spaghetti-sauce"], [71, "the-perfect-spaghetti-sauce"]], "Things to watch out for": [[35, "things-to-watch-out-for"], [54, "things-to-watch-out-for"], [55, "things-to-watch-out-for"], [78, "things-to-watch-out-for"]], "Thresholding": [[23, "thresholding"], [42, "thresholding"]], "Time series": [[84, "time-series"]], "Time series analysis on a more complicated dataset": [[90, "time-series-analysis-on-a-more-complicated-dataset"], [96, "time-series-analysis-on-a-more-complicated-dataset"]], "Time to event and censoring": [[34, "time-to-event-and-censoring"], [77, "time-to-event-and-censoring"]], "Tokenization": [[51, "tokenization"], [82, "tokenization"]], "Topic modeling": [[31, "topic-modeling"], [50, "topic-modeling"], [51, "topic-modeling"], [74, "topic-modeling"]], "Topic modeling motivation": [[31, "topic-modeling-motivation"], [50, "topic-modeling-motivation"], [51, "topic-modeling-motivation"], [74, "topic-modeling-motivation"]], "Topic modeling pipeline": [[31, "topic-modeling-pipeline"], [50, "topic-modeling-pipeline"], [51, "topic-modeling-pipeline"], [74, "topic-modeling-pipeline"]], "Topic modeling toy example": [[31, "topic-modeling-toy-example"], [50, "topic-modeling-toy-example"], [51, "topic-modeling-toy-example"], [74, "topic-modeling-toy-example"]], "Toy datasets": [[59, "toy-datasets"]], "Traditional time series approaches": [[33, "traditional-time-series-approaches"], [52, "traditional-time-series-approaches"], [76, "traditional-time-series-approaches"]], "Train/test split for temporal data": [[33, "train-test-split-for-temporal-data"], [76, "train-test-split-for-temporal-data"]], "Train/test splits": [[52, "train-test-splits"], [76, "train-test-splits"]], "Train/validation/test split": [[15, "train-validation-test-split"], [60, "train-validation-test-split"]], "Training a supervised machine learning model with X and y": [[13, "training-a-supervised-machine-learning-model-with-x-and-y"], [58, "training-a-supervised-machine-learning-model-with-x-and-y"]], "Training data for the motivating example": [[21, "training-data-for-the-motivating-example"], [64, "training-data-for-the-motivating-example"]], "Training error vs. Generalization error": [[15, "training-error-vs-generalization-error"], [60, "training-error-vs-generalization-error"]], "Training models with transformed data": [[19, "training-models-with-transformed-data"], [63, "training-models-with-transformed-data"]], "Training on the full corpus": [[56, "training-on-the-full-corpus"], [57, "training-on-the-full-corpus"], [79, "training-on-the-full-corpus"]], "Training random forests and gradient boosted trees": [[35, "training-random-forests-and-gradient-boosted-trees"], [54, "training-random-forests-and-gradient-boosted-trees"], [55, "training-random-forests-and-gradient-boosted-trees"], [78, "training-random-forests-and-gradient-boosted-trees"]], "Transfer learning": [[32, "transfer-learning"], [75, "transfer-learning"]], "Transformations on the toy data": [[19, "transformations-on-the-toy-data"], [63, "transformations-on-the-toy-data"]], "Transforming the targets": [[24, "transforming-the-targets"], [43, "transforming-the-targets"], [67, "transforming-the-targets"]], "Transparency and explainability of ML models: Motivation": [[45, "transparency-and-explainability-of-ml-models-motivation"], [69, "transparency-and-explainability-of-ml-models-motivation"]], "Transparency and explainability of ML models: Motivation (video)": [[26, "transparency-and-explainability-of-ml-models-motivation-video"]], "Tree-based ensemble models": [[68, "tree-based-ensemble-models"]], "Tree-based models": [[25, "tree-based-models"], [68, "tree-based-models"]], "Try out this moment predictor": [[79, "try-out-this-moment-predictor"]], "Tuning alpha hyperparameter of Ridge": [[24, "tuning-alpha-hyperparameter-of-ridge"], [43, "tuning-alpha-hyperparameter-of-ridge"], [67, "tuning-alpha-hyperparameter-of-ridge"]], "Tutorial 1": [[85, null], [91, null]], "Tutorial 2": [[86, null], [92, null]], "Tutorial 3": [[87, null], [93, null]], "Tutorial 6": [[88, null], [89, null], [94, null], [95, null]], "Tutorial 8": [[90, null], [96, null]], "Types of censoring": [[34, "types-of-censoring"], [53, "types-of-censoring"], [77, "types-of-censoring"]], "Types of errors": [[15, "types-of-errors"], [60, "types-of-errors"]], "Types of machine learning": [[13, "types-of-machine-learning"], [28, "types-of-machine-learning"], [58, "types-of-machine-learning"], [71, "types-of-machine-learning"]], "Types of problems involving time series": [[33, "types-of-problems-involving-time-series"], [52, "types-of-problems-involving-time-series"], [76, "types-of-problems-involving-time-series"]], "Types of questions we might want to answer:": [[34, "types-of-questions-we-might-want-to-answer"], [77, "types-of-questions-we-might-want-to-answer"]], "Typical steps to build a supervised machine learning model": [[37, "typical-steps-to-build-a-supervised-machine-learning-model"]], "UBC CPSC 330: Applied Machine Learning (2025W1)": [[1, null]], "Ubuntu Users": [[6, "ubuntu-users"]], "Underfitting": [[15, "underfitting"], [60, "underfitting"]], "Underfitting, overfitting, the fundamental trade-off, the golden rule [video]": [[15, "underfitting-overfitting-the-fundamental-trade-off-the-golden-rule-video"], [60, "underfitting-overfitting-the-fundamental-trade-off-the-golden-rule-video"]], "Undersampling": [[80, "undersampling"]], "Understanding the problem": [[79, "understanding-the-problem"]], "Unequally spaced time points": [[33, "unequally-spaced-time-points"], [52, "unequally-spaced-time-points"], [76, "unequally-spaced-time-points"]], "Uniform distribution": [[41, "uniform-distribution"], [65, "uniform-distribution"]], "Unsupervised learning": [[28, "unsupervised-learning"], [71, "unsupervised-learning"]], "Updates to assignments": [[8, "updates-to-assignments"]], "Use of Generative AI in the course": [[98, "use-of-generative-ai-in-the-course"]], "Use our template to create a repository": [[8, "use-our-template-to-create-a-repository"]], "Using OVR and OVO as wrappers": [[83, "using-ovr-and-ovo-as-wrappers"]], "Using SMOTE": [[80, "using-smote"]], "Using Silhouette scores to select the number of clusters": [[28, "using-silhouette-scores-to-select-the-number-of-clusters"], [71, "using-silhouette-scores-to-select-the-number-of-clusters"]], "Using multiple metrics in GridSearchCV or RandomizedSearchCV": [[24, "using-multiple-metrics-in-gridsearchcv-or-randomizedsearchcv"], [43, "using-multiple-metrics-in-gridsearchcv-or-randomizedsearchcv"], [67, "using-multiple-metrics-in-gridsearchcv-or-randomizedsearchcv"]], "Using pre-trained models as feature extractor": [[32, "using-pre-trained-models-as-feature-extractor"], [75, "using-pre-trained-models-as-feature-extractor"]], "Using pre-trained models out-of-the-box": [[32, "using-pre-trained-models-out-of-the-box"], [75, "using-pre-trained-models-out-of-the-box"]], "Using pre-trained word embeddings": [[31, "using-pre-trained-word-embeddings"], [50, "using-pre-trained-word-embeddings"], [74, "using-pre-trained-word-embeddings"]], "Using regression metrics with scikit-learn": [[24, "using-regression-metrics-with-scikit-learn"], [43, "using-regression-metrics-with-scikit-learn"], [67, "using-regression-metrics-with-scikit-learn"]], "Viewing the transformed data as a dataframe": [[19, "viewing-the-transformed-data-as-a-dataframe"], [63, "viewing-the-transformed-data-as-a-dataframe"]], "Visualization": [[10, "visualization"]], "Visualizing the parameter grid as a heatmap": [[22, "visualizing-the-parameter-grid-as-a-heatmap"], [41, "visualizing-the-parameter-grid-as-a-heatmap"], [65, "visualizing-the-parameter-grid-as-a-heatmap"]], "Visualizing your results": [[35, "visualizing-your-results"], [54, "visualizing-your-results"], [55, "visualizing-your-results"], [78, "visualizing-your-results"]], "Warning": [[14, null], [59, null]], "Warnings about feature selection": [[27, "warnings-about-feature-selection"], [27, "id7"], [46, "warnings-about-feature-selection"], [70, "warnings-about-feature-selection"], [81, "warnings-about-feature-selection"]], "Weaknesses": [[25, "weaknesses"], [44, "weaknesses"], [68, "weaknesses"]], "Web app on a real server": [[56, "web-app-on-a-real-server"], [57, "web-app-on-a-real-server"], [79, "web-app-on-a-real-server"]], "Web app on local server": [[56, "web-app-on-local-server"], [57, "web-app-on-local-server"], [79, "web-app-on-local-server"]], "What all transformations we need to apply on the dataset?": [[62, "what-all-transformations-we-need-to-apply-on-the-dataset"]], "What are AI, ML, and DL?": [[13, "what-are-ai-ml-and-dl"], [58, "what-are-ai-ml-and-dl"]], "What are Large Language Models (LLMs)?": [[31, "what-are-large-language-models-llms"], [50, "what-are-large-language-models-llms"], [74, "what-are-large-language-models-llms"]], "What are the options?": [[18, "what-are-the-options"], [62, "what-are-the-options"]], "What are the prerequisites for this class?": [[5, "what-are-the-prerequisites-for-this-class"]], "What are we exactly learning?": [[21, "what-are-we-exactly-learning"], [64, "what-are-we-exactly-learning"]], "What coding language and environment will we use?": [[5, "what-coding-language-and-environment-will-we-use"]], "What did we cover?": [[30, "what-did-we-cover"], [49, "what-did-we-cover"], [73, "what-did-we-cover"], [79, "what-did-we-cover"]], "What did we learn today?": [[15, "what-did-we-learn-today"], [18, "what-did-we-learn-today"], [19, "what-did-we-learn-today"], [24, "what-did-we-learn-today"], [35, "what-did-we-learn-today"], [55, "what-did-we-learn-today"], [60, "what-did-we-learn-today"], [62, "what-did-we-learn-today"], [63, "what-did-we-learn-today"], [66, "what-did-we-learn-today"], [67, "what-did-we-learn-today"], [78, "what-did-we-learn-today"]], "What does a typical week look like? What\u2019s the workload?": [[5, "what-does-a-typical-week-look-like-whats-the-workload"]], "What does this have to do with applied ML?": [[35, "what-does-this-have-to-do-with-applied-ml"], [55, "what-does-this-have-to-do-with-applied-ml"], [78, "what-does-this-have-to-do-with-applied-ml"]], "What does this mean for us, when we\u2019re trying to make claims about our data?": [[35, "what-does-this-mean-for-us-when-we-re-trying-to-make-claims-about-our-data"], [55, "what-does-this-mean-for-us-when-we-re-trying-to-make-claims-about-our-data"], [78, "what-does-this-mean-for-us-when-we-re-trying-to-make-claims-about-our-data"]], "What if we apply OHE?": [[19, "what-if-we-apply-ohe"], [63, "what-if-we-apply-ohe"]], "What is Natural Language Processing (NLP)?": [[31, "what-is-natural-language-processing-nlp"], [51, "what-is-natural-language-processing-nlp"], [74, "what-is-natural-language-processing-nlp"]], "What is a recommender system?": [[30, "what-is-a-recommender-system"], [73, "what-is-a-recommender-system"]], "What is clustering?": [[28, "what-is-clustering"], [71, "what-is-clustering"]], "What is deployment?": [[79, "what-is-deployment"]], "What is feature engineering?": [[27, "what-is-feature-engineering"], [70, "what-is-feature-engineering"]], "What is feature selection?": [[27, "what-is-feature-selection"], [46, "what-is-feature-selection"], [70, "what-is-feature-selection"]], "What is grid search?": [[35, "what-is-grid-search"], [55, "what-is-grid-search"], [78, "what-is-grid-search"]], "What is model interpretability?": [[26, "what-is-model-interpretability"], [45, "what-is-model-interpretability"], [69, "what-is-model-interpretability"]], "What is supervised machine learning (ML)?": [[13, "what-is-supervised-machine-learning-ml"], [58, "what-is-supervised-machine-learning-ml"]], "What is \u201cpositive\u201d and \u201cnegative\u201d?": [[23, "what-is-positive-and-negative"], [42, "what-is-positive-and-negative"], [66, "what-is-positive-and-negative"]], "What kind of estimators can we combine?": [[25, "what-kind-of-estimators-can-we-combine"], [44, "what-kind-of-estimators-can-we-combine"], [68, "what-kind-of-estimators-can-we-combine"]], "What next?": [[79, "what-next"]], "What should be the loss? (Activity: 4 mins)": [[35, "what-should-be-the-loss-activity-4-mins"], [55, "what-should-be-the-loss-activity-4-mins"], [78, "what-should-be-the-loss-activity-4-mins"]], "What to look for in these plots?": [[28, "what-to-look-for-in-these-plots"], [71, "what-to-look-for-in-these-plots"]], "What transformations do we need to apply on the dataset?": [[18, "what-transformations-do-we-need-to-apply-on-the-dataset"]], "What will the exams be like?": [[5, "what-will-the-exams-be-like"]], "What\u2019s the problem?": [[18, "what-s-the-problem"], [62, "what-s-the-problem"]], "When can we use broadcasting?": [[9, "when-can-we-use-broadcasting"]], "When experimenting, show the results asap": [[35, "when-experimenting-show-the-results-asap"], [55, "when-experimenting-show-the-results-asap"], [78, "when-experimenting-show-the-results-asap"]], "When is it OK to do things before splitting?": [[18, "when-is-it-ok-to-do-things-before-splitting"], [62, "when-is-it-ok-to-do-things-before-splitting"]], "When test score is much lower than CV score": [[22, "when-test-score-is-much-lower-than-cv-score"], [65, "when-test-score-is-much-lower-than-cv-score"]], "Which model is doing better in this scenario: SVC or Logistic Regression?": [[23, "which-model-is-doing-better-in-this-scenario-svc-or-logistic-regression"], [42, "which-model-is-doing-better-in-this-scenario-svc-or-logistic-regression"]], "Which model should I use?": [[25, "which-model-should-i-use"], [44, "which-model-should-i-use"], [68, "which-model-should-i-use"]], "Which type of error is more important?": [[66, "which-type-of-error-is-more-important"]], "Which types of errors would be most critical for the bank to address?": [[23, "which-types-of-errors-would-be-most-critical-for-the-bank-to-address"], [42, "which-types-of-errors-would-be-most-critical-for-the-bank-to-address"]], "Who takes this course?": [[5, "who-takes-this-course"]], "Why do we need a test set?": [[22, "why-do-we-need-a-test-set"], [65, "why-do-we-need-a-test-set"]], "Why do we want this information?": [[26, "why-do-we-want-this-information"], [45, "why-do-we-want-this-information"], [69, "why-do-we-want-this-information"]], "Why does it matter": [[15, "why-does-it-matter"]], "Why feature selection?": [[27, "why-feature-selection"], [46, "why-feature-selection"], [70, "why-feature-selection"]], "Why machine learning (ML)? [video]": [[13, "why-machine-learning-ml-video"], [58, "why-machine-learning-ml-video"]], "Why model transparency/interpretability?": [[26, "why-model-transparency-interpretability"], [45, "why-model-transparency-interpretability"], [69, "why-model-transparency-interpretability"]], "Why neural networks?": [[32, "why-neural-networks"], [75, "why-neural-networks"]], "Why not neural networks?": [[32, "why-not-neural-networks"], [75, "why-not-neural-networks"]], "Why should I use it?": [[35, "why-should-i-use-it"], [55, "why-should-i-use-it"], [78, "why-should-i-use-it"]], "Why should we care about effective communication?": [[35, "why-should-we-care-about-effective-communication"], [55, "why-should-we-care-about-effective-communication"], [78, "why-should-we-care-about-effective-communication"]], "Why should we care about recommendation systems?": [[30, "why-should-we-care-about-recommendation-systems"], [73, "why-should-we-care-about-recommendation-systems"]], "Why sparse matrices?": [[19, "why-sparse-matrices"], [63, "why-sparse-matrices"]], "Windows Users": [[6, "windows-users"]], "Word embeddings": [[51, "word-embeddings"]], "Word embeddings: The idea": [[31, "word-embeddings-the-idea"], [50, "word-embeddings-the-idea"], [74, "word-embeddings-the-idea"]], "Word vectors with spaCy": [[51, "word-vectors-with-spacy"]], "Writing a traditional program to predict quiz2 grade": [[14, "writing-a-traditional-program-to-predict-quiz2-grade"], [59, "writing-a-traditional-program-to-predict-quiz2-grade"]], "XGBoost": [[25, "xgboost"], [44, "xgboost"], [68, "xgboost"]], "[] notation": [[9, "notation"]], "class_weight=\"balanced\"": [[66, "class-weight-balanced"]], "cross_val_score": [[60, "cross-val-score"]], "cross_validate": [[15, "cross-validate"], [60, "cross-validate"]], "fit and transform paradigm for transformers": [[18, "fit-and-transform-paradigm-for-transformers"], [62, "fit-and-transform-paradigm-for-transformers"]], "fit the classifier": [[14, "fit-the-classifier"], [59, "fit-the-classifier"]], "fit, predict , and score summary": [[14, "fit-predict-and-score-summary"], [59, "fit-predict-and-score-summary"]], "iClciker exercise": [[49, "iclciker-exercise"]], "iClicker": [[98, "iclicker"]], "iClicker (for attendance)": [[26, "iclicker-for-attendance"]], "iClicker Exercise": [[32, "iclicker-exercise"], [32, "id1"], [75, "iclicker-exercise"]], "iClicker Exercise 1.1": [[58, "iclicker-exercise-1-1"]], "iClicker Exercise 10.1": [[24, "iclicker-exercise-10-1"], [67, "iclicker-exercise-10-1"]], "iClicker Exercise 10.2": [[24, "iclicker-exercise-10-2"], [67, "iclicker-exercise-10-2"]], "iClicker Exercise 11.0": [[68, "iclicker-exercise-11-0"]], "iClicker Exercise 11.1": [[44, "iclicker-exercise-11-1"], [68, "iclicker-exercise-11-1"]], "iClicker Exercise 12.1": [[25, "iclicker-exercise-12-1"]], "iClicker Exercise 14.1": [[27, "iclicker-exercise-14-1"], [70, "iclicker-exercise-14-1"]], "iClicker Exercise 2.1 Supervised vs unsupervised": [[14, "iclicker-exercise-2-1-supervised-vs-unsupervised"]], "iClicker Exercise 2.2 Classification vs regression": [[14, "iclicker-exercise-2-2-classification-vs-regression"]], "iClicker Exercise 2.2 Supervised vs unsupervised": [[59, "iclicker-exercise-2-2-supervised-vs-unsupervised"]], "iClicker Exercise 2.3 - Find the root node": [[14, "iclicker-exercise-2-3-find-the-root-node"]], "iClicker Exercise 2.3 Classification vs regression": [[59, "iclicker-exercise-2-3-classification-vs-regression"]], "iClicker Exercise 2.4: Baselines and decision trees": [[14, "iclicker-exercise-2-4-baselines-and-decision-trees"]], "iClicker Exercise 2.5: Baselines and decision trees": [[59, "iclicker-exercise-2-5-baselines-and-decision-trees"]], "iClicker Exercise 3.1": [[15, "iclicker-exercise-3-1"], [60, "iclicker-exercise-3-1"]], "iClicker Exercise 3.2": [[15, "iclicker-exercise-3-2"], [60, "iclicker-exercise-3-2"]], "iClicker Exercise 9.1": [[66, "iclicker-exercise-9-1"]], "iClicker Exercise 9.2": [[66, "iclicker-exercise-9-2"]], "iClicker questions": [[35, "iclicker-questions"]], "iClicker: Precision score": [[23, "iclicker-precision-score"]], "iClicker: Recall score": [[23, "iclicker-recall-score"]], "k-Nearest Neighbours (k-NNs) [video]": [[16, "k-nearest-neighbours-k-nns-video"], [61, "k-nearest-neighbours-k-nns-video"]], "k-nearest neighbours imputation": [[30, "k-nearest-neighbours-imputation"], [49, "k-nearest-neighbours-imputation"], [73, "k-nearest-neighbours-imputation"]], "macOS": [[6, "macos"]], "n_iter": [[22, "n-iter"], [41, "n-iter"], [65, "n-iter"]], "n_jobs=-1": [[22, "n-jobs-1"], [41, "n-jobs-1"], [65, "n-jobs-1"]], "pandas_profiler": [[24, "pandas-profiler"], [43, "pandas-profiler"], [67, "pandas-profiler"]], "predict the target of given examples": [[14, "predict-the-target-of-given-examples"], [59, "predict-the-target-of-given-examples"]], "predict_proba": [[21, "predict-proba"], [64, "predict-proba"]], "random_state argument": [[60, "random-state-argument"]], "score your model": [[14, "score-your-model"], [59, "score-your-model"]], "sklearn API summary: estimators": [[17, "sklearn-api-summary-estimators"], [18, "sklearn-api-summary-estimators"], [62, "sklearn-api-summary-estimators"]], "sklearn API summary: transformers": [[17, "sklearn-api-summary-transformers"], [18, "sklearn-api-summary-transformers"], [62, "sklearn-api-summary-transformers"]], "sklearn Transformers vs Estimators": [[39, "sklearn-transformers-vs-estimators"]], "sklearn set_config": [[19, "sklearn-set-config"], [63, "sklearn-set-config"]], "sklearn\u2019s ColumnTransformer": [[19, "sklearn-s-columntransformer"], [63, "sklearn-s-columntransformer"]], "sklearn\u2019s SimpleImputer": [[17, "sklearn-s-simpleimputer"], [39, "sklearn-s-simpleimputer"]], "sklearn\u2019s feature_importances_ and permutation_importance": [[26, "sklearn-s-feature-importances-and-permutation-importance"], [45, "sklearn-s-feature-importances-and-permutation-importance"], [69, "sklearn-s-feature-importances-and-permutation-importance"]], "sklearn\u2019s feature_importances_ attribute vs permutation_importance": [[26, "sklearn-s-feature-importances-attribute-vs-permutation-importance"], [45, "sklearn-s-feature-importances-attribute-vs-permutation-importance"], [69, "sklearn-s-feature-importances-attribute-vs-permutation-importance"]], "test score vs. cross-validation score": [[60, "test-score-vs-cross-validation-score"]], "test_size, train_size arguments": [[60, "test-size-train-size-arguments"]], "\u201cDeployment\u201d data": [[15, "deployment-data"], [60, "deployment-data"]], "\u2753\u2753 Question for you": [[30, "question-for-you"], [30, "id1"]], "\u2753\u2753 Questions for group discussion": [[66, "questions-for-group-discussion"]], "\u2753\u2753 Questions for you": [[13, "questions-for-you"], [14, "questions-for-you"], [15, "questions-for-you"], [15, "id1"], [16, "questions-for-you"], [16, "id1"], [18, "questions-for-you"], [18, "id1"], [18, "id2"], [19, "questions-for-you"], [19, "id1"], [20, "questions-for-you"], [21, "questions-for-you"], [21, "id1"], [22, "questions-for-you"], [22, "id2"], [24, "questions-for-you"], [24, "id2"], [25, "questions-for-you"], [27, "questions-for-you"], [28, "questions-for-you"], [28, "id2"], [29, "questions-for-you"], [29, "id3"], [30, "questions-for-you"], [32, "questions-for-you"], [33, "questions-for-you"], [33, "id1"], [33, "id2"], [34, "questions-for-you"], [34, "id1"], [34, "id2"], [34, "id3"], [34, "id4"], [35, "questions-for-you"], [37, "questions-for-you"], [37, "id2"], [37, "id3"], [39, "questions-for-you"], [39, "id1"], [40, "questions-for-you"], [44, "questions-for-you"], [44, "id1"], [49, "questions-for-you"], [49, "id1"], [49, "id2"], [52, "questions-for-you"], [55, "questions-for-you"], [55, "id1"], [58, "questions-for-you"], [59, "questions-for-you"], [59, "id1"], [59, "id3"], [60, "questions-for-you"], [60, "id1"], [61, "questions-for-you"], [61, "id1"], [62, "questions-for-you"], [62, "id1"], [62, "id2"], [63, "questions-for-you"], [63, "id1"], [64, "questions-for-you"], [64, "id1"], [64, "id2"], [65, "questions-for-you"], [65, "id2"], [66, "questions-for-you"], [66, "id2"], [67, "questions-for-you"], [67, "id2"], [68, "questions-for-you"], [68, "id1"], [68, "id2"], [70, "questions-for-you"], [71, "questions-for-you"], [71, "id2"], [72, "questions-for-you"], [72, "id3"], [73, "questions-for-you"], [73, "id1"], [73, "id2"], [75, "questions-for-you"], [76, "questions-for-you"], [76, "id1"], [76, "id2"], [76, "id3"], [77, "questions-for-you"], [77, "id1"], [77, "id2"], [77, "id3"], [77, "id4"], [78, "questions-for-you"], [78, "id1"], [79, "questions-for-you"], [79, "id2"]], "\ud83e\udd14 Eva\u2019s questions": [[13, "eva-s-questions"], [58, "eva-s-questions"], [60, "eva-s-questions"]]}, "docnames": ["LICENSE", "README", "docs/330_vs_340", "docs/README", "docs/asking_for_help", "docs/faq", "docs/git_installation", "docs/grades", "docs/homework_instructions", "docs/python_notes", "docs/resources", "docs/setup", "learning-objectives", "lectures/101-103-Giulia-lectures/01_intro", "lectures/101-103-Giulia-lectures/02_terminology-decision-trees", "lectures/101-103-Giulia-lectures/03_ml-fundamentals", "lectures/101-103-Giulia-lectures/04_kNNs-SVM-RBF", "lectures/101-103-Giulia-lectures/05-06-preprocessing-demo", "lectures/101-103-Giulia-lectures/05_preprocessing-pipelines", "lectures/101-103-Giulia-lectures/06_column-transformer-text-feats", "lectures/101-103-Giulia-lectures/07_class-demo", "lectures/101-103-Giulia-lectures/07_linear-models", "lectures/101-103-Giulia-lectures/08_hyperparameter-optimization", "lectures/101-103-Giulia-lectures/09-classification-metrics-short", "lectures/101-103-Giulia-lectures/10_regression-metrics", "lectures/101-103-Giulia-lectures/11_ensembles", "lectures/101-103-Giulia-lectures/12_feat-importances", "lectures/101-103-Giulia-lectures/13_feature-engineering-selection", "lectures/101-103-Giulia-lectures/14_K-Means", "lectures/101-103-Giulia-lectures/15_DBSCAN-hierarchical", "lectures/101-103-Giulia-lectures/16_recommender-systems", "lectures/101-103-Giulia-lectures/17_natural-language-processing", "lectures/101-103-Giulia-lectures/18_intro_to_computer-vision", "lectures/101-103-Giulia-lectures/19_time-series", "lectures/101-103-Giulia-lectures/20_survival-analysis", "lectures/101-103-Giulia-lectures/21_communication", "lectures/102-Varada-lectures/README", "lectures/102-Varada-lectures/class_demos/demo_03-ml-fundamentals", "lectures/102-Varada-lectures/class_demos/demo_04-kNNs-SVMs", "lectures/102-Varada-lectures/class_demos/demo_05-06-preprocessing", "lectures/102-Varada-lectures/class_demos/demo_07-linear-models", "lectures/102-Varada-lectures/class_demos/demo_08-hyperparameter-optimization", "lectures/102-Varada-lectures/class_demos/demo_09-classification-metrics", "lectures/102-Varada-lectures/class_demos/demo_10-regression-metrics", "lectures/102-Varada-lectures/class_demos/demo_11-ensembles", "lectures/102-Varada-lectures/class_demos/demo_12-feat-importances", "lectures/102-Varada-lectures/class_demos/demo_13-feature-engineering-selection", "lectures/102-Varada-lectures/class_demos/demo_14-k-means", "lectures/102-Varada-lectures/class_demos/demo_15-dbscan-hierarchical", "lectures/102-Varada-lectures/class_demos/demo_16-recommender-systems", "lectures/102-Varada-lectures/class_demos/demo_17-natural-language-processing", "lectures/102-Varada-lectures/class_demos/demo_18-natural-language-processing", "lectures/102-Varada-lectures/class_demos/demo_19_time-series", "lectures/102-Varada-lectures/class_demos/demo_20-survival-analysis", "lectures/102-Varada-lectures/class_demos/demo_21-communication", "lectures/102-Varada-lectures/class_demos/demo_22-communication", "lectures/102-Varada-lectures/class_demos/demo_23-deployment-conclusion", "lectures/102-Varada-lectures/class_demos/demo_24-deployment-conclusion", "lectures/notes/01_intro", "lectures/notes/02_terminology-decision-trees", "lectures/notes/03_ml-fundamentals", "lectures/notes/04_kNNs-SVM-RBF", "lectures/notes/05_preprocessing-pipelines", "lectures/notes/06_column-transformer-text-feats", "lectures/notes/07_linear-models", "lectures/notes/08_hyperparameter-optimization", "lectures/notes/09_classification-metrics", "lectures/notes/10_regression-metrics", "lectures/notes/11_ensembles", "lectures/notes/12_feat-importances", "lectures/notes/13_feature-engineering-selection", "lectures/notes/14_K-Means", "lectures/notes/15_DBSCAN-hierarchical", "lectures/notes/16_recommender-systems", "lectures/notes/17_natural-language-processing", "lectures/notes/18_intro_to_computer-vision", "lectures/notes/19_time-series", "lectures/notes/20_survival-analysis", "lectures/notes/21_communication", "lectures/notes/23_deployment-conclusion", "lectures/notes/AppendixA", "lectures/notes/AppendixB", "lectures/notes/AppendixC", "lectures/notes/AppendixD", "lectures/notes/final-exam-review-guiding-question", "lectures/tutorials/01_decision_boundaries", "lectures/tutorials/02_ML_fundamentals", "lectures/tutorials/03_Preprocessing", "lectures/tutorials/06_Ensembles", "lectures/tutorials/07_clustering", "lectures/tutorials/08_Time_series", "lectures/tutorials/solutions/01_decision_boundaries_solution", "lectures/tutorials/solutions/02_ML_fundamentals", "lectures/tutorials/solutions/03_Preprocessing", "lectures/tutorials/solutions/06_Ensembles_solution", "lectures/tutorials/solutions/07_clustering_sol", "lectures/tutorials/solutions/08_Time_series_sol", "lectures/web_api/Untitled", "syllabus"], "envversion": {"sphinx": 62, "sphinx.domains.c": 3, "sphinx.domains.changeset": 1, "sphinx.domains.citation": 1, "sphinx.domains.cpp": 9, "sphinx.domains.index": 1, "sphinx.domains.javascript": 3, "sphinx.domains.math": 2, "sphinx.domains.python": 4, "sphinx.domains.rst": 2, "sphinx.domains.std": 2, "sphinx.ext.intersphinx": 1}, "filenames": ["LICENSE.md", "README.md", "docs/330_vs_340.md", "docs/README.md", "docs/asking_for_help.md", "docs/faq.md", "docs/git_installation.md", "docs/grades.md", "docs/homework_instructions.md", "docs/python_notes.ipynb", "docs/resources.md", "docs/setup.md", "learning-objectives.md", "lectures/101-103-Giulia-lectures/01_intro.ipynb", "lectures/101-103-Giulia-lectures/02_terminology-decision-trees.ipynb", "lectures/101-103-Giulia-lectures/03_ml-fundamentals.ipynb", "lectures/101-103-Giulia-lectures/04_kNNs-SVM-RBF.ipynb", "lectures/101-103-Giulia-lectures/05-06-preprocessing-demo.ipynb", "lectures/101-103-Giulia-lectures/05_preprocessing-pipelines.ipynb", "lectures/101-103-Giulia-lectures/06_column-transformer-text-feats.ipynb", "lectures/101-103-Giulia-lectures/07_class-demo.ipynb", "lectures/101-103-Giulia-lectures/07_linear-models.ipynb", "lectures/101-103-Giulia-lectures/08_hyperparameter-optimization.ipynb", "lectures/101-103-Giulia-lectures/09-classification-metrics-short.ipynb", "lectures/101-103-Giulia-lectures/10_regression-metrics.ipynb", "lectures/101-103-Giulia-lectures/11_ensembles.ipynb", "lectures/101-103-Giulia-lectures/12_feat-importances.ipynb", "lectures/101-103-Giulia-lectures/13_feature-engineering-selection.ipynb", "lectures/101-103-Giulia-lectures/14_K-Means.ipynb", "lectures/101-103-Giulia-lectures/15_DBSCAN-hierarchical.ipynb", "lectures/101-103-Giulia-lectures/16_recommender-systems.ipynb", "lectures/101-103-Giulia-lectures/17_natural-language-processing.ipynb", "lectures/101-103-Giulia-lectures/18_intro_to_computer-vision.ipynb", "lectures/101-103-Giulia-lectures/19_time-series.ipynb", "lectures/101-103-Giulia-lectures/20_survival-analysis.ipynb", "lectures/101-103-Giulia-lectures/21_communication.ipynb", "lectures/102-Varada-lectures/README.md", "lectures/102-Varada-lectures/class_demos/demo_03-ml-fundamentals.ipynb", "lectures/102-Varada-lectures/class_demos/demo_04-kNNs-SVMs.ipynb", "lectures/102-Varada-lectures/class_demos/demo_05-06-preprocessing.ipynb", "lectures/102-Varada-lectures/class_demos/demo_07-linear-models.ipynb", "lectures/102-Varada-lectures/class_demos/demo_08-hyperparameter-optimization.ipynb", "lectures/102-Varada-lectures/class_demos/demo_09-classification-metrics.ipynb", "lectures/102-Varada-lectures/class_demos/demo_10-regression-metrics.ipynb", "lectures/102-Varada-lectures/class_demos/demo_11-ensembles.ipynb", "lectures/102-Varada-lectures/class_demos/demo_12-feat-importances.ipynb", "lectures/102-Varada-lectures/class_demos/demo_13-feature-engineering-selection.ipynb", "lectures/102-Varada-lectures/class_demos/demo_14-k-means.ipynb", "lectures/102-Varada-lectures/class_demos/demo_15-dbscan-hierarchical.ipynb", "lectures/102-Varada-lectures/class_demos/demo_16-recommender-systems.ipynb", "lectures/102-Varada-lectures/class_demos/demo_17-natural-language-processing.ipynb", "lectures/102-Varada-lectures/class_demos/demo_18-natural-language-processing.ipynb", "lectures/102-Varada-lectures/class_demos/demo_19_time-series.ipynb", "lectures/102-Varada-lectures/class_demos/demo_20-survival-analysis.ipynb", "lectures/102-Varada-lectures/class_demos/demo_21-communication.ipynb", "lectures/102-Varada-lectures/class_demos/demo_22-communication.ipynb", "lectures/102-Varada-lectures/class_demos/demo_23-deployment-conclusion.ipynb", "lectures/102-Varada-lectures/class_demos/demo_24-deployment-conclusion.ipynb", "lectures/notes/01_intro.ipynb", "lectures/notes/02_terminology-decision-trees.ipynb", "lectures/notes/03_ml-fundamentals.ipynb", "lectures/notes/04_kNNs-SVM-RBF.ipynb", "lectures/notes/05_preprocessing-pipelines.ipynb", "lectures/notes/06_column-transformer-text-feats.ipynb", "lectures/notes/07_linear-models.ipynb", "lectures/notes/08_hyperparameter-optimization.ipynb", "lectures/notes/09_classification-metrics.ipynb", "lectures/notes/10_regression-metrics.ipynb", "lectures/notes/11_ensembles.ipynb", "lectures/notes/12_feat-importances.ipynb", "lectures/notes/13_feature-engineering-selection.ipynb", "lectures/notes/14_K-Means.ipynb", "lectures/notes/15_DBSCAN-hierarchical.ipynb", "lectures/notes/16_recommender-systems.ipynb", "lectures/notes/17_natural-language-processing.ipynb", "lectures/notes/18_intro_to_computer-vision.ipynb", "lectures/notes/19_time-series.ipynb", "lectures/notes/20_survival-analysis.ipynb", "lectures/notes/21_communication.ipynb", "lectures/notes/23_deployment-conclusion.ipynb", "lectures/notes/AppendixA.ipynb", "lectures/notes/AppendixB.ipynb", "lectures/notes/AppendixC.ipynb", "lectures/notes/AppendixD.ipynb", "lectures/notes/final-exam-review-guiding-question.ipynb", "lectures/tutorials/01_decision_boundaries.ipynb", "lectures/tutorials/02_ML_fundamentals.ipynb", "lectures/tutorials/03_Preprocessing.ipynb", "lectures/tutorials/06_Ensembles.ipynb", "lectures/tutorials/07_clustering.ipynb", "lectures/tutorials/08_Time_series.ipynb", "lectures/tutorials/solutions/01_decision_boundaries_solution.ipynb", "lectures/tutorials/solutions/02_ML_fundamentals.ipynb", "lectures/tutorials/solutions/03_Preprocessing.ipynb", "lectures/tutorials/solutions/06_Ensembles_solution.ipynb", "lectures/tutorials/solutions/07_clustering_sol.ipynb", "lectures/tutorials/solutions/08_Time_series_sol.ipynb", "lectures/web_api/Untitled.ipynb", "syllabus.md"], "indexentries": {}, "objects": {}, "objnames": {}, "objtypes": {}, "terms": {"": [1, 4, 6, 8, 9, 10, 11, 14, 15, 20, 21, 22, 25, 27, 28, 29, 30, 31, 32, 33, 34, 37, 38, 40, 41, 44, 46, 48, 49, 50, 51, 56, 57, 59, 64, 65, 68, 70, 71, 72, 73, 74, 75, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 98], "0": [0, 1, 8, 9, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98], "00": [1, 15, 17, 19, 20, 21, 22, 23, 26, 29, 30, 33, 34, 35, 37, 39, 40, 41, 42, 45, 49, 52, 55, 58, 59, 61, 63, 64, 65, 66, 69, 72, 73, 76, 77, 78, 80, 90, 95, 96, 98], "000": [15, 16, 18, 20, 21, 22, 24, 25, 26, 28, 31, 32, 34, 40, 41, 43, 44, 45, 50, 51, 58, 60, 61, 62, 63, 64, 65, 67, 68, 69, 74, 75, 77, 92], "0000": [18, 20, 21, 23, 31, 40, 42, 51, 62, 64, 66, 74], "00000": [20, 22, 40, 41, 52, 65, 76, 96], "000000": [14, 15, 16, 17, 18, 19, 22, 23, 24, 25, 26, 27, 29, 30, 32, 33, 34, 37, 38, 39, 41, 42, 43, 44, 45, 46, 49, 52, 59, 60, 61, 62, 63, 65, 66, 67, 68, 69, 70, 72, 73, 75, 76, 77, 92, 94, 95, 96], "00000000e": [26, 45, 69], "000000e": [17, 39, 65, 95], "000001": 24, "00000e": 61, "000010": 24, "000011": [23, 34, 42, 66], "000012": 41, "000013": 41, "000021": [18, 62], "000022": 41, "000036": [23, 41, 42, 66], "000038": 65, "000039": [32, 75], "000042": 41, "000044": 34, "000045": 41, "000047": 65, "000057": [18, 62], "000058": 65, "000079": 65, "000088": 41, "000090": 65, "000091": 65, "000094": 41, "000096": 64, "0001": [21, 24, 34, 35, 40, 42, 44, 55, 64, 66, 67, 68, 75, 77, 78, 94], "000100": [18, 24, 62], "000102": 64, "000102e": [15, 37], "000108": [32, 75], "000113": [23, 42, 66], "000117": [24, 38, 43, 67], "000124": 21, "000126": 65, "000128": [38, 64], "000130": 38, "000131": 65, "000134": 21, "000142": [32, 64, 75], "000146": 41, "000148": 41, "000149": [18, 62], "000150": 67, "000151": 67, "000153": [65, 67], "000155": [18, 23, 42, 62, 66], "000156": [41, 64, 67], "000157": [65, 67], "000161": [21, 32, 75], "000163": [38, 65], "000165": 21, "000166": 64, "000169": 38, "000170": 21, "000176": [41, 67], "000177": 65, "000179": 41, "000182": 41, "000184": 38, "000187": [38, 41, 67], "000189": 64, "000197": 21, "000198": [23, 42, 66, 76], "000201": 76, "000207": 21, "000208": [18, 62], "000210": 64, "000212": [38, 70], "000216": 67, "000220": 65, "000221": 76, "000224": 41, "000227": [23, 42, 66], "000228": 41, "000230": 64, "000233": 38, "000234": [22, 41, 61, 65], "000235": [23, 38, 42, 66], "000236": 38, "000241": [38, 76], "000243": 64, "000245": [22, 41, 65], "000248": 38, "000252": 67, "000260": 62, "000261": [32, 75], "000264": 62, "000267": 62, "000270": 38, "000273": 64, "000280": 39, "000281": 38, "000283": 41, "000286": 65, "000287": [41, 43], "000289": [18, 32, 62, 75], "000291": [38, 39], "000294": 62, "000296": [38, 39], "000297": [43, 67], "000301": 64, "000303": 76, "000304": 38, "000305": 43, "000310": 38, "000312": [23, 42, 66], "000313": 38, "000316": 38, "000318": 64, "000320": 64, "000328": 38, "000329": 38, "000331": 62, "000335": 43, "000336": 21, "000337": 38, "000342": [32, 75], "000343": 64, "000346": 64, "000348": 62, "000350": [32, 38, 39, 75], "000353": 65, "000356": 65, "000361": 41, "000365": 43, "000366": [23, 42, 66], "000374": 38, "000379": 39, "00038": [22, 41, 65], "000380": 38, "000381": 41, "000384": 21, "000385": 64, "000386": [21, 38], "000387": 38, "000389": 39, "000390": 43, "000392": 39, "000396": [32, 39, 75], "000397": [24, 43, 67], "000401": 60, "000404": 60, "000407": 60, "000408": 60, "000409": 60, "000410": [60, 62], "000415": 21, "000416": 60, "000417": 60, "000419": 21, "000420": 38, "000422": 46, "000423": [32, 38, 60, 75], "000426": 41, "000428": 38, "000432": 38, "000434": [21, 60], "000438": 67, "000440": 60, "000441": 38, "000443": 60, "000446": 67, "000447": 67, "000448": 67, "000451": 60, "000452": 60, "000457": 62, "000459": [32, 75], "000460": 38, "000471": 39, "000475": 38, "000480": 38, "000486": [32, 75], "000488": 60, "000492": [23, 42, 64, 66], "000497": [32, 75], "000498": 65, "0005": [35, 55, 78], "000503": 65, "000504": 67, "000508": 65, "000514": 61, "000517": [60, 61], "000520": [38, 61], "000522": 67, "000536": 60, "000538": [60, 61], "000540": 38, "000544": [38, 60], "000546": [41, 61], "000557": [38, 61], "000559": 60, "000562": 60, "000565": [60, 61], "000568": 61, "00057": 41, "000570": 60, "000574": 60, "000575": 43, "000577": 60, "000578": 60, "00058": [22, 41, 65], "000584": 60, "000585": 60, "000586": 60, "000588": 61, "000589": 61, "000590": 21, "000592": 60, "000593": 60, "000599": 61, "000601": 65, "000608": 61, "000610": [21, 60], "000611": 43, "000622": 65, "000628": [32, 75], "000629": 62, "000630": [23, 24, 42, 61, 64, 66], "000636": [32, 75], "000643": [32, 75], "000646": 37, "00064647": 37, "000651": 61, "000653": [60, 61], "000654": 67, "000668": 65, "000681": 60, "000685": 38, "000693": 40, "000706": 40, "000724": 67, "000725": 60, "000726": [23, 42, 66], "000728": 24, "000740": 60, "000743": 39, "000747": 65, "000772": 60, "000773": [32, 75], "000781": [32, 75], "000786": [23, 42, 66], "00079": [22, 41, 65], "000791": 41, "000796": 37, "00079645": 37, "000801": 27, "000803": 61, "000804": 62, "000807": 37, "00080741": 37, "000812": 38, "000820": 61, "000826": 61, "000827": 61, "000828": 76, "000830": 43, "000838": 61, "000839": [38, 61], "000853": 61, "000855": 65, "000856": 62, "000858": 62, "000859": 61, "000877": 61, "000890": 38, "000891": 66, "000893": 62, "000895": 61, "000896": 61, "000900": 61, "000909": 38, "000916": 43, "000917": 65, "000927": [20, 23, 40, 42, 66], "000934": 38, "000939": 42, "000945": 70, "000947": 61, "000948": 60, "000954": 43, "000963": 67, "000964": 70, "000976": 65, "000977": 43, "000978": 41, "000982": [22, 41, 65], "000984": 43, "000986": 65, "000987": [32, 75], "000995": 33, "000997": 24, "001": [16, 18, 20, 21, 22, 24, 25, 26, 32, 34, 35, 40, 41, 42, 44, 45, 55, 58, 60, 61, 62, 63, 64, 65, 68, 69, 75, 77, 78, 94], "0010": [21, 64], "00100": [22, 41, 65], "001000": [22, 24, 41, 65], "001001": 24, "001002": 24, "001003": 33, "001004": 24, "001011": [16, 33], "001019": 18, "001060": [18, 62], "001061": 40, "001063": 37, "00106308": 37, "001068": [26, 45, 69], "001070": 43, "001077": 43, "001084": 21, "001087": 70, "001109": 38, "001124": 65, "001132": [23, 42], "001155": 70, "001162": [22, 41, 65, 70], "001170": 43, "001176": 40, "001180": [32, 75], "001184": 61, "001205": [23, 42, 66], "001220": 61, "001226": 62, "001228": 62, "001230": 38, "001239": [23, 42, 66], "001248": 61, "001249": [53, 77], "001252": 41, "001264": 61, "001265": 62, "001266": [24, 43, 67], "001268": 61, "001275": 62, "001279": 70, "001283": 21, "001286": [23, 42, 66], "001291": 41, "001302": 62, "001326": [32, 75], "001354": 19, "001363": 46, "001370": [32, 75], "001375": 38, "001379": 41, "001419": [32, 38, 75], "001428": 61, "001487": 61, "001506": 33, "001507": 41, "001509": 46, "00151": 65, "001510": 33, "001519": 33, "001522": [32, 38, 75], "001529": 63, "001535": 65, "001548": 43, "001549": 38, "001553": [62, 63], "001566": 38, "001573": 38, "001590": 63, "001593": 46, "001594": [22, 41, 63, 65], "001596": [41, 63], "001615": 63, "001622": 46, "001636": [41, 65], "001652": 61, "001662": 43, "001675": 46, "00168": 65, "001687": 38, "001693": 70, "001695": 41, "001699": 41, "0017": [23, 42, 66], "001700": [23, 42, 66], "001706": 65, "001712": 41, "001713": 65, "001714": 41, "001715": 41, "001726": 41, "001729": 65, "001740": [24, 43, 67], "001745": 40, "001758": 41, "001778": 63, "001781": 63, "001792": [22, 41, 65], "001799": 46, "001806": 43, "001818": 64, "001833": 63, "001834": 65, "001835": 65, "001842": 65, "001843": 63, "001847": 70, "001850": 64, "001851": 65, "001864": 61, "001867": [32, 75], "001871": [41, 64], "001877": 46, "001882": 38, "001883": 63, "001886": 94, "001907": 38, "001919": 94, "001934": 46, "001936": 94, "001948": 63, "001949": 70, "001962": 41, "0019627847": 31, "0019627889": [50, 51, 74], "001965": 41, "001967": 94, "001972": 94, "001976": 94, "001977": 94, "001982": 64, "001987": 66, "001988": 65, "001990": 18, "001991": 94, "001994": 70, "001995": [23, 42], "002": [18, 21, 25, 26, 31, 34, 44, 45, 50, 51, 63, 64, 68, 69, 74, 77], "002002": 24, "002004": 24, "002007": 18, "002008": 94, "002012": 18, "002014": 18, "002034": 94, "002038": 41, "002043": 94, "002048": 46, "002055": 94, "002057": [18, 62, 63, 93], "002062": 94, "002064": 46, "002080": 94, "002082": 46, "002089": 41, "002102": 41, "002105": [22, 41, 65], "002108": 64, "002126": 41, "002128": 41, "002137": 21, "002141": 46, "002153": 65, "002157": 18, "002158": 70, "002191": 65, "002196": 64, "002202": 18, "002241": 65, "002250": 94, "002272": 41, "002274": 21, "002284": 41, "002292": 21, "002293": [32, 75], "002301": 18, "002321": 38, "002326": 65, "002334": 46, "002339": 94, "002354": 64, "002355": [41, 70], "002357": 94, "002369": 65, "002393": 94, "002402": 63, "002416": 38, "002418": 38, "002440": 38, "002441": 70, "002473": 94, "002477": [21, 38], "002505": 18, "002531": [65, 94], "002533": 65, "002554": 41, "002561": [22, 41, 65], "002570": 94, "002576": 63, "002618": 21, "002628": 41, "002640": 94, "002643": 38, "002646": 70, "002664": 70, "002670": 64, "002675": 46, "00269": 41, "002690": [18, 62], "002705": 65, "002709": 94, "002775": 94, "002802": 38, "002805": 63, "002813": 76, "002824": 94, "002827": 63, "002845": 41, "002848": 38, "002854": 41, "002866": 65, "002867": 70, "002886": 65, "002889": 66, "002893": 63, "0029": [34, 77], "002906": 46, "002908": [62, 64], "002921": 38, "002926": 65, "002951": 63, "002952": 37, "00295235": 37, "002957": 41, "002965": 38, "002974": 21, "002987": 38, "002995": 62, "002999": [16, 65], "003": [18, 25, 26, 44, 45, 65, 68, 69], "003000": 24, "003002": 33, "003011": 63, "003018": 94, "003024": [32, 75], "003037": [38, 62], "003039": 41, "00304": 65, "003043": 41, "003044": [38, 41], "003047": 41, "003051": 65, "003057": [17, 41], "003059": 62, "003070": 18, "003071": 42, "003082": 63, "003087": 41, "003088": 38, "003092": 65, "003102": 94, "003114": 65, "003132": 46, "003133": [24, 41, 43, 67], "003165": 21, "003166": 70, "003169": 62, "003176": 65, "003182": 65, "003183": 70, "003185": [34, 53, 77], "003194": [21, 64], "003210": 38, "003258": 65, "003272": 38, "00327551": 37, "003276": 37, "003287": 63, "003293": 65, "003295": 46, "003300": [18, 62], "003310": 63, "003311": 94, "003312": [41, 46], "003313": 94, "003319": 94, "003320": [32, 75], "003365": 46, "003368": 63, "003389": 65, "003401": 70, "003414": 33, "003415": 94, "003423": 70, "003427": 70, "003433": 24, "003439": 63, "003440": 46, "003442": 76, "003463": 38, "003479": 21, "003481": 63, "003483": 41, "003485": 94, "003493": 70, "003514": [17, 41], "003522": 41, "003534": 16, "003535": 41, "003540": 38, "003543": 41, "003544": 41, "003547": [24, 43, 67], "003552": 41, "003560": 41, "003561": 60, "003588": 65, "003593": 38, "003607": 65, "00361": 65, "003626": 94, "003650": 94, "003652": 21, "003663": 38, "003681": [45, 69, 94], "003723": 41, "003732": 63, "003740": [43, 94], "003742": 65, "003767": 41, "003772": 41, "003779": 94, "003785": [24, 38, 43, 67], "003786": 43, "003788": 43, "003795": 41, "003804": 43, "003819": 43, "003823": 43, "003825": 41, "003833": 41, "003848": 43, "003877": 38, "003878": 41, "003885": 41, "003886": 43, "003892": 94, "003910": 38, "003919": [38, 41, 65], "003919287722401839": [41, 65], "003924": 70, "003950": 24, "003987": 92, "003995": 33, "003999": [16, 24], "004": [22, 25, 26, 32, 34, 41, 44, 45, 61, 65, 68, 69, 75], "004000": [15, 16, 24, 43], "004001": [24, 27], "004003": 16, "004004": [24, 27], "004011": 16, "004024": [16, 94], "004026": 92, "004027": 41, "004032": 40, "004035": 16, "004044": [32, 75], "004046": 43, "004048": 24, "004059": 65, "00406": 65, "004065": [33, 76], "004072": 41, "004076": 94, "004082": [33, 76, 94], "004087": 94, "004094": 27, "004114": 67, "004125": [23, 42], "004128": 94, "004174": 65, "004179": [24, 67], "004186": 67, "004205": 41, "004216": 67, "004221": 94, "004225": 46, "004229": 67, "004240": 94, "004249": 67, "004258": 94, "004264": [60, 67], "004265": 67, "004274": 46, "004337": [22, 41, 65], "004339": 94, "004340": 94, "00435173": [28, 71], "004352": [28, 71], "004360": [32, 75, 94], "004362": [53, 77], "004376": 27, "004379": 94, "004408": 40, "004415": 65, "004451": [32, 75], "004458": 94, "004461": 38, "004469": 38, "004472": 16, "004474": 94, "004481": 65, "004539": 94, "004553": 63, "004571": 94, "004574": 41, "004575": 94, "004594": 38, "004617": [32, 75], "004627": 67, "004631": 40, "004665": 21, "00468": 65, "004688": 65, "004691": 67, "004712": 41, "004733": 41, "004769": 60, "004770": [18, 62], "004772": 94, "00478": 65, "004793": 94, "004801": [18, 62, 63], "004807": 65, "004846": 65, "004852": [38, 65], "004877": 94, "004886": 94, "004924": 46, "004948": 94, "004954": 15, "004963": 69, "004975": 94, "005": [25, 26, 34, 35, 44, 45, 55, 58, 68, 69, 77, 78], "005000": 15, "005002": [15, 16], "005003": [15, 41], "005004": 15, "005012": [65, 69], "005013": 15, "005022": 94, "005039": 69, "005042": 94, "005049": 92, "005061": 41, "005071": 16, "005075": 92, "005081": 41, "005090": 63, "005104": [41, 67], "005116": 65, "005136": [15, 37], "005149": 65, "005150": 67, "005151": [22, 41, 65], "005157": 65, "005163": 41, "005169": 94, "005174": 16, "005180": 69, "005186": 65, "005207": 63, "005243": 18, "00525962": [18, 62], "005261": 23, "005263": [32, 75], "005264": 94, "005270": 38, "005298": 94, "00533": 65, "00535": 65, "005351": [20, 40], "005359": 69, "005387": [23, 42, 66, 80], "005399": 94, "005404": 67, "005426": [22, 41, 65], "00543825": [18, 62], "005449": 67, "005459": [32, 75], "005502": 45, "005511": 94, "005540": 94, "005562": 65, "005563": 41, "005587": 94, "005595": 67, "005603": 94, "005622": 45, "005659": 33, "005699": 60, "005725": 45, "00573": [22, 41, 65], "005756": 92, "005802": 65, "005809": [33, 76], "005810": 41, "005845": 65, "005879": 67, "005888": [18, 62], "005935": 45, "005957": 41, "005976": 94, "006": [25, 26, 44, 45, 62, 68, 69], "006000": 16, "006015": 65, "006033": 65, "006048": 16, "006070": 38, "006090": 64, "006110": [22, 41, 61, 65], "006156": 92, "006166": 15, "006187": 94, "006208": 38, "006219": 65, "006236": 38, "006250": 38, "006252": 67, "006283": 94, "006284": 65, "006302": 45, "00630932": [20, 40], "006326": 65, "006330": 94, "006333": 67, "006334": 65, "006378": 27, "006393": 19, "006429": 41, "006438": 21, "006441": 65, "006447": 41, "006452": [21, 64], "006475": 19, "006478": 94, "006531": 60, "006545": [22, 41, 65], "006546893270012566": [21, 64], "006557": [21, 64], "006578": [18, 62, 63, 93], "006582": 65, "006595": 65, "006597": 94, "006622": 16, "006626": 40, "006653": 67, "006667": 38, "006677": 41, "006702": 24, "006724": [32, 75], "006738": 41, "006744": [24, 43, 65, 67], "006752": 41, "006774": [32, 75], "006793": 94, "006805": 60, "00683": 65, "006845": 65, "00689": 65, "007": [20, 25, 40, 44, 68, 69], "007068": 70, "007074": 21, "007088": 27, "007194": 43, "007196": 94, "00720988e": [26, 45, 69], "007222": 92, "007308": 65, "007316": 60, "007321": 94, "007361": 92, "007366": 41, "007434": [26, 45, 69], "007441": 94, "007458": [18, 62, 63, 93], "007542": [15, 37], "007545": 65, "007564": 41, "00757": 65, "007577": 41, "007588": [28, 71], "00758803": [28, 71], "00759438": [26, 45, 69], "007666": [23, 42, 66], "007754": 65, "007781": 41, "007794": [17, 39], "007848": 41, "0079": 40, "007933": 41, "007938": 60, "008": [25, 44, 68, 77], "0080": 40, "008017": [18, 65], "008040": [52, 76, 96], "008073": 41, "008096": 65, "008101": 41, "008151": 18, "008167": [18, 62, 63, 93], "008241": 41, "008274": 41, "008286": 38, "0083": 40, "00830586": [19, 63], "008306": [19, 63], "008322e": 77, "008333": 63, "008399": 27, "008406": 63, "008431": 41, "008434": 65, "008484": 16, "008498": 38, "008541": 24, "008569": 92, "008584": 66, "008593": 16, "008608": 65, "008646": 27, "008667": [22, 41, 65], "008735": [16, 61], "008754": 41, "008783": 65, "008799": 42, "008803": 27, "008830": [34, 53, 77], "008854": 18, "008856": 46, "008919": 22, "009": [25, 26, 31, 34, 44, 45, 50, 68, 74], "00905": 65, "009059": 60, "009063": [22, 41, 65], "009064": 16, "009077": 16, "009086": 42, "009097": 65, "009143": 46, "009173": 46, "009298": 41, "009304": 42, "009325": 65, "009414": 65, "009418": 22, "009422": 60, "009429": [23, 42], "009457": 65, "009476": 96, "009514e": 24, "009522": 46, "009559": 67, "009627": 22, "009635": [23, 42], "009678": 65, "009724": 70, "009751": 16, "009797": 27, "009805": 65, "009833": 65, "00pm": [13, 40], "01": [16, 17, 18, 21, 22, 24, 26, 32, 33, 34, 35, 39, 40, 41, 43, 45, 52, 54, 55, 61, 62, 64, 65, 66, 67, 69, 75, 76, 77, 78, 83, 95, 96], "010": [20, 21, 22, 26, 34, 40, 45, 58, 63, 64, 65, 68, 69, 77], "0100": [21, 64], "01000": [41, 65], "010000": [18, 22, 24, 41, 62, 65], "010027": [21, 64], "010112": 41, "010125": 46, "010183": [18, 62, 63, 93], "0102": [22, 41, 61, 65], "010208": 70, "010238": 42, "010294": 60, "010336": 76, "010347": 42, "010506": 46, "010521": 16, "010650": 60, "010679": 60, "010688": 70, "010715": 65, "010721": [41, 53, 77], "010729": 41, "010750": 70, "010797": 27, "010832": 94, "010861": 22, "010915": 27, "011": [25, 32, 45, 50, 58, 63, 75, 95], "011000": 95, "011003": 65, "011039": 46, "011064": 41, "011096": 65, "011210": 70, "011234": [23, 42, 66], "011248": 76, "011252": 70, "011258": 41, "011269e": 24, "011287": 70, "011332": [34, 53, 77], "011336": [16, 61], "011389": 41, "011395": 22, "011402": 92, "011450": 27, "011476": 65, "011519": 41, "011555": 92, "011633": 18, "011678": [23, 42, 66], "011751": 42, "011767": [24, 43, 67], "01186": 41, "011906": 37, "01190633": 37, "011908": 65, "011992": 41, "012": [18, 25, 32, 44, 62, 63, 75], "012002": 65, "012003": 27, "012019": 60, "012030": 70, "012095": 37, "01209545": 37, "012121": 65, "012149": 80, "012152": 41, "012165": 22, "012240": 70, "012247": 38, "012505": 19, "012507": 65, "012534340843558311": [50, 74], "012534401379525661": 31, "0126": 40, "012616": [22, 41, 65], "012651": 16, "012690": 24, "012777": 66, "012808": 22, "012923": 40, "012940": 94, "012971": 41, "012978": 94, "013": [45, 68], "013041": 94, "013115": 41, "0131199607": 43, "01311996073": 24, "01311996076": 67, "013120": [45, 69], "013158": 46, "013161": [22, 41, 65], "013173": 37, "01317334": 37, "013178": 94, "013190": 24, "013248": 94, "013315": 94, "013328": 94, "013335": 94, "013433": [16, 61], "013445": 65, "01346": 22, "013499": 94, "013504": 41, "01352": 65, "013562": 94, "013613": 27, "013622": 65, "013628": 92, "013658": 94, "013662": 65, "013706928443177698": [41, 65], "013707": [41, 65], "013741": 41, "013755": 22, "013782": 92, "013799": 94, "014": [18, 34, 60, 62, 77], "014001": 27, "014078": 94, "014081e": 24, "01409912": [31, 50, 51, 74], "014107": 65, "014167": 94, "014176": 94, "014192": 65, "01432486e": [26, 45, 69], "014337": 38, "014381": 41, "014390": 94, "014478": 92, "014485": 41, "014494": 65, "014559": 19, "014607": [32, 75], "014650": [53, 77], "014662": 92, "014669": 65, "014706": 94, "014708": 41, "014730": 63, "01473536": [16, 61], "014758": [24, 77], "014839": 41, "014989": 38, "015": [18, 58, 62, 63, 68], "015039": [23, 42, 66, 80], "015161": 94, "015249": 94, "015263": 65, "015352": 41, "015361": 94, "015429": 65, "015433": 27, "015518": 46, "015522": 65, "015580": [45, 69], "015633": 80, "015635": 65, "015639": 38, "015665": 41, "015692": 16, "015724": 70, "015789": 27, "015831": 19, "015832": 27, "015851": 19, "015902": 41, "015927": 41, "015932": 16, "015957": 41, "015981": 92, "016047": 65, "016059": 16, "016064": 41, "01614": 65, "016143": 94, "016155": 46, "016163": 65, "016281": 41, "016297": 22, "016309": 24, "016330": 38, "016381": 19, "016451": 41, "01647": [22, 41, 65], "016525": [24, 26, 35, 43, 45, 54, 55, 67, 69, 78], "016555": [21, 64], "016577": 41, "016578": 41, "016587": [23, 42, 66], "016634": 65, "016660": [17, 39], "016676": [28, 71], "016688": [18, 27, 46, 62, 70], "016697": 41, "016731": 22, "016807": [21, 64], "016838": 41, "016853": 41, "016881": 41, "016911": 65, "016918": [66, 80], "016928": 65, "016944": [16, 61], "016963": 65, "016992": 19, "016993": 19, "017": [32, 34, 44, 45, 63, 69, 75], "017003": 19, "017182": 26, "017251": 19, "017297": 19, "017339": 19, "017344": 65, "017355": 41, "017370": 19, "017442": 41, "017468": 19, "017508": 19, "017594": 41, "017659": 19, "017795": 38, "017829": [52, 76, 96], "017864": 69, "017876": 22, "017951": 38, "017959e": [24, 67], "017972": [18, 62], "018011": 69, "018024": 65, "018035": 69, "018088": 37, "01808825": 37, "018119": 43, "018131": 41, "018169": 26, "018178": [16, 61], "018201": 41, "018217": [53, 77], "018224": 41, "018229": 24, "018245": 65, "018252": 43, "018266": 43, "018310": [16, 61], "018384": 77, "018402": 65, "018434": [52, 76, 96], "018436": [53, 77], "018459e": 24, "018487": [21, 64], "018494": 69, "0185": [21, 64], "018507e": 24, "018535": 65, "018551": 41, "018576": 22, "018622": [17, 39], "018687": 41, "018706": 41, "018712": 43, "018727": 77, "018745": 58, "018831": 43, "018844": 43, "018854": [23, 42, 66], "018886": 22, "018941": 67, "018975": 67, "018984": 43, "019001": 67, "019020": 43, "019021": [22, 67], "019111": 67, "019128": 67, "019146": 48, "019164": 67, "019178": 26, "01926": 22, "019293": 38, "019324": 77, "019342": 41, "019381838999846482": [41, 65], "019382": [41, 65], "019419": 67, "019444": 63, "019451": 41, "019485": 41, "019509": 24, "019531": [23, 42, 66], "019556": [34, 53, 77], "019558": 65, "0195598": [21, 64], "019614": 67, "019630": 67, "019656": 67, "019660": 67, "019718": 65, "019762": 41, "019839": [22, 41, 65], "019844": 67, "019856": 67, "019951": 41, "019969e": 77, "02": [1, 15, 17, 18, 21, 22, 24, 26, 27, 33, 34, 37, 39, 41, 45, 46, 52, 61, 62, 63, 64, 65, 67, 69, 70, 76, 77, 89, 93, 95, 96], "020": 63, "020000": 38, "02000e": 61, "020092": 41, "020121": 45, "020138": 42, "020161": 41, "020166": 22, "020326": 67, "020395": 41, "020414": [22, 41, 65], "020474": 65, "020495": 22, "02052": 41, "020621": 41, "020629": 65, "020649": 65, "020653": 60, "020742": 22, "020825": 65, "020833": [30, 49, 73], "020858": 65, "020873": [18, 62], "021": 77, "021082": 38, "021100": [18, 62], "021134": 22, "021146": 41, "021178": 24, "021305": [16, 61], "021329": 65, "021345": [22, 41, 65], "02148": 65, "021508": 41, "021613": 65, "0217": 65, "021729": 19, "021764": 65, "021819": 65, "021900": [22, 41, 61, 65], "021944": 23, "021970": 43, "022": 44, "022039": 66, "022064": 67, "022127": 67, "022162": 41, "022168": 22, "022331": [26, 45, 69], "022375": 77, "022629": [22, 41, 65], "022678": 80, "022730": 38, "022848": 60, "022852": 65, "022866": [23, 42, 66], "022976": 22, "023": [31, 32, 44, 68, 74, 75], "023021": 41, "023031": 41, "023086": [34, 53, 77], "023105": [52, 76, 96], "023127": 41, "02313684": 37, "023137": 37, "02325": 65, "023279": [17, 39], "023324": 19, "023366": [27, 46, 70], "023414": 22, "023636": [23, 42, 66, 80], "023985": 65, "023997": 22, "024028": [22, 41, 65], "024122": 65, "024160": 37, "02416048": 37, "02418337": 20, "02423": 22, "024286": 19, "024291": [33, 76], "024317": 22, "024323": 22, "024351e": [24, 67], "024390": [27, 46, 70], "024404": 69, "024459": 67, "02446630e": [26, 45, 69], "024534": 19, "024540": [18, 62], "024643": 41, "024746": 65, "024944": 38, "025": [23, 25, 42, 44, 66], "025115": 41, "025159": [53, 77], "025381": [26, 35, 45, 54, 55, 69, 78], "025391": [18, 62, 63, 93], "025396": [22, 41, 65], "025460": 38, "025482e": 65, "025489": [45, 69], "025661": 26, "025689": [22, 41, 65], "025910": [16, 61], "025941": 19, "025992": 32, "025997": 75, "025998": [18, 62, 63, 93], "026032": 41, "0261": [22, 41, 61, 65], "026145": 65, "026169": 19, "026378": 65, "026408": 22, "026616": 38, "026620": 65, "026631": 24, "026667": 38, "02677": 65, "026777": [41, 65], "02677733855112973": [41, 65], "026793": [24, 26, 35, 43, 45, 54, 55, 67, 69, 78], "026816": 19, "026896": 19, "026898": 27, "027": 69, "027075": 38, "027102": 19, "027112": [52, 76, 96], "027304": 95, "027321": [27, 46, 70], "027465": 19, "027521": 22, "027541": 24, "027725": 46, "027834": 24, "027949": 22, "027952": 65, "027965": 65, "028": 44, "028023": [23, 42, 66], "02807617": [31, 50, 51, 74], "028127": 24, "028177": 24, "028186": 38, "028236": 41, "028245": 27, "028337": [22, 41, 65], "028351": [22, 41, 65], "028353": 45, "02844": 22, "028647e": 77, "028651": 75, "028654": 32, "028672": [27, 46, 70], "028939": 22, "028971": 22, "029": [26, 31, 44, 50, 51, 68, 74], "029146": [23, 42, 66], "029164": [52, 76, 96], "029198": [22, 41, 65], "0292019089612867": 25, "029395": 38, "029418": 27, "029516": 22, "02952458891450549": 92, "029633": 48, "029909": 60, "029950e": 24, "02d": [33, 76], "03": [1, 15, 21, 22, 26, 31, 32, 33, 34, 37, 41, 45, 52, 64, 65, 67, 69, 75, 76, 77, 96], "030": [34, 50], "03017665e": [26, 45, 69], "030200": [18, 62], "030221": 61, "030408": [16, 61], "030466": 24, "03049217": [16, 61], "0305": [16, 61], "030566": 24, "030739733331869412": [21, 64], "030878": 24, "030952": 26, "030992": 24, "031": [26, 45, 50, 68, 74], "031011": 22, "031079": 24, "031103": 24, "031295": 24, "031326": 19, "031338": 32, "031339": 75, "031370": 26, "031385": [16, 61], "031564": [18, 62], "031605": 32, "031607": 75, "031791": 16, "031794": [24, 43, 67], "031835829826598": 41, "031836": 41, "0319": 51, "031963": 48, "031994": 45, "031997": 77, "032": 69, "032001": 38, "032139": 37, "03213916": 37, "032161": 77, "032314": 24, "032324": [41, 65], "032330": 24, "032404": [22, 41, 65], "032514": 77, "032516": 45, "032566": [19, 63], "03256625": [19, 63], "032624": 24, "032656": [16, 61], "032660": 38, "032874": [16, 61], "033": [44, 77], "033112": [32, 75], "033222": 77, "033267": [33, 76], "033279": [26, 45, 69], "033341": 22, "033348": [20, 40], "033459": [16, 61], "033477": 16, "0335": 65, "033625": 22, "033706": [22, 80], "033722": 24, "033780": 77, "033833": [66, 80], "033893": 24, "0339": [18, 62], "033993": 38, "034": [25, 26, 68], "034071": [23, 42, 66, 80], "03411038e": [26, 45, 69], "0344": [22, 41, 61, 65], "034462": 16, "034483": 95, "034543": 27, "034544": 19, "034979e": 24, "035": [32, 75], "0351": [18, 62], "035132": 22, "03516073": [26, 45, 69], "035161": [26, 45, 69], "035230": [52, 76, 96], "035300": 24, "035331": 66, "035363": 24, "035461": 48, "035583": 66, "035616": 27, "036": [18, 32, 44, 62, 75], "036136": [27, 46, 70], "0362": [18, 62], "036232": [32, 75], "036262": 66, "036351": 66, "036646": [24, 43, 67], "036656": 16, "036764": [23, 42, 66, 80], "036821": 22, "036869": 41, "036973": 24, "037": 25, "0370": [18, 62], "037012": 18, "037037": 95, "037161": 41, "037211": 24, "0373": [18, 62], "037333": 27, "037414": [52, 76, 96], "037544": 18, "037578": 41, "037627": 18, "037785": [23, 42, 66, 80], "0378": [18, 34, 62, 77], "037820": 18, "037835": 22, "038102": [21, 64], "038283": 18, "038287": 26, "038324": 24, "038395": 22, "038495": 32, "038498": 75, "038707": [45, 69], "038838": 24, "038873": 38, "038920": 24, "039": [26, 32, 44, 68, 75], "0392": 22, "039284": 65, "039344": [53, 77], "039498": [21, 64], "039739": 38, "03976": 22, "0399": [18, 62], "04": [1, 15, 17, 18, 24, 26, 33, 34, 37, 39, 45, 52, 62, 63, 65, 67, 69, 76, 77, 93, 96], "040": 18, "040000": 38, "040000e": [15, 37], "040129": [34, 77], "040142": 18, "040180": 67, "040448": [23, 42], "040497": [23, 42, 66], "040561": 38, "040698e": [24, 67], "040954": 77, "040984": [33, 76], "040992": 24, "041": [32, 75], "041031": [23, 42, 66], "041043": 95, "04108378": [21, 64], "041084": [21, 64], "041129": [16, 61], "041201": [23, 42, 66], "041212": 24, "041501": 18, "041578": 66, "041658": 18, "041704": [45, 69], "041716": [20, 40], "041737": 45, "041858": 26, "042081": [26, 45, 69], "042230": 18, "042236": 22, "042291": 22, "042382": [27, 46, 70], "042726": 24, "042740": 43, "042797": 18, "042957": [18, 62, 63, 93], "043": 65, "043196": 25, "043257": 63, "043305": 24, "043319": [26, 45, 69], "043377": 24, "043509": 65, "0437": [16, 59, 60, 61, 91], "043812": 27, "043890": [16, 61], "044": [22, 25, 41, 44, 61, 65], "044029": [18, 62, 63, 93], "044166": [21, 64], "044242": 26, "044253": [45, 69], "044313": [18, 62], "044383": 27, "044873": 60, "045": [15, 25, 32, 37, 59, 68, 75], "045199e": 24, "045267": [33, 76], "045277": 62, "045304": [16, 61], "045461": 41, "045481": [52, 76, 96], "045556": 23, "046": [32, 75], "04600e": 61, "046020": [16, 61], "046115": 38, "046116": 65, "046192": 65, "046193e": 24, "046626": 27, "046638": 63, "046702": 77, "0468": [34, 53, 77], "046882": 65, "0469": [18, 62], "047": 25, "04709519e": [26, 45, 69], "047174": 77, "047328": 27, "0474": [21, 64], "047464": 24, "04774884": [28, 71], "047749": [28, 71], "047810": 77, "047869": 24, "047958": 22, "047982": 27, "048": [15, 60, 63], "048022": 77, "048084": 22, "048304": 77, "048378": 60, "048418": 27, "04861878": [28, 71], "048630": [33, 76], "04881": 22, "048860": [18, 62], "048889": [24, 43, 67], "048949": 24, "049": [32, 63, 68, 75], "049083": [34, 53, 77], "049096": 38, "05": [1, 15, 17, 18, 23, 24, 29, 33, 34, 35, 37, 39, 42, 50, 52, 55, 61, 62, 65, 66, 72, 74, 76, 77, 78, 96], "050": [32, 58, 60, 75], "050000": 92, "050132": [18, 62, 63, 93], "050272": 41, "050306": 22, "050307": [34, 77], "050402": 22, "051": [32, 75], "051269": [18, 62, 63, 93], "05137470e": [26, 45, 69], "051472": [16, 61], "051577": 94, "051620": [18, 62], "05177790160774991": 41, "051778": 41, "051925": 65, "052": [18, 25, 62], "052349": [18, 62], "052607": 66, "052790": [23, 42, 66], "052819": [23, 42, 66], "05290827e": [26, 45, 69], "053144": 22, "053156": [28, 71], "05350962": 83, "0537": 65, "053763": 60, "053839": 22, "053862": 22, "053918": 65, "054054": 66, "054189": 95, "05422496": 17, "054225": [17, 39], "054461": [23, 42, 66], "054653": [19, 63], "05465323": [19, 63], "054669": [24, 26, 35, 43, 45, 54, 55, 67, 69, 78], "054757": 94, "054784": [19, 63], "05478443": [19, 63], "054973": 41, "054988": 22, "055": [18, 62], "055100": 65, "055197": 22, "055261": 38, "055302": 48, "055345": [44, 68], "055508": [20, 40], "055915e": [24, 67], "05598498": [19, 63], "055985": [19, 63], "056": [32, 75], "056478": [18, 62, 63], "05656664": 51, "056599": 38, "056703": [23, 42, 66], "056777": 40, "056955": 60, "057": [18, 32, 62, 75], "057003": [16, 61], "057028": 41, "057254": [34, 77], "057267": [34, 53, 77], "057296": [23, 42, 66, 80], "057333": 24, "057569": 40, "057598": 40, "057646": [16, 61], "057729": [23, 42, 66], "057732e": 77, "057793": [18, 62, 63, 93], "057910": [18, 62, 63], "058": 31, "0580": [21, 60, 64], "058176": [35, 54, 55, 78], "058259": 40, "058320": 41, "058437": 22, "058621": [20, 40], "058770e": 77, "059": [18, 31, 58, 62, 68, 74], "059077": [23, 42, 66, 80], "0591": [18, 62], "059183": 46, "059242": [18, 62, 63, 93], "059261": 40, "059406": 65, "059411": 24, "059816": 77, "059863": [16, 61], "059919": 26, "06": [1, 15, 18, 24, 29, 31, 32, 33, 34, 37, 50, 51, 52, 62, 65, 72, 74, 75, 76, 77, 83, 96], "060": [32, 69, 75], "060012": 65, "060019": 96, "060034": 22, "060543": 70, "061091": 41, "061100": [18, 62], "061164": 65, "061206": [23, 42, 66, 80], "061241": [16, 61], "061449": 22, "061641": 77, "061937": [16, 61], "061972": 92, "062": [22, 41, 58, 61, 65], "062060": 66, "062293": 77, "062449": [34, 77], "062566": 65, "062658e": [24, 67], "062702": [23, 42], "062723": 60, "062792": [16, 61], "062793": [51, 82], "062809": 66, "062822": 41, "062990": 41, "063": 25, "063004": 70, "063110": [18, 62, 63, 93], "063119": 22, "063173": [26, 45, 69], "063730": 77, "063772": [34, 53, 77], "064": 65, "064067": 66, "064200": [16, 61], "064205": 60, "064307": [27, 46, 70], "064452": [16, 61], "064604": 41, "065": [32, 75], "065183": 65, "065449": [24, 43, 67], "065463": [23, 42, 66], "065646": 41, "065805": 77, "065841": 23, "065849": [34, 77], "06597868": 20, "066166": 77, "066191": 22, "066251": 60, "066333": 77, "066341": 65, "066445": 62, "066512": 38, "066551": 65, "066614": 41, "066667": [18, 62], "066706": 46, "0667579112160865": [21, 64], "066810": 77, "066854": [20, 40], "066915": 41, "066944": 65, "067": [26, 44, 68], "067100": 38, "06717": 48, "067387": 22, "067499": 77, "067604": [20, 40], "067781": [34, 77], "067879": 77, "067925": 22, "067929": 65, "06797961": [24, 43, 67], "067990": [34, 77], "067991": [18, 62], "067994": [53, 77], "068": 58, "068042": 77, "068214": [21, 64], "06835056": 37, "068351": 37, "068427": 38, "068468": 41, "068648": 65, "068689": 77, "068706": [34, 77], "068709": 41, "068800e": [15, 37], "068817": 77, "068871": 41, "068939": 65, "069": [15, 25, 37], "069128": 41, "069145": 77, "069150": [26, 45, 69], "06915047": [26, 45, 69], "069188": 77, "069192": [34, 77], "069200": 41, "069302": 77, "0694": [22, 41, 61, 65], "069530": [16, 61], "069602": 41, "069644": 77, "069653": 77, "069800": 24, "069839": 65, "069953": [20, 40], "07": [1, 17, 24, 27, 31, 33, 34, 39, 46, 50, 52, 58, 65, 70, 74, 76, 77, 96], "07014": 41, "070142": 41, "070749": 65, "070841": 77, "070850": [23, 42, 66], "070898": [53, 77], "070911": 22, "070929": [23, 42, 66], "070954": 41, "071": [32, 62, 75], "071257": 41, "071301": 65, "071330": [52, 76, 96], "071515": 77, "071541": [18, 62, 63, 93], "071652": 22, "071654": [27, 46, 70], "071742": 41, "07174468998": 24, "07174469237": 43, "07174469245": 67, "071745": [45, 69], "071787": 77, "071838": 41, "071841": 65, "071932": 41, "071975": [27, 46, 70], "071987": 41, "072167": [20, 40], "072176": 77, "072243": [26, 45, 69], "072286": 77, "0723": [18, 62], "072306": 41, "072416": 41, "07245741": [24, 43, 67], "07262": 41, "072725": 23, "072881": 77, "072907": 41, "072935": 41, "072954": 77, "073016": [35, 54, 55, 78], "073195": 41, "073233": [21, 64], "073812": 41, "073849": 41, "073977": 65, "074": [18, 44, 62], "074074": 95, "0741": [16, 61], "074141": [16, 61], "074203": 62, "074216": 22, "074533": 41, "074701": 41, "074719": [19, 63], "07471942": [19, 63], "074765": 41, "074773": 60, "074853": [35, 54, 55, 78], "075": 25, "075000": [30, 49, 73], "075006": 22, "075009": [20, 40], "075042": [34, 77], "075063": [53, 77], "075077": 41, "075117": 62, "075170": [52, 76], "075453": [34, 77], "075467": [34, 77], "075517": 41, "075644": 65, "075668": 38, "075786": 77, "076018": 38, "076104": [24, 43, 67], "0762": [18, 62], "076284": [28, 71], "076464": 65, "076469": 41, "076476": 65, "076533": [24, 43, 67], "076798": [16, 61], "076862": 65, "076987": 41, "077": [25, 32, 75], "077039": 41, "077149": 41, "077204": [45, 69], "077717": 94, "077749": [51, 82], "077761": 77, "077887": 26, "077911e": 65, "077951": 41, "077953": 77, "078": [21, 26, 64], "0780": [59, 60, 91], "07804": 22, "078052": [23, 42, 66], "07808506982896264": 67, "07808506982896268": 24, "078268": 94, "078283": 65, "078318": 94, "078321": 41, "078387": [34, 77], "078622": 65, "078701": 23, "078732": 77, "07877994e": 83, "078851": 23, "078855": 94, "078880": 63, "078903": 41, "078995": 41, "079": 65, "079164": 62, "079238": 65, "079377": [34, 77], "0794": [22, 41, 61, 65], "079471e": [24, 67], "079477": 41, "079489": 94, "079852e": [24, 67], "079957": 65, "08": [18, 24, 27, 29, 31, 32, 33, 34, 46, 52, 62, 65, 67, 70, 72, 75, 76, 77, 90, 96], "080": [32, 75], "08002986030": [19, 63], "080112": 65, "080190": 96, "080238": 94, "080319": [19, 63], "08031924": [19, 63], "080355": 22, "080674": 41, "080694": [26, 45, 69], "080723": 94, "0808": 65, "081": [18, 58], "081040": 41, "081167": 77, "081292": [52, 76, 96], "081354": 94, "081458": 41, "08151507e": [26, 45, 69], "081548": 65, "08162": 41, "081658": 65, "08183": 65, "081837": [34, 77], "081981": 65, "082": 45, "082100": 65, "082251": [21, 64], "082265e": 77, "082353": 95, "082726": 24, "082749": [16, 61], "082835": [26, 45, 69], "082841": 94, "082949": [16, 61], "083": [22, 41, 61, 65], "083123": [18, 62, 63, 93], "083308": [34, 77], "083338": 60, "08338644": [31, 50, 51, 74], "083458": 24, "083545": [23, 42, 66], "083701": 41, "083813": [18, 62, 63, 93], "083836": 60, "083845": 41, "083943": 41, "084176": [34, 77], "084264": 24, "084286": 22, "084314": [34, 77], "084347": 23, "084489": 41, "084490": [35, 54, 55, 78], "084686": 38, "084746": [18, 62, 63], "085": 25, "085150": [33, 76], "085192": 60, "085292": 22, "085415": [26, 35, 45, 54, 55, 69, 78], "085477": [23, 42, 66, 80], "085508": 24, "085546": 24, "085550": 24, "085551": 24, "085698": 24, "085772": 41, "086": [50, 74], "086078": 38, "086085": 25, "086266": 41, "0864": 22, "08642578": [31, 50, 51, 74], "086461": [27, 46, 70], "086517": [15, 37], "086573": 65, "086830": 41, "086877": [34, 77], "086932": 60, "086985": 48, "087046": 65, "087194": 65, "087397": [20, 40], "08740234": [31, 50, 51, 74], "08791477": [31, 50, 51, 74], "088": [32, 75], "0880": [18, 62], "088193": [34, 77], "088353": 60, "088373": 60, "088616": 65, "088699": 65, "088710": 41, "088740": 65, "088772": 41, "088811": 41, "088948": [16, 61], "089156": 75, "089163": 32, "089571": 41, "089756": 22, "09": [1, 15, 24, 31, 33, 34, 37, 50, 52, 60, 63, 65, 66, 67, 74, 76, 77, 96, 98], "090000": [23, 42, 66], "090025": 24, "09009799": [24, 43, 67], "090165": 65, "090177": 65, "090231": [26, 45, 69], "090376e": 24, "090453": [23, 42, 66], "090580": 38, "09058097218": 58, "090765": 77, "090785": 24, "090950": 94, "090978": [15, 37], "091": [32, 75], "091030": 65, "091177": 65, "091410": 41, "091468": 22, "091491": [32, 75], "091579": 65, "091582": 41, "091625": [27, 46, 70], "091632": 38, "091793": 48, "091819": 60, "091988": 48, "092117": 41, "0922": [22, 41, 61, 65], "092396": 75, "092399": 32, "09245358900622544": 65, "092454": 65, "092462": 24, "092515": 65, "092604": 60, "092606": 65, "092660": [34, 77], "092728": 41, "092930": [19, 63], "09293048": 19, "0931": 65, "093228": [27, 46, 70], "093255": 22, "093350": [35, 54, 55, 78], "093390": [16, 61], "09345386": [19, 63], "093454": [19, 63], "093482": 22, "093868": 22, "094": [31, 50, 51, 58, 74], "094077": 65, "09425": 41, "094267": 60, "094290": [34, 77], "09430199": [19, 63], "094302": [19, 63], "094568": 41, "09458052": 19, "094581": [19, 63], "094586": [23, 42, 66, 80], "095": 44, "09503409246217502": 24, "095043": 65, "095101": 22, "095304": 65, "09573445": [22, 41, 65], "095812": 65, "095852": 48, "095912": 22, "095969": 41, "096": 44, "09619141": [31, 50, 51, 74], "096448": 24, "096462": 24, "096476": 96, "096482": 22, "096692": [18, 62], "096824": 22, "096825": 26, "096833": 60, "096927": 66, "096960": [24, 67], "097": [32, 44, 75], "09706504": [32, 75], "097088": [34, 77], "097123": 22, "097293": [18, 62, 63, 93], "097516": [18, 62], "097681": 41, "098": [21, 32, 64, 75], "098031": 41, "098070": [53, 77], "098082": 22, "098189": 22, "098295": 65, "098307": [24, 67], "098326": [16, 61], "098335": 22, "098674": 65, "098676": 41, "098787": 38, "098803": 22, "098888": 22, "09891476780532049": [21, 64], "098915": [21, 64], "098966": [18, 62], "098995": 22, "099": 68, "099230": [26, 45, 69], "099240": [18, 62, 63, 93], "099558": [18, 62, 63, 93], "099685": [24, 67], "099704": 22, "099723": [18, 62], "099749": [52, 76, 96], "0x00000174e2149b20": 17, "0x1227a36e0": 9, "0x12e647cb0": 65, "0x12e647e00": 65, "0x12f15ce10": 65, "0x15173cad0": 41, "0x15173cc20": 41, "0x151976490": 41, "0x15a765d10": 38, "1": [1, 5, 8, 9, 10, 17, 20, 23, 26, 31, 32, 33, 37, 38, 39, 40, 42, 43, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 56, 57, 69, 73, 74, 75, 76, 79, 80, 81, 82, 83, 89, 95, 98], "10": [1, 4, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 37, 38, 39, 40, 41, 42, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 58, 59, 60, 61, 62, 63, 64, 65, 66, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 80, 82, 83, 84, 85, 86, 90, 91, 92, 93, 95, 96, 98], "100": [13, 15, 16, 17, 18, 19, 20, 21, 22, 24, 25, 27, 28, 29, 31, 32, 33, 34, 35, 38, 39, 40, 41, 43, 44, 45, 46, 47, 50, 51, 52, 53, 54, 55, 59, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 74, 75, 76, 77, 78, 80, 81, 94, 95, 96, 97], "1000": [13, 15, 16, 20, 21, 22, 23, 24, 27, 32, 34, 35, 40, 41, 42, 43, 45, 46, 52, 53, 55, 60, 61, 64, 65, 66, 67, 69, 70, 75, 76, 77, 78, 80, 81, 83, 92, 96], "10000": [13, 15, 20, 21, 22, 24, 37, 40, 41, 52, 59, 63, 64, 65, 76, 96], "100000": [13, 16, 19, 21, 22, 24, 41, 52, 61, 63, 64, 65, 76, 96], "1000000": [17, 39, 65], "1001": 34, "100103": [52, 76], "100139": [19, 63], "10013934": 19, "100146": [52, 76], "1002": 34, "100248": [16, 61], "100253": 41, "100275": [27, 46, 70], "1003": [34, 98], "1004": [16, 34, 61], "10041668266057968": [50, 74], "10041749477386475": 31, "1005": [52, 76, 96], "100592": [32, 75], "1006": [52, 76, 96], "1007": [52, 76, 96], "1008": [52, 76, 96], "10083": [15, 37], "100833": 94, "100882": [23, 42, 66, 80], "1009": [52, 76, 96], "10092665203438746": 67, "10092665203438769": 24, "100970": [34, 77], "101": [1, 10, 13, 20, 28, 32, 34, 47, 48, 63, 68, 71, 75, 77, 98], "1010": [52, 76, 96], "1012": [52, 76, 96], "101259": 24, "101297": 22, "1014": [32, 38, 65, 75], "101406": 48, "101439": 48, "101444": 41, "1015": [32, 38, 52, 75, 76, 96], "1016": [32, 38, 52, 75, 76, 96], "101688": 65, "101699": 77, "1017": [32, 38, 52, 75, 76, 96], "101796": [24, 67], "1018": [32, 38, 52, 75, 76, 96], "101894": 66, "1019": [32, 38, 52, 75, 76, 96], "102": [1, 17, 23, 24, 34, 39, 42, 43, 66, 67, 68, 88, 94, 96, 98], "1020": [15, 27, 32, 37, 38, 46, 52, 65, 70, 75, 76, 96], "102044": [27, 46, 70], "102050": 65, "1021": [32, 38, 52, 75, 76, 96], "102135": [23, 42, 66, 80], "1022": [32, 38, 52, 75, 76, 96], "1023": [32, 38, 52, 75, 76, 96], "1024": [32, 38, 47, 48, 52, 75, 76, 96], "102435": [16, 24, 61, 67], "102463": 65, "102474": [19, 63], "10247431": [19, 63], "102485": 24, "102498": 94, "1025": [52, 76, 96], "10254": [33, 76], "1026": [16, 21, 25, 26, 28, 52, 64, 76], "102629": 65, "102694": [44, 68], "1027": [52, 76, 96], "10273": [24, 43, 67], "10274": 66, "102773": 41, "1028": [52, 76, 96], "1029": [52, 76, 96], "102918": 22, "103": [1, 5, 13, 44, 47, 68, 77, 98], "1031": [52, 76], "103122": 65, "103137": 41, "103147": 22, "103219": [27, 46, 70], "103244": 65, "1034": [27, 46, 70], "103439": [19, 63], "10343943": 19, "103448": 95, "103464": 22, "103520": [32, 75], "103846274635209263023": 22, "103886": 22, "1039": [52, 76, 96], "103917": 41, "104": [16, 18, 28, 32, 34, 61, 62, 71, 75], "1040": [18, 62], "104060": 65, "104070": [24, 67], "1041": [24, 26, 43, 45, 52, 67, 69, 76, 96], "10416666666666667": [30, 49, 73], "1042": [41, 65], "104235": [53, 77], "104294": 32, "1043": [19, 63], "1044": 58, "104643": [24, 43, 67], "105": [15, 44], "1050": [15, 37, 59], "105080": [27, 46, 70], "105089": [19, 63], "10508947": 19, "10513": [33, 76], "105166": 92, "1052": 34, "1053": 34, "105314": [52, 76], "1054": 34, "105427": 77, "105498": 22, "1055": 34, "10556679": [28, 71], "1056": 34, "105656": [45, 69], "105661": 24, "1057": 34, "1058": 34, "10584062": 75, "10584063": 32, "1059": 34, "106": [17, 39, 44], "106000": [18, 62], "106023": [24, 67], "106112": [52, 76], "106180": [52, 76], "106234": 96, "106319": [52, 76], "106322": [52, 76], "106377": 76, "106424": [52, 76], "10644531": [31, 50, 51, 74], "106452": [16, 61], "10645223": [16, 61], "106453": 65, "10653": [52, 76, 96], "106705": [52, 76], "106724": 65, "106816": [52, 76], "10693359": [31, 50, 51, 74], "1070": [27, 46, 70], "107050": [52, 76], "107292": [52, 76], "107458": 48, "107502": [52, 76, 96], "1076": [15, 37], "107726": 22, "10781": [25, 26, 44, 45, 68, 69], "107838": 41, "107917": [52, 76, 96], "10793260e": [32, 75], "107947": [24, 67], "107985": [24, 67], "107991": 66, "108": [47, 58, 94], "1080": 58, "10800": 58, "108138": 22, "1084": 41, "108461": 65, "1085": [21, 64], "108521": 22, "10868": [33, 76], "108681": [16, 61], "10884": 41, "108840": 41, "1089": [24, 43, 67], "108918": 65, "10910": [33, 76], "109135": 22, "10931": 63, "109334": 65, "109526": 66, "109532": 65, "109577": 38, "1096": 63, "109699": 65, "1099": [24, 43, 67], "10_000": [20, 34, 40, 53, 77], "10th": [22, 25, 26, 44, 45, 65, 66, 68, 69], "10x": 66, "11": [1, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 33, 34, 37, 38, 39, 41, 42, 43, 45, 46, 47, 49, 50, 51, 52, 53, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 69, 70, 71, 72, 73, 74, 76, 77, 84, 92, 93, 94, 96, 98], "110": [21, 32, 41, 64, 75, 94], "1101": [18, 19], "110133": 65, "1102": 18, "110223e": 95, "1103": 18, "110316": [52, 76, 96], "110319": [52, 76, 96], "1104": [16, 18, 61], "110429": 65, "11057": [33, 76], "1106": [18, 27, 46, 70], "110645": 24, "1107": 18, "1108": 18, "1109": 18, "110915e": [24, 67], "110985": [53, 77], "111": [18, 23, 24, 34, 42, 53, 62, 65, 66, 77, 80], "1110": 18, "1111": 18, "1112": 18, "11121453": [28, 71], "111215": [28, 71], "111220": [33, 76], "111271": 22, "11129": 22, "1114": 18, "111438": [27, 46, 70], "1115": 18, "111543": 24, "1116": 18, "111668": 65, "111692": 22, "111770": 32, "111771": 75, "111793": 77, "111841": 41, "112": [16, 34, 61, 94], "1122": [24, 26, 43, 45, 67, 69], "1123": 65, "112442": 22, "112519": 77, "112821": 26, "112848": [24, 43, 67], "112977": 22, "113": [68, 94], "113033": 65, "113097": 65, "1131": [15, 37], "11336331e": [26, 45, 69], "113452": 75, "113458": 32, "113600": [18, 62, 63, 93], "1138": [27, 46, 70], "113815": 26, "113837": 24, "1139": [24, 26, 35, 43, 45, 54, 55, 67, 69, 78], "113949e": 77, "114": [18, 25, 62, 63], "1140": [24, 26, 35, 43, 45, 54, 55, 58, 67, 69, 78], "114000": [18, 27, 46, 62, 70], "114521": 26, "11457": [24, 26, 35, 43, 45, 54, 55, 67, 69, 78], "114757": [15, 37], "114766": [45, 69], "114836": [27, 46, 70], "114966": [45, 69], "114976": 65, "1150": 58, "115081": 65, "115083": [18, 62], "115089": [52, 76], "11509": [24, 43, 67], "115090": [52, 76], "115091": [52, 76], "115092": [52, 76], "115139": 26, "115230": 42, "115276": 77, "115289": 26, "115401": 24, "115406": [16, 61], "115428": [52, 76, 96], "11562": 65, "115782": 22, "115956": [21, 64], "116": [18, 47, 48, 62, 95], "116086": 65, "116145": [27, 46, 70], "116167": [21, 64], "116192": 41, "116395": 24, "116443": [27, 46, 70], "116497": 24, "116505": 95, "116587": 41, "116733": 22, "11693": [24, 43, 67], "117": [18, 21, 27, 39, 46, 62, 63, 64, 70, 93], "117058": [21, 64], "117378": 77, "117380": [18, 62], "117412": [24, 67], "117528": [27, 46, 70], "11758": [52, 76, 96], "117712": [52, 76], "117816": [18, 62], "117899e": 24, "1179": [18, 62], "118": [18, 21, 24, 26, 27, 35, 43, 45, 46, 54, 55, 62, 63, 64, 67, 69, 70, 78, 94], "1180": [15, 37, 59], "118142": 65, "118182": [18, 62, 63, 93], "118230": 25, "118281": 77, "118347": [24, 67], "118438": 41, "118450": [66, 80], "1185": 63, "118563": [27, 46, 70], "11860274523496628": 31, "11860340088605881": [50, 74], "11872": 58, "118835": 48, "11886432": [22, 41, 65], "118874": 24, "118934": [23, 42, 66, 80], "11898": [23, 42, 66], "119": [18, 21, 27, 46, 52, 62, 63, 64, 70, 76, 93, 96], "1190": [15, 18, 37, 62], "119049": [52, 76, 96], "119094": 77, "11909976": [28, 71], "119100": [28, 71], "119123": 38, "11914062": [31, 50, 51, 74], "119161": 38, "119269": 22, "119400": [18, 62], "119499": 22, "1195": 19, "119570": [27, 46, 70], "119834": 75, "119847": 32, "119911": [52, 76, 96], "11th": [25, 26, 44, 45, 66, 68, 69], "12": [1, 11, 14, 16, 17, 18, 19, 20, 21, 23, 24, 27, 28, 29, 30, 31, 33, 34, 35, 37, 38, 39, 41, 42, 43, 44, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 70, 71, 72, 73, 74, 76, 77, 78, 83, 84, 85, 86, 88, 89, 90, 91, 92, 94, 95, 96, 98], "120": [16, 17, 18, 21, 24, 32, 33, 39, 43, 47, 52, 61, 62, 64, 67, 75, 76, 83, 97], "1204": [16, 61], "120445": 41, "120769e": 24, "120929": 75, "120932": 32, "121": [15, 18, 21, 22, 25, 27, 33, 37, 41, 44, 46, 58, 62, 63, 64, 65, 68, 70, 76], "1210": 65, "121056e": 24, "121084e": 24, "1212": 41, "12138": [18, 62], "1214": [24, 43, 67], "121403": [53, 77], "121438": [34, 53, 77], "1215": 98, "121504": 22, "12150684": [21, 64], "121531": [23, 42, 66, 80], "121590": 48, "121598": 26, "121599": [26, 45, 69], "121628": [16, 61], "1217": [53, 77], "12178": [27, 46, 70], "121846": [45, 69], "12194": 92, "121985": [24, 67], "122": [15, 18, 27, 32, 37, 46, 47, 58, 59, 60, 62, 63, 70, 75, 88, 91, 94], "1220": [18, 58, 62, 65], "1222": [41, 65], "122210": 26, "122307": [18, 62, 63, 93], "122331": 24, "1225": 34, "122968": 24, "123": [4, 13, 15, 16, 17, 18, 20, 21, 22, 23, 24, 25, 26, 27, 32, 33, 34, 35, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 75, 76, 77, 78, 79, 80, 83, 86, 87, 91, 92, 93, 94, 95, 97], "123049e": [15, 37], "123215": 48, "123312": 22, "123367": 24, "123432": 24, "1235387316046016": [41, 65], "123539": [41, 65], "123826": 96, "123971": 22, "124": [18, 31, 48, 50, 51, 62, 74, 94], "1240": 58, "1241": [24, 27, 43, 46, 67, 70], "1242": 34, "1243": [18, 62], "12436984": [19, 63], "124370": [19, 63], "1247": [41, 65], "12483182": 20, "12498": [26, 45, 69], "124982": [27, 46, 70], "125": [9, 18, 24, 43, 47, 67, 94], "1250": [18, 62, 63, 93], "125000": [15, 37], "125036": 24, "12508": [24, 26, 35, 43, 45, 54, 55, 67, 69, 78], "125440e": [24, 67], "125476": [16, 61], "125523": [52, 76, 96], "125617": [52, 76, 96], "125644": 24, "1258": [34, 77], "125831": [34, 77], "126": [18, 25, 27, 41, 46, 70], "126011": [53, 77], "126231": 22, "126238": [27, 46, 70], "126278": 24, "126325": 24, "126398": [18, 62, 63, 93], "126488": [28, 71], "12649": [18, 62], "126500": [18, 62], "126563": 65, "126707": 48, "126808": [18, 62, 63, 93], "127": [18, 21, 56, 57, 60, 62, 64, 65, 79, 94], "127086": [18, 62], "127087": 77, "1271": [25, 44, 68], "127107": [26, 45, 69], "127203": 26, "127226": 63, "127242": 24, "1273": [26, 45, 69], "127326": [24, 67], "1274": [27, 46, 70], "127418": 24, "127439": 24, "127441": 24, "127614": [24, 43, 67], "12761659": [24, 67], "127652": 24, "12768": [15, 37], "127774": 24, "127878": [16, 61], "1279": [24, 43, 67], "1280": [18, 24, 41, 43, 62, 65, 67], "1281": [24, 43, 67, 83], "128188": [18, 62, 63, 93], "128384": [24, 67], "128522": [34, 77], "128528": [24, 43, 67], "128692": [45, 69], "1287": [15, 37], "128820": [52, 76], "128828": [52, 76], "128829": [52, 76], "128830": [52, 76], "12890625": [31, 50, 51, 74], "128984": [24, 43, 67], "129": [16, 21, 27, 34, 46, 61, 64, 68, 70, 77, 88, 94], "1290": [18, 62], "12906": 58, "129216": 65, "129257": [24, 43, 67], "12927": 58, "129300": [18, 62, 63, 93], "129459": [27, 46, 70], "129600": [24, 43, 67], "129900": [23, 42, 66], "129904": [24, 43, 67], "129985": [18, 62], "12th": [25, 26, 44, 45, 66, 68, 69], "13": [1, 9, 15, 16, 17, 18, 19, 20, 23, 24, 25, 26, 29, 30, 31, 33, 34, 37, 38, 39, 42, 43, 44, 45, 48, 49, 50, 51, 52, 53, 58, 59, 60, 61, 62, 63, 65, 66, 67, 68, 69, 72, 73, 74, 76, 77, 83, 84, 92, 93, 96, 98], "130": [16, 18, 24, 26, 27, 35, 43, 45, 46, 54, 55, 58, 59, 60, 61, 62, 63, 65, 67, 69, 70, 78, 91, 93, 94], "1300": [24, 26, 35, 43, 45, 54, 55, 67, 69, 78], "1302": 80, "130339": 24, "130395": [52, 76, 96], "1304": [16, 34, 35, 53, 54, 55, 61, 77, 78], "130432": [52, 76, 96], "1306": [56, 57, 79], "130666": 24, "130690e": [24, 67], "1307": [24, 43, 67], "130855": [45, 69], "130979": 65, "131": [17, 18, 34, 39, 52, 62, 76, 77], "131000": [24, 43, 67], "13107": [33, 76], "13119": 22, "131274": 22, "131275": 66, "131287": 48, "1313": [24, 43, 67], "1314": [24, 26, 35, 43, 45, 54, 55, 67, 69, 78], "131607": [24, 26, 35, 43, 45, 54, 55, 67, 69, 78], "131639": 32, "131640": 75, "13169": 92, "131773": [34, 77], "1319796954314723": [25, 44, 68], "132": [34, 77], "1320": [27, 46, 70], "1321": 58, "132158": [24, 67], "132292": [27, 46, 70], "13229595e": [26, 45, 69], "13255": [33, 76], "13265": 92, "132667": [23, 42], "132856": 24, "132875": [18, 62, 63, 93], "132886": [52, 76], "133": [34, 47, 65, 77], "133000": [24, 43, 67], "133270": [24, 67], "133337": [24, 43, 67], "133562": [34, 53, 77], "13375": 92, "133894": [23, 42], "13392236": [32, 75], "134": [21, 59, 60, 64, 91], "1340": [15, 37, 59], "134061": [27, 46, 70], "13407": [26, 45, 69], "134090": [34, 77], "134270": [20, 40], "134287": 66, "13452": 20, "1346": [18, 24, 26, 27, 34, 43, 45, 46, 62, 67, 69, 70, 77], "134615": [21, 64], "134658": [18, 62], "134728": 24, "13476562": [31, 50, 51, 74], "134894": [52, 76, 96], "135": [25, 34, 52, 76, 77, 96], "1350": [15, 37], "135032": 22, "135134": [52, 76, 96], "135197": [52, 76, 96], "13521135": [26, 45, 69], "135299": [27, 46, 70], "135305": [18, 62, 63, 93], "135384": 24, "13540": [15, 37], "135422": [24, 43, 67], "1357": [15, 37, 58], "135706": 24, "136": [18, 34, 62, 96], "1360": [15, 37, 59], "1364": 18, "1365": 18, "1366": 18, "136646": 67, "13665": [18, 62, 63, 93], "136714": [23, 42, 66, 80], "1368": 18, "137": 34, "1370": [18, 22, 34, 41, 53, 58, 61, 65, 77], "13704": [24, 26, 35, 43, 45, 54, 55, 67, 69, 78], "1371": 18, "1372": [18, 35, 54, 55, 78], "137239": 24, "137269": 24, "1373": 18, "1374": 18, "137410": [28, 71], "1375": 18, "137500": [18, 62, 63, 93], "1376": 18, "1377": 18, "13775911927223206": [50, 74], "1377594769001007": 31, "137796": 95, "1378": [18, 24, 43, 67], "1379": 18, "138": [34, 47, 48, 94], "1380": [18, 58], "1381": 18, "1382": 18, "1383": [18, 65], "1384": 18, "138417": 95, "1384684145450592": [50, 74], "13846909999847412": 31, "1385": [18, 34], "138503": [27, 46, 70], "138528": [21, 64], "138564": [15, 37], "138571": [20, 40], "1386": [18, 34], "138603": 95, "1387": [18, 34], "1388": [18, 34], "138876": 77, "1389": [18, 24, 26, 34, 43, 45, 62, 67, 69], "139": [18, 19, 34, 62], "1390": 58, "139297": [23, 42, 66], "139317": 80, "139322": [23, 42, 66, 80], "139349": [23, 42, 66], "13941": 66, "139412": [53, 77], "139554": 80, "1396": 65, "1397": [41, 65], "139863": 65, "139912": 65, "139943": 92, "14": [1, 15, 16, 17, 18, 19, 22, 23, 24, 26, 29, 30, 31, 32, 33, 34, 37, 38, 39, 42, 43, 45, 46, 47, 48, 49, 50, 51, 52, 53, 58, 59, 60, 61, 62, 63, 65, 66, 67, 69, 72, 73, 74, 75, 76, 77, 84, 89, 92, 95, 96, 98], "140": [18, 62, 94], "140185": [27, 46, 70], "140210": [32, 75], "140371": 38, "1404": [16, 34, 53, 61, 77], "1405": [27, 46, 70], "1406": [18, 24, 26, 43, 45, 62, 67, 69], "140631": [34, 77], "140641": [52, 76, 96], "140828": [15, 37], "140953": [52, 76, 96], "140986": 96, "141": [18, 21, 62, 64], "1410": [15, 37], "141056": 95, "141232": [52, 76, 96], "14159265358979323": 9, "14160": 66, "14176653": 37, "141851": [52, 76, 96], "142": 31, "142051e": [15, 37], "142193": [52, 76, 96], "142199": [52, 76, 96], "1423": 80, "142348": 24, "142375": 24, "142398": [52, 76, 96], "142424e": 65, "142467": 60, "142653": 75, "142654": 32, "1427": [15, 35, 37, 54, 55, 78], "142806": [52, 76, 96], "142857": 63, "14289": [18, 62, 63, 93], "14294": 92, "143": [23, 42, 47, 65, 66], "143491": [34, 77], "143693": [52, 76, 96], "143803": [27, 46, 70], "1438387200": [33, 76], "1438398000": [33, 76], "1438408800": [33, 76], "1438419600": [33, 76], "1438430400": [33, 76], "1438441200": [33, 76], "1438452000": [33, 76], "1438462800": [33, 76], "1438473600": [33, 76], "1438484400": [33, 76], "143975": [52, 76, 96], "144": [58, 65], "144000": [24, 26, 35, 43, 45, 54, 55, 67, 69, 78], "14419": 92, "144199": [52, 76, 96], "144246": 24, "144450": 24, "144686": [26, 45, 69], "14471": [18, 62, 63, 93], "144728": 76, "144729": [52, 76, 96], "144730": [52, 76, 96], "144731": [52, 76, 96], "144732": [52, 76, 96], "144733": [52, 76, 96], "144750": [16, 61], "14485": [24, 43, 67], "144851": 23, "145": [38, 48, 52, 76, 94, 96], "145185": 38, "1452": [27, 46, 70], "145425": [24, 43, 67], "145454": [52, 76, 96], "145455": [52, 76, 96], "145456": [52, 76, 96], "145457": [52, 76, 96], "145458": [52, 76, 96], "145459": [52, 76, 96], "145460": [52, 76, 96], "1457": [18, 34, 62, 63, 77, 93], "14579": [27, 46, 70], "1458": [18, 62, 63, 93], "145833": [30, 49, 73], "146": [35, 38, 54, 55, 58, 78], "1460": [24, 34, 43, 67, 77], "14648438": [31, 50, 51, 74], "1465": [18, 62, 63, 93], "146621": 42, "146656": [52, 76, 96], "146673": 41, "146681": [53, 77], "1467": [27, 46, 70], "146767": [26, 45, 66, 69], "146809": [23, 42, 66], "146830": [23, 42, 66, 80], "14690": 63, "146987": [34, 77], "147": [26, 35, 38, 45, 54, 55, 63, 69, 78], "147166": [25, 26, 44, 45, 68, 69], "14716638": [26, 45, 69], "1472": [17, 39], "147401": [53, 77], "14751": 65, "147641": [24, 43, 67], "147893": [18, 62], "147898": [23, 42, 66], "147932": [53, 77], "147944": 65, "148": [22, 25, 26, 38, 39, 41, 45, 61, 65, 69], "14813": [33, 76], "148148e": 95, "148227": 77, "148273": 95, "148343": [24, 43, 67], "148349": [34, 53, 77], "14841": 66, "148437": 66, "148684": 41, "1486840817915398": 41, "149": [34, 38, 53, 77], "1490": [15, 37], "149122": 79, "14970": [18, 62], "149788": [26, 45, 69], "149822": [18, 62, 63, 93], "14999": [18, 62], "15": [1, 9, 14, 15, 16, 17, 18, 19, 22, 23, 24, 25, 26, 27, 29, 30, 31, 32, 33, 34, 37, 38, 39, 41, 42, 43, 44, 46, 49, 50, 51, 52, 53, 59, 60, 61, 62, 63, 65, 66, 67, 68, 69, 70, 71, 73, 74, 76, 77, 81, 84, 85, 91, 92, 96, 97, 98], "150": [22, 24, 32, 35, 38, 41, 43, 47, 55, 61, 65, 67, 78, 94], "1500": [17, 39], "150000": [23, 30, 42, 49, 66, 73], "1501": 96, "150115": 65, "15026771": [24, 67], "150395": [16, 61], "1504": [16, 61], "1505": [18, 62], "150528": 47, "1509": [15, 37], "150999": [34, 77], "150mb": [23, 42, 66], "150p": 58, "151": 25, "151357": [27, 46, 70], "1514": [56, 57, 79], "151508": 24, "152": [18, 33, 47, 76], "1520": [63, 65], "152148": 93, "1523300141": [15, 37], "1523300157": [15, 37], "152401": [23, 42, 66], "152455": [44, 68], "152475": 24, "152691": 38, "152859": [23, 42, 66, 80], "152934": 65, "153": 18, "1530": [15, 37, 58], "1531": 19, "153164": 75, "153165": 32, "153376": 48, "1534": [18, 62], "15377": [18, 20, 27, 46, 62, 70], "153792": [53, 77], "1538": [16, 25, 26, 28], "154": 18, "1540": 58, "154076": [26, 45, 66, 69], "154105": [27, 46, 70], "15429": [33, 76], "154386": [18, 62, 63], "1544": 96, "1545": [27, 46, 70], "154556": [53, 77], "1547": 34, "154795": [24, 26, 35, 43, 45, 54, 55, 67, 69, 78], "1548": 34, "154842": [34, 77], "154883": 38, "154883837629511": [44, 68], "1549": 34, "155": [18, 41, 58, 65], "1550": 34, "15500": [24, 43, 67], "1551": 34, "155178e": 24, "1552": 34, "1553": 34, "1554": 34, "15559528e": [26, 45, 69], "155624": [24, 43, 67], "155625": 96, "155637": [34, 77], "155900": [15, 37], "156": [18, 23, 41, 42, 47, 62, 65, 66, 80, 94], "1560": [15, 37], "1562": 65, "156245": 24, "156311e": 24, "1564": [65, 96], "15661": [33, 76], "156906": 65, "157": [18, 32, 41, 58, 65, 75, 94], "157008": [24, 43, 67], "157115": 65, "157234": [27, 46, 70], "15725": [18, 20, 27, 46, 62, 70], "157571": 38, "15775": [33, 76], "1578": [26, 45, 69], "157877": 48, "15795": [26, 45, 66, 69], "157993": [23, 42], "158": [41, 47, 65], "1580": 58, "15813": 92, "158170": 24, "1582": [26, 45, 69], "158709": 77, "158792": 48, "158867": [52, 76, 96], "158982": [24, 43, 67], "159": [41, 65, 69], "1590": [22, 41, 61, 65], "15915": [33, 76], "159347": [53, 77], "159750": 48, "159751": 38, "159776": 77, "15992": [26, 45, 69], "16": [1, 13, 14, 15, 16, 18, 19, 21, 22, 23, 24, 27, 31, 33, 34, 37, 41, 42, 43, 46, 48, 50, 51, 52, 53, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 70, 74, 76, 77, 79, 84, 85, 89, 91, 92, 95, 96, 98], "160": [21, 22, 24, 41, 43, 48, 60, 61, 64, 65, 67, 86, 92, 94], "1600": [15, 37], "160000": [24, 26, 35, 43, 45, 54, 55, 67, 69, 78], "160213e": 24, "160258": 60, "160282": [27, 46, 70], "1604": [16, 61], "160506": [23, 42, 66], "1606": 41, "16063983": [19, 63], "160640": [19, 63], "160727": [26, 45, 69], "160729": [52, 76, 96], "161": [17, 18, 39, 45, 62], "161001": [53, 77], "1610243052583633": [21, 64], "1611": 98, "16111330565237114": [21, 64], "1613": [18, 62], "161300e": [15, 37], "161339": 77, "161429": 38, "16153": [33, 76], "16157": [33, 76], "16160": [33, 76], "161606": [18, 62, 63, 93], "161782": [23, 42, 66, 80], "1619": [41, 65], "161931": [24, 26, 35, 43, 45, 54, 55, 67, 69, 78], "161932": 24, "162": [47, 58], "162000": [24, 43, 67], "162214": [35, 54, 55, 78], "162330": [23, 42, 66], "162458": 42, "162667": [26, 45, 66, 69], "1627": [27, 46, 70], "162747": [32, 75], "162904": [53, 77], "163": [15, 37], "1631": 65, "163195": [18, 62, 63, 93], "163397": [18, 62, 63, 93], "1634": [18, 41, 62, 63, 65, 93], "163466": 24, "163541": 77, "16358": [33, 76], "164": [27, 32, 46, 70, 75], "164358": 42, "1645": [21, 64], "16460": [27, 46, 70], "164679": [23, 42, 66], "164706": 95, "164960": [53, 77], "165": [21, 24, 43, 47, 64, 67, 83], "1650": [22, 41, 61, 65], "16507": [21, 27, 46, 64, 70], "16508": [21, 27, 46, 64, 70], "16509": [21, 27, 46, 64, 70], "16510": [21, 27, 46, 64, 70], "16511": [21, 27, 46, 64, 70], "16512": [21, 27, 46, 64, 70], "1652": [21, 60, 64], "16533": [33, 76], "165485": [26, 45, 69], "165617": [33, 76], "165713": [34, 77], "165811": 65, "16630": [27, 46, 70], "166631": [18, 62, 63, 93], "166636": 48, "167": [18, 60], "167214": [16, 61], "167600": [27, 46, 70], "168": [18, 24, 43, 47, 67], "1680": [15, 37, 59], "168196": [18, 62, 63, 93], "168244": [26, 45, 69], "1683": 92, "1687": 65, "169": [18, 21, 27, 46, 47, 60, 64, 70], "1690": [15, 37, 58, 59], "1691": 41, "169269e": 77, "169570": 42, "169693": [16, 61], "169748": [21, 64], "16991815": 9, "1699181533555938": 9, "17": [1, 4, 9, 15, 16, 17, 18, 19, 21, 22, 23, 24, 25, 27, 33, 34, 37, 39, 42, 43, 46, 48, 49, 51, 52, 53, 59, 61, 62, 63, 64, 65, 66, 67, 70, 73, 76, 77, 84, 92, 93, 95, 96, 98], "170": [18, 29, 62, 72], "17000249028205872": 31, "1700027883052826": [50, 74], "170071": 48, "170100": [18, 62, 63, 93], "170277": [25, 26, 44, 45, 68, 69], "1704": [16, 61], "170492": 48, "170505": 32, "170512": 75, "17054987": [32, 75], "170670": [24, 67], "171": [32, 48, 58, 75], "17144": [33, 76], "171468": [24, 26, 35, 43, 45, 54, 55, 67, 69, 78], "1715": 65, "171657": 60, "171779": 24, "171800": 24, "171894": 65, "171899": [53, 77], "171997": 77, "172": 94, "1720": [18, 62], "17205": [33, 76], "172096": 48, "172161": 37, "17216105": 37, "172414": 95, "1724668": 51, "172697": [53, 77], "172792": [23, 42, 66], "172985": [20, 40], "173": [22, 41, 61, 65], "173025": 65, "173086": 24, "17333954": [20, 40], "173370": 48, "173478": [53, 77], "1738": 41, "17393037": 9, "1739787032867638": 65, "173979": 65, "174": [22, 26, 41, 44, 58, 61, 65], "174590": [23, 42, 66, 80], "174652": 77, "174766": [27, 46, 70], "175": 68, "1750": [18, 56, 57, 62, 79], "175000": [24, 26, 35, 43, 45, 54, 55, 67, 69, 78], "17518": [33, 76], "175459": [15, 37], "176": [18, 47, 62], "176028": 38, "1762": [50, 74], "176468": 41, "1764683596365657": 41, "176471": 95, "1766": [24, 43, 67], "176924": 77, "177": [27, 46, 47, 70], "17730": [18, 20, 27, 46, 62, 70], "177709": 77, "178": [24, 43, 58, 67], "178494": [24, 43, 67], "178529": 95, "178657": 42, "178761": [23, 42], "1788": [15, 37], "17896": [33, 76], "179": [25, 34, 44, 68, 77], "179061": 75, "179064": 32, "179080": [23, 42, 66], "179123": [16, 61], "179152": [17, 39], "179300": [18, 62], "179631": [15, 37], "179726": 48, "179730": [41, 65], "17973005068132514": [41, 65], "179802": [24, 43, 67], "18": [1, 15, 16, 17, 18, 19, 21, 22, 23, 24, 27, 28, 30, 31, 33, 34, 35, 39, 41, 42, 43, 46, 48, 49, 50, 52, 53, 55, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 70, 71, 73, 74, 76, 77, 78, 80, 84, 89, 92, 93, 95, 96, 98], "180": [22, 24, 32, 43, 65, 67, 75, 94], "1800": [15, 22, 37, 41, 58, 59, 61, 65], "18000": [33, 76], "180000": [15, 37, 59], "180214": [53, 77], "180234": [34, 77], "180279e": 24, "180290": 95, "180388": [16, 61], "1804": [16, 61], "18066406": [31, 50, 51, 74], "180900": [27, 46, 70], "180926": 38, "18096": [33, 76], "181": [34, 77], "18113": [33, 76], "18116": [33, 76], "181262": 24, "1813": 65, "181755": 95, "182": [33, 34, 76, 77], "18201414": [26, 45, 69], "182342": [34, 77], "182384": 38, "18245": [33, 76], "182639": [24, 67], "182648": [24, 43, 67], "1830": [15, 37], "18311": [33, 76], "18313": [33, 76], "18317085": 9, "183179": [34, 53, 77], "183423": [16, 61], "183471e": [24, 67], "18365": 63, "183716": 48, "18391": [18, 62, 63], "184": [33, 34, 68, 76, 77], "1840": [15, 37, 58], "184220": [20, 40], "184405": [26, 45, 69], "1847": 19, "185": [34, 60, 77], "185000": 60, "185155": [26, 45, 69], "185175": [34, 53, 77], "185270": 22, "18533": [33, 76], "1854": 65, "1857": 34, "185707": [22, 41, 61, 65], "18571": [18, 62, 63, 93], "18572": [18, 62, 63, 93], "18573": [18, 62, 63, 93], "18574": [18, 62, 63, 93], "18575": [18, 62, 63, 93], "18576": [18, 62, 63, 93], "1858": [27, 34, 46, 70], "185868": [27, 46, 70], "1859": 34, "185975": [26, 45, 69], "18597545": [26, 45, 69], "186": [17, 39], "1860": 34, "186024": 58, "1861": 34, "186561": 96, "186814": [23, 42, 66, 80], "186869": [53, 77], "186899": [23, 42, 66], "187": [21, 60, 64, 94], "1870": 65, "187000": [18, 62], "1872": [24, 43, 67], "1875": [21, 31, 50, 51, 64, 74], "187502": 77, "187503": [52, 76], "187663": [16, 61], "187700": [18, 62], "188": [21, 47, 58, 60, 64, 94], "1880": 65, "188506": 77, "1886": [21, 64], "1887": [26, 45, 66, 69], "188885": 48, "189": [17, 39], "18955": [33, 76], "189862": 95, "189981": [24, 43, 67], "18_natur": 51, "19": [1, 9, 15, 16, 19, 23, 24, 27, 30, 31, 34, 37, 42, 43, 46, 48, 49, 50, 51, 53, 58, 59, 60, 61, 63, 65, 66, 67, 70, 73, 74, 77, 84, 92, 96], "190": [15, 24, 27, 43, 44, 46, 48, 60, 67, 70], "1900": [15, 37], "19000e": 61, "1901": 58, "190319": [27, 46, 70], "19032": [33, 76], "1904": [16, 61], "190617": [18, 62, 63, 93], "1907": 41, "190832": 77, "191": [18, 48, 62], "1910": [15, 37], "1911": [27, 46, 70], "191169": [24, 43, 45, 67, 69], "191204": [27, 46, 70], "191254e": 67, "191396": [16, 61], "1914": [34, 63], "1915": 34, "1916": 34, "1917": 34, "191700": [27, 46, 70], "1918": [19, 34], "1919": 34, "191k": [45, 69], "192": 63, "1920": [34, 58], "192001": 24, "1921": 34, "19213263": [19, 63], "192133": [19, 63], "192158": 24, "19255": 92, "19266": [33, 76], "192932": [23, 42], "193": [32, 75], "1930": 58, "193021": [23, 42, 66, 80], "193122": 66, "193247": [27, 46, 70], "1933": [15, 37, 59], "193346": [45, 69], "193427": 65, "1936": 58, "19365": [33, 76], "193704": [52, 76, 96], "19380": [33, 76], "1940": [19, 58, 63], "194002": [16, 61], "194008": 48, "194034": [52, 76, 96], "194040": [18, 62], "1942": 20, "19422": [45, 69], "19433594": [31, 50, 51, 74], "1944": [15, 37], "1945": [24, 43, 67], "1946": [24, 43, 58, 67], "194710": [24, 43, 67], "1948": [15, 37], "19485": [18, 62], "194883": [20, 40], "194914": 38, "194985": [24, 67], "195": [17, 18, 62, 94], "1950": [24, 43, 67], "1951": [15, 37, 59], "195228": 63, "1953": [24, 43, 65, 67], "195334": 77, "19536": 66, "1954": [15, 37, 51], "1954400510": [15, 37], "1955": [15, 37, 59], "195564": [27, 46, 70], "1957": [31, 50, 51, 74], "195753": 66, "1959": [13, 15, 37, 58], "19591": [27, 46, 70], "1960": [15, 37, 59], "1962": [31, 51, 74], "1963": 65, "196385": [26, 45, 69], "1965": [15, 37, 59], "196599": [24, 43, 67], "1966": [24, 43, 67], "19664": 20, "196739": [33, 76], "1968": 58, "196958": 24, "196963": 38, "1970": [21, 24, 33, 43, 58, 64, 67, 76], "197007": 24, "197064": 26, "1971": [15, 37], "1972": [24, 43, 67], "197432": 75, "197436": 32, "197473": 77, "1975": [15, 37], "197500": 60, "197649": [27, 46, 70], "1977": [34, 58, 77], "19777": [25, 26, 44, 45, 68, 69], "19781": [33, 76], "197917": 60, "197951": 96, "198": 34, "198127": [24, 43, 67], "1984": [24, 43, 67], "1985": [24, 43, 67], "1986": [15, 37, 63], "198645": [34, 77], "1987": [15, 37, 58, 59], "1989": 58, "198924": [18, 62, 63, 93], "199": [16, 23, 42, 58, 61, 66], "1990": [21, 22, 41, 61, 64, 65], "1991": [15, 25, 37, 44, 59, 68], "1992": [33, 76], "1993": [24, 43, 67], "199364": [23, 42, 66], "1994": [25, 58], "199412": [38, 77], "199413": [22, 41, 61, 65], "19966": [18, 27, 46, 62, 63, 70], "1997": [15, 21, 37, 41, 64, 65], "199771": [26, 45, 69], "19th": 13, "1_000_000_000": 65, "1__1stflrsf": [24, 43], "1__2ndflrsf": [24, 43], "1__3ssnporch": [24, 43], "1__bedroomabvgr": [24, 43], "1__bsmtfinsf1": [24, 43], "1__bsmtfinsf2": [24, 43], "1__bsmtfullbath": [24, 43], "1__bsmthalfbath": [24, 43], "1__bsmtunfsf": [24, 43], "1__enclosedporch": [24, 43], "1__fireplac": [24, 43], "1__fullbath": [24, 43], "1__garagearea": [24, 43], "1__garagecar": [24, 43], "1__garageyrblt": [24, 43], "1__grlivarea": [24, 43], "1__halfbath": [24, 43], "1__kitchenabvgr": [24, 43], "1__lotarea": [24, 43], "1__lotfrontag": [24, 43], "1__lowqualfinsf": [24, 43], "1__masvnrarea": [24, 43], "1__miscval": [24, 43], "1__openporchsf": [24, 43], "1__overallcond": [24, 43], "1__overallqu": [24, 43], "1__poolarea": [24, 43], "1__screenporch": [24, 43], "1__totalbsmtsf": [24, 43], "1__totrmsabvgrd": [24, 43], "1__wooddecksf": [24, 43], "1__yearbuilt": [24, 43], "1__yearremodadd": [24, 43], "1__yrsold": [24, 43], "1d": [17, 32, 34, 39, 75], "1e": [22, 24, 41, 65], "1e1": 22, "1e3": [22, 41, 65], "1e4": [22, 65], "1faipqlsdr_pmcm": 22, "1h": [18, 27, 46, 62, 63, 70, 93], "1m": 75, "1mb": 31, "1r7enrhgx5af97genxm0ix3z_j25lecfocq4kzb": 16, "1st": [9, 20, 25, 26, 33, 44, 45, 66, 68, 69, 76], "1stflrsf": [24, 26, 35, 43, 45, 54, 55, 67, 69, 78], "1v": 83, "1v2": 83, "1v3": 83, "1x10000": 20, "2": [1, 4, 5, 8, 9, 10, 17, 20, 23, 25, 26, 27, 31, 32, 33, 37, 38, 39, 40, 41, 42, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 56, 57, 68, 69, 70, 73, 74, 75, 76, 79, 80, 82, 83, 95, 98], "20": [1, 4, 9, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 30, 31, 33, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 54, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 73, 74, 76, 80, 83, 84, 86, 90, 92, 93, 94, 96, 98], "200": [13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 25, 27, 29, 31, 35, 37, 38, 39, 40, 41, 42, 44, 46, 47, 50, 51, 55, 58, 59, 60, 61, 62, 63, 64, 65, 66, 68, 70, 72, 74, 78, 80, 81, 85, 86, 87, 91, 92, 93], "2000": [16, 17, 20, 22, 24, 25, 26, 27, 32, 39, 40, 41, 43, 44, 45, 46, 56, 57, 61, 65, 67, 68, 69, 70, 75, 79, 80, 83], "200000": [41, 44, 45, 52, 65, 68, 69, 76, 94, 96], "200000e": [15, 37], "200024": [34, 77], "2003": [15, 37], "200326e": [24, 67], "2004": [15, 24, 37, 43, 67], "200458": 38, "200475": [23, 42, 66, 80], "2005": [15, 37], "2006": [24, 26, 35, 43, 45, 54, 55, 67, 69, 78], "2007": [15, 24, 26, 35, 37, 43, 45, 52, 54, 55, 67, 69, 76, 78, 96], "2008": [15, 24, 26, 35, 37, 43, 45, 52, 54, 55, 67, 69, 76, 78, 96], "200849": 24, "200876": [19, 63], "20087625": [19, 63], "2009": [15, 24, 26, 35, 37, 43, 45, 52, 54, 55, 67, 69, 78], "200978": [16, 61], "201": [16, 18, 34, 61, 68], "2010": [20, 24, 26, 40, 43, 45, 52, 67, 69, 76], "20113": [18, 62, 63, 93], "2012": [9, 18, 22, 41, 62, 65], "2013": [15, 31, 37, 50, 51, 52, 74, 76, 96], "201332": [29, 72], "2014": [15, 25, 37, 44, 52, 58, 68, 76], "20140521t000000": [15, 37], "20140623t000000": [15, 37], "20141013t000000": [15, 37], "20141015t000000": [15, 37], "20141209t000000": [15, 37], "201434": 66, "201488": 24, "2015": [15, 32, 33, 37, 52, 75, 76, 96], "20150116t000000": [15, 37], "20150218t000000": [15, 37], "20150223t000000": [15, 37], "20150225t000000": [15, 37], "20150630": [52, 76, 90, 96], "201534": [53, 77], "2016": [9, 32, 33, 75, 76], "20160101": [33, 76], "2017": [26, 45, 52, 69, 76, 96], "201810": [23, 42, 66, 80], "201862": [27, 46, 70], "202": [16, 18, 61], "202060": 80, "2022": [33, 76], "202247": 38, "202259": 48, "2023": [1, 31, 33, 50, 74, 76], "2024": [0, 16, 19, 21, 29, 45, 51, 55, 57, 85, 90, 93, 94, 96], "20248": [18, 62], "2024w1": [0, 13], "2024w2": 13, "2025": [1, 13, 14, 15, 18, 22, 24, 25, 26, 27, 28, 30, 31, 33, 34, 35, 44, 52, 53, 54, 56, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 86, 87, 88, 89, 91, 92, 95], "2025w": 98, "2025w1": [11, 13, 32, 59, 75], "202679": 66, "202736": 75, "20274": [33, 76], "202743": 32, "20277493": 17, "202775": [17, 39], "202839": [23, 42, 66], "203": [16, 18, 48, 61], "20310": [33, 76], "20311": [27, 46, 70], "20319": [33, 76], "203265": [26, 45, 69], "20334": [33, 76], "203397": 32, "203399": 75, "203421": 24, "203500": [18, 62], "20357847293371834": [21, 64], "2036": 58, "204": [16, 18, 51, 59, 60, 61, 65, 91], "2043": [34, 77], "204302": [52, 76, 96], "20433": [27, 46, 70], "204583": 60, "2046": 63, "204600": [22, 41, 61, 65], "204692": 24, "204734": 66, "20485": [33, 76], "205": [16, 18, 48, 59, 60, 61, 91], "205000": [18, 24, 26, 35, 43, 45, 54, 55, 62, 63, 67, 69, 78, 93], "205059": [27, 46, 70], "20509": [33, 76], "20514": [33, 76], "205144": [27, 46, 70], "205323": [52, 76, 96], "205470": 77, "205479": [21, 64], "205527": 77, "205597": [24, 43, 67], "20564": [33, 76], "205795": 48, "206": [16, 18, 22, 41, 56, 57, 59, 60, 61, 65, 79, 80, 91], "206024": 38, "206073": [23, 42, 66, 80], "206099": 65, "20620": [33, 76], "206292": [18, 62], "20639": [27, 46, 70], "2064": [18, 62], "20640": [21, 27, 46, 64, 70], "206724": [34, 53, 77], "20683258": [21, 64], "206897": 95, "20694": [33, 76], "20699": [15, 37], "207": [16, 18, 22, 32, 41, 51, 59, 60, 61, 62, 65, 75, 82, 91], "207039e": 24, "2071": [27, 46, 70], "207814e": 24, "2079": [15, 37], "20794": [33, 76], "208": [16, 21, 22, 41, 59, 60, 61, 64, 65, 91], "209": [16, 22, 41, 48, 58, 59, 60, 61, 65, 91], "209080": 48, "209221": [35, 54, 55, 78], "209583": 60, "209746": 66, "209903": [27, 46, 70], "209935": 24, "209943": 77, "20analysi": [34, 53, 77], "20assumpt": [34, 77], "20hazard": [34, 77], "20intro": [34, 53, 77], "20lifelin": [34, 53, 77], "20with": [34, 53, 77], "21": [1, 14, 15, 16, 17, 18, 19, 20, 23, 24, 27, 28, 30, 31, 33, 37, 39, 42, 43, 46, 48, 49, 50, 51, 52, 53, 58, 59, 61, 62, 63, 66, 67, 70, 71, 73, 74, 76, 77, 92, 96, 98], "210": [22, 41, 65], "210001": [23, 42, 66], "210240": 65, "210272": [27, 46, 70], "210289": 38, "210300": 24, "210591": [18, 62, 63, 93], "210779": [52, 76], "210833": 60, "210852": [34, 77], "21086181023099465": [21, 64], "211": [22, 41, 65], "2110": [18, 62], "211250": 60, "211343": [27, 46, 70], "211378": 26, "211544": [23, 42, 66, 80], "211731": 38, "211892": [18, 62, 63, 93], "211980": 66, "212": [22, 41, 60, 65], "212133": [53, 77], "212303": [53, 77], "212385": [26, 45, 69], "212581": [27, 46, 70], "212688": [23, 42], "21274": [33, 76], "212870": [24, 43, 67], "212975": [24, 43, 67], "213": [22, 32, 33, 41, 65, 75, 76, 94], "2130": 58, "21353": [33, 76], "213571": [53, 77], "21389": [33, 76], "213896": [15, 37], "2139": [18, 62, 63, 93], "214": [22, 41, 48, 58, 65, 94], "21405": [33, 76], "214148": 24, "21436": [15, 37], "2144": 65, "21450": [15, 37], "214677": 42, "214740": [18, 62], "214821": [33, 76], "214852": 66, "2149": 34, "215": [22, 41, 65], "2150": 34, "2151": 34, "215166": 38, "2152": 34, "215245": [24, 43, 67], "2153": 34, "21530": [33, 76], "2154": 34, "215412": [24, 43, 67], "21549": [33, 76], "2155": 34, "2156": 34, "21571": [33, 76], "215744": [53, 77], "21581": [33, 76], "215812": 24, "21582031": [31, 50, 51, 74], "215865": [26, 45, 69], "21596": [33, 76], "216": [22, 41, 65], "21603": [33, 76], "21605": [33, 76], "21608": [15, 37], "21609": [15, 37], "21610": [15, 37], "21611": [15, 37], "21612": [15, 37], "216123": [34, 53, 77], "21613": [15, 37, 59], "21616484": 83, "21617": [33, 76], "216237": 24, "216250": 60, "216346": [26, 45, 69], "21634631": [26, 45, 69], "216585": [18, 62], "216596": [52, 76, 96], "21668": [33, 76], "21670": [33, 76], "216718": 66, "216728": [18, 62], "21694": [33, 76], "21697": [33, 76], "217": [50, 56, 57, 74, 79], "2170": [15, 37, 59], "217334": [19, 63], "21733442": [19, 63], "2173627": [31, 50, 51, 74], "21767954": [26, 45, 69], "21768": [26, 33, 45, 69, 76], "217680": [25, 26, 44, 45, 68, 69], "21774": [33, 76], "218": [19, 63], "21813167": [44, 68], "218207": [18, 62, 63, 93], "21847": [33, 76], "21872": [24, 26, 35, 43, 45, 54, 55, 67, 69, 78], "218760": [26, 45, 69], "218830": [18, 62], "218869": 38, "219": [27, 46, 70], "2190": [18, 62], "2192": 65, "219500e": [15, 37], "219512": [27, 46, 70], "219686": 77, "219700": [27, 46, 70], "219718": 38, "21972656": [31, 50, 51, 74], "219845e": [24, 67], "22": [16, 17, 18, 22, 23, 24, 25, 26, 27, 31, 33, 34, 39, 41, 42, 43, 44, 45, 46, 47, 48, 50, 51, 52, 61, 62, 63, 65, 66, 67, 68, 69, 70, 74, 76, 77, 92, 93, 95, 96, 98], "220": [18, 60], "2200": [17, 39], "220000": 95, "22001": [45, 69], "220392": [34, 77], "220427": 94, "220441": 24, "22057": [33, 76], "2206": [34, 77], "22078": [33, 76], "221": 18, "2210": [15, 37, 58], "22114": [33, 76], "221329": [24, 67], "221348": [52, 76, 96], "221381": 96, "221531": 48, "22154": [33, 76], "221622": [18, 62, 63, 93], "22168237": 83, "221761": 38, "221900": [15, 37, 59], "222": 18, "22219": [33, 76], "22221842": 25, "22221894": [24, 43, 67], "222222": [18, 62], "22225": [33, 76], "222307": [18, 62], "222500": 60, "22260": [33, 76], "222647": [24, 26, 35, 43, 45, 54, 55, 67, 69, 78], "222765": 94, "2229": [21, 64], "222917": 60, "222943": 66, "223": 48, "22320": [33, 76], "223460": [34, 53, 77], "223750": 60, "223804": [45, 69], "223894": 48, "224": [47, 48, 65], "224389": 24, "22452": [33, 76], "224662": [24, 43, 67], "22471154513694652": [21, 64], "224865": [24, 26, 43, 45, 67, 69], "22490352392196655": 31, "22490517795085907": [50, 74], "225": 26, "225301e": 24, "2254": [18, 62], "22550": [33, 76], "226": [47, 65], "226374": 48, "226415": [18, 62], "22648": 20, "226748": 75, "226750": 32, "226789": [34, 53, 77], "2268": [25, 44, 68], "22697768": [19, 63], "226978": [19, 63], "227": 32, "2270": 65, "227090": [20, 40], "227143": [18, 62], "2272": [56, 57, 79, 80], "227289": 77, "227304": [52, 76, 96], "22741": [27, 46, 70], "227559": [24, 26, 35, 43, 45, 54, 55, 67, 69, 78], "227836": [23, 42, 66], "22788": [33, 76], "228": 32, "22811601": [21, 64], "22826": [33, 76], "228329": [23, 42, 66, 80], "2285": 52, "22851562": [31, 50, 51, 74], "228603": [24, 43, 67], "228675": 24, "228716": 24, "229000": [18, 62], "22910": [33, 76], "229102": [26, 45, 69], "2294": 96, "2295": 52, "229718": [45, 69], "229930": 94, "23": [1, 15, 16, 17, 18, 21, 22, 23, 24, 27, 31, 33, 34, 37, 39, 41, 42, 43, 46, 47, 48, 50, 51, 52, 61, 62, 63, 64, 65, 66, 67, 70, 74, 76, 77, 80, 83, 92, 93, 96], "230": [22, 41, 61, 65], "2300": 58, "230000": [15, 37], "23011": [26, 45, 69], "230194": 77, "230412": 26, "2305": [26, 45, 69], "2307": [21, 60, 64], "2309": 52, "231": 98, "2310": [15, 37, 52], "2311": 52, "2312": 52, "2313": 52, "23175": [33, 76], "231815": [26, 45, 69], "232": [17, 39], "232074": 38, "232143": 63, "23223111033439636": [50, 74], "23223206400871277": 31, "232703": 66, "232751": [34, 53, 77], "23290": [33, 76], "233": [15, 37, 59], "233608": 77, "234": [25, 34, 48, 77], "234040": [66, 80], "234303": [15, 37], "234361": 95, "234436": 77, "234616": 24, "234730": [34, 77], "234952": 94, "235": [27, 46, 70], "235096": [18, 62, 63, 93], "235152": [16, 61], "235706": [27, 46, 70], "235833": 60, "236": [22, 34, 41, 61, 65, 77], "2360": [15, 37], "236174": [27, 46, 70], "236210": [28, 71], "23621041": [28, 71], "236217": 26, "23640124": [21, 64], "236456": [18, 62], "236522": 77, "23654": [26, 45, 66, 69], "236960": 65, "237": [34, 77, 80, 98], "2373": 96, "237935": [26, 45, 69], "238": [23, 34, 42, 47, 66, 77], "238192": [26, 45, 66, 69], "2388": [15, 37], "2389": 63, "239": [34, 77], "23900927": 25, "23902": [33, 76], "239083": 38, "23941": [33, 76], "239944e": [24, 67], "239949": 66, "24": [1, 11, 16, 17, 18, 23, 24, 25, 26, 27, 31, 33, 34, 38, 39, 42, 43, 44, 45, 46, 47, 48, 50, 51, 52, 58, 61, 62, 66, 67, 68, 69, 70, 74, 76, 77, 83, 92, 96], "240": [34, 77], "2401": [27, 46, 70], "240483": 95, "24051381": [44, 68], "240893": [27, 46, 70], "241": [34, 77], "24113328": [44, 68], "241379": 95, "241489": [34, 53, 77], "241620": [23, 42, 66], "24182": [52, 76], "242015": [25, 26, 44, 45, 68, 69], "24202916": 25, "242083": 60, "242169": [23, 42, 66], "242308": 95, "242381": [52, 76], "242742": 38, "24295676": [19, 63], "242957": [19, 63], "242996": [18, 62, 63, 93], "243": [33, 76], "243223": 15, "243243": [24, 43, 67], "243447": [45, 69], "2435": [27, 46, 70], "2436": [27, 46, 70], "24395": [25, 26, 44, 45, 68, 69], "24397122221206388": [52, 76], "244": [33, 48, 76], "244020": 15, "244273": [53, 77], "244344": 77, "244556": 48, "244592": [16, 61], "2447": [25, 44, 68], "244814": [34, 53, 77], "245": [33, 76], "2451": 65, "245329": [24, 43, 67], "245521": 66, "245635": 38, "245686": [23, 42, 66, 80], "246": [33, 69, 76], "246332": [24, 43, 67], "246486": [17, 39], "246646": 65, "246646103936": 65, "246653": 65, "24670054": 20, "246950": 15, "247": [33, 76], "247059": 95, "247075": 25, "247119": [52, 76, 96], "247439": [28, 71], "24743939": [28, 71], "247596": [44, 68], "247690828913": 65, "247691": 65, "248": [33, 48, 76], "2483": 40, "2484": 58, "248457": [24, 26, 35, 43, 45, 54, 55, 67, 69, 78], "248609": [24, 67], "248664": [27, 46, 70], "2487200875": [15, 37], "2488": [16, 61], "248843": 15, "248999": [34, 53, 77], "249": 48, "2496": [21, 60, 64], "249601e": 24, "249618e": 24, "249720": [16, 61], "249804": 48, "24h": [56, 57, 79, 80], "25": [1, 9, 15, 16, 17, 18, 19, 21, 22, 23, 24, 25, 26, 27, 28, 29, 31, 33, 34, 35, 37, 39, 41, 42, 43, 44, 45, 46, 47, 48, 50, 51, 52, 54, 55, 57, 58, 59, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 72, 74, 76, 77, 78, 84, 85, 92, 93, 94, 95, 96], "250": [92, 94], "2500": [9, 17, 39], "25000": 58, "250000": [15, 18, 23, 24, 37, 42, 43, 62, 66, 67, 92], "250218": 24, "25031": [33, 76], "25037": [33, 76], "250588": [17, 39], "25058829": 17, "2506": [59, 60, 91], "250696": 15, "250900": [24, 43, 67], "250944": 15, "251": 94, "251093": 65, "251158e": 24, "251239": 37, "25123925": 37, "2516": [25, 44, 68], "2517": 40, "25176": [33, 76], "252": [56, 57, 79], "252042": [27, 46, 70], "25214": [33, 76], "252160": [16, 61], "252163": 15, "252468": 15, "252570": 92, "252846": 15, "253": 48, "2530": 58, "2533": [21, 60, 64], "253312": [18, 62, 63, 93], "253432": [26, 45, 69], "253724": [16, 61], "253914": [24, 43, 67], "254380": 77, "254443": [23, 42, 66, 80], "25462": 92, "25477": 92, "255": [18, 38, 62], "2550": [15, 37], "255000": 95, "255165": [34, 77], "2556": [25, 44, 68], "255751": [27, 46, 70], "255889": [52, 76, 96], "256": [58, 94], "25622": [33, 76], "256263": [25, 26, 44, 45, 68, 69], "256333": [18, 62], "256437": [27, 46, 70], "25658": [27, 46, 70], "256813": [16, 61], "257": [15, 16, 25, 26, 28, 37, 47, 59], "2570": [15, 37, 58, 59], "257024": 65, "257103": [23, 42, 66, 80], "257187": 15, "2574": [27, 46, 70], "257633": 48, "257724": 32, "257725": 75, "257787": [17, 39], "258": 41, "2580": 58, "258225": [33, 76], "25823": 66, "258311": 15, "258387": [26, 45, 69], "2584": [51, 82], "258427": [16, 61], "258495": 48, "258815": [23, 42], "259": [24, 27, 43, 46, 67, 70, 94], "259027": 38, "25904": [33, 76], "2590575478171857": 21, "2590575478171884": 64, "259087": 38, "259286": [16, 61], "259500": [18, 62], "259521": 38, "26": [9, 13, 14, 15, 16, 17, 18, 22, 23, 24, 25, 26, 27, 28, 30, 31, 33, 34, 35, 39, 41, 42, 43, 44, 45, 46, 48, 50, 51, 52, 53, 54, 56, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 86, 87, 88, 89, 90, 91, 92, 95, 96], "2600": [18, 62, 63, 93], "260258": [27, 46, 70], "26048": [26, 44, 45, 68, 69], "260572": [24, 43, 67], "26063": [33, 76], "260890": [24, 26, 35, 43, 45, 54, 55, 67, 69, 78], "261": 94, "261035": [24, 43, 67], "261086": 95, "261953": [52, 76, 96], "262": [24, 26, 35, 43, 45, 54, 55, 67, 69, 78], "262079e": 24, "262096": 94, "262156e": [24, 67], "262269e": 24, "2623": [24, 43, 67], "262361": [27, 46, 70], "262500": [24, 43, 67], "263": [24, 26, 43, 47, 67], "2630": [18, 62], "263000018": [15, 37], "263541": [34, 77], "263600": [18, 62], "26370005": [21, 64], "263736": 77, "263742e": 24, "26376": [33, 76], "264195": 77, "2642": 96, "264283e": [24, 67], "26447953": [19, 63], "264480": [19, 63], "265": [48, 94], "265273": [21, 64], "265483": 38, "266": 94, "266120": [52, 76, 96], "266135": [18, 62, 63, 93], "267": 94, "2670": 65, "267612e": [24, 67], "268": [41, 65], "2683": 66, "26831": [33, 76], "268339": 96, "269": [25, 45], "2691": [59, 60, 91], "26919": [27, 46, 70], "269347": 77, "269880": [16, 61], "269972": [24, 26, 35, 43, 45, 54, 55, 67, 69, 78], "27": [1, 9, 15, 16, 17, 19, 22, 23, 24, 31, 33, 34, 37, 39, 42, 43, 48, 50, 51, 52, 53, 61, 63, 65, 66, 67, 74, 76, 77, 92, 95, 96], "270093": 65, "270093376167": 65, "27021": [33, 76], "270270": [30, 49, 73], "27048": 66, "2705": 65, "271": 44, "271037": [27, 46, 70], "271287": [52, 76], "2713": 92, "271500": [27, 46, 70], "271738e": 24, "2720": [15, 37, 59], "27206": [33, 76], "272297": [53, 77], "27263": [45, 69], "272667": [18, 62, 63, 93], "273": [47, 48, 68], "2730": [18, 62], "27304": [15, 37], "273382": [18, 62, 63, 93], "273606": [18, 62, 63, 93], "2739": 14, "273962": [27, 46, 70], "274": [18, 33, 48, 62, 63, 76, 93], "2742": [45, 69], "274404": [18, 62], "274631": 77, "2749": [45, 59, 60, 69], "275": [25, 32], "275008": [52, 76, 96], "27502378984": 24, "27502379083": 67, "275023791124": 43, "275290": [23, 42, 66], "275352": [16, 61], "275410": [21, 64], "27576982": [20, 40], "2759": [26, 45, 69], "276": [18, 62], "27610135": [31, 50, 51, 74], "27638": [33, 76], "27652": 66, "276533": 95, "276687": [24, 43, 67], "2767": 96, "27676": [56, 57, 79, 80], "27678": [56, 57, 79, 80], "276784": 77, "276943e": 24, "27697": [56, 57, 79, 80], "2770": 65, "27705": [56, 57, 79, 80], "27715": [56, 57, 79, 80], "277381": [16, 61], "277384": 77, "2777": [34, 77], "278441": [52, 76, 96], "278634": 80, "2787": 96, "27874871715903127": [21, 64], "278755": [19, 63], "27875502": [19, 63], "2788": [21, 60, 64], "279371": 94, "2794": [21, 64], "28": [1, 16, 18, 21, 22, 23, 24, 27, 28, 31, 33, 34, 41, 42, 43, 46, 48, 50, 51, 52, 61, 62, 63, 64, 65, 66, 67, 70, 71, 74, 76, 77, 92, 94, 96], "280": [18, 27, 41, 46, 48, 62, 70], "2800": 9, "280028": [27, 46, 70], "280148": 77, "28030": 20, "280310": [18, 62, 63, 93], "2806": 65, "280618": 66, "2807": [34, 53, 77], "280801": [34, 53, 77], "281": [18, 62], "281180": 77, "2812": 96, "28122025534": 24, "281220255387": 67, "281220255463": 43, "281583": [24, 43, 67], "281677": 94, "2817": [26, 45, 69], "281962": 18, "282": 47, "282021e": 24, "2822": [26, 45, 69], "282600": [34, 53, 77], "282778": 95, "283": [32, 75, 94], "283119e": 24, "28327": [33, 76], "283421": [24, 43, 67], "2836": [26, 45, 69], "28362": [33, 76], "283857": [16, 61], "283921": [18, 62], "283948": 20, "284": [27, 33, 45, 46, 70, 76], "284137": 96, "2845": [34, 77], "285": [18, 33, 62, 63, 76, 93], "285263": [26, 45, 69], "28526302": [26, 45, 69], "285467": [24, 26, 35, 43, 45, 54, 55, 67, 69, 78], "28571429": [14, 59], "285740": 95, "286": [15, 22, 33, 41, 60, 61, 65, 76], "286000": 65, "286200": [27, 46, 70], "286327": 38, "286416": 63, "286442": 20, "286482": [53, 77], "2865025": 83, "286545": 75, "286546": 32, "286821": [16, 61], "286870": 20, "287": [33, 76], "287001": 65, "287031": [52, 76, 96], "287147": 95, "2873": 96, "287344": [18, 62, 63, 93], "2874": 34, "287500": [27, 46, 70], "28753559": [31, 50, 51, 74], "288": [33, 76], "288002": [52, 76, 96], "2884": 96, "288462": [21, 64], "28854": [33, 76], "28868": 66, "289": [33, 76, 94], "2890": [22, 41, 61, 65], "289269": [45, 69], "28953": [33, 76], "289541": [24, 26, 35, 43, 45, 54, 55, 67, 69, 78], "289799": [16, 61], "29": [1, 9, 15, 16, 17, 18, 23, 24, 31, 33, 34, 37, 39, 42, 43, 48, 50, 51, 52, 53, 58, 61, 62, 66, 67, 74, 76, 77, 80, 92, 96], "290": [15, 33, 37, 76], "290002": [23, 42, 66, 80], "2902": 96, "290215": [32, 75], "290385": 77, "290424": [24, 67], "29045704": [24, 43, 67], "2907": 96, "290961e": 24, "291": [15, 21, 33, 37, 64, 76], "291134": 48, "291310100": [15, 37], "291667": [30, 49, 73], "291829": 94, "292": [33, 76], "2920": 96, "2925": 96, "292587": 77, "293": [33, 76], "29324459": [32, 75], "293304": 48, "2936": 96, "293631": [53, 77], "293663": [23, 42, 66, 80], "2937": 96, "294": [18, 31, 50, 51, 62, 74, 94], "2940": [34, 96], "2941": 34, "2942": 34, "29425051": 19, "294251": [19, 63], "2943": 34, "2944": 34, "2945": 34, "2946": 34, "2947": 34, "2948": [18, 62, 63, 93], "294855": [26, 45, 69], "295": 69, "295192": 38, "2953863599856858": [21, 64], "295397": [23, 42, 66], "2954": 96, "29545": [24, 43, 67], "2955": 96, "29572402": [31, 50, 51, 74], "295741": 20, "2959": 18, "296": [18, 62], "2960": [18, 96], "2961": 18, "2961559258": 34, "2962": 18, "296236": 48, "2964": 18, "296601": [27, 46, 70], "29691": [33, 76], "297": [21, 64], "2976": 96, "297949": 48, "2980": 96, "29802": [26, 45, 66, 69], "298043": 38, "298434": 38, "298561": [34, 53, 77], "2986": 96, "298612": [52, 76, 96], "2987": 96, "2988": 96, "29881": [33, 76], "299": [15, 37, 48], "299164": [27, 46, 70], "2992": 96, "2993": 96, "2997": 96, "2__bsmtcond": [24, 43], "2__bsmtqual": [24, 43], "2__extercond": [24, 43], "2__exterqu": [24, 43], "2__fireplacequ": [24, 43], "2__garagecond": [24, 43], "2__garagequ": [24, 43], "2__heatingqc": [24, 43], "2__kitchenqu": [24, 43], "2__poolqc": [24, 43], "2d": [14, 17, 32, 34, 39, 75], "2d454e5fd9a5": [34, 53, 77], "2e": 1, "2f": [15, 20, 22, 30, 33, 40, 49, 52, 60, 65, 73, 76, 96], "2m": [32, 75], "2nd": 20, "2ndflrsf": [24, 26, 35, 43, 45, 54, 55, 67, 69, 78], "2qps0o7vbmhf8wkupvnrapiaclcbga": [31, 50, 74], "2v": 83, "2v3": 83, "2x1": [89, 95], "3": [1, 8, 9, 16, 17, 19, 20, 22, 23, 24, 25, 26, 27, 30, 31, 32, 33, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 61, 63, 64, 65, 66, 67, 68, 69, 71, 73, 74, 75, 76, 78, 79, 80, 82, 83, 84, 89, 95, 97], "30": [1, 4, 15, 16, 17, 21, 23, 24, 25, 26, 27, 31, 33, 34, 35, 38, 39, 42, 43, 44, 45, 46, 50, 51, 52, 53, 54, 55, 58, 60, 61, 62, 63, 64, 66, 67, 68, 69, 70, 74, 76, 77, 78, 92, 94, 96, 98], "300": [16, 29, 31, 35, 50, 51, 54, 55, 58, 61, 72, 74, 78, 83], "3000": [17, 39], "300000": [18, 52, 62, 63, 76, 96], "3000000": [31, 50, 51, 74], "3001": 96, "300464": [27, 46, 70], "3005": 96, "3008": 98, "300837": [23, 42, 66, 80], "3009": 92, "301": [34, 47, 77], "3010": [27, 46, 70], "301200": 65, "3013": 96, "3014": [27, 46, 70], "30146": [33, 76], "301563": [24, 43, 67], "3016": 96, "30167": [33, 76], "301784": 77, "3018": 96, "301838": [35, 54, 55, 78], "3019": [21, 59, 60, 64, 91], "301952": [27, 46, 70], "302": [24, 25, 26, 35, 43, 45, 54, 55, 67, 69, 78], "302037": 38, "3021": 96, "302131": [24, 43, 67], "3023": 96, "3026": 96, "302679": 77, "30279": [33, 76], "302801": [34, 53, 77], "302844": 77, "303": [24, 26, 35, 43, 45, 54, 55, 67, 69, 78, 94], "303000": [18, 62], "303004": [27, 46, 70], "303030": [21, 64], "303109": [19, 63], "30310942": 19, "303533e": 77, "303694": 38, "3038344082": [45, 69], "303916": [16, 61], "304": [16, 61], "3040": 52, "3041": 52, "3042": 52, "304211": 48, "3043": 52, "3044": 52, "304494": 20, "304784": [24, 43, 67], "305": 58, "30504657": [28, 71], "305047": [28, 71], "305236": 94, "30530902": [16, 61], "305346": [16, 61], "305674": [27, 46, 70], "3057": [21, 60, 64], "30573": [27, 46, 70], "306500": [16, 61], "307": [18, 62], "307279": [53, 77], "307419": 94, "307521": [21, 64], "30792853": [31, 50, 51, 74], "30798381": [31, 50, 51, 74], "308": 68, "308120": [18, 62], "30815": [24, 43, 67], "308236": 38, "308240": 96, "308448": [16, 61], "3089": 65, "308900e": [15, 37], "309": [27, 46, 70], "3092": [59, 60, 91], "309394": 95, "309859": [21, 64], "30pm": 13, "30th": 58, "31": [15, 16, 18, 21, 23, 24, 25, 26, 28, 31, 33, 34, 37, 42, 43, 44, 45, 47, 50, 51, 52, 58, 61, 62, 63, 64, 66, 67, 68, 69, 71, 74, 76, 77, 80, 92, 93, 94, 96], "310": [1, 94, 98], "310000": [18, 62], "31000e": 61, "310284": [26, 45, 69], "31029469": 17, "310295": [17, 39], "310345": 95, "31038074": [31, 50, 51, 74], "310405": [23, 42, 66, 80], "311": [18, 62], "3110": [18, 62], "311151": [34, 53, 77], "31127015": [26, 45, 69], "311310": 58, "311769": [27, 46, 70], "31177786": 40, "3119640638146517": [21, 64], "3120": [18, 62], "31230": 20, "3125": [18, 62], "312500": [30, 49, 73], "312501": [24, 26, 35, 43, 45, 54, 55, 67, 69, 78], "3128": 96, "31297381": [19, 63], "312974": [19, 63], "31298589e": 75, "31298590e": 32, "313": [24, 25, 43, 48, 67], "313064": 92, "313254": 77, "313397": 77, "31384": 66, "314": [18, 62], "3140": [18, 62], "314000": 65, "31449687e": [26, 45, 69], "31454": [27, 46, 70], "314582": [26, 45, 69], "314840": [27, 46, 70], "314929": [52, 76, 96], "315000": [15, 37], "315134": [52, 76, 96], "3153625428676605": [50, 74], "3153638541698456": 31, "315630": [23, 42, 66], "316": 63, "316164": [27, 46, 70], "316230": [27, 46, 70], "31634363": [31, 50, 51, 74], "316363": [16, 61], "316395e": 24, "316426": [27, 46, 70], "316552": [19, 63], "31655231": [19, 63], "316764": 95, "316798": [27, 46, 70], "317": [18, 26, 34, 45, 62, 69, 98], "317277": [27, 46, 70], "31767136668453344": [15, 37], "317761": [23, 42, 66], "317887": 22, "3179": 96, "318": [18, 34, 62], "3180": 65, "3180174485124284": [18, 62], "3188": 96, "3189": 96, "318937": [18, 62, 63], "319": [15, 18, 19, 34, 37, 59, 62, 68], "31908384": [32, 75], "319483": 38, "319513": 27, "319559": [15, 37], "319630": [34, 53, 77], "31973465": 25, "31984311": [24, 67], "31st": [33, 76], "32": [9, 16, 17, 18, 21, 22, 24, 28, 31, 33, 34, 38, 39, 41, 43, 50, 51, 52, 53, 61, 62, 63, 64, 65, 67, 71, 74, 76, 77, 92, 93, 94, 95, 96], "320": [18, 34, 62], "320155": 66, "320430": [24, 43, 67], "3209427041566191": [15, 37], "321": 34, "321050": [15, 37], "321111e": 24, "3211822": [44, 68], "32127053": [24, 43, 67], "322": [27, 34, 41, 46, 47, 70], "32240": [25, 26, 44, 45, 68, 69], "322465": [15, 37], "32247597e": [26, 45, 69], "322755": [16, 61], "323045": [18, 62, 63], "32323": 58, "32397724e": [26, 45, 69], "324179": 24, "324190": 77, "3244": 92, "324400": 94, "3245": 58, "324762": 38, "325000": [15, 37], "325103": 22, "3252": [27, 46, 70], "325319": [27, 46, 70], "32561": 66, "326": [18, 27, 46, 47, 62, 70], "326368": 96, "326616": [15, 37], "326730": [23, 42, 66], "326741e": 77, "326933": [22, 41, 61, 65], "327": [48, 94], "327037": 77, "327188": [23, 42, 66], "3272": [34, 77], "327283": [24, 43, 67], "32734": [27, 46, 70], "3274": [34, 53, 77], "327408": 66, "327412": [20, 40], "327667e": 24, "3279": 92, "32791718": [31, 50, 51, 74], "328": [27, 46, 47, 70], "328000": [15, 37], "328077e": 24, "328111": [20, 40], "328953": [16, 61], "3298721": [32, 75], "3299": [51, 82], "329911": 94, "33": [9, 15, 16, 18, 21, 22, 23, 24, 27, 31, 34, 37, 41, 42, 43, 46, 50, 51, 52, 58, 61, 62, 63, 64, 65, 66, 67, 70, 74, 76, 77, 92, 96], "330": [5, 10, 14, 17, 33, 35, 36, 39, 48, 55, 58, 59, 75, 76, 78, 98], "33000e": 61, "330207": 96, "330346": [34, 53, 77], "3310": [18, 62], "331585": 65, "331587": 38, "331599": 95, "33191802": [31, 50, 51, 74], "332": 47, "332130": 24, "33223002": [31, 50, 51, 74], "3322447": [31, 50, 51, 74], "33224516": [31, 50, 51, 74], "33224759": [31, 50, 51, 74], "332290": 46, "332671": [26, 45, 69], "3327": [52, 76, 96], "332710": 24, "332746": [34, 77], "332791": 77, "332824": [24, 43, 67], "333": [17, 39, 94], "3330": [18, 62], "33308783": [19, 63], "333088": [19, 63], "333139": [23, 42, 66], "333333": [14, 18, 30, 38, 41, 49, 59, 62, 65, 73], "3333333333333333": [30, 49, 73], "333340": [16, 61], "3336693048477173": [50, 74], "3336699604988098": 31, "33380649": [31, 50, 51, 74], "33380754": [31, 50, 51, 74], "33380761": [31, 50, 51, 74], "33381373": [31, 50, 51, 74], "33394593": [31, 50, 51, 74], "3339473": [31, 50, 51, 74], "33394769": [31, 50, 51, 74], "33395626": [31, 50, 51, 74], "33397112": [31, 50, 51, 74], "334": [27, 46, 48, 70], "33400489": [31, 50, 51, 74], "33411086": [31, 50, 51, 74], "334241": 22, "33425967": [31, 50, 51, 74], "33435326": [31, 50, 51, 74], "33439238": [31, 50, 51, 74], "33440682": [31, 50, 51, 74], "334411": [16, 61], "334576": [24, 43, 67], "33462759": [31, 50, 51, 74], "334668": 95, "33476534": [31, 50, 51, 74], "334768": 38, "335309": [24, 67], "335379": 26, "3355": [18, 62, 63, 93], "3356700488_183566145b": [32, 75], "335746": 94, "33590": [33, 76], "33641142": [26, 45, 69], "3364114233677307": [26, 45, 69], "336411423367732": [26, 45, 69], "33643394": 17, "336434": [17, 39], "33662": 20, "336735": [41, 65], "336826": [19, 63], "33682642": [19, 63], "33683087": [21, 64], "336831": [21, 64], "337034": 70, "33726089": [24, 43, 67], "33732465": [31, 50, 51, 74], "337626": 38, "33782315": [31, 50, 51, 74], "33797555": [31, 50, 51, 74], "338": [22, 41, 61, 65, 94], "338508": [34, 77], "33888659": 9, "339": [23, 42, 47, 66], "339368": [34, 53, 77], "3398": 96, "339889": 77, "34": [16, 17, 18, 21, 23, 24, 27, 31, 33, 34, 39, 42, 43, 46, 50, 51, 58, 61, 62, 63, 64, 66, 67, 70, 74, 76, 77, 92, 93], "340": [1, 3, 14, 25, 27, 32, 33, 34, 44, 48, 52, 53, 59, 68, 75, 76, 77, 81], "34000e": 61, "340162": 32, "340169": 75, "340435": 22, "340986": 22, "340988": [23, 42, 66, 80], "341": 48, "341109": [24, 43, 67], "341300": [27, 46, 70], "341465": 95, "341571": [34, 77], "34161762": [24, 26, 43, 45, 67, 69], "341712": [52, 76, 96], "34182": [45, 69], "342": 48, "3420": [18, 62], "342200": [27, 46, 70], "3423": 92, "342605e": 24, "342902": 22, "343": 48, "343542": 48, "3436": [52, 76, 96], "344": [18, 44, 48, 62], "3442": [34, 53, 77], "34426571": [24, 43, 67], "34441": [24, 67], "344770": 48, "344799": 94, "345": [26, 45, 48, 69], "345136": [16, 61], "345236": 48, "345324": 22, "345386e": 24, "3454": [34, 53, 77], "345651": 22, "345831": 58, "345842": 48, "345904": [23, 42], "346": [15, 18, 37, 48, 62, 63, 93], "346850": [23, 42, 66, 80], "34691": [52, 76], "347": [48, 94], "347047": 22, "347523": 65, "347917": [34, 77], "348": [18, 27, 46, 48, 62, 70], "34806": [24, 67], "34836": 22, "348569": [35, 54, 55, 78], "348755": 22, "348820": 77, "349": 48, "34900": [24, 43, 67], "34924955": [31, 50, 51, 74], "35": [15, 16, 18, 21, 24, 25, 26, 28, 31, 34, 37, 43, 44, 45, 50, 51, 52, 53, 61, 62, 64, 66, 67, 68, 69, 74, 76, 77, 86, 88, 92, 94, 96], "350": [47, 48, 58], "3500": [17, 39], "350000": [18, 62], "350061e": 67, "3509": 92, "351351": [30, 49, 73], "351366": [23, 42, 66], "3515": [34, 77], "351538": 94, "351718": 22, "351812": 77, "351821": [34, 53, 77], "351883": [35, 54, 55, 78], "3521": 58, "352100": [27, 46, 70], "352114": [45, 69], "352309": 22, "3524": 34, "352556": 48, "352868": 22, "352930": [18, 62, 63, 93], "353": [32, 75], "3534": 77, "35375221": 83, "353961": 65, "354045": 22, "354114": [24, 26, 35, 43, 45, 54, 55, 67, 69, 78], "3546": 92, "354604": [23, 42, 66], "3547": [27, 46, 70], "354759e": [24, 67], "355": 68, "355053": 93, "355121": 77, "3552": 34, "35561437": [31, 50, 51, 74], "356689": [25, 26, 44, 45, 68, 69], "35671794": [26, 45, 69], "356908": 94, "357": [18, 62], "3573886": [31, 50, 51, 74], "357441": 94, "357500": [18, 62, 63, 93], "3576": 58, "35771821": [31, 50, 51, 74], "357823": 58, "358": [58, 65], "3582": [34, 53, 77], "358264": [24, 26, 35, 43, 45, 54, 55, 67, 69, 78], "358333": [16, 61], "358500": [27, 46, 70], "358614": 80, "358913": [19, 63], "3589134": [19, 63], "359": [22, 41, 61, 65], "3590": 65, "359618": 94, "359784": 65, "359887": [28, 71], "359992": [16, 61], "35p": 58, "36": [15, 16, 17, 18, 21, 22, 24, 25, 26, 27, 31, 33, 34, 37, 39, 43, 44, 45, 46, 48, 50, 51, 52, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 74, 76, 77, 96], "360": 63, "360000": [15, 37], "360918": [52, 76, 96], "361": [34, 77], "361718": [23, 42, 66], "362": [15, 34, 37, 77], "362009": [33, 76], "362185e": 24, "362250": 66, "362553": [27, 46, 70], "36269995": [19, 63], "362700": [19, 63], "363": [34, 77], "363192": [16, 61], "363340": 18, "363913": [23, 42, 66, 80], "364": [33, 34, 76, 77], "36400": 58, "364008": 37, "36400802": 37, "364352": [21, 64], "364995": 77, "364998": [45, 69], "365": [33, 76], "36525": [45, 69], "365461": 94, "36559349298477173": 31, "3655935227870941": [50, 74], "365603": [21, 64], "365623": [16, 61], "365787": 94, "365897": 26, "365898": 38, "365922": 38, "366": [19, 33, 34, 63, 76, 77], "366005": [23, 42, 66, 80], "3661": 92, "3663": [34, 77], "366626": [16, 61], "36695134": [31, 50, 51, 74], "367": [33, 76], "367329e": 77, "367423": [41, 65], "367547": [31, 50, 74], "367700": [31, 50, 74], "367868": 77, "368": [33, 41, 76], "368064": 77, "368080": 41, "3681": [26, 45, 69], "368304": [21, 64], "3684": [34, 53, 77], "368406": [17, 39], "36840629": 17, "368922": [29, 72], "369": [24, 43, 67], "369142": 96, "369875": [16, 61], "37": [15, 17, 18, 21, 24, 27, 31, 33, 34, 37, 39, 43, 46, 50, 51, 52, 53, 62, 63, 64, 67, 70, 74, 76, 77, 92, 93, 94, 96], "37033313512802124": [50, 74], "37033477425575256": 31, "370370": 95, "37050406": 9, "370643": [23, 42, 66, 80], "370842": [15, 37], "371": [25, 27, 46, 52, 70, 76, 96], "3717": [26, 45, 69], "371722": [45, 69], "371875": 95, "372": [18, 62], "372000": 92, "372706": [52, 76, 96], "372763": [24, 26, 35, 43, 45, 54, 55, 67, 69, 78], "373": 77, "373031": [16, 61], "373116": 95, "373275": [52, 76, 96], "373309": 38, "373411": [15, 37], "373656": [33, 76], "374": [17, 18, 62], "37446": 92, "374678": 22, "374914": [31, 50, 74], "375108": [31, 50, 74], "37546": [45, 69], "376": [17, 18, 24, 31, 39, 43, 62, 67], "376089": [24, 43, 67], "376914": 95, "377032": [24, 43, 67], "377109": 77, "377191": 22, "377619": 65, "377619120792": 65, "37797291": [19, 63], "377973": [19, 63], "378": 77, "37807203": [31, 50, 51, 74], "378108": 22, "378159": [24, 43, 67], "37849843": 25, "378764": [16, 61], "378839": 48, "378971e": 24, "379": 17, "37903": [17, 39], "37906": [23, 42, 66, 80], "379320": 24, "379416e": 24, "379875e": [24, 67], "38": [9, 15, 16, 18, 21, 24, 27, 31, 32, 33, 34, 37, 43, 46, 50, 51, 52, 61, 62, 64, 66, 67, 70, 74, 75, 76, 77, 92, 96], "3803": [34, 77], "380436": [19, 63], "38043616": [19, 63], "380495": [16, 61], "380504": [18, 62, 63, 93], "380643": [16, 61], "381099": 94, "381190": [27, 46, 70], "3814": 63, "381416e": 77, "381428": [24, 26, 35, 43, 45, 54, 55, 67, 69, 78], "381676": [16, 61], "38192364": [28, 71], "381924": [28, 71], "38214537": [44, 68], "382558": [23, 42, 66], "3828125": [31, 50, 51, 74], "383": [18, 27, 46, 62, 70], "383119": 77, "383232": 96, "383482": 95, "383826": 22, "384": 94, "384127": [16, 61], "384532": 38, "3851": 66, "3856": [16, 61], "385639": [28, 71], "385843": [31, 50, 74], "386": 65, "386071e": 24, "386306e": 24, "386530": [26, 35, 45, 54, 55, 69, 78], "386853": 77, "387": 65, "387392": 94, "387779e": 95, "387967": 20, "388": [34, 92], "388023": [23, 42, 66, 80], "388169": [27, 46, 70], "38853": [24, 43, 67], "38867": 40, "3889": 63, "389": [25, 27, 46, 65, 70], "389065": [26, 45, 69], "389349": [27, 46, 70], "389455": 22, "389655": 77, "389736": [18, 62, 63, 93], "39": [16, 22, 23, 24, 28, 31, 33, 41, 42, 43, 47, 50, 51, 52, 61, 65, 66, 67, 71, 74, 76, 88, 94, 95, 96], "390": 26, "390103": 75, "390105": 32, "390428669205": 65, "390429": 65, "390691": [15, 37], "390725": [24, 43, 67], "39095422e": [26, 45, 69], "391": [18, 62], "3912": [34, 53, 77], "391304": [15, 37], "39163": [23, 42, 66, 80], "392": [58, 94], "392082": [26, 45, 69], "392221": [21, 64], "392385": 77, "392572": 48, "392612": [24, 43, 67], "392893": [22, 41, 61, 65], "392894": [31, 50, 74], "392910": [31, 50, 74], "393": [15, 17, 37, 39, 59, 63], "3932": [34, 53, 77], "39375": [33, 76], "393893": 22, "394113e": 24, "394351": 22, "394920": [18, 62], "394943": 22, "395282e": [24, 67], "395429": 34, "39562": 92, "395686e": 24, "395688": [34, 53, 77], "395697e": 24, "396": [18, 34, 39, 62, 77], "396752e": 24, "396991": [18, 62, 63, 93], "397": [34, 77, 94], "398": [27, 46, 70], "398068": 41, "398495": [52, 76, 96], "398916": 38, "39896994": [19, 63], "398970": [19, 63], "399": [15, 18, 37, 62], "3990": [59, 60, 91], "3991": [24, 43, 67], "399287": 95, "39931": [45, 69], "399827": [23, 42, 66], "39x15": [31, 51], "3__bsmtexposur": [24, 43], "3__bsmtfintype1": [24, 43], "3__bsmtfintype2": [24, 43], "3__fenc": [24, 43], "3__function": [24, 43], "3blue1brown": [32, 75], "3d": [27, 32, 46, 70, 75], "3f": [14, 15, 16, 18, 20, 23, 24, 30, 31, 40, 42, 43, 49, 50, 51, 59, 60, 61, 62, 66, 67, 73, 74], "3h": [33, 76], "3m": 32, "3rd": [20, 31, 50, 51, 74], "3ssnporch": [24, 26, 35, 43, 45, 54, 55, 67, 69, 78], "3v": 83, "3x3": [89, 95], "4": [0, 1, 9, 10, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 37, 39, 40, 41, 42, 43, 44, 46, 48, 49, 50, 51, 52, 53, 54, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 82, 83, 84, 95, 97, 98], "40": [9, 16, 17, 21, 22, 24, 25, 26, 27, 29, 32, 33, 34, 35, 38, 39, 43, 44, 45, 46, 52, 53, 55, 58, 61, 64, 65, 66, 67, 68, 69, 70, 72, 75, 76, 77, 78, 86, 92, 94, 96, 98], "400": [15, 18, 22, 35, 37, 41, 55, 59, 62, 65, 78], "40000": [52, 76, 96], "400000": [15, 31, 37, 41, 50, 52, 65, 74, 76, 96], "400047": [34, 77], "400157": [27, 46, 70], "400309": 48, "400649628005": 65, "400650": 65, "400881e": [15, 37], "401": [15, 22, 37, 41, 61, 65], "4011": 51, "401102": [52, 76], "401168": 22, "401541": [23, 42, 66], "401623": [24, 43, 67], "401729": 38, "401830": [26, 45, 69], "401895": 65, "402": 58, "402101": [15, 37], "402209": 22, "402258": [15, 37], "402541": 40, "402655": 18, "402808": [26, 45, 69], "402892": 77, "403169": [31, 50, 74], "403875": 40, "404": [16, 27, 31, 46, 50, 61, 70, 74], "404403": 22, "404809": [34, 77], "405": 94, "405227e": 24, "405415": [16, 61], "405650": [24, 43, 67], "405681": 77, "40584038": 25, "40584038179225734": 25, "406168": 95, "406202": 65, "406212e": 65, "40689": [27, 46, 70], "407": 80, "40725012": [32, 75], "407510": [23, 42, 66], "407862": [34, 77], "408053": 40, "40828": 58, "4084": [34, 77], "409430": [15, 37], "4095": [31, 50, 74], "409524": 32, "409525": 75, "40b5a809b05a": [34, 53, 77], "41": [16, 18, 24, 25, 26, 27, 28, 30, 32, 33, 34, 43, 45, 46, 49, 52, 61, 62, 66, 67, 69, 70, 71, 73, 75, 76, 77, 92, 96], "410": [18, 62], "4101": 92, "410240": [26, 45, 66, 69], "410599": [27, 46, 70], "410687": 94, "411": 94, "411240": 48, "411412": [24, 43, 67], "41150573": [24, 43, 67], "412": [22, 41, 58, 61, 65], "41210938": [31, 50, 51, 74], "412500": [27, 46, 70], "413017": 22, "413718": [34, 53, 77], "413793e": 95, "413796": [24, 43, 67], "413958": [23, 42, 66], "4143": [34, 77], "414404": 38, "415": [17, 39], "4151": [25, 44, 68], "415285": 22, "4153": [27, 46, 70], "4158382658": 62, "416438": 22, "416470": [20, 40], "4165": [25, 44, 68], "4166": 92, "4169": [34, 77], "416992e": 67, "417009": 48, "417259": [31, 50, 74], "417289": [20, 40], "417394": 77, "4175": 92, "418": [31, 50, 51, 74], "418031": [16, 61], "418069": 65, "418213": [34, 77], "41901484361": 65, "419015": 65, "419355": [21, 64], "4195": [45, 69], "4197": [21, 59, 60, 64, 91], "419892": 96, "42": [13, 16, 18, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 32, 33, 34, 38, 42, 43, 44, 45, 46, 47, 48, 49, 50, 58, 59, 60, 61, 62, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 80, 81, 83, 85, 86, 88, 91, 92, 94, 95, 96], "420": 65, "420000": 58, "420347": 23, "42060": [27, 46, 70], "420730e": 77, "420849": 22, "421": [32, 75], "42104086": [26, 45, 69], "421215": [28, 71], "42121526": [28, 71], "42182019352912903": 31, "4218207597732544": [50, 74], "421875": [21, 64], "422": [24, 43, 67], "422024": 48, "422930": 40, "423162": 48, "4234": [26, 45, 69], "423446": 22, "4236": [26, 45, 69], "4237": 26, "4238": 80, "423852": [23, 42, 66, 80], "424221": 24, "424222": 67, "424337e": 24, "424703": 92, "425": 94, "425112": 48, "425365": [34, 77], "42541681": 83, "425419": [24, 43, 67], "425467": 22, "426067": [18, 62], "426410": [16, 61], "427": [34, 77], "427512": 38, "427558": 22, "4276": [56, 57, 79], "428": [34, 77], "428277": 38, "429": [18, 24, 26, 35, 43, 45, 54, 55, 67, 69, 78], "429217": [23, 42, 66, 80], "429634": [34, 77], "4296875": [31, 50, 51, 74], "429741": 95, "429887": 22, "43": [16, 21, 22, 23, 24, 32, 33, 34, 41, 42, 43, 52, 61, 64, 65, 66, 67, 75, 76, 77, 94, 95], "430": [24, 26, 34, 35, 43, 45, 54, 55, 65, 67, 69, 77, 78], "430295": [23, 42], "430323": [18, 62], "430571": [23, 42, 66, 80], "430704": [28, 71], "4307043": [28, 71], "430868": [21, 64], "4309767675259022": [44, 68], "43097677": [44, 68], "431": [34, 77], "4310": [18, 22, 41, 61, 62, 65], "431104": 38, "431137": [21, 64], "4314": 66, "431408": [34, 77], "432": [34, 77], "433": [25, 34, 77], "433514": [52, 76, 96], "433713": 22, "433814": [34, 53, 77], "433861": 95, "434": [21, 22, 34, 41, 45, 61, 64, 65, 77], "43445": [27, 46, 70], "435": [34, 77], "435186": [16, 61], "435294": 95, "435489": [23, 42, 66], "435792": 65, "436": [34, 77], "436492": [24, 43, 67], "43697758253484525": [21, 64], "437": 69, "4372": [28, 71], "437367": [18, 62, 63, 93], "4375": [27, 30, 46, 49, 70, 73], "437500": [30, 49, 73], "437684": [33, 76], "438": [30, 49, 73], "43820175528526306": [50, 74], "4382021725177765": 31, "438275": [19, 63], "43827545": [19, 63], "43833466": [24, 67], "438592": [26, 35, 45, 54, 55, 69, 78], "438906": [26, 45, 69], "439": [18, 62], "4390": [22, 41, 61, 65], "439209": [23, 42, 66], "439254e": [17, 39], "439360": [18, 62], "439384": 40, "439497e": 24, "439779": 66, "44": [16, 18, 21, 23, 24, 27, 28, 33, 34, 42, 43, 46, 47, 51, 52, 60, 61, 62, 64, 66, 67, 70, 76, 77, 82, 92, 96], "440": [33, 41, 52, 65, 76], "440373": 22, "440415": 75, "440418": 32, "440570": 18, "440601": 32, "440602": 75, "440897": [15, 37], "441": [24, 43, 67, 68], "441036": 92, "441136": 40, "441445": [27, 46, 70], "442": [15, 37], "44228": 22, "442377e": 24, "442806": [16, 61], "442918": 38, "4430": [53, 77], "44311": [27, 46, 70], "4432": [27, 46, 70], "44322699": [44, 68], "443317": [16, 61], "443419": [24, 26, 35, 43, 45, 54, 55, 67, 69, 78], "44372": 92, "443993": 48, "444263": 77, "444297": [27, 46, 70], "444444": [18, 62], "444523": 48, "4448": [27, 46, 70], "445": [25, 65], "445111e": 24, "445124e": 24, "445341": 95, "445922": 95, "446216": [27, 46, 70], "446284e": 24, "446617": 22, "446869": [27, 46, 70], "447": [18, 26, 44, 45, 60, 62, 69], "447059": 95, "447461": [52, 76, 96], "447517": [26, 45, 69], "447650": 77, "44787197": [31, 50, 51, 74], "448": 94, "448184": 77, "4482": 58, "448276": 95, "448276e": 95, "448313": 48, "4484": [16, 61], "448757": [34, 77], "44878422": 25, "449061": 22, "449263": 38, "449666": [16, 61], "44966612": [16, 61], "45": [9, 16, 21, 24, 33, 34, 43, 51, 52, 53, 56, 57, 59, 60, 61, 64, 66, 67, 76, 77, 79, 80, 82, 90, 91, 92, 96], "450000": [30, 49, 73], "450000e": [15, 37], "450132": [52, 76, 96], "450739": [24, 43, 67], "450822": [27, 46, 70], "451888": [23, 42, 66], "452600": [27, 46, 70], "453367": [27, 46, 70], "453678": 94, "4537": [34, 53, 77], "454427": [18, 62, 63, 93], "454677": [28, 71], "45467725": [28, 71], "454788": [26, 35, 45, 54, 55, 69, 78], "454966": [23, 42, 66, 80], "4552": [26, 45, 69], "45555535": [26, 45, 69], "455652": [15, 37], "455837": 41, "45587": [52, 76, 96], "45588": [52, 76, 96], "45589": [52, 76, 96], "45590": [52, 76, 96], "45591": [52, 76, 96], "456395": 22, "456419": [27, 46, 70], "45653693": [19, 63], "456537": [19, 63], "456984": [23, 42], "457170": [23, 42], "457211": 18, "457435": [52, 76, 96], "458": [18, 62], "458063": 77, "458084": 48, "458333": [30, 49, 73], "458524": [34, 53, 77], "458879": 48, "459": [17, 24, 39, 43, 67], "4591": [18, 62], "459214e": 24, "459873": 77, "459937": 51, "45a": [52, 76, 90, 96], "45am": [52, 76, 90, 96], "46": [9, 16, 17, 18, 21, 24, 33, 34, 39, 41, 43, 52, 59, 60, 61, 62, 63, 64, 67, 76, 77, 80, 91, 93, 94, 95, 96], "460047": 77, "46019608e": [26, 45, 69], "460294": 41, "460316": 48, "4608": [59, 60, 91], "460950": [28, 71], "461": [17, 18, 62, 65], "462": [44, 50], "462060": 77, "462545": [26, 45, 69], "462963": [21, 64], "463": 66, "463582": [25, 44, 68], "464485": 48, "464815": 48, "465000": 95, "465279e": 24, "46530779": [19, 63], "465308": [19, 63], "465356": [34, 77], "4664": 58, "467": 25, "46729488": [24, 43, 67], "467379": [26, 45, 69], "467628": [27, 46, 70], "467657": 22, "467755": 77, "468": [22, 26, 41, 45, 61, 65, 69], "468232": [52, 76, 96], "468672": 92, "4687": [27, 46, 70], "468882": 95, "468996": 38, "469": [18, 62, 80], "469383": [66, 80], "4695": 66, "469571": [27, 46, 70], "469953": 92, "47": [1, 15, 16, 18, 21, 22, 24, 27, 37, 41, 43, 46, 58, 59, 60, 61, 62, 64, 65, 67, 70, 92, 95], "470": [18, 62], "4700": 65, "470060": [24, 67], "470350": 34, "470666": [24, 43, 67], "471000": [15, 37], "471032": [26, 45, 69], "471357": 48, "472": 19, "47242662": 83, "4726": [34, 53, 77], "472603": [24, 43, 67], "47278": 20, "472790": [23, 42, 66, 80], "473": [31, 50, 51, 74], "473189": 77, "473691": [16, 61], "474": 80, "474552": [16, 61], "47491": [23, 42, 66], "475000": 92, "475099": [26, 45, 69], "475188": 75, "475197": 32, "475540": [31, 50, 51, 74], "476": [14, 18, 59], "4760": 65, "47606": [27, 46, 70], "476092": [24, 26, 35, 43, 45, 54, 55, 67, 69, 78], "476406": [26, 45, 69], "476412": [28, 71], "47641249": [28, 71], "477": [18, 65], "477091": 22, "477291": [27, 46, 70], "477964": 48, "478": 18, "478060": [52, 76, 96], "478508": 38, "478647": 95, "479": [18, 25], "479109": [16, 61], "479132": [27, 46, 70], "479773": [31, 50, 51, 74], "48": [16, 21, 23, 24, 30, 33, 34, 42, 43, 47, 48, 49, 52, 59, 60, 61, 64, 66, 67, 73, 76, 77, 91, 92, 94, 96, 98], "480": [18, 24, 43, 67], "4800": 58, "480219": 48, "480249": [16, 61], "4806334": 51, "48073598": [28, 71], "4809": 65, "481": [18, 62, 96], "4810": [56, 57, 79], "4813": [21, 60, 64], "481514": [24, 67], "481693": 32, "481698": 75, "481793": [18, 62], "481807": 22, "481893": [23, 42, 66, 80], "481960": [23, 42, 66], "482": 18, "4820": [15, 37], "4822": [34, 77], "482233": 48, "482500": 92, "482759e": 95, "482910": 48, "483": [18, 25], "483751": [16, 61], "484": 18, "484937": [21, 64], "485": 18, "485192": 38, "4854": [26, 45, 69], "485722": [31, 50, 51, 74], "486": 18, "4861": [18, 62, 63, 93], "486266": [18, 62], "4863": 92, "486664": [31, 50, 51, 74], "48666667": 39, "487": [18, 62, 63], "487740": [31, 50, 51, 74], "488": [18, 62], "488000": 95, "488163": [31, 50, 51, 74], "488753": [52, 76, 96], "489": 18, "489130": [21, 64], "489238": 16, "489511": 22, "489593": [31, 50, 51, 74], "49": [16, 21, 23, 24, 27, 33, 34, 42, 43, 46, 52, 61, 64, 66, 67, 70, 76, 77, 80, 88, 92, 94, 96], "490": [18, 27, 46, 70], "490000": [18, 62], "490033": [24, 43, 67], "49006623": 39, "490568": 65, "490797": [31, 50, 51, 74], "490930": [31, 50, 51, 74], "491217": [23, 42, 66], "491366": [26, 35, 45, 54, 55, 69, 78], "491379": [18, 27, 46, 62, 70], "491632": 22, "491880": 48, "491968": [31, 50, 51, 74], "492": [18, 62, 63, 80], "49206349206349204": [17, 39], "492270": [19, 63], "49227046": 19, "492307": [31, 50, 51, 74], "492551": [31, 50, 51, 74], "492994": 48, "493": [18, 62], "493489": [31, 50, 51, 74], "493544": [18, 62], "49392051": 19, "493921": [19, 63], "494": [18, 22, 34, 41, 61, 62, 65], "4943": 65, "494309": [15, 37], "495524": 38, "49575": [23, 42, 66, 80], "496": [27, 46, 70], "496146": 77, "496213": [24, 43, 67], "496757": [26, 45, 69], "497143": [31, 50, 51, 74], "497386": [16, 61], "497601": [31, 50, 74], "497787": [24, 67], "497949": [31, 50, 51, 74], "498": [56, 57, 79, 80], "498133e": 24, "498157": 38, "498325": 96, "498381": 48, "498562": [16, 61], "498738": 95, "499375": 16, "499900": [18, 62], "49997": 92, "4__alley_grvl": [24, 43], "4__alley_miss": [24, 43], "4__alley_pav": [24, 43], "4__bldgtype_1fam": [24, 43], "4__bldgtype_2fmcon": [24, 43], "4__bldgtype_duplex": [24, 43], "4__bldgtype_twnh": [24, 43], "4__bldgtype_twnhs": [24, 43], "4__centralair_i": [24, 43], "4__centralair_n": [24, 43], "4__condition1_arteri": [24, 43], "4__condition1_feedr": [24, 43], "4__condition1_norm": [24, 43], "4__condition1_posa": [24, 43], "4__condition1_posn": [24, 43], "4__condition1_rra": [24, 43], "4__condition1_rran": [24, 43], "4__condition1_rrn": [24, 43], "4__condition1_rrnn": [24, 43], "4__condition2_arteri": [24, 43], "4__condition2_feedr": [24, 43], "4__condition2_norm": [24, 43], "4__condition2_posa": [24, 43], "4__condition2_posn": [24, 43], "4__condition2_rra": [24, 43], "4__condition2_rran": [24, 43], "4__condition2_rrnn": [24, 43], "4__electrical_fusea": [24, 43], "4__electrical_fusef": [24, 43], "4__electrical_fusep": [24, 43], "4__electrical_miss": [24, 43], "4__electrical_mix": [24, 43], "4__electrical_sbrkr": [24, 43], "4__exterior1st_asbshng": [24, 43], "4__exterior1st_asphshn": [24, 43], "4__exterior1st_brkcomm": [24, 43], "4__exterior1st_brkfac": [24, 43], "4__exterior1st_cblock": [24, 43], "4__exterior1st_cemntbd": [24, 43], "4__exterior1st_hdboard": [24, 43], "4__exterior1st_imstucc": [24, 43], "4__exterior1st_metalsd": [24, 43], "4__exterior1st_plywood": [24, 43], "4__exterior1st_ston": [24, 43], "4__exterior1st_stucco": [24, 43], "4__exterior1st_vinylsd": [24, 43], "4__exterior1st_wd": [24, 43], "4__exterior1st_wdsh": [24, 43], "4__exterior2nd_asbshng": [24, 43], "4__exterior2nd_asphshn": [24, 43], "4__exterior2nd_brk": [24, 43], "4__exterior2nd_brkfac": [24, 43], "4__exterior2nd_cblock": [24, 43], "4__exterior2nd_cmentbd": [24, 43], "4__exterior2nd_hdboard": [24, 43], "4__exterior2nd_imstucc": [24, 43], "4__exterior2nd_metalsd": [24, 43], "4__exterior2nd_oth": [24, 43], "4__exterior2nd_plywood": [24, 43], "4__exterior2nd_ston": [24, 43], "4__exterior2nd_stucco": [24, 43], "4__exterior2nd_vinylsd": [24, 43], "4__exterior2nd_wd": [24, 43], "4__foundation_brktil": [24, 43], "4__foundation_cblock": [24, 43], "4__foundation_pconc": [24, 43], "4__foundation_slab": [24, 43], "4__foundation_ston": [24, 43], "4__foundation_wood": [24, 43], "4__garagefinish_fin": [24, 43], "4__garagefinish_miss": [24, 43], "4__garagefinish_rfn": [24, 43], "4__garagefinish_unf": [24, 43], "4__garagetype_2typ": [24, 43], "4__garagetype_attchd": [24, 43], "4__garagetype_bas": [24, 43], "4__garagetype_builtin": [24, 43], "4__garagetype_carport": [24, 43], "4__garagetype_detchd": [24, 43], "4__garagetype_miss": [24, 43], "4__heating_floor": [24, 43], "4__heating_gasa": [24, 43], "4__heating_gasw": [24, 43], "4__heating_grav": [24, 43], "4__heating_othw": [24, 43], "4__heating_wal": [24, 43], "4__housestyle_1": [24, 43], "4__housestyle_1stori": [24, 43], "4__housestyle_2": [24, 43], "4__housestyle_2stori": [24, 43], "4__housestyle_sfoy": [24, 43], "4__housestyle_slvl": [24, 43], "4__landcontour_bnk": [24, 43], "4__landcontour_hl": [24, 43], "4__landcontour_low": [24, 43], "4__landcontour_lvl": [24, 43], "4__landslope_gtl": [24, 43], "4__landslope_mod": [24, 43], "4__landslope_sev": [24, 43], "4__lotconfig_corn": [24, 43], "4__lotconfig_culdsac": [24, 43], "4__lotconfig_fr2": [24, 43], "4__lotconfig_fr3": [24, 43], "4__lotconfig_insid": [24, 43], "4__lotshape_ir1": [24, 43], "4__lotshape_ir2": [24, 43], "4__lotshape_ir3": [24, 43], "4__lotshape_reg": [24, 43], "4__masvnrtype_brkcmn": [24, 43], "4__masvnrtype_brkfac": [24, 43], "4__masvnrtype_miss": [24, 43], "4__masvnrtype_ston": [24, 43], "4__miscfeature_gar2": [24, 43], "4__miscfeature_miss": [24, 43], "4__miscfeature_othr": [24, 43], "4__miscfeature_sh": [24, 43], "4__miscfeature_tenc": [24, 43], "4__mosold_1": [24, 43], "4__mosold_10": [24, 43], "4__mosold_11": [24, 43], "4__mosold_12": [24, 43], "4__mosold_2": [24, 43], "4__mosold_3": [24, 43], "4__mosold_4": [24, 43], "4__mosold_5": [24, 43], "4__mosold_6": [24, 43], "4__mosold_7": [24, 43], "4__mosold_8": [24, 43], "4__mosold_9": [24, 43], "4__mssubclass_120": [24, 43], "4__mssubclass_160": [24, 43], "4__mssubclass_180": [24, 43], "4__mssubclass_190": [24, 43], "4__mssubclass_20": [24, 43], "4__mssubclass_30": [24, 43], "4__mssubclass_40": [24, 43], "4__mssubclass_45": [24, 43], "4__mssubclass_50": [24, 43], "4__mssubclass_60": [24, 43], "4__mssubclass_70": [24, 43], "4__mssubclass_75": [24, 43], "4__mssubclass_80": [24, 43], "4__mssubclass_85": [24, 43], "4__mssubclass_90": [24, 43], "4__mszoning_c": [24, 43], "4__mszoning_fv": [24, 43], "4__mszoning_rh": [24, 43], "4__mszoning_rl": [24, 43], "4__mszoning_rm": [24, 43], "4__neighborhood_blmngtn": [24, 43], "4__neighborhood_bluest": [24, 43], "4__neighborhood_brdal": [24, 43], "4__neighborhood_brksid": [24, 43], "4__neighborhood_clearcr": [24, 43], "4__neighborhood_collgcr": [24, 43], "4__neighborhood_crawfor": [24, 43], "4__neighborhood_edward": [24, 43], "4__neighborhood_gilbert": [24, 43], "4__neighborhood_idotrr": [24, 43], "4__neighborhood_meadowv": [24, 43], "4__neighborhood_mitchel": [24, 43], "4__neighborhood_nam": [24, 43], "4__neighborhood_noridg": [24, 43], "4__neighborhood_npkvil": [24, 43], "4__neighborhood_nridght": [24, 43], "4__neighborhood_nwam": [24, 43], "4__neighborhood_oldtown": [24, 43], "4__neighborhood_sawy": [24, 43], "4__neighborhood_sawyerw": [24, 43], "4__neighborhood_somerst": [24, 43], "4__neighborhood_stonebr": [24, 43], "4__neighborhood_swisu": [24, 43], "4__neighborhood_timb": [24, 43], "4__neighborhood_veenk": [24, 43], "4__paveddrive_i": [24, 43], "4__paveddrive_n": [24, 43], "4__paveddrive_p": [24, 43], "4__roofmatl_clytil": [24, 43], "4__roofmatl_compshg": [24, 43], "4__roofmatl_membran": [24, 43], "4__roofmatl_met": [24, 43], "4__roofmatl_rol": [24, 43], "4__roofmatl_tar": [24, 43], "4__roofmatl_wdshak": [24, 43], "4__roofmatl_wdshngl": [24, 43], "4__roofstyle_flat": [24, 43], "4__roofstyle_g": [24, 43], "4__roofstyle_gambrel": [24, 43], "4__roofstyle_hip": [24, 43], "4__roofstyle_mansard": [24, 43], "4__roofstyle_sh": [24, 43], "4__salecondition_abnorml": [24, 43], "4__salecondition_adjland": [24, 43], "4__salecondition_alloca": [24, 43], "4__salecondition_famili": [24, 43], "4__salecondition_norm": [24, 43], "4__salecondition_parti": [24, 43], "4__saletype_cod": [24, 43], "4__saletype_con": [24, 43], "4__saletype_conld": [24, 43], "4__saletype_conli": [24, 43], "4__saletype_conlw": [24, 43], "4__saletype_cwd": [24, 43], "4__saletype_new": [24, 43], "4__saletype_oth": [24, 43], "4__saletype_wd": [24, 43], "4__street_grvl": [24, 43], "4__street_pav": [24, 43], "4__utilities_allpub": [24, 43], "4__utilities_nosewa": [24, 43], "4f": [16, 19, 20, 23, 31, 40, 42, 51, 61, 63, 66, 74], "4th": [20, 25, 26, 44, 45, 66, 68, 69], "4x": 98, "5": [1, 4, 20, 21, 22, 23, 24, 25, 27, 29, 30, 31, 33, 37, 38, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 52, 53, 54, 58, 64, 65, 66, 67, 68, 72, 73, 76, 80, 83, 84, 85, 91, 95, 97, 98], "50": [1, 15, 16, 17, 18, 19, 23, 24, 25, 26, 27, 29, 30, 31, 33, 34, 35, 37, 39, 41, 42, 43, 44, 45, 46, 50, 51, 52, 53, 54, 55, 58, 61, 62, 63, 65, 66, 67, 68, 69, 70, 72, 73, 74, 76, 77, 78, 80, 92, 95, 96, 98], "500": [18, 20, 25, 26, 27, 31, 40, 44, 45, 46, 50, 58, 62, 66, 68, 69, 70, 74], "5000": [13, 15, 20, 37, 40, 56, 57, 58, 59, 79], "50000": [52, 76, 96], "500000": [15, 16, 18, 23, 24, 29, 37, 42, 43, 52, 62, 63, 66, 67, 72, 76, 96], "500000e": [15, 37, 65], "500001": [18, 62], "5000x10000": 20, "500140": 95, "5002": [24, 43, 67], "500625": 61, "50062e": 61, "500924": [18, 62, 63, 93], "501": [18, 62], "501191": [31, 50, 51, 74], "501250": [16, 61], "501304e": 24, "501875": [16, 61], "5024752475247525": 65, "502500": [16, 61], "502654": 95, "502985": [23, 42, 66, 80], "503": 40, "503000": [18, 62], "503090": [23, 42, 66], "503125": [16, 61], "50325": 40, "5034000000000001": 20, "50350": 40, "503709": 94, "503750": [16, 61], "503807": [31, 50, 51, 74], "504": [16, 27, 40, 46, 61, 70], "504231": 77, "504375": [16, 61], "504429": [19, 63], "50442945": 19, "504644": [22, 41, 65], "50475372e": [26, 45, 69], "50483": 22, "504fde4fcf8": [34, 53, 77], "505000": [16, 61], "505026": [15, 37], "505180": [31, 50, 51, 74], "505335": [23, 42, 66], "505592e": 24, "505625": 16, "5057": [24, 43, 67], "50596432e": 83, "506035e": 24, "506079e": 24, "506084e": 24, "506211": [18, 22, 41, 62, 65], "506250": 16, "506410": [21, 64], "506637": 22, "506875": [16, 61], "507130": [41, 65], "507225": 48, "507359": [18, 22, 41, 62, 65], "507500": 61, "50774": [22, 41, 65], "507740": [18, 62], "50775": [22, 41, 65], "507750": [22, 41, 65], "507752": [18, 22, 41, 62, 65], "507754": 77, "507995": [21, 64], "508": [18, 24, 43, 62, 67], "508125": 61, "508133": [18, 22, 41, 62, 65], "508371": [22, 41, 65], "508534": 51, "508741": [31, 50, 51, 74], "50884": [27, 46, 70], "50899": [22, 41, 65], "509000": 58, "509001": [24, 43, 67], "509043": 22, "509045": [15, 37], "509317": [18, 22, 41, 62, 65], "509375": 16, "5098": [31, 51, 74], "509859": [31, 50, 51, 74], "509930": [52, 76, 96], "509991": [23, 42], "50k": [13, 25, 26, 44, 45, 66, 68, 69], "51": [16, 18, 22, 24, 26, 28, 33, 34, 35, 41, 43, 45, 52, 55, 61, 62, 63, 65, 66, 67, 69, 71, 76, 77, 78, 93, 94, 96], "5100": [15, 37], "510000": [15, 16, 22, 37, 41, 59, 61, 65], "510421": [31, 50, 51, 74], "510505": [31, 50, 51, 74], "510625": 61, "510697e": [15, 37], "5107": [15, 37], "510836": [22, 41, 65], "5109": [26, 45, 69], "511": [10, 95], "5112": [15, 37, 59], "51137414e": [26, 45, 69], "51143": [27, 46, 70], "51150": [23, 42, 66, 80], "511620e": 24, "5118": [26, 45, 69], "511862": 48, "512": [32, 75], "5120": 58, "512000": [22, 41, 61, 65], "51226051": [28, 71], "5123": 51, "512319": [18, 62], "512408": [24, 26, 35, 43, 45, 54, 55, 67, 69, 78], "512897": [16, 61], "512x640": [32, 75], "513": [18, 62], "513063": 96, "5131": [51, 82], "513124": 48, "513239": 48, "513333": [17, 39], "513678": [34, 53, 77], "514150": [31, 50, 51, 74], "514155": [18, 24, 43, 62, 63, 67, 93], "514347": 51, "514598e": [24, 67], "5146": [21, 64], "5147": 92, "514950": [17, 39], "51503393": [19, 63], "515034": [19, 63], "515351e": 24, "515443": [45, 69], "5156": [18, 27, 46, 62, 70], "515677": 75, "515678": 32, "515755": [17, 39], "515848": [27, 46, 70], "516199": 51, "516394": [27, 46, 70], "516556": [17, 39], "5166": 58, "516774": 38, "516858": 51, "517241e": 95, "517273": [31, 50, 51, 74], "517346": [23, 42, 66], "517647": 95, "518113": [31, 50, 51, 74], "519000": [15, 37], "519029": [23, 42, 66, 80], "519133": 38, "51923": 22, "52": [16, 18, 21, 23, 24, 27, 33, 34, 42, 43, 46, 52, 61, 62, 64, 66, 67, 70, 76, 77, 80, 95, 96], "520076": 95, "520236": 95, "520495": [31, 50, 51, 74], "520519": 48, "52061": [52, 76], "520700": 51, "520782": [31, 50, 51, 74], "5208": [15, 37, 59], "520835": 94, "520855": 48, "520857": [23, 42, 66], "520864": 92, "5209": [24, 43, 67], "520926": 23, "5212": [24, 43, 67], "521284e": [24, 67], "521567e": 24, "521578e": 24, "521743e": 24, "521772": 51, "521797": 22, "522": [24, 43, 67], "522563e": 24, "5227966": 51, "523595": [31, 50, 51, 74], "523659": 48, "523684": [31, 50, 51, 74], "5238095238095238": [14, 59], "52398": [27, 46, 70], "524": [14, 30, 49, 59, 73], "524364": 77, "5245916114790287": 39, "525": [17, 39], "5253": [26, 45, 69], "525554": [27, 46, 70], "525757": [16, 61], "526046": 51, "526078": [18, 62, 63, 93], "526435": 38, "526501": 22, "526596": [27, 46, 70], "526602": [24, 43, 67], "526780": 38, "527251": [34, 77], "5274": [34, 53, 77], "527500": [18, 62], "528": [24, 43, 67], "5282": [34, 53, 77], "528403": [16, 61], "52881619": [16, 61], "529": 94, "529210": [23, 42, 66], "529212": 32, "529213": 75, "529388e": 24, "5294": [25, 44, 68], "529412": [18, 62], "52980132": 39, "53": [15, 21, 24, 33, 37, 41, 43, 47, 52, 64, 67, 76], "530052": 65, "530468": 32, "530470": 75, "530978": [23, 42, 66, 80], "531": [35, 55, 78], "531116e": 24, "5315": 65, "53187": 79, "532034": [24, 43, 67], "5324": 34, "5325916114790287": 17, "532694": 77, "533035": 38, "53333333": 39, "533498": [16, 61], "533875": 48, "534114": 65, "534342": [27, 46, 70], "5345": [15, 37], "534753": 96, "535": [18, 27, 46, 62, 70], "535014": [18, 62], "53520104": [16, 61], "535604": [18, 62], "535622": [27, 46, 70], "535896": [20, 40], "536": 25, "536362": [28, 71], "53636249": [28, 71], "53642384": 17, "536751": 92, "537": 63, "537267": [18, 62], "537584": 92, "537732": [31, 50, 51, 74], "537778": 95, "538000": [15, 37, 59], "538565": 48, "538702": [16, 61], "538816": [23, 42, 66, 80], "539": [24, 94], "5390": [26, 45, 66, 69], "5391": [18, 27, 46, 62, 70], "539116": [52, 76, 96], "539254": 38, "539376": 77, "539424": [34, 77], "539989": [15, 37], "54": [24, 33, 34, 39, 43, 50, 52, 67, 74, 76, 77, 88, 92, 94, 96], "540": [33, 52, 76], "540000": [18, 62], "540039": 51, "540088": 37, "540359": [27, 46, 70], "541117": [24, 43, 67], "541347": [31, 50, 51, 74], "541408": 22, "541488": [27, 46, 70], "54152": 66, "541667": 63, "541795": [23, 42, 66], "542": [35, 55, 78], "542049": [45, 69], "54240": [23, 42, 66], "542624": [26, 45, 69], "542873": [18, 62, 63, 93], "54304636": [17, 39], "5431876379690949": 17, "543297": 65, "543351": [26, 45, 69], "543464": [31, 50, 51, 74], "543673": 38, "544": 65, "544084": 38, "544122": 32, "544123": 75, "544821": 48, "546": [18, 62], "5461": [24, 43, 67], "546137": 38, "546322": 94, "5463515822289584": 41, "546352": 41, "546473": [21, 64], "546610": [16, 61], "54666667": [17, 39], "54676006e": [26, 45, 69], "547": [24, 43, 65, 67], "547090": 51, "547804": 48, "547993": [23, 42, 66, 80], "548": [16, 25, 26, 28, 94], "548750": 16, "548778": 95, "5488206169941388": 92, "548831": [26, 45, 69], "54966887": [17, 39], "549682": [23, 42, 66, 80], "5498": [16, 61], "549946": [31, 50, 51, 74], "55": [16, 21, 24, 25, 26, 33, 34, 35, 43, 44, 45, 47, 50, 53, 55, 59, 60, 61, 64, 66, 67, 68, 69, 74, 76, 77, 78, 80, 91], "55000": 65, "550000": [18, 62, 63, 65], "550004": [25, 44, 68], "55015": 38, "550616": [66, 80], "551": 63, "55101": [52, 76], "55121578": 25, "5513": 65, "5514": [25, 26, 44, 45, 68, 69], "5515": [34, 53, 77], "551686": 22, "551724": 95, "551759e": 77, "551862e": [24, 67], "551975": 24, "552": [18, 24, 43, 62, 67], "552364": 48, "552492": [15, 37], "552721": [44, 68], "553": 15, "55333333": [17, 39], "553965": [26, 45, 69], "553979": [23, 42, 66], "554": 92, "5540": [34, 77], "554180": [52, 76, 96], "554463": 51, "554621": [27, 46, 70], "5551": [21, 64], "555180": [15, 37], "555625": 16, "555740": [16, 61], "556": [31, 50, 74], "55629139": 39, "5566": [18, 62, 63, 93], "556716": [17, 39], "55677301": [44, 68], "557": 68, "557242": [23, 42, 66], "557739": 24, "558": [24, 26, 27, 35, 43, 45, 46, 54, 55, 67, 69, 70, 78], "558564": [23, 42, 66, 80], "55862988e": [26, 45, 69], "55873323": 75, "55873324": 32, "5588": 58, "558824": [23, 42, 66], "558889": [24, 43, 67], "559": [24, 26, 35, 43, 44, 45, 54, 55, 65, 67, 69, 78], "559284": [15, 37], "559905": 32, "559906": 75, "56": [16, 23, 24, 28, 34, 42, 43, 52, 61, 63, 66, 67, 76, 77, 88, 94, 96], "560": [15, 37, 92], "560053": [15, 37], "560225": [18, 62], "560439": 96, "560768": [24, 43, 67], "561": [1, 22, 26, 27, 41, 46, 61, 65, 70], "561017": 23, "561074": 23, "561467": [18, 62, 63, 93], "561602": [26, 45, 69], "561645e": [24, 67], "562112": [18, 62], "5623061656951904": [31, 50, 74], "5623062252998352": 51, "562680": 92, "562712": [31, 50, 51, 74], "56291391": 17, "563": 1, "5630224174651548": [21, 64], "5630921721458435": [31, 50, 51, 74], "5631500400": [15, 37], "563314": [24, 26, 35, 43, 45, 54, 55, 67, 69, 78], "563467": [18, 62], "5639418363571167": [50, 74], "5639421939849854": 31, "564264": 22, "5644": [24, 43, 67], "564483": [27, 46, 70], "564548e": 24, "564631": 77, "565": [27, 46, 70], "5650": [15, 37, 59], "565062": [34, 53, 77], "56521734": 9, "565344": 48, "565621": 95, "565679": [23, 42, 66], "565746": 77, "565888": [18, 62], "566": [18, 62], "566092": [18, 62], "566144": 26, "56666667": 39, "5667": 66, "567169": [34, 77], "567183": 23, "567856e": 24, "568": [32, 75], "568009": [16, 61], "56804591": [24, 43, 67], "568474": 92, "568549": 92, "568663": 24, "568750": 61, "5690201394302518": [26, 45, 69], "56902014": [26, 45, 69], "56902323": [44, 68], "5690232324740979": [44, 68], "569375": 16, "5694": [27, 46, 70], "56953642": [17, 39], "57": [15, 16, 18, 22, 23, 24, 26, 33, 34, 35, 42, 43, 45, 52, 53, 54, 55, 61, 62, 63, 66, 67, 69, 76, 77, 78, 80, 92, 93, 94, 96], "570015": [24, 43, 67], "570449": [23, 42, 66], "570473": [27, 46, 70], "570599": 34, "5707": [34, 53, 77], "570739": [27, 46, 70], "571": [17, 28, 39, 71], "571431": [31, 50, 51, 74], "571500": [27, 46, 70], "571676": [20, 40], "571800": [15, 37], "571875": 16, "571901e": 24, "571969": [27, 46, 70], "572": 1, "572105": [16, 61], "572549": [18, 62], "572962": 77, "573": 83, "573050": [23, 42, 66, 80], "573129": [24, 26, 35, 43, 45, 54, 55, 67, 69, 78], "5732": [56, 57, 79, 80], "573275": 92, "57333333": 17, "573457e": 77, "573542": [27, 46, 70], "573818": [23, 42, 66, 80], "573941": 92, "574": 15, "57415": [52, 76, 96], "574260": [27, 46, 70], "5744": 92, "575": 25, "575000": [30, 49, 73], "575043": [15, 37], "57510": [27, 46, 70], "575111": 95, "575190": 92, "5755444169044495": [50, 51, 74], "5755444765090942": 31, "575625": 61, "575636": [17, 39], "575756": 32, "575759": 75, "575907": [27, 46, 70], "576": [18, 62], "57615894": [17, 39], "57640869": [19, 63], "576409": [19, 63], "576434": 75, "576441": 32, "576565": 92, "576921": [31, 50, 51, 74], "578459": 38, "578523": [21, 64], "578567": 38, "578654": [66, 80], "5789": [24, 43, 67], "579": [41, 91], "579091": [27, 46, 70], "579245": [31, 50, 51, 74], "579432": [21, 64], "579559e": 24, "579660": [25, 44, 68], "5798": [25, 44, 68], "57994": [23, 42, 66, 80], "58": [16, 21, 24, 28, 33, 34, 43, 59, 60, 61, 64, 67, 76, 77, 91, 92], "580": [32, 75], "580000": 16, "580302e": [15, 37], "5804311633110046": [31, 50, 51, 74], "580539e": [24, 67], "580963": 22, "581": [26, 45, 69], "581217": [25, 44, 68], "581275": 23, "5813": [15, 37], "58137177": [19, 63], "581372": [19, 63], "5814": 58, "581687": [27, 46, 70], "581787": 77, "582": [25, 44, 58, 68], "582090": [23, 42, 66], "5824530124664307": [31, 50, 74], "5824530720710754": 51, "582469": [24, 67], "582570": [17, 39], "583": 15, "583125": 16, "58387198": [28, 71], "583872": [28, 71], "583972": 38, "584": [18, 62], "584101": 48, "584375": 61, "584615": [18, 27, 46, 62, 70], "585": [18, 62], "585187": [17, 39], "585513": [21, 64], "585609": 92, "5857": [34, 77], "586095": [18, 62, 63, 93], "586207": 95, "586875": 16, "587773": 66, "588": [22, 41, 61, 65], "588235": [21, 64], "588307": [18, 62], "589262": 95, "59": [1, 13, 16, 24, 34, 41, 43, 52, 53, 61, 67, 76, 77, 94, 95, 98], "590": [15, 26], "590243": [31, 50, 51, 74], "59049": [42, 66], "59050": [42, 66], "590618": [27, 46, 70], "59082668": [19, 63], "590827": [19, 63], "5915": 63, "591875": 61, "591971": [23, 42], "592401": 58, "592500": [16, 61], "592508": 38, "5925410985946655": [31, 50, 51, 74], "592797e": 77, "59300": [27, 46, 70], "5931": [24, 43, 67], "593125": 61, "593370": 24, "593508": [28, 71], "593750": 61, "5938": [18, 62], "593860": 26, "594": [18, 62], "5941": [15, 37], "5941596182077427": 25, "59415962": 25, "5944": [15, 37], "594595": [16, 61], "594982": [23, 42, 66, 80], "594995": 66, "5950": [18, 62], "595569e": 24, "596151": [27, 46, 70], "596810": [16, 61], "596864": [24, 43, 67], "5970": [25, 44, 68], "59700": [23, 42, 66], "597015": [21, 64], "59708": [23, 42, 66], "597326": 66, "597500": 61, "597555": 58, "597924": [24, 26, 35, 43, 45, 54, 55, 67, 69, 78], "598": [18, 62], "598057": [17, 39], "59810": [23, 42, 66], "598100": [21, 64], "598149": [24, 26, 35, 43, 45, 54, 55, 67, 69, 78], "598723": 22, "598821": 92, "5993570685386658": 51, "5993571281433105": [31, 50, 74], "599492": [21, 64], "599860": [16, 61], "599894": [52, 76, 96], "59pm": 13, "5fin": [24, 43, 67, 69], "5m": 32, "5th": [25, 26, 44, 45, 66, 68, 69], "5unf": [24, 43, 67, 69], "6": [1, 9, 15, 16, 18, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 37, 38, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 58, 59, 60, 61, 62, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 83, 84, 85, 91, 97], "60": [9, 18, 24, 26, 27, 28, 30, 33, 34, 35, 43, 45, 46, 51, 53, 54, 55, 58, 62, 67, 69, 70, 71, 73, 76, 77, 78, 80, 82, 94], "600": [18, 21, 50, 51, 62, 64, 74], "60000": [52, 76, 96], "600000": [16, 41, 52, 60, 61, 65, 76, 92, 96], "600193": [23, 42, 66], "60023631": [24, 67], "600299": 38, "600k": [24, 43, 67], "600x400": 97, "601": 65, "601042": 58, "601198": 48, "601504": [21, 64], "601712": [23, 42, 66], "601790": [21, 64], "602": [15, 18, 62, 63, 93, 94], "602000": [18, 62], "602649": [16, 61], "6028": 66, "602936": 95, "602941": [23, 42, 66], "602954": [44, 68], "6031432151794434": [50, 51, 74], "6031432747840881": 31, "60319915": 83, "603243": [15, 37], "603739": [15, 37], "603750": 61, "603970": 77, "604": [16, 61, 95], "6040": [22, 41, 61, 65], "604000": [15, 37, 59], "604032": [23, 42, 66, 80], "60429913": [24, 43, 67], "604320": [21, 64], "60455": [52, 76, 96], "604619": [21, 64], "604797": [21, 64], "6048": [52, 76], "604807": 77, "60495488": [16, 61], "605060": [23, 42, 66], "6051": [18, 62, 63, 93], "605100": [21, 64], "605101": [21, 64], "605102": [21, 64], "605263": [16, 61], "605665": 48, "605696": [21, 64], "606": [18, 62], "606000": 92, "606061": [21, 64], "6063088774681091": [31, 50, 51, 74], "606557": [21, 64], "606567": [21, 64], "606754": 20, "606811": [22, 41, 65], "606902": [21, 64], "607062": [52, 76, 96], "608050": [21, 64], "608125": 16, "6082": [18, 62], "608468": [21, 64], "608565": [34, 53, 77], "60860": [18, 62], "608633": [20, 40], "6086404323577881": [31, 50, 74], "6086405515670776": 51, "608943": 96, "609": [18, 62], "609039": 48, "6092": 58, "6093292236328125": [31, 51], "6093292832374573": [50, 74], "60943": [23, 42, 66, 80], "60k": [24, 43, 67], "61": [16, 19, 21, 24, 28, 34, 43, 48, 52, 61, 63, 64, 66, 67, 71, 76, 77], "610143": 38, "61029914": [24, 43, 67], "610407": [23, 42, 66], "610931": [29, 72], "611": 63, "6111123561859131": [50, 51, 74], "6111124157905579": 31, "611178": [52, 76, 96], "611390": 92, "611445e": 24, "611742": 48, "611875": 16, "612349": [19, 63], "61234944": [19, 63], "6124": [34, 53, 77], "6124401913875598": 91, "612500": 61, "612546": [23, 42, 66], "612621": [21, 64], "612755": [16, 61], "612998": 77, "613231": [17, 39], "613507": [21, 64], "613738": 65, "613738418384": 65, "614": [18, 62], "61420598": [19, 63], "614206": [19, 63], "614236e": 77, "614567": [27, 46, 70], "614629": 25, "614761": 23, "614861": 38, "615": [18, 62], "615124": [44, 68], "6154": [27, 46, 70], "616": 65, "616099": [22, 41, 65], "6168": [15, 37, 59], "617342": 77, "617431": [29, 72], "6176": [23, 42, 66], "617647": [23, 42, 66], "61785463": [44, 68], "618": [18, 62], "618000e": [15, 37], "618012": [22, 41, 65], "618125": 16, "6186580061912537": 51, "6186580657958984": [31, 50, 74], "618967": [31, 50, 51, 74], "61912405": [26, 45, 69], "62": [16, 17, 22, 23, 24, 33, 34, 39, 42, 43, 52, 61, 65, 66, 67, 76, 77, 94, 96], "620": 45, "620729": 38, "6210": [15, 37], "62150157": 25, "621537": 25, "622091": [20, 40], "622255": [18, 62], "622454": [22, 41, 65], "6226": [27, 46, 70], "622612": [23, 42, 66, 80], "622709": [21, 64], "623000": [18, 62], "623012": 77, "623034": 48, "62320": [52, 76], "624049": [24, 43, 67], "6241": 58, "624382": 92, "624450e": 24, "624615": [24, 43, 67], "624897": 48, "6250": [18, 62], "625000": 61, "625387": [22, 41, 65], "625682": 92, "6257": [34, 77], "626206": [24, 67], "62657": [52, 76], "62688064": [26, 45, 69], "626946": 77, "627153": 48, "627256": 48, "6273": 65, "6275": [59, 60, 91], "627722": [26, 45, 69], "627741": 48, "627966": [18, 62], "628032": [27, 46, 70], "628139": [23, 42, 66], "62873917": [26, 45, 69], "629792e": 24, "63": [16, 22, 23, 24, 33, 34, 41, 42, 43, 52, 61, 65, 66, 67, 76, 77, 80, 92, 96], "6303": [18, 62, 63, 93], "6306": [18, 27, 46, 62, 70], "630625": 61, "631104": 22, "631122": 77, "631899": 77, "632": 41, "6320": [21, 64], "6320978999137878": [50, 74], "6320979595184326": [31, 51], "6322": [27, 46, 70], "632294": 38, "632353": [23, 42, 66], "632786": [52, 76, 96], "63316788": 83, "63362": [24, 67], "633750": 16, "633933424949646": [31, 50, 51, 74], "634397": [21, 64], "634490": 63, "634686": [23, 42, 66], "634832": 48, "635": [18, 62], "635200": [27, 46, 70], "635239": [18, 62, 63, 93], "635466": 25, "635648": [21, 64], "635815": [44, 68], "636": [18, 34, 58, 62, 63, 77, 93], "636688": 48, "636849e": [24, 67], "637": [32, 75], "637982": [16, 61], "638169": [26, 45, 69], "6386": [17, 39], "638822": 92, "6389": [18, 27, 46, 62, 70], "6391518364256": [34, 53, 77], "6392": [27, 46, 70], "639754": [24, 43, 67], "64": [16, 21, 24, 33, 34, 43, 52, 61, 64, 67, 75, 76, 77, 94, 95], "640": [32, 41, 65, 75], "6400": [18, 62], "640000": [23, 42, 66], "640266": [18, 62, 63, 93], "640370e": 77, "640x480": [16, 61], "641216": [52, 76], "641297": 77, "6414100192": [15, 37], "641538": [34, 53, 77], "641873": [24, 43, 67], "642": 34, "642059": 38, "642676": [33, 76], "642965": 66, "643": [65, 77], "6431": [27, 46, 70], "643125": 61, "643311e": 24, "64331495": 17, "643315": [17, 39], "643700e": 77, "644106": [23, 42, 66, 80], "64417243": [32, 75], "64454": [23, 42, 66, 80], "644770": [29, 72], "645000": 61, "645190": 96, "645519": [23, 42, 66], "6458": [59, 60, 91], "645963": [22, 41, 65], "646050": [26, 45, 69], "6464": [34, 53, 77], "646617": [35, 54, 55, 78], "6467019867549668": [17, 39], "647": 94, "647796": [27, 46, 70], "648": [18, 22, 41, 61, 62, 65], "6480": [25, 44, 68], "648195": [23, 42, 66, 80], "648527": 48, "649513": 48, "649658": [26, 45, 69], "64994": [52, 76, 96], "65": [19, 22, 24, 34, 43, 47, 59, 63, 67, 77], "650": [66, 94], "65000": 65, "650000": 65, "65000e": 61, "65013704": [28, 71], "650743": [15, 37], "651": [15, 37], "651000": 95, "65125032": 83, "6513": [26, 45, 69], "651359e": [15, 37], "651446": [52, 76, 96], "652": 94, "65243": [24, 43, 67], "652487": [27, 46, 70], "652500": 16, "652683": 48, "6526853": [24, 43, 67], "652828": [22, 65], "652986": [27, 46, 70], "653": [18, 62], "6530": 92, "653205": 65, "653205232272": 65, "653371": 92, "653475": 48, "654": [18, 62], "65424895": [24, 43, 67], "65486": [51, 82], "654935": 77, "655050e": 67, "655172": 95, "656297e": [24, 67], "656349": [16, 61], "656827": [23, 42, 66], "656873": [15, 37], "657675": [27, 46, 70], "657786e": 24, "658047": [21, 64], "658222": [34, 77], "658645": [21, 64], "659056": [24, 43, 67], "66": [18, 21, 24, 43, 52, 59, 60, 62, 64, 67, 76, 91, 92, 94, 95, 96], "6600060120": [15, 37], "6601256728172302": 51, "660125732421875": [31, 50, 74], "660171": [16, 61], "6604": [18, 62, 63, 93], "660714": 63, "660834": 32, "660837": 75, "661023": [31, 50, 51, 74], "66214339": [16, 61], "662205": 48, "66221": [52, 76], "6622507572174072": [31, 50, 51, 74], "662450": [23, 42, 66, 80], "662500": 16, "662541e": 24, "662745": [18, 62], "662777": 25, "662853": [44, 68], "663576": 95, "66368": [26, 45, 69], "663680": [24, 26, 35, 43, 45, 54, 55, 67, 69, 78], "6637": [34, 77], "6638": [34, 77], "663822": [26, 45, 69], "6639": [34, 77], "6639008522033691": [50, 74], "6639009118080139": [31, 51], "6641": [34, 77], "6642": [34, 77], "664207": [23, 42, 66], "6643": [34, 77], "6644": [34, 77], "6645": [34, 77], "664625": [31, 50, 51, 74], "664707": [21, 64], "66473": [52, 76, 96], "665": [18, 62], "665307": [31, 50, 51, 74], "665351e": 24, "665882": [25, 44, 68], "666": [18, 62], "666166": [52, 76, 96], "666667": [18, 30, 41, 49, 60, 62, 73], "666875": 61, "667450": [52, 76], "6679946879150066": 17, "668": [31, 50, 51, 74], "668787": [16, 61], "6688": 58, "669": 17, "669376": [25, 44, 68], "66941678": 17, "669417": [17, 39], "669614": [23, 42, 66, 80], "669805e": [24, 67], "669897": 48, "67": [19, 21, 24, 33, 34, 43, 52, 53, 59, 60, 63, 64, 66, 67, 76, 77, 80, 92, 95], "670003": 22, "670344": [16, 61], "670625": 61, "6706507304116865": 39, "670854": 25, "6709133386611938": [50, 74], "6709133982658386": 51, "6709135174751282": 31, "671219": 20, "671250": 61, "671272e": [15, 37], "671772": 20, "6718650306": 24, "6718650315": 43, "67186503176": 67, "6731126308441162": [31, 51], "673112690448761": [50, 74], "673277": [22, 65], "6733849048614502": 51, "673384964466095": [31, 50, 74], "6734487414360046": [31, 50, 51, 74], "673951": 75, "673952": 32, "673983": [44, 68], "674": [17, 39], "6744": [26, 45, 69], "674490": 65, "675": 94, "675000": 58, "67501": [52, 76], "67512181": [24, 43, 67], "675570": 41, "67562658": [19, 63], "675627": [19, 63], "675676": [30, 49, 73], "675814": [16, 61], "676": [35, 54, 55, 78], "67672595": [24, 43, 67], "677": [17, 18, 39, 62], "6771429181098938": [31, 50, 51, 74], "6772": [34, 77], "677268": 77, "677567": [15, 37], "677579": [16, 61], "677601": [22, 65], "677629": [16, 61], "6778583526611328": [31, 50, 51, 74], "678": [22, 41, 61, 65], "678000": [15, 37], "678347": 41, "678689": [21, 64], "678924": 25, "679": 94, "679240": [15, 37], "679356": [25, 44, 68], "679478": [18, 62], "679516": 48, "679877": [24, 26, 35, 43, 45, 54, 55, 67, 69, 78], "68": [15, 16, 19, 24, 26, 28, 29, 33, 34, 43, 45, 52, 53, 59, 60, 61, 63, 66, 67, 69, 71, 72, 76, 77, 92, 96], "68000": [34, 53, 77], "680000": 58, "680029571056366": [31, 50, 74], "6800296306610107": 51, "680437": 92, "680657": [18, 62], "680838": 92, "681223": [16, 61], "681427": 38, "681716": [31, 50, 51, 74], "681732": 77, "682500": 16, "683015": [25, 44, 68], "683061": 92, "683171": [23, 42, 66], "68323": [22, 41, 65], "68339": [52, 76, 96], "683588": [20, 40], "683955": 96, "684211": [16, 61], "684447": [18, 62], "684532": 48, "684623": [25, 44, 68], "684960": [18, 62, 63, 93], "685": [15, 37], "685006": [17, 39], "685103e": 24, "685175": 15, "68517546": 15, "68523": [52, 76], "685625": 16, "685786": [25, 44, 68], "6858": [21, 64], "685841": 77, "686": [18, 62], "686348e": 24, "686569536423841": [17, 39], "687": [24, 43, 67], "687055": [23, 42, 66, 80], "687307": [22, 41, 65], "687500": 60, "687504": [31, 50, 51, 74], "687613": 41, "688": [41, 65], "6880359361853483": [21, 64], "688043475151062": [50, 51, 74], "6880435943603516": 31, "688135": 65, "68822214": 40, "688484": [15, 37], "689338": [24, 26, 35, 43, 45, 54, 55, 67, 69, 78], "689356": 92, "69": [15, 16, 17, 19, 24, 28, 34, 43, 47, 52, 53, 59, 60, 61, 63, 67, 71, 76, 77, 94, 95, 96], "690115": 92, "69027185e": [26, 45, 69], "690402": [22, 41, 65], "690599e": 65, "690778": [26, 45, 69], "691241": [23, 42, 66], "691617": [31, 50, 51, 74], "691640": [16, 61], "691877": [22, 65], "691924": [28, 71], "69192445": [28, 71], "692126": 38, "692308": [18, 62], "693": [18, 62], "693498": [22, 41, 65], "693590": [19, 63], "6935905": 19, "6938": [33, 58, 76], "693890": [52, 76], "693898": [33, 76], "693936": [19, 63], "69393613": [19, 63], "694": [17, 39, 41], "69411": [27, 46, 70], "694155": [16, 61], "6950": [26, 45, 69], "695156": 48, "695322": 48, "695407": 95, "695449": 75, "695457": 32, "695532": [18, 62], "695783": [31, 50, 51, 74], "696": [17, 39], "696034e": [24, 67], "696107": 92, "6962": [18, 62], "6963": [26, 45, 69], "696373": [18, 62], "696429": [23, 42, 66], "696508": 92, "696712": [33, 76], "696859": 65, "696970": [21, 64], "69698010e": [26, 45, 69], "697": [18, 27, 46, 62, 70], "697248": [23, 42, 66], "6973": [18, 62], "698": [18, 62], "698167": [52, 76, 96], "698206": [24, 43, 67], "698384608345687": [41, 65], "698385": [41, 65], "6984": [27, 46, 70], "698857": 65, "699224": [16, 61], "6993": [15, 37], "6999": 34, "699901396097971": [29, 72], "6th": [25, 26, 44, 45, 66, 68, 69], "6x61": 19, "7": [1, 14, 15, 16, 17, 18, 19, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 37, 38, 41, 42, 43, 45, 46, 48, 49, 50, 51, 52, 53, 54, 55, 58, 59, 60, 61, 62, 63, 65, 66, 67, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 83, 84, 90, 92, 96], "70": [15, 19, 24, 28, 29, 33, 34, 35, 37, 38, 43, 47, 48, 52, 53, 54, 55, 59, 60, 63, 67, 71, 72, 76, 77, 78, 80, 92, 94, 96], "70000": [52, 76, 96], "700000": [52, 76, 96], "700000e": [15, 37], "700108": 93, "700855": [23, 42, 66], "701089": 77, "701128": [52, 76, 96], "701173": [22, 65], "701186e": 24, "70162085e": [26, 45, 69], "7017": [34, 53, 77], "701863": [22, 41, 65], "702703": [16, 61], "703289": 48, "703406": 77, "703500e": 77, "703704e": 95, "704": [16, 18, 24, 43, 61, 62, 67], "704040": 92, "704099": [19, 63], "70409944": 19, "7041": [51, 82], "7042": [34, 53, 77], "704240": 96, "7043": [34, 53, 77], "7046136400143141": [21, 64], "70472": [27, 46, 70], "704969": [22, 41, 65], "705": 44, "705000": [18, 62], "705286": 41, "705470": [31, 51], "705471": [50, 74], "705511": [22, 65], "70560276": [19, 63], "705603": [19, 63], "70568": [24, 67], "705696": [16, 61], "705882": [22, 41, 60, 65], "70588235": 60, "705898": [27, 46, 70], "705952": 96, "705995e": 77, "706": 63, "706128": [16, 61], "7063": 92, "706444": [23, 42, 66, 80], "706489": [15, 37], "706533": 96, "7065342163355408": [17, 39], "706783": [19, 63], "70678332": [19, 63], "706966": [52, 76], "707681": [16, 61], "707712": [34, 53, 77], "707899": [28, 71], "70789903": [28, 71], "70799": [22, 41, 65], "708": [18, 62, 63, 65, 93], "708075": [22, 41, 65], "708527": [18, 62], "708978": [22, 41, 65], "709145": 48, "709185": [16, 61], "709334": 95, "709526": 96, "7097425133911417": 92, "70978": [27, 46, 70], "709784": 92, "709874": 65, "709880": 65, "709893": [52, 76, 96], "7099": [27, 46, 70], "71": [15, 19, 21, 24, 28, 33, 34, 43, 52, 58, 59, 60, 63, 64, 67, 71, 76, 77, 80, 96], "710000": [18, 62], "710031": [26, 45, 69], "710526": [16, 61], "710719": 95, "710896": [23, 42, 66], "71096": [27, 46, 70], "711": 65, "711077": [18, 62], "711086": 65, "711356": [15, 37], "711717": 65, "711754": [18, 62, 63, 93], "711819": [31, 50, 51, 74], "711852": [27, 46, 70], "71199006": [24, 43, 67], "712": [18, 62], "712074": [22, 41, 65], "71219761": [19, 63], "712198": [19, 63], "712324": 65, "712500": [41, 61], "7129": 65, "7129300520": [15, 37], "713": [25, 63], "713195": 92, "71327467": [24, 43, 67], "713677": 80, "714": [32, 60, 75], "714077": [18, 62, 63, 93], "714286": [22, 41, 65], "714357": 95, "7149": 34, "71517": [22, 41, 65], "7153": [34, 53, 77], "715424": 65, "715728": [23, 42, 66], "715845": [17, 39], "716": 83, "716157": [23, 42, 66], "716599": 48, "716655": [22, 65], "716657": [22, 65], "716792": [23, 42, 66], "716985": [16, 61], "717289": [22, 41, 65], "717391": [22, 41, 65], "717829": [18, 62], "718242": 65, "718266": [22, 41, 65], "718524": [52, 76, 96], "71866979": [24, 67], "718675": 77, "7188": 63, "719": [18, 27, 46, 58, 62, 70], "719141": 22, "719427e": [24, 67], "719500": [16, 61], "719606": [20, 40], "719747": [23, 42, 66, 80], "719915905190645": [15, 37], "72": [16, 23, 24, 33, 34, 42, 43, 59, 60, 61, 66, 67, 76, 77, 80, 91, 92], "7200": [15, 37], "720357": [52, 76, 96], "72036": [52, 76], "720383": 41, "720393": [22, 41], "720497": [22, 41, 65], "720859": [18, 62], "720893": [34, 77], "720904": [52, 76], "7210": [15, 37, 59], "721006": 65, "721008": [22, 41, 65], "721031": 41, "7212512828409687": [21, 64], "721616": [41, 65], "721622": 22, "721705": [18, 62], "7218": [59, 60, 91], "721818": [27, 46, 70], "721910": [34, 77], "721917": [15, 37], "721921": [18, 62], "722": [18, 62], "722241": 65, "722249": [22, 65], "722803": [15, 37], "722856": 41, "722873": [15, 37], "722887": 41, "723": [18, 62], "723220": 15, "72322046": 15, "72345029": [43, 67], "7234503": 24, "723481": 22, "723602": [22, 41, 65], "723613": [16, 61], "723951": [15, 37], "724011": 92, "724068": [15, 37], "724138e": 95, "7242": [15, 37, 59], "72423018": 20, "724410": [15, 37], "724458": [22, 41, 65], "724539": [52, 76, 96], "724703e": 77, "724722": 41, "724891": [23, 42, 66], "725": [21, 64, 65], "7250894": 83, "7255": 34, "725668": [20, 40], "725960": 41, "726": [18, 23, 27, 42, 46, 62, 66, 70], "726277": 38, "726412": [18, 62, 63, 93], "726441": 38, "726573": [22, 41, 65], "726583": [22, 41, 65], "726634": [23, 42, 66], "726659": [15, 37], "726788": [24, 43, 67], "727": 77, "727014": [52, 76], "727197": 41, "727198": [22, 41, 65], "727273": [16, 61], "727394": 77, "727554": [22, 41, 65], "7277854625841886": [34, 77], "727821": [41, 65], "7278214718381631": [41, 65], "727829": [22, 41, 65], "727994": 38, "728": [18, 23, 34, 42, 62, 66], "728235": [18, 62, 63, 93], "7283": [23, 42, 66], "728324": [23, 42, 66], "728584": 75, "728587": 32, "728777": [16, 61], "728836": 48, "729": 65, "729143": [23, 42, 66, 80], "7292": [27, 46, 70], "729374": [15, 37], "729814": [22, 41, 65], "73": [15, 19, 21, 22, 23, 24, 29, 33, 34, 42, 43, 59, 60, 63, 64, 65, 66, 67, 72, 76, 77, 80, 92], "730000": 92, "730025": [15, 37], "730383": 66, "730512": 96, "730704": [15, 37], "7309385996961713": 65, "731349": 32, "731354": 75, "731498": [34, 77], "7315": [21, 64], "7315558717766282": 22, "731572": [21, 64], "731583": [16, 61], "731733": 92, "73183": 51, "732": [31, 74, 95], "732000": 95, "732674": 34, "7328": [18, 62], "732919": [22, 41, 65], "733102": [18, 62, 63, 93], "733333": [18, 41, 60, 62, 63], "733724": 95, "733746": [22, 41, 65], "734": [24, 34, 43, 65, 67, 77], "734011": [22, 65], "7340179085731506": [50, 74], "7340192198753357": 31, "734048": [15, 37], "734385": [23, 42, 66, 80], "734816": [52, 76], "734986": [15, 37], "735": [24, 43, 67], "735043": [23, 42, 66], "735261": [22, 41, 65], "7352614272253524": [22, 65], "735637": [15, 37], "7356574535369873": [50, 74], "7356575131416321": [31, 51], "735879": [22, 41, 65], "736": 83, "7363681793212891": [31, 50, 51, 74], "736498": [22, 41, 65], "736545": 80, "7367969155311584": 31, "7367984056472778": [50, 74], "736900": [18, 62], "737285": [15, 37], "7378551974307357": 37, "7379": [15, 37, 59], "738": [18, 24, 43, 62, 67], "738564": [52, 76, 96], "738701": [18, 62, 63], "738715": 77, "738746": 77, "738836": 77, "738839": [21, 64], "738977": [22, 41, 65], "738980": 65, "739264": [18, 27, 46, 62, 70], "7395977155164125": [22, 41, 65], "739598": [22, 41, 65], "739726": 94, "739938": [22, 41, 65], "74": [15, 18, 19, 21, 22, 23, 24, 29, 34, 41, 42, 43, 59, 60, 62, 63, 64, 65, 66, 67, 72, 80, 93, 95], "740": 94, "740000": 16, "740319": [15, 37], "740542": 58, "740741": 95, "740842": 65, "740844": 41, "741": [34, 68, 77], "741037": [52, 76, 96], "741060": [15, 37], "741461": 41, "741463": 65, "741465": [41, 65], "7418": [26, 45, 69], "742078": 65, "742084": [41, 65], "742086": 41, "742088": [41, 65], "742703": 65, "7429753541946411": 31, "7429758906364441": [50, 74], "742981": [23, 42, 66], "743": [18, 22, 41, 61, 62, 65], "743132": 48, "743133": [16, 61], "743135": [23, 42, 66], "743243": 94, "743323": 65, "743324": [41, 65], "743391": [16, 61], "743555": [26, 45, 69], "7436": [59, 60, 91], "743820": 92, "743917": [18, 62, 63, 93], "743949": 41, "7440": 58, "744201": [23, 42, 66], "744673": 48, "745801": 41, "745925": [15, 37], "746": 23, "746114": [44, 68], "746328": [16, 61], "747": 58, "7472092075": 24, "7472092076": 67, "7472092077": 43, "747975": 77, "74798624e": [26, 45, 69], "748": [17, 39], "748510": [23, 42, 66], "748725": 77, "748797": [21, 64], "748977": 41, "749": [17, 39], "749118": [26, 45, 69], "75": [9, 15, 17, 18, 19, 21, 22, 23, 24, 26, 28, 34, 35, 37, 39, 41, 42, 43, 45, 52, 54, 55, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 69, 71, 76, 77, 78, 80, 92, 93, 95, 96], "750": [17, 39, 58, 92, 94], "7500": [24, 43, 67], "750000": [15, 24, 37, 41, 43, 67], "7503": [15, 37, 59], "750401": [31, 50, 51, 74], "750483": 48, "751": [17, 39], "752": [17, 39], "752169": [15, 37], "7524": [33, 76], "752728": [15, 37], "753": [17, 39], "753286": [18, 62, 63, 93], "75329946": [20, 40], "753764e": 77, "753821": [34, 77], "753x117": 17, "754": [18, 62], "754386": [23, 42, 66], "754620": [15, 37], "754874": [27, 46, 70], "75490599": 15, "754906": 15, "754938": [15, 37], "755": [34, 77], "755000": [24, 43, 67], "7551": 65, "755364": [16, 61], "755418": [22, 41, 65], "755477": [16, 61], "756": [34, 77], "7562": 58, "75625": [52, 76, 96], "757": [23, 42, 66], "757412": 48, "7574257425742574": [22, 41, 65], "75745416": [28, 71], "757545": [24, 43, 67], "757591": [33, 76], "757932": [34, 77], "75797084": 25, "757985": [25, 26, 44, 45, 68, 69], "758": [25, 26, 34, 44, 45, 68, 69, 77, 94], "758035": 38, "758062e": [24, 67], "758259": [15, 37], "75826": [25, 26, 44, 45, 68, 69], "758514": [22, 41, 65], "7588186": [32, 75], "7588527798652649": 51, "7588528394699097": [31, 50, 74], "75886672": [44, 68], "75948619": [44, 68], "759561": [28, 71], "75956122": [28, 71], "7599": [21, 64], "76": [18, 21, 23, 24, 26, 27, 34, 42, 43, 45, 46, 48, 60, 62, 64, 65, 66, 67, 69, 70, 77, 80, 92, 94], "760": [25, 34, 77], "760000": 25, "760262": [41, 65], "760678": [52, 76], "760966": [15, 37], "76099073": 25, "76161": [22, 41, 65], "761936": 77, "761945e": [24, 67], "762": [34, 77], "7620": [15, 37, 58], "762093e": 24, "76270194": [26, 45, 69], "762965": 96, "763": [18, 62], "763480": [15, 37], "763525": 48, "7639": [15, 37, 59], "764": 94, "764052": [27, 46, 70], "764124": 48, "76470588": 60, "764706": [16, 22, 41, 60, 61, 65], "765": 80, "765000": 41, "765591": [23, 42, 66], "765601": [24, 43, 67], "766317e": 24, "766318": [15, 37], "766423": [24, 43, 67], "766430": [16, 61], "766957": [23, 42], "767": [24, 26, 35, 43, 45, 54, 55, 67, 69, 78], "7675780653953552": 31, "7675789594650269": [50, 74], "767704": 77, "767742": [21, 64], "767802": [22, 41, 65], "767819": [52, 76, 96], "767852": [16, 61], "768": [18, 24, 26, 35, 43, 45, 54, 55, 62, 63, 67, 69, 78, 93, 94], "768176": 77, "768184": [15, 37], "768279": [35, 54, 55, 78], "768407": 41, "7684071705306555": 41, "768512": [23, 42, 66], "769": 60, "769030": [15, 37], "769231": [18, 62], "769349": 15, "76934947": 15, "77": [14, 15, 19, 21, 23, 24, 29, 33, 34, 42, 43, 47, 59, 60, 63, 64, 66, 67, 72, 76, 77, 84, 88, 92, 94], "770": [15, 37, 59], "770000": 25, "770163": [15, 37], "770833": [30, 49, 73], "770898": [22, 41, 65], "771": [18, 41, 62], "771089": 95, "771511": 48, "771969": [16, 61], "772000": 15, "772185": [15, 37], "772245": 92, "772532": [23, 42, 66], "7728396574320712": 15, "772848": 95, "773017": [24, 26, 35, 43, 45, 54, 55, 67, 69, 78], "7736": 65, "773851": [33, 76], "773902e": 67, "774261": [52, 76], "774789": [34, 77], "774844": [19, 63], "77484447": [19, 63], "7750553478074826": [52, 76, 96], "775270": [24, 43, 67], "7752884548630534": [21, 64], "775311": [45, 69], "77536150e": [26, 45, 69], "775558e": 95, "7758": 65, "776": [41, 65], "7763": [18, 20, 27, 46, 62, 70], "776427": [34, 53, 77], "776883e": 24, "77709": [22, 41, 65], "777600": [15, 37], "77778158": 25, "777934": [16, 61], "778078": 27, "7781845435415525": [52, 76, 96], "7784948928666875": [15, 37], "779": [18, 27, 46, 62, 70], "779271": [27, 46, 70], "779838": 20, "78": [14, 15, 18, 19, 24, 27, 28, 33, 34, 43, 46, 53, 58, 59, 60, 62, 63, 66, 67, 70, 71, 76, 77, 80, 83, 84, 94], "780": 41, "7800": 65, "780000": [44, 68], "780296": 24, "780298": 24, "780316": 24, "780497": 24, "78058051e": [26, 45, 69], "780822": 94, "780864": [23, 42, 66, 80], "781": [18, 62], "781004": [16, 61], "781531": [66, 80], "7816": [24, 43, 67], "781769": 15, "78176915": 15, "78186833": [44, 68], "781977": 38, "782183": 24, "782219": [16, 61], "7827": 66, "782850": 77, "783266": 48, "783274": 77, "783282": [22, 41, 65], "783582": [16, 61], "783784": [30, 49, 73, 94], "783789": [16, 61], "784424": [21, 64], "784573": [27, 46, 70], "785105": 24, "785108": 24, "785134": 24, "78521263": [31, 50, 51, 74], "785399": 24, "785483": [52, 76, 96], "785714": [18, 62], "786": 25, "786024": 48, "786115": [27, 46, 70], "7864": [20, 40], "786506": [32, 75], "786555": 24, "786682": 48, "787": [18, 62], "787574": [24, 67], "787879": [16, 21, 61, 64], "78792657": 15, "787927": 15, "787933": 24, "788": [34, 47, 77], "788647472858429": [31, 51], "7886475920677185": [50, 74], "7887": [26, 45, 69], "789": 94, "7891381897690053": [21, 64], "789436": [18, 62], "789657": [52, 76, 96], "79": [15, 18, 19, 21, 24, 33, 34, 43, 59, 60, 62, 63, 64, 67, 76, 77, 80, 91], "790": [23, 42, 66], "790000": [18, 62], "7901": 34, "79041": [24, 43, 67], "790481e": [17, 39], "790521": [15, 37], "790721": [35, 54, 55, 78], "790731": [21, 64], "791017": 77, "791071": 77, "791467": [18, 62], "792": 83, "792023": [26, 35, 45, 54, 55, 69, 78], "79250": [18, 62], "792577": [24, 43, 67], "792603": [16, 61], "792828": 24, "792894": 48, "793": [27, 46, 70], "793243": [18, 62], "79378": [23, 42, 66, 80], "7938": 63, "794118": [16, 61], "794236": [18, 62], "794521": 94, "794820": [18, 62], "794894": [20, 40], "795": [22, 41, 61, 65], "79500e": 61, "7951": 65, "7951559890417756": 24, "7951559890417759": [43, 67], "795902": [52, 76, 96], "795985": 15, "79598528": 15, "796": [18, 62], "7964215270662817": [21, 64], "797": [18, 62], "797355": [18, 62, 63, 93], "7978563117812038": [18, 62], "798": [18, 62], "7982": [16, 61], "798427": 94, "7986538": 24, "7986544": 67, "7986546": 43, "799476": 75, "799486": 32, "799845": 77, "799983": [16, 61], "79998417": 83, "7f688092391a": [32, 75], "7pm": [27, 46, 70], "7th": [25, 26, 44, 45, 66, 68, 69], "8": [1, 10, 14, 15, 16, 17, 18, 19, 21, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 37, 38, 39, 40, 42, 43, 44, 45, 46, 48, 49, 50, 51, 52, 53, 54, 55, 58, 59, 60, 61, 62, 63, 64, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 83, 84, 86, 92, 95, 97], "80": [5, 14, 15, 16, 17, 18, 19, 21, 24, 26, 27, 28, 29, 33, 34, 35, 38, 39, 43, 45, 46, 47, 52, 53, 54, 55, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 69, 70, 72, 76, 77, 78, 80, 84, 89, 94, 95, 96, 97, 98], "800": [15, 17, 22, 39, 41, 50, 51, 58, 60, 65, 74], "800000": [41, 52, 65, 76, 96], "8001": [21, 64], "800190": [16, 61], "800391": 41, "80062924": [16, 61], "800k": [35, 55, 78], "801219e": [24, 67], "801666": [23, 42, 66], "801863": [16, 61], "802502": [27, 46, 70], "802902": 24, "802960": 96, "802987": [16, 61], "803": [16, 18, 61, 62], "803373": 96, "803617": [23, 42, 66], "804": [16, 34, 61, 77], "804072": 95, "8041": 34, "804337": 92, "8044116": 15, "804412": 15, "804580": 20, "804818": [18, 62, 63, 93], "80482065": [19, 63], "804821": [19, 63], "804845": 93, "804955": 15, "80495534": 15, "805": 44, "805198": 24, "805342": [52, 76], "805415": 38, "805970": [16, 21, 61, 64], "806": [63, 94], "8062": [15, 37, 59], "806334557802439": 41, "806335": 41, "8076": [24, 43, 67], "807684": [16, 61], "807735": [23, 42, 66], "8078": 58, "808": [34, 77], "8080": [15, 37, 59], "808208": [23, 42, 66, 80], "808219": 94, "808857": 77, "808958": [16, 61], "809": [18, 62], "809450": [34, 77], "8098": [34, 77], "809894": [34, 77], "81": [15, 16, 19, 21, 22, 23, 24, 26, 28, 33, 34, 35, 41, 42, 43, 45, 52, 54, 55, 59, 60, 61, 63, 64, 65, 66, 67, 69, 71, 76, 77, 78, 80, 95, 96], "810": 83, "810073": [24, 26, 45, 69], "810098": [27, 46, 70], "810267": [23, 42], "810368": [16, 61], "810625": 61, "810631": 77, "81071706": [22, 41, 65], "810811": [30, 49, 73, 94], "8112": 58, "811297": 92, "811877": 75, "811878": 32, "812133": 41, "812272": 24, "812298": 15, "81229831": 15, "812363": [24, 43, 67], "812500": [41, 60], "812875": [34, 53, 77], "813": [18, 62], "813586": [23, 42, 66], "813842": 41, "814218": 77, "814356": [23, 42], "814815": 95, "815000": 92, "815669": [23, 42, 66], "815732": 41, "815890": 92, "816201": 38, "8162831858407079": [56, 57, 79], "816717791411044": [34, 53, 77], "817": [25, 44, 68], "817159": 92, "817244": 94, "817558": [18, 62, 63], "817640": 48, "817920": 92, "8180": [18, 62], "818041": [34, 77], "818591": 92, "818868": [18, 62], "818936": 92, "818982": 92, "819152": [16, 61], "819213": 77, "8195": [21, 64], "819549": [16, 61], "819584": [16, 61], "81970188": [19, 63], "819702": [19, 63], "82": [14, 19, 20, 22, 28, 29, 34, 52, 59, 63, 65, 72, 76, 77, 80, 92, 95, 96], "820": [16, 61], "820033": 24, "820143": [21, 64], "82025568e": [26, 45, 69], "820287": 92, "820312": 41, "820324": 32, "820326": 75, "820564": 24, "8208955223880597": 32, "821040": [26, 45, 69], "821327": [31, 50, 51, 74], "821807": 24, "8219": [18, 62], "821918": 94, "8221": 63, "82273995": [19, 63], "822740": [19, 63], "822822": 94, "823364": [17, 39], "82336432": 17, "823511": [23, 42, 66, 80], "823529": [16, 21, 60, 61, 64], "82352941": 60, "823543": [27, 46, 70], "823610e": 77, "823875": 41, "824": 94, "824324": 94, "824735": 92, "824849": [23, 42, 66], "824884": 24, "825": [18, 20, 62], "825123": [27, 46, 70], "8253": [16, 61], "825306": 65, "825460": 92, "825470": [34, 77], "8256": [20, 40], "825697": [24, 43, 67], "826142": [24, 43, 67], "82615": [20, 40], "826203": [21, 64], "826216": 24, "826513": [52, 76, 96], "826553": 24, "82666046": [20, 40], "82670": [52, 76, 96], "826739": 24, "826758": 24, "826760": 24, "827039": [21, 64], "827068": [21, 64], "827130": [23, 42, 66, 80], "827261": 24, "8277511961722488": 91, "827842": [21, 64], "827907": [22, 41, 65], "828": [15, 20, 37, 40], "8280229354283182": 67, "8280229354283185": 24, "82804": [22, 41, 65], "828332": [24, 26, 35, 43, 45, 54, 55, 67, 69, 78], "828358": [16, 61], "828405": [33, 76], "828682": [22, 41, 65], "82869879": [31, 50, 51, 74], "828891": [22, 65], "828976": 65, "829": 94, "829027": 77, "829754": 95, "829887": 92, "829932": 94, "83": [14, 15, 19, 23, 29, 30, 31, 33, 34, 41, 42, 49, 50, 51, 52, 59, 60, 63, 65, 66, 72, 73, 74, 76, 77, 80, 84, 95, 96], "830": [40, 41], "830382": [23, 42, 66], "830712e": [24, 67], "831135": [16, 61], "8312": [20, 40], "831314": 48, "831611": [24, 26, 45, 69], "831989": [22, 41, 65], "832": [18, 20, 62], "8322": [20, 40], "832221": [32, 75], "832320": [21, 64], "832370": [23, 42, 66, 80], "832866": 24, "833": [22, 40, 41, 61, 65], "83320": [52, 76], "8334": [26, 45, 69], "833913": [15, 37], "8340": [16, 20, 40, 61], "834109": [22, 41, 65], "834180": 75, "834183": 32, "834356e": [24, 67], "83437": [24, 67], "834455": [16, 61], "8347": 34, "8348": 92, "835": 34, "835531": 94, "835571": 96, "8356": [26, 45, 69], "835616": 94, "835651": 65, "835749": [24, 26, 45, 69], "835876": [15, 37], "835995e": 77, "836": 34, "83603": [24, 43, 45, 67, 69], "8361313": [24, 43, 67], "836189": [16, 61], "836735": [23, 42, 66, 94], "836817": 92, "836878e": 24, "836880e": 24, "837": 34, "837022e": 24, "837838": [16, 61], "837848": [16, 61], "838": [22, 34, 41, 61, 65], "83848726e": 75, "83848731e": 32, "83876": [22, 41, 65], "8388866943476289": [21, 64], "838951": [24, 67], "8389756947416367": [21, 64], "839": 34, "839225": [24, 43, 67], "84": [14, 15, 19, 33, 34, 37, 47, 52, 53, 59, 60, 63, 65, 76, 77, 84, 92, 95, 96], "840": [18, 34, 40, 62], "84002795": [19, 63], "840028": [19, 63], "840074": 60, "840183": [24, 43, 67], "840492": [24, 26, 35, 43, 45, 54, 55, 67, 69, 78], "84062193": [26, 45, 69], "841": [20, 24, 34, 43, 67], "841208": [22, 41, 65], "841886": 65, "841983": [22, 41, 65], "842": [18, 20, 34, 40, 62], "842028": [23, 42, 66, 80], "842064": 77, "842105": [16, 61], "8422": [20, 40], "843": [44, 68], "843281": [26, 45, 69], "843284": [16, 21, 61, 64], "843537": 94, "843842": [18, 62, 63, 93], "843992": [24, 26, 45, 69], "844": [20, 25], "844409": [19, 63], "84440919": [19, 63], "844921": [28, 71], "845": 65, "8451161623704895": [44, 68], "846154": [18, 62], "8462": [27, 46, 70], "846260e": 24, "846650": 24, "84679073": [16, 61], "84698489": [32, 75], "847": [25, 26], "847178": [23, 42, 66], "847287": [22, 41, 65], "8475": [33, 76], "84772": [23, 42, 66], "847799": [22, 41, 65], "847808": [23, 42, 66], "8478316682480326": [52, 76, 96], "848": [40, 44, 45, 68, 69], "84893192": [22, 41, 65], "849": [25, 26, 44, 45, 68, 69], "849172": 94, "849315": 94, "849438e": [24, 67], "849612": [22, 41, 65], "849812": [34, 77], "85": [14, 15, 19, 24, 25, 26, 27, 33, 34, 43, 44, 45, 46, 52, 59, 60, 63, 66, 67, 68, 69, 70, 76, 77, 80, 84, 95, 96], "850": [25, 26, 44, 45, 58, 68, 69], "850000": 92, "8502": 65, "850283": [52, 76, 96], "850340": 94, "850503": [22, 41, 65], "850746": [16, 61], "8507462686567164": 75, "851003": 77, "851291": 77, "851351": 94, "851460": 24, "851852": [21, 64], "852": [53, 77], "852053": [22, 41, 65], "852104": [24, 43, 67], "852941": [21, 64], "8532608695652174": 94, "853399": [23, 42, 66, 80], "854129": [24, 43, 67], "854167": [30, 49, 73], "854500": [34, 77], "854560": 94, "8546143543902771": [34, 77], "854744525547446": [34, 53, 77], "854749": [52, 76], "855306": 96, "85545875": [16, 61], "855461": 94, "85597188": [19, 63], "855972": [19, 63], "856": 65, "856164": 94, "856175": [18, 62], "856589": [22, 41, 65], "856721": 38, "856795": 77, "856868": 94, "857": [24, 43, 67], "857456": 38, "857874": [22, 41, 65], "858": [21, 44, 64, 68], "8580": [18, 62, 63, 93], "858209": [16, 21, 61, 64], "858475": 41, "858915": [22, 41, 65], "859": 25, "859318": 24, "859439": [28, 71], "85943906": [28, 71], "859455": [34, 77], "859659": 94, "859668": 94, "85969": [22, 41, 65], "859799": [22, 41, 65], "86": [14, 19, 21, 22, 23, 27, 33, 34, 41, 42, 46, 47, 48, 52, 59, 61, 63, 64, 65, 66, 70, 76, 77, 80, 94], "860": [25, 26, 45, 66, 69, 95], "86000e": 61, "8601643854446082": 67, "8601643854446083": 24, "860329": 48, "860523": 77, "860677": [23, 42, 66, 80], "861": [18, 62], "86102": [52, 76, 96], "861157": [35, 54, 55, 78], "861348": [22, 41, 65], "862236": 77, "862236e": 67, "862432": [24, 43, 67], "862552": [18, 62], "8625888648969532": [34, 77], "862644": 48, "86267067": [19, 63], "862671": [19, 63], "862997": [27, 46, 70], "863014": [21, 64, 94], "863305": [34, 77], "863699": 94, "863889": [33, 76], "863941": 24, "863998": 95, "864": [25, 44, 68], "86400": [52, 76, 96], "864172": 48, "8641864337292489": [34, 77], "864205": [45, 69], "864294": 38, "864865": 94, "865152": 94, "865562": [34, 77], "866110": [21, 64], "866328": [34, 77], "866364": 94, "866667": [23, 42, 60, 66], "866980": 24, "867558": [27, 46, 70], "867841": 94, "867927e": 77, "868003": 24, "868182": 94, "868281": 24, "868305": 24, "868308": 24, "868381": 94, "868397": 48, "869077": [19, 63], "86907725": [19, 63], "869094": [22, 41, 65], "8691": 63, "869531": [16, 61], "869713": 75, "869717": 32, "869964": [22, 41, 65], "87": [18, 19, 33, 34, 59, 62, 63, 76, 77, 80], "870": [25, 44, 68], "870748": 94, "871": [25, 26, 44, 45, 65, 68, 69], "871094": [52, 76, 96], "8711": 66, "871200": [15, 37], "871212": 94, "871782": 94, "872": [25, 26, 44, 45, 68, 69], "872093": [22, 41, 65], "872302": [20, 40], "872722908439952": [26, 45, 69], "8727229084399575": [26, 45, 69], "872961060": [24, 43, 67], "8729610607986": 24, "873": [25, 44, 68], "8731": [24, 26, 35, 43, 45, 54, 55, 67, 69, 78], "873103": [16, 61], "873131": 48, "873182": [33, 76], "873356": [16, 61], "873486": 94, "873529": 48, "873643": [22, 41, 65], "873704": [24, 43, 67], "874062": [19, 63], "87406235": [19, 63], "874305": [33, 76], "874433": 94, "874516": [22, 41, 65], "874532": [24, 43, 67], "874767e": [24, 67], "874966": 38, "875": [80, 94], "8750": [18, 27, 46, 62, 70], "875000": [41, 60], "87516818": [20, 40], "875946": 94, "876065": [22, 41, 65], "876540": [34, 77], "876566e": [15, 37], "876574": [18, 62, 63, 93], "876712": 94, "87681182": [31, 50, 51, 74], "877046": [27, 46, 70], "877390": [45, 69], "877458": 94, "877519": [22, 41, 65], "877551": [23, 42, 66, 94], "878183": [16, 61], "878378": 94, "87844893": [24, 43, 67], "87849316": [21, 64], "878971": 94, "879": [18, 62], "87907": [22, 41, 65], "879938": [22, 41, 65], "88": [15, 17, 18, 19, 21, 23, 27, 34, 42, 46, 47, 59, 60, 62, 63, 64, 66, 70, 77, 80, 92, 93], "880": [27, 46, 70], "8801": [51, 82], "880303": 94, "880348": [22, 41, 65], "880831": [52, 76, 96], "881351": 48, "881370": 41, "881370370570494": 41, "881395": [22, 41, 65], "881720": [23, 42, 66], "881807": 48, "881818": 94, "883138": [22, 41, 65], "884354": 94, "884586": [22, 41, 65], "885": 58, "885044": [24, 26, 35, 43, 45, 54, 55, 67, 69, 78], "8859": [13, 20, 40, 58], "885968": [34, 77], "886047": [22, 41, 65], "886759": [21, 64], "887": [25, 44, 68], "887017": [23, 42, 66], "887159": [52, 76, 96], "8873": [23, 42, 66], "887324": [23, 42, 66], "887343": [16, 61], "887597": [22, 41, 65], "887701": [23, 42, 66], "887772": 15, "8878117": [19, 63], "887812": [19, 63], "887979": 94, "888": [25, 26, 44, 45, 65, 68, 69], "888066": [26, 45, 69], "888372": [22, 41, 65], "888513": [23, 42, 66], "888645": 15, "888811": 65, "888889": [18, 21, 62, 64], "888961": [26, 45, 69], "889": [25, 44, 68], "889086": [24, 43, 67], "889147": [22, 41, 65], "889394": 94, "889429": [33, 76], "889921": [52, 76], "89": [14, 15, 19, 23, 29, 33, 34, 42, 47, 48, 52, 59, 60, 63, 66, 72, 76, 77, 84, 96], "890": [17, 34, 39], "890001": 48, "890107": 15, "890201": 15, "890411": 94, "890456": [15, 37], "890457": [24, 43, 67], "890933": [34, 53, 77], "891": [25, 34], "891001": 66, "891156": 94, "891174": 15, "891223": 15, "891224": 15, "891384": 15, "891557": [22, 41, 65], "891892": 94, "892": 34, "892476": [23, 42, 66], "892477": [16, 61], "892491": [18, 62], "892587": 94, "89270": [27, 46, 70], "892733": [33, 76], "892961": [27, 46, 70], "892983": 15, "893": 34, "893000": [18, 62], "893260": [19, 63], "89326049": 19, "893580": 77, "8937442459553657": [26, 45, 69], "893915": 15, "894": [18, 34, 62], "894230": 77, "894587": [35, 54, 55, 78], "894828": 15, "894960": [15, 37], "895": [25, 44, 68], "89515383": 17, "895154": [17, 39], "895349": [22, 41, 65], "895405": 48, "895541": [24, 43, 67], "895613": 94, "89572": [52, 76, 96], "895833": [23, 42, 66], "895963": [21, 64], "897": [25, 44, 63, 68], "897010": [18, 62, 63], "89706451e": [26, 45, 69], "897126": 94, "897674": [22, 41, 65], "897736": 34, "898": [26, 45, 69], "898016": [22, 41, 65], "898237": 38, "898703e": 24, "899": [18, 62, 63, 65, 93], "8994": [26, 45, 69], "8997": [24, 43, 67], "899736": [15, 37], "899940": 77, "899969": [52, 76, 96], "8th": [25, 26, 44, 45, 66, 68, 69], "8xnvb3wojvta7atnvk1s_obfsvwldyzibljoboxw": 22, "9": [1, 4, 15, 16, 17, 18, 19, 20, 21, 22, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 37, 38, 40, 41, 43, 44, 45, 46, 48, 49, 50, 51, 52, 53, 55, 58, 59, 60, 61, 62, 63, 64, 65, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 80, 84, 85, 91, 92, 96], "90": [9, 14, 15, 16, 19, 23, 24, 29, 30, 33, 34, 42, 43, 58, 59, 60, 61, 63, 66, 67, 72, 73, 76, 77, 80, 84], "900": [19, 22, 63, 65, 80], "90000": [52, 76, 96], "900000": [52, 60, 76, 96], "900000e": [15, 37], "900662": 60, "901": 63, "901085": [21, 64], "9010852321946795": [21, 64], "901261": 95, "901262": [33, 76], "90159483": [28, 71], "901595": [28, 71], "901802": 48, "902": 68, "902122": 96, "902232": 41, "902337": 38, "902401": [22, 41, 65], "903080": 48, "903101": [22, 41, 65], "903125": 61, "903434": 38, "904": [16, 22, 41, 61, 65], "90403853": [19, 63], "904039": [19, 63], "904110": 94, "904226": [16, 61], "904462e": 77, "904565": 38, "9047619047619048": [14, 59], "904930e": [15, 37], "905": [16, 18, 61, 62], "905249": 48, "905327": [52, 76], "905405": 94, "906": 95, "906510": 92, "906667": [38, 60], "90669": [27, 46, 70], "906865": 60, "907": [34, 53, 77], "907595": [33, 76], "907752": 77, "907874": 96, "908": [18, 62], "908140": [18, 62, 63, 93], "908215": [24, 43, 67], "909091": [18, 62], "909471e": 67, "90982": [27, 46, 70], "91": [14, 15, 18, 19, 22, 27, 28, 33, 37, 41, 46, 52, 59, 60, 62, 63, 65, 66, 70, 71, 76, 80, 84, 96], "910": [15, 19, 37, 59], "9100": [33, 76], "910018": [24, 43, 67], "910174": [24, 43, 67], "9103": [33, 76], "910456e": 24, "91063776": [26, 45, 69], "9108334653214172": 15, "910843": [24, 43, 67], "911": [17, 39], "911024": 48, "911615": [24, 43, 67], "911846": [24, 43, 67], "912": [18, 34, 62], "912395": [26, 45, 69], "912847": 92, "913": 34, "913333": [38, 60], "913767": [24, 43, 67], "913849": [24, 43, 67], "914": 34, "914003": [26, 45, 69], "914451894256": 24, "914451894267": [43, 67], "914520": 48, "914585": [26, 45, 69], "915": 34, "91515735": [24, 43, 67], "915701": 94, "915714e": 24, "915952": [24, 43, 67], "916": 34, "916254": [16, 61], "916347": 38, "916722": [26, 45, 69], "917": [34, 94], "917526": [23, 42, 66], "917808": 94, "917837": [23, 42, 66], "91795": [20, 40], "918": [15, 25, 34, 37, 44, 68, 94], "918124": [23, 42, 66], "9182": [33, 76], "918224": [17, 39], "918919": 94, "919": 34, "919198": [26, 45, 69], "919270": [34, 77], "9196": 58, "92": [14, 15, 19, 29, 33, 34, 52, 59, 60, 63, 66, 72, 76, 77, 84, 92, 96], "920": 34, "920000": [38, 60], "920067": [34, 77], "920093": 95, "9203": 65, "920305": [27, 46, 70], "920462": [26, 45, 69], "921": 34, "92120500e": 83, "921422": [34, 77], "921438": [24, 38, 43, 67], "921850": [24, 43, 67], "92195464": [26, 45, 69], "921955": [26, 45, 69], "922": 63, "923077": [23, 42, 66], "923283": [18, 62, 63, 93], "923432": [26, 45, 69], "924485": [27, 46, 70], "9245": [21, 60, 64], "925272e": 24, "925288e": 24, "925593": [16, 61], "925768": [23, 42, 66], "926": [34, 94], "926657": [24, 43, 67], "926667": 38, "926733e": 24, "926829": [23, 42, 66], "927": 34, "927685": 77, "927710": 48, "927814": 32, "927826": 75, "928": [34, 65], "92809": [27, 46, 70], "92852376": [16, 61], "929": [34, 65], "9295": 65, "93": [14, 15, 19, 21, 28, 33, 34, 59, 60, 63, 64, 65, 71, 76, 77, 84], "930": 34, "930000": [18, 62], "930062": [15, 37], "930123": [16, 61], "930561": [16, 61], "9308647034083802": 37, "931": 34, "931439e": 24, "931556": 77, "931786": [21, 64], "931896": [15, 37], "932": [18, 34, 62], "932070": [34, 77], "932124": [16, 61], "932365": 95, "932375": 80, "932379e": 77, "932733": [23, 42], "93279": [52, 76], "933": [34, 92], "933191": 77, "933333": 38, "9336": [18, 62], "934": [17, 39], "93402132": [20, 40], "934205": [16, 61], "934269": [18, 62, 63, 93], "934783": [23, 42, 66], "9351": [27, 46, 70], "935512": 77, "935802": [16, 61], "93665": [52, 76, 96], "936733": 34, "937429": [35, 54, 55, 78], "9375": 60, "937500": [19, 60, 63], "938": [23, 42, 66], "938201": [15, 37], "938219": [34, 77], "9383": [16, 21, 61, 64], "93869659": [19, 63], "938697": [19, 63], "939006": [66, 80], "9391": [24, 43, 67], "939394": [16, 21, 61, 64], "939805": [15, 37], "94": [14, 15, 18, 19, 21, 23, 24, 33, 42, 43, 47, 52, 59, 60, 62, 63, 64, 65, 66, 67, 76, 84, 93], "940": 94, "940000": 38, "9401": [33, 76], "940434": 48, "9406": [59, 60, 91], "941": [34, 53, 77], "9410": [15, 37], "941176": [19, 60, 63], "94117647": 60, "941938": 77, "942": [17, 39, 63], "943": 34, "943609": [27, 46, 70], "944": [34, 58], "944092": [23, 42, 66, 80], "944342": [34, 77], "944354": 63, "944733": 96, "944745": [32, 75], "944878": 41, "94487839624894": 41, "945": 34, "945000": 38, "945749": 48, "945980": 38, "946": 34, "946402e": 67, "946667": 38, "946783": [16, 61], "946875e": 67, "947": [18, 34, 62, 65], "9471": 65, "947500": 16, "948": 34, "948482": 77, "94888": [23, 42, 66], "948893": 94, "948901": 77, "949": [18, 19, 62], "9490": [18, 62], "9492": [24, 43, 67], "94933723": [24, 43, 67], "94959681": [19, 63], "949597": [19, 63], "949734": 75, "949736": 32, "95": [14, 15, 19, 29, 33, 34, 35, 47, 55, 59, 60, 63, 66, 72, 76, 77, 78, 89, 92, 94, 95], "950000": [18, 62, 92], "950088": [27, 46, 70], "9505": [26, 45, 69], "950564": [27, 46, 70], "9506": [26, 45, 69], "950696": [34, 53, 77], "950733": [16, 61], "951294": [24, 43, 67], "951574": [27, 46, 70], "951644": [27, 46, 70], "951667": 38, "951669": [27, 46, 70], "951696": [16, 61], "952456e": 65, "953": [25, 44, 63, 68], "953005": 77, "9530973451327434": [56, 57, 79], "953333": 38, "954003": 94, "954082": 94, "954294e": 77, "954798": 48, "955034": 41, "955078": 41, "95511263": [16, 61], "955113": [16, 61], "955355": 41, "95535503227586": 41, "955723": 94, "9558": [33, 76], "956": [18, 62], "956966": [27, 46, 70], "957075": [27, 46, 70], "9573": [33, 76], "957411": 94, "9576": 58, "957919": [16, 61], "957987": [16, 61], "958": 41, "9583333333333334": [32, 75], "958393": [18, 27, 46, 62, 70], "95886206e": [32, 75], "959": [17, 18, 39, 62], "959139": [26, 45, 69], "959402e": [24, 67], "959870": [23, 42, 66], "959873": 77, "959922": 41, "96": [19, 21, 22, 27, 33, 46, 52, 59, 63, 64, 65, 66, 70, 76], "960": [17, 19, 21, 39, 64], "960000e": [17, 39], "9601165335428803": 41, "960117": 41, "960914": 41, "961": [17, 39], "961109802000133": [29, 72], "961404": [18, 62, 63], "961498": [24, 26, 35, 43, 45, 54, 55, 67, 69, 78], "961583": 80, "961771": [21, 64], "961898": [21, 64], "962": [17, 39], "963": [17, 39], "963024": [15, 37], "963030": 80, "96319": [52, 76], "96320": [52, 76], "96321": [52, 76], "96322": [52, 76], "96323": [52, 76], "96325": [52, 76], "963333": 38, "963641": 92, "963689": [27, 46, 70], "964": [17, 39], "964225": 94, "965517": 95, "96554": [27, 46, 70], "965787": 41, "9661": [24, 43, 67], "966131": [18, 62, 63, 93], "966393": 80, "9664": [59, 60, 91], "966667": 38, "966681": 25, "966812": [15, 37], "967907": [23, 42, 66], "968": [18, 62], "968233": [27, 46, 70], "96833": [51, 82], "968333": 38, "96834506": [16, 61], "968493": 77, "968514e": [24, 67], "96875": [32, 75], "968750": 41, "968857": 92, "9691": [24, 43, 67], "9692602666681306": [21, 64], "96965253": [26, 45, 69], "969653": [26, 45, 69], "97": [15, 19, 21, 22, 26, 29, 33, 34, 41, 59, 60, 63, 64, 65, 69, 72, 76, 77], "970518": 66, "970646": 41, "970683": [27, 46, 70], "9707980910387133": 25, "971725": 95, "972003": [44, 68], "97203586": [19, 63], "972036": [19, 63], "97217": [52, 76], "972198": 65, "972208": 95, "97223953": [19, 63], "972240": [19, 63], "972379": [17, 39], "97237936": 17, "972440": [66, 80], "97253": [52, 76], "9730": 63, "973225": 66, "973280": [19, 63], "97328024": [19, 63], "973294": [17, 39], "973333": 38, "974": [18, 62, 94], "974181": 38, "974480": [27, 46, 70], "974534": 38, "9748": [21, 64], "974801e": [24, 67], "975104": [17, 39], "975172e": 77, "97581663": [20, 40], "975895": [52, 76, 96], "976": [18, 23, 25, 42, 44, 62, 66, 68], "976000": 95, "9760519862174988": 31, "9760521650314331": [50, 74], "9760765550239234": 91, "976517": 41, "976562": 41, "976667": 38, "977": [18, 52, 62, 76, 96], "977278": [27, 46, 70], "9773": [16, 59, 60, 61, 91], "977359e": 77, "977873": 77, "978": [21, 64], "978031": 77, "9781449369880": [33, 76], "9781789957211": [32, 75], "97823755": [21, 64], "978487": 41, "9785299": 51, "978738": [27, 46, 70], "979": [25, 26, 44, 45, 68, 69], "979353": 48, "979562": [34, 53, 77], "98": [18, 19, 21, 24, 26, 28, 33, 34, 35, 43, 45, 51, 53, 54, 55, 59, 62, 63, 64, 67, 69, 71, 76, 77, 78, 82, 92, 94], "980": [52, 76, 96], "980000": 38, "98001": [15, 37], "98007": 58, "98010": 15, "98024": 15, "98027": [15, 37], "98028": [15, 37, 59], "98033": [15, 37], "98038": 15, "98039": 15, "980431": 41, "98045": 58, "98052": [15, 58], "98055": 58, "980634": [34, 77], "98065": [15, 37], "98072": 58, "98074": [15, 37, 59], "98075": 58, "98077": [15, 37], "9808": [21, 64], "980862": 77, "980894": 48, "980958": 38, "981": 26, "98102": 15, "98103": [15, 37], "98107": 58, "98112": 58, "98115": 15, "98116": 58, "98117": 15, "98118": [15, 37], "981195": [52, 76], "98125": [15, 37, 59], "98136": [15, 37, 59], "98144": [15, 37], "981447": 77, "98146": [15, 37], "98148": 15, "981643": [15, 37], "981735": [21, 64], "98178": [15, 37, 59], "981948": 77, "98199": [15, 37], "982184": [22, 41, 65], "982570": [34, 77], "983": [32, 75], "983333": 38, "983340": [15, 37], "9837": [21, 60, 64], "984": 65, "984653": [21, 64], "984664": [24, 43, 67], "985000": 38, "985283": [22, 41, 65], "9854": [21, 59, 60, 64, 91], "985457": 77, "98570": [20, 40], "985816": 60, "986047": [22, 41, 65], "986207": [22, 41, 65], "987": [32, 44, 65, 75], "987062": [24, 43, 67], "987597": [22, 41, 65], "9876": [25, 26, 44, 45, 68, 69], "987681": [27, 46, 70], "988": [27, 46, 70], "988000": 95, "9881": [59, 60, 91], "988281": 41, "988333": 38, "988381": [22, 41, 65], "988841": [22, 41, 65], "988901": [24, 43, 67], "989": [14, 59], "989147": [22, 41, 65], "989156": [22, 41, 65], "989443": [34, 77], "989922": [22, 41, 65], "989973": [21, 64], "99": [15, 18, 19, 22, 23, 33, 41, 42, 52, 59, 60, 62, 63, 65, 66, 76, 92, 96], "990000": 92, "990631": [52, 76, 96], "990754": [52, 76], "991052": 92, "9912": [16, 21, 61, 64], "991209": [34, 77], "9915": [52, 76, 96], "991667": 38, "991810": [15, 37], "991966": [34, 77], "992": [60, 65], "992148": 92, "992188": 41, "992220": [15, 37], "992254": [22, 41, 65], "99240562": [26, 45, 69], "992406": [22, 41, 65], "992569": [17, 39], "9926": 63, "992857": 60, "992908": 60, "993023": [22, 41, 65], "993029": [22, 41, 65], "993065": [34, 53, 77], "9931": [59, 60, 91], "993164": 41, "993333": 38, "9934531067299874": [21, 64], "993666": [26, 45, 69], "99369068": 20, "993692": 32, "993694": 75, "993969": [24, 26, 35, 43, 45, 54, 55, 67, 69, 78], "994": 58, "994135": 41, "994138": 41, "994266": [22, 41, 65], "994574": [22, 41, 65], "994764": [52, 76, 96], "995": [27, 32, 46, 70, 75, 92], "9950": [27, 46, 70], "9951": [59, 60, 91], "995112": 41, "99515": [52, 76], "995434": [24, 43, 67], "995707631111145": [31, 50, 74], "996": 92, "996090": 41, "996424": [15, 37], "996487": [15, 37], "996765": [45, 69], "996788": [34, 77], "996820": [34, 77], "9968347348881582": 37, "996899": [22, 41, 65], "997": [23, 34, 92], "99744241e": [26, 45, 69], "9977957422135844": [45, 69], "9977957422135846": 26, "998": [23, 34, 42, 66, 77, 92], "998019e": 67, "9983": [23, 42, 66], "998302": [23, 42, 66], "998370": [15, 37], "998440": [15, 37], "99845": [22, 41, 65], "998451": [22, 41, 65], "998569": 92, "998848": 92, "999": [21, 34, 64, 92], "99907": [22, 41, 65], "999122": [23, 42, 66], "9991338290544213": [15, 37], "999147": [23, 42, 66], "999172": [23, 42, 66], "999178": [15, 37], "999183": [23, 42, 66], "999185": [23, 42, 66], "999192": [23, 42, 66], "999210": [23, 42, 66], "999213": [15, 37], "999214": [23, 42, 66], "999221": [23, 42, 66], "999223": [23, 42, 66], "999225": [22, 41, 65], "999254": [23, 42, 66], "999298": [23, 42, 66], "999317": [23, 42, 66], "99931882": [43, 67], "99931883": 24, "999335": [23, 42, 66], "999438": [15, 37], "9994394006711425": [15, 37], "9994770884513855": [31, 50, 74], "999480": [15, 37], "999518": [15, 37], "999535": [22, 41, 65], "999539": [15, 37], "999544": [15, 37], "999545": [15, 37], "999546": [15, 37], "999558": [15, 37], "999562": [15, 37], "999567": [15, 37], "999577": [52, 76], "999622": [18, 62], "99975": [20, 40], "99980": [20, 40], "999885": 92, "9999": 13, "999916": 92, "999999": 92, "9999999999999998": 26, "9am": [27, 46, 70], "9m": 75, "9th": [13, 25, 26, 44, 45, 66, 68, 69], "A": [0, 1, 5, 9, 10, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 24, 25, 26, 27, 28, 30, 32, 33, 34, 35, 38, 39, 40, 41, 43, 44, 45, 46, 47, 48, 49, 51, 53, 54, 55, 58, 59, 60, 61, 62, 63, 64, 65, 67, 68, 69, 70, 71, 73, 75, 77, 78, 79, 82, 83, 84, 90, 96, 98], "AND": [0, 24, 43, 67], "AS": 0, "And": [13, 20, 22, 24, 28, 31, 33, 34, 35, 43, 50, 51, 53, 55, 58, 59, 65, 67, 74, 76, 77, 78, 84, 85, 86, 91, 92], "As": [4, 15, 16, 19, 22, 24, 25, 26, 30, 34, 35, 43, 44, 45, 49, 52, 53, 54, 55, 56, 57, 58, 60, 63, 65, 67, 68, 69, 73, 76, 77, 78, 79, 83, 86, 88, 91, 92, 94, 98], "At": [4, 11, 13, 15, 21, 23, 25, 27, 28, 32, 33, 34, 37, 42, 44, 46, 58, 60, 64, 66, 68, 70, 71, 75, 86, 92], "BE": [0, 31, 51, 74], "BUT": [0, 9], "BY": [0, 1], "Be": [5, 8, 13, 16, 26, 35, 45, 54, 55, 61, 69, 78, 79, 84, 86, 92], "Being": [32, 75], "But": [9, 13, 14, 15, 16, 17, 18, 19, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 39, 42, 43, 44, 45, 46, 49, 50, 52, 53, 55, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 83, 86, 88, 90, 92, 94, 96, 98], "By": [8, 12, 13, 15, 16, 19, 23, 25, 28, 31, 34, 35, 38, 42, 44, 50, 51, 53, 55, 58, 59, 60, 61, 62, 63, 66, 68, 71, 74, 77, 78, 86, 92, 93], "FOR": 0, "For": [0, 1, 4, 6, 8, 9, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 82, 84, 86, 88, 90, 92, 94, 96, 98], "IN": [0, 15, 21, 39, 60, 64], "IT": [21, 39, 64], "If": [1, 4, 5, 6, 7, 8, 9, 11, 13, 14, 15, 16, 17, 18, 19, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 37, 39, 42, 43, 44, 45, 46, 49, 50, 51, 52, 53, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 90, 91, 92, 93, 94, 96, 98], "In": [1, 5, 7, 8, 9, 10, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 82, 84, 85, 86, 87, 88, 90, 91, 92, 93, 94, 96, 98], "It": [2, 4, 6, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 86, 88, 89, 92, 94, 95, 98], "Its": [34, 53, 58, 77], "NEAR": [18, 27, 46, 62, 63, 70, 93], "NO": 0, "NOT": [0, 9, 19, 21, 39, 63, 64], "No": [0, 13, 14, 17, 24, 25, 26, 27, 29, 32, 34, 35, 39, 43, 44, 45, 46, 52, 53, 54, 55, 58, 59, 67, 68, 69, 70, 72, 75, 76, 77, 78, 84, 90, 92, 93, 96, 98], "Not": [24, 25, 26, 27, 28, 30, 34, 43, 44, 45, 46, 49, 52, 53, 58, 66, 67, 68, 69, 70, 71, 73, 76, 77, 93], "OF": 0, "OR": [0, 9, 24, 43, 67], "Of": [10, 19, 22, 41, 63, 65, 66], "On": [4, 8, 15, 17, 18, 19, 20, 22, 23, 24, 25, 26, 27, 29, 32, 34, 35, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 54, 55, 58, 62, 63, 65, 66, 67, 68, 69, 70, 72, 75, 77, 78, 94], "One": [6, 9, 14, 15, 17, 19, 20, 21, 22, 23, 26, 27, 28, 29, 31, 34, 39, 40, 42, 45, 50, 53, 59, 60, 63, 64, 65, 66, 69, 71, 72, 74, 77, 84, 90, 95, 96], "Or": [11, 16, 22, 35, 38, 41, 55, 61, 63, 65, 78, 86, 92], "Such": [7, 30, 33, 58, 73, 76], "THE": [0, 15, 60], "TO": [0, 31, 51, 74], "That": [6, 14, 18, 21, 22, 24, 25, 26, 28, 29, 30, 31, 33, 34, 35, 41, 43, 44, 45, 50, 51, 53, 55, 58, 59, 60, 62, 64, 65, 67, 68, 69, 71, 72, 73, 74, 76, 77, 78, 79], "The": [0, 2, 5, 8, 9, 11, 12, 13, 14, 16, 17, 18, 19, 20, 23, 24, 26, 27, 29, 30, 32, 33, 34, 35, 37, 38, 39, 40, 42, 43, 45, 46, 49, 51, 52, 53, 54, 55, 56, 57, 58, 59, 61, 62, 63, 66, 67, 69, 72, 73, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 86, 87, 90, 91, 92, 93, 96, 98], "Then": [14, 21, 25, 28, 33, 44, 56, 57, 59, 64, 68, 71, 76, 79], "There": [1, 2, 5, 6, 9, 10, 13, 14, 15, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 39, 41, 42, 43, 44, 45, 46, 47, 49, 50, 51, 52, 53, 55, 56, 57, 58, 59, 60, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 96, 98], "These": [4, 11, 14, 16, 21, 24, 25, 26, 27, 28, 30, 33, 35, 43, 45, 46, 50, 52, 55, 59, 60, 61, 64, 67, 68, 69, 70, 71, 73, 74, 76, 78, 80, 88, 94, 95, 98], "To": [9, 11, 13, 14, 15, 16, 17, 18, 19, 20, 21, 24, 25, 27, 31, 32, 33, 38, 39, 43, 44, 46, 47, 48, 50, 51, 55, 58, 59, 60, 61, 62, 63, 64, 67, 68, 70, 72, 74, 75, 76, 78, 79, 86, 88, 90, 92, 94, 96, 98], "WITH": 0, "Will": [66, 77, 84], "With": [0, 6, 13, 14, 16, 17, 18, 19, 21, 22, 24, 26, 27, 28, 29, 30, 31, 32, 34, 38, 43, 45, 46, 50, 53, 58, 59, 61, 62, 63, 64, 65, 67, 69, 70, 71, 72, 73, 74, 75, 77, 83, 86, 92], "_": [34, 44, 49, 51, 68, 77, 82], "___": [31, 50, 74], "__array__": 34, "__call__": [19, 34, 63], "__class__": [21, 33, 64, 76], "__finalize__": [34, 77], "__getitem__": 62, "__init__": [16, 25, 26, 28], "__name__": [21, 33, 64, 76], "__sklearn_tags__": 18, "__testing_word2vec": [31, 50, 51, 74], "_ahead": [76, 90, 96], "_array_api": 34, "_asarray_with_ord": 34, "_assert_all_finit": 18, "_assert_all_finite_element_wis": 18, "_astype_nansaf": [34, 77], "_base": 18, "_blank": [23, 42], "_california_housing_dataset": [21, 64], "_call_func_on_transform": [19, 34, 63], "_check_i": [18, 34], "_column_transform": [19, 34, 63], "_constructor_from_mgr": [34, 77], "_count_physical_cor": [16, 25, 26, 28], "_data": 34, "_deprecate_force_all_finit": 18, "_distn_infrastructur": [41, 65], "_encod": [19, 63], "_err_msg_1dcolumn": 34, "_estim": [18, 34], "_execute_child": [16, 25, 26, 28], "_fit": 18, "_fit_context": 18, "_fit_transform_on": 34, "_get_empty_rout": 34, "_get_sequential_output": [19, 34, 63], "_i": [24, 32, 75], "_is_numpy_namespac": 18, "_iter": 34, "_lag": [76, 90, 96], "_logist": 83, "_mgr": [34, 77], "_original_iter": 34, "_print_elapsed_tim": 34, "_proba": [44, 68], "_raise_for_param": 34, "_regress": 18, "_reset": 34, "_run": 34, "_score": [19, 63], "_scorer": [19, 63], "_set_output": [19, 34, 63], "_time_fit_was_cal": [53, 77], "_transform": [19, 63], "_transform_on": [19, 63], "_valid": [19, 63], "_validate_param": 18, "_valu": 34, "_winapi": [16, 25, 26, 28], "_with_config": 34, "aaaaaaaacu0": [31, 50, 74], "aaja": 40, "ab": [21, 23, 24, 26, 42, 43, 45, 64, 66, 67, 69, 76, 90, 96], "abbrevi": [51, 82], "abil": [13, 19, 20, 22, 26, 31, 33, 40, 45, 51, 58, 63, 65, 69, 74, 76, 86, 92], "abl": [5, 9, 12, 13, 14, 15, 16, 18, 19, 21, 22, 24, 25, 26, 27, 28, 29, 30, 31, 33, 35, 44, 49, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 76, 78, 79, 86, 91, 92], "about": [1, 2, 4, 7, 8, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 31, 32, 33, 34, 37, 39, 40, 41, 42, 43, 44, 45, 47, 49, 50, 51, 52, 53, 54, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 71, 72, 74, 75, 76, 77, 79, 82, 83, 84, 85, 86, 87, 88, 89, 91, 92, 94, 95, 98], "abov": [0, 6, 9, 13, 14, 15, 16, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33, 35, 37, 39, 41, 42, 43, 44, 45, 49, 50, 51, 52, 55, 58, 59, 60, 61, 64, 65, 66, 67, 68, 69, 71, 72, 73, 74, 75, 76, 78, 80, 82, 83, 86, 90, 92, 96, 98], "absenc": [19, 26, 30, 45, 63, 69, 73], "absent": [44, 98], "absolut": [12, 17, 21, 24, 26, 28, 39, 42, 43, 45, 64, 66, 67, 69, 71], "absorb": 58, "abspath": [13, 14, 15, 16, 17, 18, 19, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 83, 84, 85, 86, 88, 89, 90, 91, 92, 94, 95, 96], "academ": [1, 8, 27, 46, 70, 79], "accent": 20, "accept": [6, 8, 9, 18, 23, 24, 31, 42, 43, 50, 51, 56, 57, 66, 67, 74, 79, 86, 92], "accept_large_spars": [18, 34], "accept_spars": [18, 19, 34, 63], "access": [1, 6, 13, 15, 22, 25, 28, 30, 33, 35, 36, 41, 44, 49, 51, 55, 56, 57, 60, 62, 65, 68, 71, 73, 76, 78, 79, 82], "accessori": [33, 76], "accident": [16, 18, 61, 62, 79], "acclaim": 58, "accommod": 58, "accompani": [8, 13, 58, 59], "accomplish": [38, 79], "accord": [21, 23, 24, 25, 27, 30, 34, 42, 43, 46, 49, 53, 58, 64, 66, 67, 70, 73, 77, 88, 94, 98], "account": [6, 8, 13, 30, 34, 49, 56, 57, 58, 60, 66, 70, 73, 77, 79, 84], "accur": [13, 25, 26, 27, 30, 34, 35, 44, 45, 49, 55, 58, 60, 68, 69, 70, 73, 77, 78, 81, 84, 85, 91], "accuraci": [12, 14, 15, 16, 17, 18, 22, 23, 25, 26, 27, 29, 30, 32, 34, 35, 37, 38, 41, 42, 44, 45, 53, 55, 59, 60, 61, 62, 65, 66, 68, 69, 70, 72, 75, 77, 78, 80, 84, 85, 88, 91, 94, 98], "accuracy_scor": [23, 42, 66], "acdm": [25, 26, 44, 45, 66, 68, 69], "acf": [33, 76], "achiev": [9, 16, 23, 42, 56, 57, 58, 61, 66, 79, 80, 88, 90, 94, 96], "acinonyx": [32, 58, 75], "ackland": 20, "acoust": [18, 22, 41, 61, 62, 65], "acquir": 12, "acquisit": [30, 49, 73], "across": [11, 13, 14, 15, 18, 23, 26, 31, 32, 42, 45, 50, 58, 59, 60, 62, 66, 69, 74, 75, 96, 98], "act": [20, 21, 40, 58, 64, 98], "action": [0, 13, 25, 26, 28, 30, 34, 44, 45, 49, 51, 53, 58, 68, 69, 71, 73, 77, 98], "activ": [4, 5, 11, 22, 32, 41, 58, 65, 75, 84, 98], "actor": [30, 49, 51, 73], "actual": [8, 13, 17, 19, 20, 21, 23, 25, 26, 28, 30, 32, 34, 35, 40, 42, 44, 45, 49, 51, 52, 53, 55, 58, 64, 66, 68, 69, 71, 73, 75, 76, 77, 78, 82, 88, 93, 94, 96], "ad": [6, 11, 13, 17, 19, 20, 21, 22, 25, 26, 27, 29, 31, 32, 34, 41, 44, 45, 46, 50, 51, 53, 63, 64, 65, 66, 68, 69, 70, 72, 74, 75, 76, 77, 81, 89, 90, 95, 96, 97], "adam": 20, "adapt": [0, 18, 19, 31, 33, 35, 44, 51, 55, 58, 62, 63, 66, 68, 74, 76, 78], "add": [1, 8, 9, 11, 18, 24, 25, 26, 27, 29, 33, 34, 43, 44, 45, 46, 51, 53, 58, 62, 63, 67, 68, 69, 70, 72, 76, 77, 80, 81, 82, 87, 88, 89, 90, 93, 94, 95, 96], "add_ind": [39, 44, 45, 62, 63, 67, 68, 69], "addit": [0, 4, 11, 13, 24, 30, 35, 43, 49, 55, 66, 67, 73, 76, 78, 90, 96, 98], "addition": [86, 91, 92], "address": [13, 20, 29, 32, 56, 57, 58, 72, 75, 79], "adekany": [1, 98], "adelaid": [52, 76, 90, 96], "adequ": 58, "adio": [35, 55, 78], "adj": [51, 82], "adject": [31, 50, 51, 74], "adjust": [5, 16, 22, 29, 32, 33, 38, 41, 61, 65, 72, 75, 76, 86, 89, 92, 95], "adm": [25, 26, 44, 45, 66, 68, 69], "admin": [1, 98], "administr": [1, 31], "admit": [58, 60], "adopt": [7, 30, 49, 73], "ador": 20, "adp": [31, 50, 51, 74, 82], "adroitli": 58, "adult": [25, 26, 44, 45, 66, 68, 69], "adult_df_larg": [25, 26, 44, 45, 68, 69], "adv": [31, 50, 51, 74, 82], "advanc": [12, 19, 22, 28, 29, 30, 31, 32, 41, 49, 50, 51, 58, 63, 65, 71, 72, 73, 74, 75, 85, 91], "advantag": [12, 18, 19, 20, 21, 25, 29, 30, 40, 44, 49, 50, 51, 62, 63, 64, 68, 72, 73, 74, 84], "advent": 58, "advic": [34, 46, 58, 77], "advis": [13, 58], "advisor": 98, "af": [26, 44, 45, 69], "affair": 58, "affect": [16, 18, 21, 22, 28, 33, 34, 40, 41, 56, 57, 61, 62, 64, 65, 66, 71, 76, 77, 79, 80, 86, 92], "affix": [51, 82], "africa": 25, "aft": [56, 57, 79], "after": [4, 7, 8, 11, 14, 15, 17, 18, 19, 20, 23, 24, 26, 28, 29, 32, 33, 34, 39, 40, 42, 43, 45, 51, 53, 55, 58, 60, 62, 63, 66, 67, 69, 71, 72, 75, 76, 77, 78, 79, 80, 82, 84, 88, 90, 94, 96, 98], "ag": [17, 20, 21, 24, 25, 26, 27, 28, 30, 39, 43, 44, 45, 46, 48, 49, 58, 64, 66, 67, 68, 69, 70, 73, 88, 94], "again": [14, 15, 17, 18, 29, 30, 31, 34, 37, 38, 39, 49, 50, 51, 53, 56, 57, 58, 59, 60, 62, 72, 73, 74, 77, 79, 82, 86, 88, 90, 92, 94, 96], "against": [20, 30, 33, 49, 51, 66, 73, 76, 82], "agenc": [51, 82], "agent": 1, "agglomerativeclust": [29, 72], "aggress": [51, 82], "aggressive_elimin": [41, 65], "agit": [31, 50, 74], "agnost": [26, 45, 69], "ago": [32, 33, 75, 76], "agre": [14, 58, 98], "agreement": [34, 53, 77, 98], "ahead": [76, 90, 96], "ai": [8, 10, 27, 31, 32, 50, 51, 66, 70, 74, 75], "aight": 58, "aim": [17, 39, 84], "ain": [51, 82], "air": [20, 40, 95], "airplan": [35, 55, 78], "airport": [56, 57, 79, 80, 96], "aka": [21, 34, 53, 64, 77], "al": [25, 31, 44, 50, 51, 68, 74], "alamine_aminotransferas": 58, "alan": [1, 20, 58], "alarm": 66, "alaska": [21, 64], "albani": 96, "albania": 25, "alberta": [31, 50, 51, 74], "album": 65, "albumin": 58, "albumin_and_globulin_ratio": 58, "alburi": [52, 76, 96], "alec": 58, "alex": 58, "alexand": [35, 55, 78], "alexnet": [32, 75], "algebra": [30, 31, 50, 51, 73, 74], "algorithm": [2, 12, 13, 18, 19, 24, 25, 26, 29, 31, 35, 38, 39, 44, 45, 50, 51, 55, 58, 60, 62, 63, 66, 67, 68, 69, 72, 74, 78, 79, 80, 81, 82, 85, 86, 87, 91, 92, 93, 94], "alicespr": 96, "align": [9, 13, 14, 15, 58, 59, 60], "align_kei": [34, 77], "aliv": [56, 57, 58, 79], "alkaline_phosphotas": 58, "all": [0, 1, 4, 5, 6, 7, 8, 9, 14, 15, 16, 17, 18, 19, 20, 22, 24, 25, 26, 27, 31, 32, 33, 34, 37, 38, 39, 40, 41, 43, 44, 45, 46, 48, 50, 51, 52, 53, 54, 56, 57, 58, 60, 61, 63, 65, 67, 68, 69, 70, 74, 75, 76, 77, 79, 80, 81, 82, 83, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 98], "all_featur": [52, 76, 90, 96], "allei": [24, 26, 35, 43, 45, 54, 55, 67, 69, 78], "alley_grvl": [24, 67, 69], "alley_miss": [24, 67, 69], "alley_pav": [24, 67, 69], "alloc": [9, 31, 32, 50, 51, 74, 75], "allow": [5, 8, 13, 18, 22, 27, 33, 34, 39, 41, 51, 52, 53, 56, 57, 58, 60, 62, 65, 66, 70, 76, 77, 79, 80, 86, 90, 91, 92, 96, 98], "allow_nan": 18, "allow_nd": [18, 34], "allpub": [24, 26, 35, 43, 45, 54, 55, 67, 69, 78], "allya": [1, 98], "almond": 95, "almost": [15, 21, 22, 24, 27, 29, 30, 43, 51, 58, 64, 65, 67, 72, 73, 81], "along": [5, 8, 19, 23, 32, 33, 35, 42, 55, 59, 63, 66, 75, 76, 78, 80, 85, 91], "aloof": 58, "alpha": [16, 38, 52, 61, 62, 76, 86, 90, 92, 96], "alpha_": [24, 43, 67], "alphabet": [21, 64], "alphago": [13, 28, 58, 71], "alq": [24, 26, 35, 43, 45, 54, 55, 67, 69, 78], "alreadi": [4, 9, 11, 12, 13, 20, 24, 26, 28, 31, 32, 34, 35, 43, 45, 50, 51, 52, 53, 54, 55, 67, 69, 71, 74, 76, 77, 78, 80, 82, 90, 91, 93, 96], "also": [1, 2, 4, 5, 6, 8, 9, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 38, 39, 41, 42, 43, 44, 45, 49, 50, 51, 52, 53, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 71, 72, 73, 74, 75, 76, 77, 78, 79, 81, 82, 83, 84, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 98], "alt": 11, "altar": [32, 75], "alter": 58, "altern": [9, 22, 28, 38, 55, 65, 71, 78], "although": [25, 28, 30, 34, 44, 49, 60, 68, 71, 73, 77, 95], "alwai": [1, 5, 13, 14, 15, 16, 17, 19, 20, 21, 23, 24, 25, 26, 28, 29, 30, 37, 39, 42, 43, 44, 45, 58, 59, 61, 62, 63, 64, 66, 67, 68, 69, 71, 72, 73, 84, 85, 86, 91, 92, 93, 98], "am": [13, 15, 17, 18, 20, 31, 35, 40, 50, 51, 55, 58, 62, 71, 74, 78, 82, 98], "amatriain": [30, 49, 73], "amaz": [17, 20, 31, 39, 40, 50, 58, 74], "amazon": [13, 28, 30, 49, 58, 71, 73], "ambianc": 17, "ambienc": [17, 39], "ambigu": [13, 31, 51, 58, 74, 82], "ambiti": [31, 50, 74], "ambrosin": 40, "amer": 66, "america": [31, 50, 51, 63, 74], "american": [17, 28, 39, 71], "amicu": 20, "aml": [18, 62], "among": [13, 14, 22, 23, 25, 26, 30, 42, 44, 45, 58, 59, 65, 68, 69, 73, 88, 94, 95], "amount": [4, 13, 15, 20, 21, 22, 23, 24, 26, 27, 28, 32, 33, 34, 41, 42, 43, 45, 52, 58, 60, 64, 65, 66, 67, 69, 71, 75, 76, 77, 79, 80, 90, 96], "amp": [20, 25, 26, 40, 44, 45, 68, 69], "amplifi": [31, 50, 51, 66, 74], "amuel": [18, 62], "amus": 58, "an": [0, 1, 2, 4, 7, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 32, 33, 34, 38, 39, 41, 42, 43, 45, 46, 47, 49, 50, 51, 52, 53, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 69, 70, 71, 72, 73, 74, 75, 76, 77, 79, 80, 81, 82, 83, 84, 87, 88, 90, 92, 93, 94, 96, 98], "anaconda": [11, 26, 45, 69], "anaconda3": [14, 16, 18, 19, 25, 26, 28, 31, 32, 34], "analogi": [16, 29, 31, 35, 50, 51, 55, 72, 74, 78], "analysi": [1, 2, 10, 12, 24, 28, 29, 33, 35, 43, 51, 53, 55, 59, 66, 67, 71, 72, 78], "analyt": [33, 76], "analyz": [12, 20, 23, 31, 34, 35, 40, 41, 42, 50, 52, 63, 65, 66, 70, 74, 76, 77, 78, 90, 96], "anatinu": [32, 75], "anca": [1, 98], "ancestor": [27, 81], "ancestr": 98, "andrea": [1, 10], "andrew": [1, 10, 22, 27, 58, 65, 70], "andr\u00e3": 20, "anemon": [32, 75], "angel": [34, 53, 77], "anger": [31, 50, 74], "angl": 20, "ani": [0, 5, 11, 14, 15, 17, 18, 19, 20, 21, 23, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 37, 39, 42, 44, 45, 46, 49, 50, 51, 52, 53, 55, 58, 59, 60, 62, 63, 64, 66, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 91, 92, 98], "anim": [31, 38, 50, 66, 74, 75], "animal_fac": 38, "anneal": [27, 46, 70, 81], "anniversari": 58, "annoi": 20, "annot": [5, 8, 26, 28, 69, 71, 98], "announc": 8, "annoy": 20, "annoyingli": [24, 43, 67], "annual": 28, "annual_incom": 28, "anomali": [24, 28, 67, 71, 80], "anonym": [33, 76], "anoth": [5, 9, 11, 14, 16, 20, 21, 22, 23, 25, 26, 28, 29, 30, 32, 33, 34, 35, 41, 42, 44, 45, 49, 52, 53, 55, 58, 59, 61, 64, 65, 66, 68, 69, 71, 72, 73, 75, 76, 77, 78, 79, 84, 85, 87, 88, 90, 91, 93, 94, 96], "answer": [4, 7, 8, 13, 15, 22, 25, 28, 30, 31, 33, 35, 40, 44, 51, 55, 58, 59, 60, 65, 68, 71, 73, 74, 76, 78, 83, 84, 85, 86, 88, 90, 91, 92, 94, 96, 98], "anteat": [32, 75], "anthologi": 20, "anthrop": [31, 74], "anti": [34, 53, 58, 77], "anymor": [24, 28, 30, 43, 49, 67, 71, 73, 86, 92], "anyon": [31, 35, 50, 55, 56, 57, 58, 74, 78, 79], "anyth": [0, 13, 15, 17, 19, 23, 30, 34, 39, 42, 51, 53, 56, 57, 58, 60, 63, 66, 73, 77, 79, 82], "anytim": 98, "anywai": 58, "anywher": [19, 31, 50, 63, 74], "ap": [12, 84], "ap_lr": [23, 42, 66], "ap_svc": [23, 42, 66], "apart": [16, 29, 31, 50, 58, 61, 72, 74, 96], "apeendixa": [46, 70], "api": [31, 33, 34, 50, 51, 74, 76, 80, 84], "app": [13, 14, 31, 59, 84], "appdata": [31, 34], "appeal": [31, 51, 74], "appear": [2, 8, 19, 25, 31, 32, 44, 50, 56, 57, 58, 63, 68, 74, 75, 79, 86, 88, 92, 94, 95, 98], "append": [4, 9, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 25, 26, 27, 28, 29, 30, 31, 32, 34, 35, 37, 38, 39, 40, 41, 42, 44, 45, 46, 47, 48, 49, 50, 51, 53, 54, 55, 58, 59, 60, 61, 62, 63, 64, 65, 66, 68, 69, 70, 71, 72, 73, 74, 75, 77, 78, 80, 81, 82, 83, 85, 86, 87, 88, 89, 91, 92, 93, 94, 95], "appendix": [66, 70], "appendix_b": 51, "appendixa": 27, "appendixc": [31, 50, 74], "appendixd": [32, 75], "appl": [11, 31, 50, 51, 74], "appli": [0, 2, 5, 7, 10, 12, 13, 14, 15, 17, 20, 21, 22, 26, 27, 28, 29, 30, 31, 32, 33, 34, 39, 40, 41, 46, 49, 50, 51, 52, 53, 58, 59, 60, 64, 65, 66, 69, 70, 71, 72, 73, 74, 75, 76, 77, 79, 83, 84, 87, 93, 96, 98], "applianc": 92, "applic": [0, 6, 13, 19, 22, 24, 26, 27, 31, 34, 41, 45, 46, 50, 51, 53, 56, 57, 58, 63, 65, 66, 67, 69, 70, 74, 77, 79, 80, 84, 98], "appreci": [12, 71, 79, 98], "apprehens": 40, "apprentic": 40, "approach": [1, 12, 16, 17, 18, 19, 22, 24, 25, 26, 28, 31, 32, 38, 39, 40, 41, 45, 50, 51, 60, 61, 62, 63, 65, 66, 67, 68, 69, 70, 71, 74, 75, 80, 84, 86, 90, 92, 96], "appropri": [0, 4, 12, 14, 15, 19, 24, 28, 29, 33, 34, 37, 40, 43, 53, 58, 59, 63, 66, 67, 71, 72, 76, 77, 79, 84, 89, 95, 98], "approv": [40, 66, 98], "approx": [16, 26, 45, 61, 69], "approxim": [14, 22, 27, 46, 59, 65, 70, 79], "april": [52, 76, 96], "apt": 6, "ar": [0, 1, 2, 4, 6, 7, 8, 9, 10, 11, 14, 15, 16, 17, 19, 20, 22, 23, 24, 25, 26, 27, 32, 33, 34, 35, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 51, 52, 53, 54, 55, 56, 57, 60, 61, 63, 65, 67, 68, 69, 70, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 98], "arang": [9, 15, 16, 20, 21, 22, 23, 24, 37, 38, 40, 41, 42, 43, 48, 60, 61, 64, 65, 66, 67, 86, 92], "arbitrari": [26, 28, 29, 33, 45, 52, 69, 71, 72, 76], "arch": 58, "architectur": [32, 75], "area": [22, 24, 25, 27, 28, 35, 41, 44, 46, 55, 65, 67, 68, 70, 71, 78, 80, 84], "aren": [8, 20, 24, 27, 28, 32, 33, 43, 46, 51, 52, 67, 70, 71, 75, 76, 82, 90, 96], "arena": [27, 46, 70], "arg": [16, 18, 19, 25, 26, 28, 34, 38, 60, 63], "argentina": 25, "argh": [34, 53, 77], "argmax": [20, 38, 40], "argmin": [16, 23, 28, 42, 60, 61, 66, 71], "argsort": [26, 31, 45, 50, 51, 69, 74], "argu": [13, 28, 51, 71], "argument": [9, 14, 19, 22, 23, 24, 26, 35, 41, 42, 43, 45, 55, 58, 59, 63, 65, 66, 67, 69, 78, 84, 87, 93], "arima": [33, 52, 76], "arima_model": [33, 52, 76], "aris": [0, 31, 51, 58, 70, 74, 76], "aristotl": [16, 61], "arithmet": 9, "ariti": 34, "arm": [20, 31, 50, 74], "around": [8, 16, 19, 20, 22, 23, 24, 32, 33, 34, 37, 40, 42, 43, 53, 58, 61, 63, 66, 67, 75, 76, 77, 85, 89, 91, 95], "aroundn": 58, "arr": [34, 77], "arr1": 9, "arr2": 9, "arrai": [14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 37, 39, 40, 41, 42, 43, 44, 45, 46, 47, 49, 50, 51, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 82, 83, 91, 94], "arrang": [32, 75], "array_equ": 9, "array_orig": 18, "arriv": [17, 31, 50, 70, 74], "arson": 20, "art": [35, 55, 58, 78], "arthur": [13, 58], "articl": [1, 14, 18, 28, 30, 31, 32, 35, 50, 51, 55, 59, 60, 62, 66, 71, 73, 74, 75, 78], "articul": [35, 55, 78], "artifici": [1, 13, 31, 50, 51, 58, 74], "artist": [18, 22, 41, 61, 62, 65], "as_fram": [16, 38, 61, 86, 92], "asarrai": 34, "ascend": [9, 17, 19, 20, 21, 22, 24, 25, 26, 27, 33, 34, 37, 40, 43, 44, 45, 46, 52, 53, 63, 64, 65, 67, 68, 69, 70, 76, 77, 84, 88, 94, 96], "ased": [29, 72], "asi": 94, "asia": 63, "asid": [4, 15, 25, 44, 60, 68, 86, 92], "ask": [3, 8, 13, 14, 15, 19, 27, 28, 30, 31, 34, 35, 46, 49, 50, 51, 53, 55, 58, 59, 60, 61, 63, 66, 70, 71, 73, 74, 77, 78, 85, 91, 92, 98], "asleep": [21, 64], "aspartate_aminotransferas": 58, "aspect": [21, 26, 27, 29, 30, 34, 35, 45, 49, 55, 64, 69, 70, 72, 73, 77, 78, 84], "aspir": 20, "assassin": 20, "assault": 98, "assembl": 58, "assert": [8, 19, 25, 26, 44, 45, 63, 66, 68, 69], "assess": [1, 5, 12, 13, 14, 15, 17, 18, 23, 26, 35, 39, 42, 55, 58, 59, 60, 62, 66, 69, 71, 78, 98], "assign": [1, 4, 6, 7, 9, 11, 13, 14, 16, 18, 21, 22, 26, 27, 28, 29, 31, 32, 33, 34, 35, 38, 45, 46, 50, 51, 52, 53, 55, 56, 57, 59, 61, 62, 63, 64, 65, 68, 69, 70, 71, 72, 74, 75, 76, 77, 78, 79, 82, 84, 85, 87, 89, 90, 91, 93, 95, 96], "assist": [13, 31, 58, 74], "assoc": [25, 26, 44, 45, 66, 68, 69], "associ": [0, 13, 14, 15, 16, 20, 24, 26, 27, 28, 31, 32, 33, 34, 36, 40, 43, 45, 50, 51, 52, 53, 55, 56, 57, 58, 60, 61, 66, 67, 69, 70, 71, 74, 75, 76, 77, 78, 79, 84, 88, 94], "assum": [1, 13, 19, 21, 29, 30, 33, 49, 50, 51, 52, 53, 55, 58, 59, 63, 64, 66, 67, 72, 73, 74, 76, 78, 84, 90, 96], "assumpt": [34, 53, 77], "assur": 58, "asterisk": [22, 65], "astonish": 58, "astyp": [9, 20, 33, 34, 38, 40, 52, 53, 76, 77, 90, 96], "astype_arrai": [34, 77], "astype_array_saf": [34, 77], "astype_is_view": 34, "ata": 94, "aten": 32, "atlanta": 58, "atmospher": [17, 20, 58], "atratu": [32, 75], "attack": [14, 59], "attempt": [15, 20, 22, 38, 58, 60], "attend": [13, 98], "attent": [7, 31, 50, 51, 74, 79], "attic": [24, 43, 67], "attract": [31, 40, 51, 74], "attribut": [0, 1, 13, 14, 16, 18, 20, 21, 22, 27, 28, 31, 40, 41, 50, 51, 58, 59, 61, 62, 64, 65, 70, 71, 74, 81, 88, 89, 94, 95], "attrit": [34, 77], "au": 20, "auc": [12, 34, 53, 77, 79, 84], "audienc": [5, 12, 35, 55, 58, 78, 79, 84], "audio": [32, 75, 98], "audit": [79, 98], "auditor": [5, 98], "augment": [31, 50, 74, 80], "august": [33, 52, 76, 96], "austen": 58, "austin": [31, 50, 51, 74], "australia": [25, 52, 76, 90, 96], "authent": [17, 28, 71], "author": [0, 31, 50, 51, 74, 98], "autism": 20, "auto": [13, 22, 27, 28, 35, 38, 39, 41, 44, 45, 47, 48, 55, 58, 62, 63, 65, 66, 67, 68, 69, 71, 78, 80, 81, 94, 95], "autocorrel": [33, 76], "autograd": 77, "autom": [14, 24, 31, 35, 41, 43, 51, 55, 59, 67, 74, 78, 82], "automat": [13, 17, 18, 19, 24, 27, 34, 35, 39, 43, 46, 51, 52, 53, 55, 58, 62, 63, 67, 70, 76, 77, 78, 82, 90, 96], "automodelfortokenclassif": [31, 50, 74], "autoregress": [21, 64], "autotoken": [31, 50, 74], "autumn": [52, 76, 96], "autumn_month": [52, 76, 96], "aux": [51, 82], "av": [24, 26, 31, 35, 43, 45, 50, 51, 54, 55, 67, 69, 74, 78], "avail": [0, 1, 8, 10, 13, 14, 15, 19, 22, 24, 27, 29, 30, 31, 32, 33, 34, 41, 43, 47, 48, 49, 50, 51, 52, 53, 58, 60, 63, 65, 66, 67, 72, 73, 74, 75, 76, 77, 80, 82, 84, 88, 90, 94, 96, 98], "avebedrm": [21, 64], "aveoccup": [21, 64], "averag": [12, 15, 16, 19, 21, 22, 23, 24, 26, 28, 29, 34, 42, 43, 45, 51, 53, 58, 60, 61, 63, 64, 65, 66, 67, 69, 71, 72, 77, 79, 84, 86, 92, 95], "average_precis": [23, 42, 66, 80], "average_precision_scor": [23, 42, 66], "averaging_model": [25, 44, 68, 88, 94], "averaging_model_ndt": [25, 44, 68], "averoom": [21, 64], "avg": [23, 30, 33, 42, 49, 52, 66, 73, 76, 80], "avg_sent_emb": 51, "avocado": [35, 55, 78], "avoid": [4, 5, 8, 9, 18, 24, 29, 33, 34, 35, 40, 43, 58, 59, 62, 66, 67, 72, 76, 77, 78, 79, 83, 84, 86, 92, 98], "aw": [17, 20, 39, 40, 56, 57, 58, 79], "awai": [4, 7, 14, 21, 28, 30, 34, 49, 53, 55, 59, 64, 71, 73, 77, 78, 79, 84], "awar": [13, 19, 31, 35, 50, 53, 55, 63, 74, 77, 78, 93], "award": [13, 58], "awesom": [10, 20], "ax": [14, 16, 21, 28, 29, 32, 34, 35, 38, 53, 54, 55, 60, 61, 64, 66, 71, 72, 75, 77, 78, 85, 86, 89, 91, 92, 95, 97], "axi": [8, 9, 13, 14, 15, 17, 18, 19, 20, 21, 26, 28, 29, 31, 32, 33, 35, 38, 45, 47, 48, 50, 51, 52, 54, 55, 58, 59, 60, 62, 63, 64, 69, 71, 72, 74, 75, 76, 78, 85, 89, 90, 91, 94, 95, 96], "axvlin": [28, 71], "ayanf": [1, 98], "b": [1, 9, 13, 14, 15, 16, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 29, 30, 31, 32, 33, 34, 35, 40, 41, 42, 44, 49, 51, 52, 53, 54, 55, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 70, 72, 73, 74, 75, 76, 77, 78, 81], "b3": [45, 62, 69], "baba": [31, 50, 74], "babe": 58, "babi": [27, 31, 51, 74, 81], "babysitt": 20, "bach": 6, "bachelor": [25, 26, 44, 45, 66, 68, 69], "back": [9, 14, 15, 18, 22, 31, 37, 38, 50, 51, 58, 62, 65, 74, 84, 98], "backdrop": [33, 76], "backend": [16, 25, 26, 28, 31, 32, 47, 48, 50, 74], "background": [12, 35, 55, 59, 78, 79], "backward": [32, 46, 70, 75], "bad": [9, 14, 15, 16, 17, 20, 24, 25, 26, 27, 28, 33, 39, 43, 44, 52, 58, 59, 60, 61, 63, 66, 67, 68, 69, 70, 71, 76], "badgeryscreek": [52, 76, 96], "badli": 58, "bag": [17, 20, 27, 31, 32, 39, 40, 46, 50, 51, 70, 74, 75, 84], "bai": [18, 27, 46, 62, 63, 70, 93], "baidu": 60, "bal_scor": 66, "balanc": [7, 16, 17, 20, 25, 30, 39, 40, 44, 49, 61, 68, 71, 73, 83, 88, 94], "ball": 58, "ballarat": [52, 76, 96], "balltre": 18, "balust": [32, 75], "balustrad": [32, 75], "bambi": [30, 49, 73], "banist": [32, 75], "bank": [26, 33, 34, 45, 53, 66, 69, 76, 77], "bannist": [32, 75], "bar": [23, 24, 26, 32, 34, 35, 42, 43, 45, 52, 53, 54, 55, 66, 67, 69, 75, 76, 77, 78, 79, 90, 95, 96], "barbar": 58, "barbara": 40, "barbu": [1, 98], "bard": [31, 74], "bare": 20, "barnstorm": 58, "barri": [21, 64], "bart": [31, 50, 74], "base": [6, 9, 11, 12, 13, 14, 15, 16, 17, 18, 19, 21, 22, 23, 24, 26, 28, 29, 31, 32, 34, 35, 38, 39, 41, 42, 43, 44, 45, 50, 51, 53, 58, 59, 60, 62, 63, 64, 65, 66, 67, 69, 71, 72, 74, 77, 78, 79, 81, 82, 84, 85, 88, 89, 91, 94, 95, 98], "base_scor": [25, 44, 68], "base_valu": [26, 45, 69], "baseblockmanag": [34, 77], "baselin": [34, 38, 77, 79, 84, 85, 87, 90, 91, 93, 96], "baseline_hazard_": [34, 77], "basement": 58, "basi": [14, 16, 59, 61], "basic": [2, 9, 13, 14, 20, 22, 27, 30, 31, 32, 34, 40, 41, 46, 49, 50, 53, 58, 59, 65, 70, 73, 74, 75, 77, 88, 89, 90, 94, 95, 96], "batch": [31, 32, 38, 50, 51, 74, 75], "batch_siz": [38, 47, 48], "bath": 58, "bathroom": [15, 21, 37, 58, 59, 64], "bayesian": [22, 41, 65], "bayesopt": [22, 41, 65], "bbc": [20, 40, 58], "bc": 5, "beagl": [32, 58, 75], "bear": [32, 75], "beat": [25, 34, 44, 58, 68, 77], "beauti": [20, 30, 35, 49, 51, 55, 73, 78, 82], "beautifulli": [31, 50, 74], "becam": [32, 58, 75], "becaus": [1, 8, 9, 16, 17, 18, 19, 21, 22, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 38, 39, 41, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 55, 56, 57, 58, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 86, 90, 91, 92, 95, 96, 98], "becom": [4, 15, 16, 21, 22, 26, 27, 28, 31, 41, 42, 46, 51, 58, 60, 61, 64, 65, 66, 69, 70, 71, 74, 80, 81, 91], "bed": [56, 57, 79, 80], "bedroom": [14, 15, 21, 37, 58, 59, 64], "bedroomabvgr": [24, 26, 35, 43, 45, 54, 55, 67, 69, 78], "bedrooms_per_household": [18, 62, 63, 87, 93], "beef": [17, 39, 51, 82], "been": [4, 7, 13, 18, 19, 20, 21, 22, 23, 24, 26, 28, 29, 30, 31, 32, 33, 34, 35, 42, 43, 45, 49, 50, 51, 52, 54, 55, 58, 59, 62, 63, 64, 65, 66, 67, 69, 71, 72, 73, 74, 75, 76, 78, 80, 82, 83, 86, 89, 92, 95, 98], "beet_salad": [32, 75], "befor": [1, 4, 5, 6, 14, 15, 16, 17, 19, 20, 21, 24, 25, 28, 29, 30, 32, 33, 34, 39, 43, 44, 47, 49, 51, 52, 53, 56, 57, 58, 59, 60, 61, 63, 64, 67, 68, 71, 72, 73, 75, 76, 77, 79, 82, 85, 86, 88, 89, 90, 91, 92, 94, 95, 96], "began": [31, 50, 74], "begin": [5, 21, 27, 30, 31, 32, 33, 34, 39, 46, 50, 53, 59, 64, 70, 73, 74, 75, 76, 77, 84], "beginn": 6, "beguil": 58, "behav": [22, 26, 41, 45, 65, 69], "behavior": [23, 30, 42, 62, 66, 73, 79], "behaviour": [19, 63, 76, 88, 94], "behind": [12, 13, 21, 22, 31, 32, 58, 64, 74, 75, 98], "being": [4, 13, 15, 18, 23, 24, 25, 29, 31, 34, 35, 42, 43, 44, 45, 50, 51, 54, 55, 58, 60, 62, 66, 67, 68, 69, 72, 74, 77, 78, 82, 86, 92, 98], "belat": 58, "belgian": 20, "belief": [35, 55, 78], "believ": [8, 20, 22, 33, 37, 45, 52, 58, 65, 69, 76], "bell": [32, 75], "belong": [21, 25, 29, 50, 59, 64, 72, 74, 85, 91], "below": [1, 6, 9, 13, 14, 15, 18, 19, 21, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 38, 39, 42, 43, 44, 45, 46, 47, 48, 49, 51, 52, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 82, 84, 85, 86, 88, 89, 90, 91, 92, 94, 95, 96, 98], "ben": 20, "bench": [32, 75], "benchmark": [32, 37, 75], "bendigo": [52, 76, 96], "beneath": 58, "benefici": [19, 35, 55, 63, 78], "benefit": [4, 25, 29, 35, 44, 55, 61, 68, 72, 78, 84], "bengio": [22, 41, 65], "bennet": 58, "bennett": 20, "ber": [50, 51, 74], "bereav": 40, "bergstra": [22, 41, 65], "berni": 58, "berri": [50, 51, 74], "bert": [31, 50, 74], "bertop": [31, 50, 51, 74], "bertsdpaselfattent": [50, 74], "besid": 58, "best": [2, 8, 14, 15, 16, 17, 18, 20, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 34, 35, 37, 38, 41, 42, 43, 44, 45, 46, 49, 50, 55, 56, 57, 58, 59, 60, 61, 65, 66, 67, 68, 69, 71, 72, 73, 74, 77, 78, 79, 80, 81, 85, 86, 88, 91, 92, 94, 95], "best_alpha": [24, 43, 67], "best_c": 38, "best_depth": [15, 37, 60], "best_estimator_": [22, 24, 41, 43, 65, 67], "best_k": 38, "best_n_neighbour": [16, 61], "best_param": [22, 35, 55, 65, 78], "best_paramet": [22, 65], "best_params_": [22, 24, 35, 41, 43, 55, 65, 67, 78], "best_scor": [22, 65], "best_score_": [22, 24, 41, 43, 65, 67], "best_svr": [35, 55, 78], "bestalpha_coeff": [24, 43, 67], "bet": 58, "better": [7, 14, 16, 17, 18, 19, 20, 21, 24, 25, 26, 28, 29, 30, 32, 33, 34, 38, 39, 43, 44, 45, 46, 47, 49, 51, 53, 56, 57, 58, 59, 61, 62, 63, 64, 67, 68, 69, 71, 72, 73, 75, 76, 77, 79, 82, 84, 85, 86, 87, 88, 91, 92, 93, 94, 98], "between": [2, 9, 12, 13, 14, 15, 17, 18, 19, 21, 23, 24, 25, 26, 27, 28, 29, 30, 32, 33, 34, 35, 37, 38, 42, 43, 44, 45, 47, 48, 49, 50, 51, 52, 53, 55, 58, 60, 63, 64, 66, 67, 68, 69, 70, 71, 72, 73, 75, 76, 77, 78, 80, 82, 84, 86, 89, 92, 95], "bewar": [51, 82], "beyond": [15, 22, 27, 46, 55, 58, 60, 65, 70, 78], "bfg": [53, 77], "bhatt": [1, 98], "bia": [21, 26, 34, 45, 64, 66, 69, 77, 79, 84], "bias": [12, 26, 31, 34, 45, 50, 51, 66, 69, 74, 77], "bicycl": [14, 33, 59, 76], "bidirect": [31, 50, 74], "big": [8, 16, 19, 20, 22, 25, 27, 28, 29, 30, 31, 32, 34, 35, 39, 40, 44, 46, 49, 50, 51, 53, 55, 58, 61, 63, 65, 66, 68, 70, 71, 72, 73, 74, 75, 77, 78], "bigalpha_coeff": [24, 43, 67], "bigger": [16, 21, 24, 26, 29, 32, 33, 43, 45, 47, 51, 52, 61, 63, 64, 67, 69, 72, 75, 76, 82], "biggest": [24, 27, 43, 46, 67, 70, 90, 96], "bike": [33, 76], "bilg": 58, "bill": [32, 75], "billboard": [33, 76], "billi": 58, "billie_holidai": [31, 50, 51, 74], "billion": [20, 24, 31, 43, 50, 67, 74], "billionth": [33, 76], "bin": [17, 18, 22, 24, 27, 31, 33, 34, 35, 39, 41, 43, 46, 50, 52, 53, 54, 55, 62, 65, 67, 70, 74, 76, 77, 78, 85, 91], "binar": [14, 19, 59, 63], "binari": [14, 17, 18, 19, 21, 31, 32, 34, 35, 39, 40, 41, 44, 50, 55, 59, 62, 63, 64, 65, 68, 74, 75, 77, 78, 83, 84, 89, 95], "binary_feat": [17, 19, 39, 63], "binary_featur": [25, 26, 44, 45, 66, 68, 69, 88, 94], "binary_transform": [17, 25, 26, 39, 44, 45, 66, 68, 69, 88, 94], "bincount": [25, 44, 48, 66, 68, 80], "bind": [16, 61, 86, 92], "binomi": [22, 65], "biolog": [27, 81], "biologi": [19, 63], "bird": 47, "birds_class": 47, "birds_input": 47, "birnlei": 58, "bit": [14, 15, 18, 19, 20, 21, 22, 23, 24, 25, 26, 32, 33, 34, 35, 38, 40, 41, 42, 43, 44, 45, 47, 53, 55, 59, 60, 62, 63, 64, 65, 66, 67, 68, 69, 71, 75, 76, 77, 78, 80, 90, 95, 96], "black": [16, 26, 28, 32, 52, 58, 61, 69, 71, 75, 76, 90, 96], "blackhawk": [31, 50, 51, 74], "blake": 20, "bland": 20, "blast": 58, "bld": 32, "bldgtype": [24, 26, 35, 43, 45, 54, 55, 67, 69, 78], "bldgtype_1fam": [24, 67, 69], "bldgtype_2fmcon": [24, 67, 69], "bldgtype_duplex": [24, 67, 69], "bldgtype_twnh": [24, 67, 69], "bldgtype_twnhs": [24, 67, 69], "blei": [31, 50, 51, 74], "blend": 51, "blindli": [24, 43, 66, 67], "blob": [83, 89, 95], "block": [21, 31, 34, 50, 64, 74, 77], "blog": [31, 33, 50, 51, 52, 74, 76], "blogspot": [31, 50, 74], "blood": [20, 58], "bloomberg": [1, 10], "blore": 40, "blq": [24, 26, 35, 43, 45, 54, 55, 67, 69, 78], "blue": [14, 16, 22, 26, 27, 28, 33, 41, 45, 46, 52, 59, 61, 65, 66, 69, 70, 71, 76], "bluesman": [31, 50, 51, 74], "bluf": 58, "blunt": 58, "bluntli": 58, "bmatrix": [27, 30, 46, 70, 73], "bmo": [31, 50, 74], "boat": 58, "boathous": [32, 75], "bob_dylan": [31, 50, 51, 74], "bodi": 58, "boggl": [44, 68], "boi": [20, 31, 40, 50, 74], "bold": [35, 55, 78], "bomb": 58, "bon": 95, "bond": [56, 57, 79, 80], "bonehead": 58, "bonu": [13, 25, 44, 68, 98], "book": [10, 24, 30, 31, 33, 35, 49, 50, 51, 54, 55, 67, 73, 74, 76, 78, 80, 98], "bool": [20, 24, 33, 40, 43, 67, 76, 90, 96], "bool_t": 34, "boost": [51, 79, 84], "booster": [25, 44, 68], "boosting_typ": [44, 45, 68, 69, 94], "bootstrap": [35, 44, 55, 78, 94], "border": [21, 29, 51, 59, 64, 72, 82, 83, 85, 91], "bore": [20, 21, 40, 58, 64], "borrow": 58, "boss": 58, "boston": [21, 64], "both": [2, 5, 7, 11, 14, 15, 16, 17, 19, 20, 21, 22, 24, 25, 26, 27, 28, 30, 32, 33, 34, 35, 39, 40, 41, 43, 44, 45, 51, 53, 54, 55, 56, 57, 59, 60, 61, 63, 64, 65, 66, 67, 68, 69, 71, 73, 75, 76, 77, 78, 79, 80, 81, 82, 84, 87, 89, 93, 95, 98], "bother": [26, 45, 69], "bottom": [29, 72], "bought": [30, 49, 73, 97], "bound": [27, 34, 46, 70, 77], "boundari": [15, 29, 35, 51, 55, 60, 72, 78, 79, 82, 86, 92], "bouquet": [31, 50, 74], "bow": [20, 31, 40, 50, 74], "bow_df": [17, 19, 63], "bow_kmean": [50, 74], "box": [10, 26, 69, 84], "boxplot": [26, 45, 69], "boyc": [14, 59], "bp": [31, 50, 74], "br": [20, 40, 51, 58, 82], "bracket": 9, "brain": [27, 32, 70, 75], "brainstorm": 98, "branch": [14, 29, 31, 34, 51, 59, 72, 74, 77], "brand": [35, 55, 78], "brazenli": 40, "brazil": 25, "break": [1, 18, 20, 23, 40, 42, 58, 66, 84, 86, 92], "break_ti": [41, 42, 63, 65], "breakdown": 13, "breakthrough": [13, 58], "breakwat": [32, 75], "breath": 84, "breathless": [31, 50, 74], "breathtak": [31, 50, 51, 74], "breed": 84, "breiman": [25, 44, 68], "brian": 58, "bridg": 58, "brief": [4, 21, 25, 44, 64, 68], "briefest": 58, "briefli": [13, 23, 25, 27, 42, 46, 58, 66, 68, 70, 98], "bring": [6, 7, 11, 26, 29, 31, 37, 45, 50, 56, 57, 58, 69, 72, 74, 79, 84], "brisban": 96, "britain": 58, "british": [1, 31, 50, 51, 58, 74, 82], "british_columbia": [31, 50, 51, 74], "broach": 58, "broad": [13, 16, 38, 51, 58, 61, 86, 92], "broadcast": 51, "broader": [2, 25, 31, 44, 50, 51, 68, 74], "broadest": 51, "broadli": [14, 16, 21, 25, 28, 29, 31, 50, 51, 61, 64, 66, 68, 71, 72, 74], "brook": 20, "broth": [17, 39], "brother": 58, "brownle": [27, 70], "browser": 11, "brush": [5, 32, 75], "bryan": 20, "bsmtcond": [24, 26, 35, 43, 45, 54, 55, 67, 69, 78], "bsmtexposur": [24, 26, 35, 43, 45, 54, 55, 67, 69, 78], "bsmtfinsf1": [24, 26, 35, 43, 45, 54, 55, 67, 69, 78], "bsmtfinsf2": [24, 26, 35, 43, 45, 54, 55, 67, 69, 78], "bsmtfintype1": [24, 26, 35, 43, 45, 54, 55, 67, 69, 78], "bsmtfintype2": [24, 26, 35, 43, 45, 54, 55, 67, 69, 78], "bsmtfullbath": [24, 26, 35, 43, 45, 54, 55, 67, 69, 78], "bsmthalfbath": [24, 26, 35, 43, 45, 54, 55, 67, 69, 78], "bsmtqual": [24, 26, 35, 43, 45, 54, 55, 67, 69, 78], "bsmtunfsf": [24, 26, 35, 43, 45, 54, 55, 67, 69, 78], "btw": [26, 45, 69], "bu": 58, "bubbl": [30, 32, 49, 73, 75], "buck": 58, "bucket": [27, 46, 70], "budget": [22, 30, 41, 49, 58, 65, 73], "buff": 58, "bug": [4, 9], "bui": [30, 73, 79], "build": [0, 2, 12, 15, 17, 18, 19, 25, 27, 28, 31, 32, 33, 35, 39, 44, 46, 50, 51, 55, 60, 62, 63, 68, 70, 71, 74, 75, 76, 78, 82, 83, 84, 86, 90, 92, 96], "built": [9, 13, 14, 21, 22, 26, 31, 35, 41, 45, 50, 52, 55, 56, 57, 58, 59, 60, 64, 65, 69, 74, 76, 78, 79, 90, 96], "bullshit": [1, 34, 77], "bulwark": [32, 75], "bunch": [9, 14, 15, 24, 25, 32, 34, 35, 37, 43, 44, 53, 54, 55, 59, 67, 68, 75, 77, 78, 79], "bundl": 8, "bureau": [21, 64], "burt": 58, "busi": [23, 28, 34, 42, 66, 71, 77], "businessman": 40, "businesswoman": [31, 50, 51, 74], "bust": 58, "bustl": [33, 76], "butterfli": [29, 72], "buzz": [13, 58], "buzzword": [13, 58], "bypass": 98, "bystand": 58, "c": [0, 1, 9, 10, 11, 13, 14, 15, 17, 18, 19, 20, 21, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 34, 35, 38, 39, 40, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 53, 55, 58, 59, 60, 62, 63, 64, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 77, 78, 79, 80, 81, 86, 92, 94, 98], "c1": [29, 72], "c2": [29, 72], "c_1": [28, 71], "c_2": [28, 71], "c_3": [28, 71], "c_log": [16, 38, 61, 86, 92], "c_val": 38, "c_valu": 38, "c_widget": [16, 61, 86, 92], "ca": [1, 10, 13, 58, 79, 98], "ca_transform": [19, 63], "cabl": 58, "cach": 31, "cache_s": [35, 41, 42, 55, 63, 65, 78], "cairn": 96, "cal_hous": [21, 64], "calcul": [8, 15, 16, 18, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 37, 42, 43, 44, 45, 46, 47, 49, 50, 52, 58, 60, 61, 62, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 79, 83, 84, 86, 90, 92, 96], "calendar": [1, 98], "calgary_flam": [31, 50, 51, 74], "calibr": 79, "california": [18, 27, 46, 62, 70], "california_h": [27, 46, 70], "californian": [18, 62], "call": [1, 9, 13, 14, 15, 16, 17, 18, 19, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 39, 41, 42, 43, 44, 45, 46, 49, 50, 51, 52, 53, 54, 55, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 83, 84, 86, 88, 90, 92, 94, 96], "callback": [25, 44, 68], "caller": 79, "came": [33, 76], "camera": [19, 20, 63], "campaign": 58, "campu": [27, 46, 70, 98], "can": [1, 4, 6, 7, 8, 11, 13, 14, 16, 17, 19, 20, 21, 22, 23, 24, 27, 29, 30, 31, 32, 33, 34, 35, 37, 38, 39, 40, 41, 42, 43, 46, 47, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 61, 63, 64, 65, 66, 67, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 98], "canada": [16, 19, 21, 31, 35, 50, 51, 55, 60, 61, 63, 64, 74, 78, 82, 84], "canada_usa_c": [16, 21, 59, 60, 61, 64, 85, 91], "canadian": [17, 31, 39, 50, 51, 74], "canadien": [31, 50, 51, 74], "canberra": [52, 76, 96], "cancel": 98, "cancer": [13, 27, 46, 58, 70], "candi": [89, 95], "candid": [22, 31, 37, 41, 44, 50, 51, 65, 68, 74, 86, 92], "candidate_label": [31, 50, 74], "candy_df": [89, 95], "candy_transform": [89, 95], "cannot": [0, 8, 9, 13, 15, 16, 22, 23, 25, 26, 27, 29, 32, 33, 34, 35, 39, 42, 44, 45, 46, 55, 58, 60, 61, 65, 66, 68, 69, 70, 72, 76, 77, 78, 80, 81, 90, 96, 98], "cant": [31, 50, 74], "canuck": [31, 50, 51, 74], "canva": [1, 8, 13, 79, 98], "capabl": [10, 31, 50, 74], "capit": [25, 26, 44, 45, 66, 68, 69], "caption": [8, 32, 75], "captiv": [31, 50, 51, 74], "captor": 58, "captur": [12, 15, 18, 21, 25, 27, 29, 30, 31, 33, 34, 44, 46, 49, 50, 51, 60, 62, 64, 68, 70, 72, 73, 74, 76, 77, 84], "car": [13, 32, 51, 58, 75, 79, 82], "caramel": 95, "card": [14, 23, 34, 35, 42, 53, 55, 58, 59, 66, 77, 78], "cardin": 39, "care": [5, 8, 15, 18, 22, 23, 24, 26, 27, 28, 31, 33, 34, 39, 42, 43, 45, 46, 49, 50, 52, 53, 58, 60, 62, 65, 66, 67, 69, 70, 71, 74, 76, 77, 84, 88, 90, 94, 96], "carefulli": [1, 5, 8, 13, 24, 43, 66, 67, 84], "cari": 20, "carpent": 58, "carpentri": 6, "carrel": 40, "carri": [14, 15, 16, 17, 19, 20, 22, 24, 25, 28, 30, 31, 33, 37, 39, 41, 43, 44, 49, 50, 51, 52, 59, 60, 61, 63, 65, 66, 67, 68, 71, 73, 74, 76, 79, 86, 90, 92, 96], "caruana": [26, 45, 69], "case": [7, 12, 13, 14, 15, 16, 17, 18, 20, 22, 23, 24, 25, 26, 27, 28, 30, 31, 33, 34, 35, 39, 40, 42, 43, 44, 45, 46, 49, 50, 51, 52, 55, 56, 57, 58, 59, 60, 61, 62, 65, 66, 67, 68, 69, 70, 71, 73, 74, 76, 77, 78, 79, 80, 83, 84, 90, 91, 96, 98], "casei": 58, "cash": 58, "cast": [20, 30, 49, 58, 73], "castl": [32, 75], "cat": [25, 31, 32, 38, 44, 50, 51, 58, 66, 68, 74, 75, 82, 84], "catamount": [32, 58, 75], "catboost": [12, 26, 35, 45, 55, 69, 78, 84], "catboostclassifi": [25, 44, 68], "catboostregressor": [25, 44, 68], "catch": [66, 98], "categir": 39, "categor": [14, 22, 23, 24, 25, 27, 28, 30, 31, 34, 35, 37, 42, 43, 44, 46, 47, 49, 51, 52, 53, 54, 55, 59, 65, 66, 67, 68, 70, 71, 73, 74, 77, 78, 84, 86, 87, 90, 92, 93, 96], "categori": [16, 17, 18, 24, 25, 26, 27, 28, 32, 35, 38, 39, 41, 43, 44, 45, 46, 54, 55, 61, 62, 65, 66, 67, 68, 69, 70, 71, 75, 78, 84, 94], "categorical_feat": [17, 19, 22, 39, 41, 63, 65, 84], "categorical_featur": [24, 25, 26, 34, 35, 43, 44, 45, 52, 53, 54, 55, 63, 66, 67, 68, 69, 76, 77, 78, 88, 90, 93, 94, 96], "categorical_transform": [17, 24, 25, 26, 35, 39, 43, 44, 45, 52, 54, 55, 63, 66, 67, 68, 69, 76, 78, 88, 90, 93, 94, 96], "categories_": [18, 19, 62, 63], "cater": [28, 71], "caus": [26, 27, 30, 31, 32, 34, 45, 49, 50, 53, 58, 69, 73, 74, 75, 77, 80, 81], "causal": [26, 27, 45, 46, 69, 70, 81], "caution": [33, 76], "cautiou": 21, "cb": 20, "cbar": [21, 64], "cbtf": [1, 7, 98], "cc": [0, 1], "cc_df": [23, 42, 66, 80], "cconj": [31, 50, 51, 74, 82], "ccp_alpha": [35, 37, 44, 55, 68, 78, 94], "cd": 11, "cell": [8, 9, 11, 15, 17, 18, 19, 20, 22, 23, 24, 25, 26, 27, 30, 32, 34, 35, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 54, 55, 58, 62, 63, 65, 66, 67, 68, 69, 70, 73, 75, 77, 78, 85, 86, 88, 89, 91, 92, 94, 95], "ceme": 98, "censor": [1, 12, 55, 78, 79, 84], "censorship": 58, "censu": [21, 25, 26, 44, 45, 64, 66, 68, 69], "census_df": 66, "cent": [17, 24, 43, 67], "center": [16, 28, 29, 32, 61, 71, 72, 75, 83, 95], "centers_df": 95, "centers_idx": [28, 71], "central": [6, 31, 50, 74], "centralair": [24, 26, 35, 43, 45, 54, 55, 67, 69, 78], "centralair_i": [24, 67, 69], "centralair_n": [24, 67, 69], "centric": [12, 35, 78], "centroid": [28, 29, 71, 72, 95], "centroids_idx": [28, 71], "centroids_idx_init": [28, 71], "centuri": 51, "certain": [16, 21, 22, 26, 27, 28, 31, 34, 35, 40, 41, 45, 51, 55, 58, 61, 64, 65, 66, 69, 70, 71, 74, 77, 78], "certainli": [85, 91], "certainti": [23, 42, 66], "cesspool": 58, "cezannec": [32, 47, 75], "chaat": 51, "chain": [19, 63], "challeng": [4, 7, 12, 13, 27, 30, 32, 33, 39, 46, 49, 60, 70, 71, 73, 75, 76, 79, 84, 88, 94], "chambar": [17, 39], "chanc": [5, 22, 23, 24, 27, 28, 34, 35, 42, 43, 45, 46, 55, 58, 59, 60, 65, 66, 67, 70, 71, 77, 78, 79], "chang": [0, 6, 8, 9, 13, 14, 15, 16, 17, 18, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 34, 35, 38, 41, 42, 43, 44, 45, 50, 52, 53, 54, 55, 59, 60, 61, 62, 65, 67, 68, 69, 71, 72, 73, 74, 75, 76, 77, 78, 85, 86, 88, 90, 91, 92, 94, 96], "channel": [1, 11, 47], "chap": 58, "chapman": 58, "chapter": 1, "charact": [19, 20, 31, 50, 51, 63, 74, 80], "character": [28, 30], "characterist": [14, 21, 59, 60, 64, 86, 92], "charg": [0, 34, 53, 58, 77], "charl": [20, 21, 58, 64], "charm": [20, 51], "chart": [26, 34, 35, 45, 52, 54, 55, 69, 76, 77, 78, 90, 96], "chase": 58, "chat": 98, "chatbot": [31, 50, 74], "chatgpt": [31, 50, 51, 58, 74, 98], "chatterje": 40, "che210d": 10, "cheaper": [27, 46, 70], "cheat": 10, "cheatsheet": 66, "check": [1, 4, 5, 8, 11, 13, 14, 15, 17, 18, 21, 23, 24, 26, 27, 28, 29, 31, 32, 33, 34, 35, 42, 43, 45, 46, 50, 51, 53, 55, 58, 59, 60, 62, 64, 66, 67, 69, 70, 71, 72, 74, 75, 76, 77, 78, 80, 86, 88, 89, 90, 92, 94, 95, 96, 98], "check_arrai": [18, 34], "check_assumpt": [34, 53, 77], "check_consistent_length": 18, "check_invers": [19, 63, 67], "check_param": [18, 34], "check_x_i": 18, "check_y_param": 18, "checklist": 84, "checkmark": [30, 73], "checkout": [22, 41, 65], "cheetah": [32, 58, 75], "chemic": 20, "chemistri": 20, "cherri": [35, 54, 55, 78], "chess": [13, 58], "chest": [15, 60], "chestpaintyp": [88, 94], "chetah": [32, 58, 75], "chi": [34, 77], "chicken": [17, 28, 71], "chief": 58, "child": [20, 26, 44, 45, 58, 66, 69], "children": [30, 49, 58, 73], "chill": 20, "chines": [17, 39, 51, 82], "chloe": 20, "chn": 9, "chocol": 95, "chocolate_cak": [32, 75], "choic": [2, 5, 11, 15, 22, 24, 25, 26, 28, 29, 30, 33, 43, 44, 45, 49, 58, 65, 66, 67, 68, 69, 71, 72, 73, 76, 86, 87, 92, 93], "cholesterol": [88, 94], "choos": [6, 11, 22, 25, 29, 35, 44, 55, 56, 57, 58, 65, 66, 68, 72, 78, 79, 84, 86, 92], "chop": [35, 51, 54, 55, 65, 78, 82], "chose": [15, 35, 37, 55, 78], "chosen": [15, 22, 23, 34, 35, 42, 55, 60, 65, 77, 78, 80, 84, 88, 94], "chrbv": [34, 53, 77], "christoph": 20, "chrome": 13, "chuckl": 58, "chunki": [28, 71], "churn": [27, 53, 55, 78, 84], "chvcf": 34, "ciml": 1, "cinematograph": 58, "cinematographi": [31, 50, 51, 58, 74], "cinereu": [32, 75], "circl": [16, 23, 42, 61, 66], "circuit": 98, "circumst": 8, "citat": 8, "cite": [5, 34, 53, 77, 98], "citi": [16, 33, 35, 51, 55, 59, 60, 61, 76, 78, 82, 84, 85, 91], "citibik": [33, 76], "cities_df": [16, 21, 61, 64], "citizen": [34, 53, 77], "cityscap": [33, 76], "civ": [25, 26, 44, 45, 66, 68, 69], "clai": [45, 69], "claim": [0, 22, 65, 66], "clarif": 71, "clarifi": [6, 98], "clariti": 12, "class": [1, 4, 6, 8, 14, 15, 16, 18, 19, 21, 27, 28, 31, 34, 35, 58, 59, 60, 61, 62, 63, 64, 70, 71, 76, 77, 78, 79, 85, 86, 88, 91, 92, 94, 96], "class_attend": [14, 15, 59, 60, 84], "class_attendance_enc": [19, 63], "class_attendance_level": [19, 63], "class_label": 66, "class_labels_fil": [13, 58], "class_nam": [14, 16, 25, 32, 38, 44, 47, 48, 59, 61, 68, 75, 85, 91], "class_sep": 80, "class_weight": [25, 35, 40, 41, 42, 44, 45, 55, 63, 65, 68, 69, 75, 78, 94], "classes_": [20, 21, 23, 25, 26, 32, 40, 42, 44, 45, 64, 66, 68, 69, 75, 83], "classic": [16, 32, 58, 61, 75, 83], "classif": [1, 2, 12, 13, 15, 16, 17, 18, 19, 21, 24, 25, 26, 27, 30, 31, 33, 34, 35, 37, 43, 44, 45, 47, 48, 50, 51, 52, 55, 58, 60, 61, 62, 63, 64, 67, 68, 69, 73, 74, 76, 77, 78, 81, 83, 85, 86, 88, 91, 92, 94], "classifi": [15, 16, 18, 19, 22, 23, 26, 31, 32, 35, 38, 41, 42, 45, 47, 48, 50, 55, 60, 61, 62, 63, 65, 66, 69, 74, 75, 78, 83, 85, 87, 88, 91, 93, 94], "classification_df": [14, 15, 59, 60], "classification_report": [23, 42, 66, 80], "classifier_result": 94, "classifiers_ndt": [25, 44, 68], "classify_imag": [13, 32, 58, 75], "classmat": [7, 86, 87, 88, 89, 90, 92, 93, 94, 95, 96, 98], "classroom": [1, 5], "claud": [25, 31, 50, 74, 98], "claudio": 40, "clean": [2, 15, 17, 20, 29, 35, 37, 39, 40, 54, 55, 58, 72, 78, 90, 96, 98], "clean_text": [31, 50, 51, 74], "cleaned_hm": [56, 57, 79, 80], "cleaned_restaurant_data": [17, 39], "cleaner": [26, 44, 45, 66, 69], "clear": [8, 12, 13, 23, 28, 38, 42, 58, 66, 71, 79, 86, 92], "clearli": [4, 8, 22, 25, 26, 33, 44, 45, 65, 68, 69, 76], "cleric": [25, 26, 44, 45, 66, 68, 69], "clever": [35, 54, 55, 78], "clf": [13, 14, 16, 21, 58, 59, 61, 64], "click": [1, 6, 8, 11, 14, 30, 36, 49, 55, 56, 57, 66, 73, 78, 79], "client": [30, 50, 56, 57, 73, 74, 79], "clinic": [14, 31, 59, 74], "clip": [38, 58, 76, 90, 96], "cloak": 20, "clone": [6, 8, 11], "close": [2, 16, 21, 22, 23, 28, 29, 31, 33, 34, 38, 41, 42, 50, 51, 58, 60, 61, 64, 65, 66, 71, 72, 74, 76, 82, 83, 86, 91, 92, 98], "close_default_lr": [23, 42, 66], "close_fd": [16, 25, 26, 28], "close_zero_svm": [23, 42, 66], "closer": [7, 16, 17, 18, 21, 30, 49, 61, 62, 64, 73, 85, 91], "closest": [15, 16, 18, 28, 29, 31, 33, 42, 50, 51, 61, 62, 66, 71, 72, 74, 76], "closet": [20, 40], "cloth": [33, 58, 76], "cloud": [1, 13, 22, 29, 41, 65, 98], "cloud3pm": [52, 76, 90, 96], "cloud9am": [52, 76, 90, 96], "clouzot": 20, "clung": [31, 50, 74], "clust_label": [28, 71], "cluster": [1, 2, 12, 30, 31, 33, 50, 51, 52, 58, 73, 74, 76, 79], "cluster_cent": [28, 71], "cluster_centers_": [28, 47, 48, 71, 89, 95], "cluster_label": 48, "cluster_std": [29, 32, 72, 75], "cluster_summari": 95, "clutter": 59, "cm": [16, 21, 23, 26, 30, 38, 42, 49, 61, 64, 66, 69, 73, 86, 92], "cmap": [22, 26, 41, 62, 65, 66, 69], "cmn": [24, 43, 67, 69], "cmp": [34, 77], "cnn": [33, 52, 76], "co": [19, 31, 50, 51, 58, 63, 74], "coal": 58, "coast": [32, 75], "cobar": 96, "cocain": 58, "cocknei": 58, "cockpit": [35, 55, 78], "code": [4, 6, 8, 9, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 85, 86, 87, 88, 89, 91, 92, 93, 94, 95], "codecademi": 10, "coef": [34, 52, 53, 76, 77, 96], "coef0": [35, 41, 42, 55, 63, 65, 78], "coef_": [20, 21, 24, 25, 26, 27, 30, 32, 33, 34, 40, 43, 44, 45, 46, 49, 52, 53, 64, 67, 68, 69, 70, 73, 75, 76, 77, 83, 88, 94, 96], "coef_df": [21, 26, 45, 64, 69], "coef_nonzero": [33, 76], "coeff": [20, 21, 40, 64], "coeff_df": [52, 76, 96], "coeffici": [24, 25, 27, 30, 32, 33, 34, 43, 44, 46, 49, 52, 53, 55, 67, 68, 70, 73, 75, 76, 77, 78, 83, 84, 88, 90, 94, 96], "coefs_df": [27, 46, 70], "coffsharbour": 96, "coher": [28, 71], "col": [14, 19, 21, 30, 33, 49, 59, 63, 64, 73, 76, 84], "col1": 9, "col2": 9, "col3": 9, "col4": 9, "col5": 9, "col6": 9, "cold": [18, 62], "colinear": [26, 45, 69], "collabor": [5, 6, 12, 30, 49, 73], "collaps": [26, 45, 69], "colleagu": [9, 10], "collect": [12, 13, 14, 17, 18, 19, 25, 26, 27, 30, 31, 32, 33, 34, 39, 44, 45, 46, 49, 50, 51, 53, 58, 59, 62, 63, 66, 68, 69, 70, 73, 74, 75, 76, 77, 79, 80, 84, 88, 89, 94, 95, 98], "colleg": [25, 26, 44, 45, 66, 68, 69], "collinear": [27, 81], "colombia": 25, "color": [21, 26, 27, 28, 29, 35, 45, 46, 47, 52, 55, 64, 69, 70, 71, 72, 76, 78, 95, 97], "color_continuous_scal": [27, 46, 70], "color_threshold": [29, 72], "colorbar": [21, 62, 64], "colour": [19, 21, 22, 26, 28, 29, 32, 41, 45, 48, 63, 64, 65, 69, 71, 72, 75], "colsample_bylevel": [25, 44, 68], "colsample_bynod": [25, 44, 68], "colsample_bytre": [25, 44, 45, 68, 69, 94], "columbia": [1, 10, 31, 50, 51, 74, 82], "column": [8, 13, 14, 15, 16, 17, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 34, 35, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 77, 78, 79, 80, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96], "column_as_label": 34, "column_nam": [19, 63, 89, 93, 95], "column_stack": [27, 46, 70], "columntranform": [87, 93], "columntransform": [1, 17, 18, 22, 24, 25, 26, 27, 33, 34, 35, 39, 41, 43, 44, 45, 46, 52, 53, 54, 55, 62, 65, 66, 67, 68, 69, 70, 76, 77, 78, 88, 89, 90, 94, 95, 96], "columntransformer__countvectorizer__max_featur": [22, 41, 65], "columntransformercolumntransform": [19, 22, 24, 25, 27, 46, 70], "columntransformerifit": [39, 41, 45, 63, 67, 69], "columntransformerifittedcolumntransform": [19, 24, 35, 43, 54, 55, 78], "columntransformerinot": [17, 19, 25, 44, 63, 68], "com": [0, 6, 9, 10, 11, 13, 16, 22, 23, 29, 31, 32, 33, 34, 42, 50, 53, 66, 74, 75, 76, 77, 79, 80, 89, 95], "comat": [31, 50, 51, 74], "combin": [14, 17, 18, 22, 23, 27, 30, 31, 33, 34, 35, 39, 41, 42, 46, 50, 55, 58, 59, 62, 65, 66, 70, 73, 74, 76, 77, 78, 81, 85, 86, 88, 91, 92, 94], "come": [13, 14, 17, 18, 19, 27, 30, 31, 32, 33, 34, 35, 37, 39, 46, 50, 51, 53, 55, 58, 59, 62, 63, 66, 70, 73, 74, 75, 76, 77, 78, 85, 91, 95], "comedi": [20, 30, 40, 49, 58, 73], "comfi": [17, 39], "comfort": [5, 20, 31, 40, 50, 74], "command": [4, 11, 40, 51, 56, 57, 79, 80], "comment": [9, 10, 17, 39, 58, 89, 90, 96], "commerci": [0, 92], "commit": [8, 23, 42, 66, 98], "common": [1, 5, 9, 12, 14, 15, 16, 22, 24, 27, 29, 30, 32, 33, 34, 41, 43, 46, 49, 51, 53, 56, 57, 59, 60, 61, 65, 66, 67, 68, 70, 72, 73, 75, 76, 77, 79, 81, 82, 83, 86, 92, 93, 98], "commonli": [14, 18, 22, 23, 28, 31, 32, 34, 42, 53, 59, 62, 65, 66, 71, 74, 75, 77], "commonwealth": [31, 50, 51, 74], "commun": [1, 2, 7, 12, 19, 22, 24, 58, 63, 65, 67, 79, 98], "commut": 9, "comp_dict": 66, "compact": [22, 27, 46, 65, 70], "compani": [6, 27, 28, 30, 31, 34, 50, 51, 66, 71, 73, 74, 77, 82], "compar": [9, 12, 14, 15, 16, 18, 21, 22, 23, 24, 25, 26, 27, 29, 30, 32, 35, 37, 41, 42, 43, 44, 45, 46, 49, 51, 52, 54, 55, 59, 60, 61, 62, 64, 65, 66, 67, 68, 69, 70, 72, 73, 75, 76, 78, 83, 84, 88, 89, 90, 94, 95, 96, 98], "comparis": 94, "comparison": [29, 32, 34, 39, 66, 72, 75, 77, 84], "compassion": 98, "compat": [9, 45, 69], "compatibitl": 9, "compel": [33, 76], "competit": [25, 32, 68, 75, 83], "competitornam": [89, 95], "complain": 7, "complaint": [7, 98], "complement": 51, "complet": [1, 5, 7, 8, 11, 13, 15, 18, 20, 22, 25, 26, 27, 29, 32, 34, 35, 39, 41, 44, 45, 51, 55, 58, 62, 65, 68, 69, 70, 72, 75, 77, 78, 82, 85, 88, 89, 91, 94, 95, 98], "complex": [12, 13, 14, 16, 21, 24, 25, 26, 27, 29, 31, 32, 33, 34, 38, 39, 44, 45, 46, 50, 51, 56, 57, 58, 59, 61, 64, 65, 67, 68, 69, 70, 72, 74, 75, 76, 79, 86, 92], "complex_warn": 34, "complexwarn": 34, "compli": [0, 98], "complic": [13, 14, 17, 22, 24, 27, 38, 39, 47, 58, 59, 60, 65, 67, 70], "compon": [19, 30, 33, 35, 52, 55, 63, 66, 73, 76, 78, 98], "components_": [31, 50, 51, 74], "compos": [17, 19, 22, 24, 25, 26, 27, 33, 34, 35, 38, 39, 41, 43, 44, 45, 46, 47, 48, 52, 53, 54, 55, 61, 63, 65, 66, 67, 68, 69, 70, 76, 77, 78, 87, 88, 89, 90, 93, 94, 95, 96], "composit": [19, 63], "compound": [32, 34, 51, 75, 77, 82], "comprehend": [31, 38, 50, 51, 74], "comprehens": [28, 71, 84, 98], "compress": [17, 19, 20, 28, 31, 39, 40, 50, 51, 63, 71, 74], "compris": [13, 14, 28, 58, 59, 71], "compromis": [86, 92], "comput": [1, 5, 8, 10, 11, 12, 19, 22, 23, 26, 27, 28, 29, 31, 33, 34, 35, 38, 42, 44, 45, 46, 47, 48, 50, 51, 55, 56, 57, 58, 63, 65, 66, 68, 69, 70, 71, 72, 74, 76, 78, 79, 81, 82, 83, 88, 89, 93, 94, 95, 98], "computation": [27, 46, 70], "compute_class_weight": 66, "computer_programm": [31, 50, 51, 74], "coms4995": [18, 62], "con": [28, 31, 35, 45, 50, 51, 55, 58, 71, 74, 78], "concat": [13, 16, 18, 19, 21, 26, 39, 41, 44, 45, 58, 61, 62, 63, 64, 65, 67, 68, 69, 94], "concaten": [19, 51, 63], "concav": [27, 46, 70], "concensu": 60, "concentr": [41, 65, 84], "concept": [1, 5, 12, 14, 15, 17, 26, 27, 28, 31, 33, 39, 45, 50, 58, 69, 70, 71, 74, 76, 84, 86, 92, 98], "conceptnet": [31, 50, 51, 74], "conceptu": [5, 25, 35, 44, 55, 68, 78], "concern": [4, 12, 13, 15, 19, 25, 31, 37, 44, 58, 63, 68, 74, 98], "concess": [1, 8], "concis": [14, 59, 79], "conclus": [1, 35, 55, 78], "concord": [34, 53, 77], "concordance_index": [34, 53, 77], "concordance_index_": [34, 53, 77], "concret": [13, 35, 55, 58, 78], "conda": [13, 23, 24, 25, 26, 28, 31, 34, 38, 42, 43, 44, 45, 47, 48, 50, 51, 53, 58, 66, 67, 68, 69, 71, 74, 77, 80], "condens": 14, "condit": [0, 14, 15, 19, 20, 27, 34, 37, 40, 51, 53, 58, 59, 63, 77, 81, 82], "condition1": [24, 26, 35, 43, 45, 54, 55, 67, 69, 78], "condition1_arteri": [24, 67, 69], "condition1_feedr": [24, 67, 69], "condition1_norm": [24, 67, 69], "condition1_posa": [24, 67, 69], "condition1_posn": [24, 54, 67, 69], "condition1_rra": [24, 54, 67, 69], "condition1_rran": [24, 54, 67, 69], "condition1_rrn": [24, 54, 67, 69], "condition1_rrnn": [24, 54, 67, 69], "condition2": [24, 26, 35, 43, 45, 54, 55, 67, 69, 78], "condition2_arteri": [24, 45, 67, 69], "condition2_feedr": [24, 45, 67, 69], "condition2_norm": [24, 45, 67, 69], "condition2_posa": [24, 45, 67, 69], "condition2_posn": [24, 43, 45, 67, 69], "condition2_rra": [24, 43, 45, 67, 69], "condition2_rran": [24, 43, 45, 67, 69], "condition2_rrnn": [24, 43, 45, 67, 69], "conditional_aft": [34, 53, 77], "conduct": [12, 13], "confer": [31, 50, 51, 74], "confid": [13, 15, 20, 26, 34, 40, 45, 53, 58, 60, 69, 77, 79, 84, 86, 88, 92, 94], "confidenti": [23, 42, 66], "config": [11, 34], "config_context": [18, 34], "configur": [22, 25, 41, 44, 65, 67, 68], "confin": 20, "confirm": 66, "conflict": [5, 11, 29, 58, 72, 98], "confound": [27, 70, 81], "confus": [9, 16, 19, 24, 43, 61, 63, 67, 71, 79, 86, 92], "confusingli": 13, "confusion_matrix": [23, 34, 42, 53, 66, 77], "confusionmatrixdisplai": [23, 42, 66, 80, 81], "congrat": [19, 63], "conjunct": [27, 46, 70], "connect": [0, 13, 14, 29, 30, 32, 49, 56, 57, 59, 72, 73, 75, 79, 84], "connot": 51, "conort": [27, 46, 70], "consecut": [33, 52, 76], "consequ": [8, 13, 30, 35, 49, 55, 58, 63, 66, 73, 78], "consid": [14, 15, 16, 18, 19, 21, 22, 23, 26, 27, 28, 29, 30, 31, 33, 35, 38, 41, 42, 44, 45, 49, 50, 51, 55, 58, 59, 60, 61, 62, 63, 64, 65, 66, 68, 69, 71, 72, 73, 74, 76, 78, 79, 81, 82, 84, 86, 92, 98], "consider": [2, 12, 25, 28, 30, 34, 44, 49, 55, 56, 57, 58, 68, 71, 73, 77, 78, 79, 80], "consist": [7, 8, 11, 14, 15, 17, 18, 28, 34, 39, 58, 59, 60, 62, 71, 79], "consol": 58, "const": [31, 50, 51, 74], "constant": [14, 17, 24, 25, 26, 33, 34, 35, 39, 43, 44, 45, 52, 54, 55, 59, 66, 67, 68, 69, 76, 77, 78, 90, 96], "constantli": 20, "constitu": [25, 44, 68], "constitut": [31, 50, 51, 74], "construct": [20, 30, 49, 73], "constructor": [17, 18, 59, 62], "consult": [16, 38, 61, 86, 92], "consum": [13, 20, 27, 28, 30, 40, 58, 70, 71, 73, 79, 84], "consumpt": [20, 33, 76, 86, 92], "contact": [1, 13, 20, 58, 98], "contain": [9, 13, 14, 18, 19, 20, 21, 24, 30, 31, 32, 34, 43, 49, 50, 51, 56, 57, 58, 59, 62, 63, 64, 67, 73, 74, 75, 76, 79, 82, 83, 90, 96], "container": [56, 57, 79], "content": [1, 4, 5, 12, 13, 31, 32, 40, 41, 50, 51, 56, 57, 63, 65, 71, 74, 75, 79, 84, 98], "contest": 7, "context": [12, 14, 16, 18, 21, 22, 23, 25, 26, 27, 28, 29, 30, 31, 32, 33, 35, 41, 42, 44, 45, 46, 49, 50, 55, 59, 62, 64, 65, 66, 68, 69, 70, 72, 73, 74, 75, 76, 78, 81, 84, 86, 92], "contextu": [12, 31, 50, 74], "contin": 63, "conting": [29, 72], "continu": [17, 19, 22, 24, 27, 31, 33, 35, 39, 43, 44, 46, 50, 51, 52, 55, 63, 65, 67, 68, 70, 74, 76, 78, 90, 96], "contract": [0, 27, 31, 34, 53, 74, 77], "contract_month": [34, 53, 77], "contract_on": [34, 53, 77], "contract_two": [34, 53, 77], "contracttyp": 27, "contradict": 58, "contrapt": 58, "contrast": [12, 58, 84], "contribut": [16, 21, 26, 32, 45, 58, 61, 64, 69, 75, 88, 94, 98], "control": [5, 6, 9, 14, 16, 19, 21, 24, 25, 32, 43, 44, 59, 60, 61, 63, 64, 67, 68, 75, 98], "convei": 12, "conveni": [9, 13, 22, 23, 28, 31, 33, 34, 35, 41, 42, 45, 50, 51, 53, 55, 56, 57, 65, 66, 71, 74, 76, 77, 78, 79, 82, 95], "convent": [76, 90, 96], "converg": [25, 28, 71], "convers": [24, 26, 31, 43, 45, 51, 67, 69, 74, 79, 80], "convert": [13, 17, 18, 19, 21, 25, 26, 27, 31, 33, 34, 39, 44, 45, 46, 50, 51, 58, 62, 63, 64, 68, 69, 70, 74, 76, 77, 82, 90, 96], "convinc": [19, 20, 35, 55, 63, 78], "convincingli": 58, "convolut": [27, 70], "convolutional_neural_network": [32, 47, 75], "cooccurrencematrix": [31, 50, 51, 74], "cook": [31, 50, 71, 74], "cool": [20, 32, 47, 75], "coolwarm": [21, 64], "coordin": [89, 95, 98], "copi": [0, 8, 9, 14, 18, 25, 26, 28, 30, 32, 34, 35, 39, 41, 42, 44, 45, 49, 52, 54, 55, 59, 62, 63, 65, 67, 68, 69, 71, 73, 75, 76, 77, 78, 88, 90, 94, 96, 98], "copilot": [31, 74], "copy_x": 67, "copyright": [0, 31, 50, 74, 98], "cor": [26, 69], "coral": [32, 75], "core": [10, 12, 17, 18, 19, 22, 23, 24, 27, 29, 30, 34, 41, 42, 43, 46, 52, 53, 60, 62, 63, 65, 66, 67, 70, 72, 73, 76, 77, 79, 84, 92, 94, 96], "corefer": [51, 82], "corei": [56, 57, 79], "corgi": [32, 58, 75], "corner": 11, "corpora": [19, 31, 50, 51, 63, 74], "corpu": [19, 31, 50, 51, 63, 74, 80, 82], "corr": [26, 45, 69], "corr_df": [26, 45, 69], "correct": [8, 13, 14, 15, 16, 23, 25, 26, 34, 35, 41, 42, 44, 45, 53, 55, 58, 59, 60, 61, 65, 66, 68, 69, 77, 78, 85, 86, 88, 91, 92, 94], "correctli": [14, 23, 42, 59, 60, 66], "correl": [33, 76, 84, 93], "correspond": [1, 13, 14, 15, 19, 21, 22, 23, 24, 26, 28, 30, 33, 38, 39, 41, 42, 45, 48, 49, 58, 59, 60, 61, 63, 64, 65, 66, 67, 69, 71, 73, 76, 86, 92], "cos_sim": [31, 50, 74], "cosin": [31, 50, 51, 74], "cosine_similar": [31, 51, 74], "cost": [9, 32, 35, 55, 58, 75, 78, 98], "cost_rep": 9, "costco": [31, 50, 51, 74], "costli": [23, 42, 66], "cot": [32, 75], "cote": [32, 75], "could": [7, 9, 14, 15, 16, 18, 19, 22, 23, 24, 25, 27, 28, 30, 31, 33, 34, 35, 40, 41, 42, 43, 44, 45, 46, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 65, 66, 67, 68, 70, 71, 73, 74, 76, 77, 78, 79, 86, 90, 92, 93, 95, 96, 98], "couldn": [20, 51, 82], "count": [9, 14, 15, 17, 18, 19, 23, 24, 27, 32, 34, 37, 39, 40, 42, 43, 46, 50, 51, 52, 53, 56, 57, 58, 59, 62, 63, 66, 67, 70, 74, 75, 76, 77, 79, 83, 86, 89, 90, 92, 94, 95, 96], "counter": 80, "counti": [15, 37], "countplot": [89, 95], "countri": [16, 21, 25, 26, 44, 45, 51, 60, 61, 63, 64, 66, 68, 69, 82, 98], "country_cambodia": 44, "country_canada": 44, "country_china": 44, "country_columbia": [26, 44, 45, 69], "country_cuba": 44, "country_dominican": [26, 44, 45, 69], "country_ecuador": 44, "country_el": 44, "country_england": 44, "country_fr": 44, "country_germani": 44, "country_greec": 44, "country_guatemala": [26, 44, 45, 69], "country_ha": 44, "country_holand": 44, "country_hondura": [26, 44, 45, 69], "country_hong": [26, 44, 45, 69], "country_hungari": [26, 44, 45, 69], "country_india": [26, 44, 45, 69], "country_iran": [26, 44, 45, 69], "country_ireland": 44, "country_itali": 44, "country_jamaica": 44, "country_japan": 44, "country_lao": 44, "country_mexico": 44, "country_miss": [25, 26, 44, 45, 68, 69], "country_nicaragua": 44, "country_outli": 44, "country_peru": 44, "country_philippin": 44, "country_poland": 44, "country_portug": 44, "country_puerto": [26, 44, 45, 69], "country_scotland": [26, 44, 45, 69], "country_south": [26, 44, 45, 69], "country_taiwan": [26, 44, 45, 69], "country_thailand": [26, 44, 45, 69], "country_trinadad": [25, 26, 44, 45, 68, 69], "country_unit": [25, 26, 44, 45, 68, 69], "country_vietnam": [25, 26, 44, 45, 68, 69], "country_yugoslavia": [25, 26, 44, 45, 68, 69], "countvector": [13, 17, 20, 21, 22, 31, 39, 40, 41, 50, 51, 56, 57, 58, 64, 65, 74, 79, 80, 84], "countvectorizercountvector": [17, 19, 20, 22], "countvectorizersong_titl": 22, "coupl": [4, 5, 22, 29, 59, 65, 72, 89, 90, 95, 96], "cour": [31, 50, 51, 74], "cours": [2, 4, 6, 7, 8, 14, 15, 17, 19, 21, 23, 24, 25, 26, 27, 28, 30, 31, 32, 33, 34, 37, 38, 39, 42, 43, 44, 45, 46, 47, 48, 50, 51, 52, 53, 59, 60, 63, 64, 66, 67, 68, 69, 70, 71, 73, 74, 75, 76, 77, 80, 84, 91], "coursera": [1, 10], "coursework": 98, "court": [31, 50, 51, 74], "covari": [14, 34, 53, 59, 77], "cover": [5, 9, 12, 13, 28, 33, 50, 52, 58, 66, 68, 71, 74, 76, 98], "coverag": [23, 42, 66], "cow": [35, 55, 78], "cox": 12, "coxph_fitt": [53, 77], "coxphfitt": [34, 53, 77], "cph": [34, 53, 55, 77, 78, 84], "cph_param": [34, 53, 77], "cpp": 32, "cpsc": [10, 14, 25, 27, 31, 32, 33, 35, 36, 44, 50, 51, 52, 55, 58, 59, 68, 74, 75, 76, 78, 79, 81, 98], "cpsc330": [0, 1, 11, 13, 14, 16, 18, 19, 25, 26, 28, 31, 32, 34, 38, 45, 50, 51, 53, 58, 59, 60, 63, 69, 74, 75, 77, 79, 83, 98], "cpsc330env": 11, "cpu": [22, 31, 32, 38, 41, 47, 48, 65, 75], "cpu_info": [16, 25, 26, 28], "craft": [16, 25, 26, 28, 44, 45, 61, 66, 68, 69, 71, 86, 92], "cramp": 40, "crap": 20, "crash": [1, 23, 42], "crate": [32, 75], "crazi": [17, 39, 79], "creat": [6, 9, 10, 13, 15, 16, 17, 18, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 31, 32, 33, 34, 35, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 50, 51, 52, 53, 54, 55, 58, 61, 62, 64, 65, 66, 67, 68, 69, 70, 71, 72, 74, 75, 76, 77, 78, 80, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97], "create_lag_df": [33, 76], "create_lag_featur": [52, 76, 90, 96], "create_y_from_r": [30, 49, 73], "createprocess": [16, 25, 26, 28], "creativ": [1, 13, 14, 20, 31, 50, 51, 58, 74], "creatur": 58, "credenc": [35, 55, 78], "credenti": 6, "credit": [0, 14, 23, 31, 33, 34, 35, 42, 44, 50, 51, 53, 55, 58, 59, 66, 68, 74, 76, 77, 78], "creditcard": [23, 42, 66, 80], "creepi": 20, "crime": [21, 58, 64], "crimin": [26, 45, 69], "crispedricewaf": 95, "criteria": [14, 29, 59, 72], "criterion": [29, 35, 37, 44, 48, 55, 68, 72, 78, 94], "critic": [12, 35, 54, 55, 78], "cross": [14, 19, 22, 24, 25, 26, 28, 30, 34, 35, 39, 41, 43, 44, 49, 55, 59, 61, 63, 65, 67, 68, 69, 71, 73, 77, 78, 79, 80, 84, 87, 88, 90, 93, 94, 96, 98], "cross_val": [25, 44, 68], "cross_val_predict": [23, 25, 34, 42, 44, 53, 66, 68, 77], "cross_val_scor": [15, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 33, 34, 35, 39, 40, 41, 42, 43, 44, 45, 46, 52, 53, 54, 55, 62, 63, 64, 65, 66, 67, 68, 69, 70, 76, 77, 78, 80, 81, 83, 84, 87, 88, 90, 93, 94, 96], "cross_valid": [16, 17, 18, 19, 20, 21, 22, 23, 25, 26, 27, 30, 33, 34, 35, 37, 38, 39, 40, 41, 42, 44, 45, 46, 49, 52, 53, 54, 55, 56, 57, 61, 62, 63, 64, 65, 66, 68, 69, 70, 73, 76, 77, 78, 79, 80, 81, 83, 84, 86, 87, 88, 90, 92, 93, 94, 96], "cross_validate_std": 60, "crowd": [5, 25, 29, 68, 72], "crown": 98, "crown_princ": [31, 50, 51, 74], "crucial": [13, 21, 26, 28, 29, 30, 31, 45, 50, 51, 58, 60, 64, 69, 71, 72, 73, 74], "crude": [51, 82], "cs189": 10, "cs189_ch7": 10, "cs324": [31, 50, 74], "csc": 34, "csr": [18, 34], "css": [56, 57, 79], "csv": [13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 30, 31, 32, 33, 34, 35, 37, 39, 40, 41, 42, 43, 44, 45, 46, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 73, 74, 75, 76, 77, 78, 79, 80, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96], "ct": [19, 63, 89, 95], "ctrl": 11, "cuda": [32, 38, 47, 48, 75], "cui": [1, 98], "cuisin": 79, "cultiv": 12, "cultur": [32, 75, 98], "cup": 25, "curios": [13, 58], "curiou": [13, 17, 58, 86, 92], "curl": [56, 57, 79], "current": [1, 5, 25, 31, 32, 33, 34, 35, 44, 50, 51, 52, 55, 68, 74, 75, 76, 77, 78, 79, 82], "curriculum": 12, "curs": [35, 55, 78], "curt": 58, "curv": [8, 9, 12, 21, 28, 55, 71, 78, 84, 86, 92], "cush": 20, "custodi": 58, "custom": [9, 13, 14, 17, 19, 23, 24, 27, 30, 31, 39, 42, 43, 56, 57, 58, 59, 63, 66, 67, 73, 74, 79, 84, 85, 91], "custom_plot_tre": [14, 25, 26, 44, 45, 59, 60, 68, 69, 85, 91], "customerid": [27, 34, 53, 77], "cut": [20, 29, 58, 72], "cv": [15, 19, 24, 25, 26, 27, 33, 34, 35, 38, 41, 43, 44, 45, 46, 52, 55, 60, 63, 67, 68, 69, 70, 76, 77, 78, 79, 80, 81, 84, 86, 92, 93, 94, 96], "cv_results_": [22, 24, 41, 43, 65, 67], "cv_score": [15, 24, 38, 43, 60, 67], "cv_train_scor": [15, 37, 86, 92], "cv_valid_scor": [15, 37, 86, 92], "cyberpunk": 20, "cycl": 9, "cyclic": [33, 76], "cycling_data": 9, "cygnu": [32, 75], "cynic": 40, "c\u00e9zann": 25, "d": [4, 9, 13, 14, 15, 16, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 32, 33, 34, 41, 42, 43, 44, 49, 51, 52, 53, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 71, 72, 73, 75, 76, 77, 79, 82, 88, 94], "d3": [28, 71], "da": 58, "dabeaz": 10, "dad": [27, 81], "dahl": 20, "dai": [1, 4, 9, 17, 27, 32, 34, 35, 39, 46, 52, 55, 58, 70, 75, 77, 78, 84, 86, 90, 92, 96, 98], "daili": [34, 77, 84], "dair": [31, 50, 74], "dall": [33, 76], "dam": 58, "damag": [0, 66], "dan": [31, 50, 51, 74], "dana": 58, "danceabl": [18, 22, 41, 61, 62, 65], "dare": 58, "dark": 58, "darker": [22, 41, 65], "dartmoor": 96, "darwin": 96, "dashboard": [16, 38, 61, 86, 92], "data": [1, 2, 5, 6, 8, 9, 10, 12, 20, 23, 27, 29, 31, 32, 34, 38, 40, 41, 42, 46, 47, 48, 49, 50, 51, 56, 57, 66, 72, 74, 75, 77, 81, 82, 83, 84, 85, 87, 88, 89, 91, 93, 94, 95, 97, 98], "data_dict": [21, 64], "data_dir": [13, 14, 15, 16, 17, 18, 19, 21, 22, 23, 24, 25, 26, 27, 30, 31, 32, 33, 34, 35, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 73, 74, 75, 76, 77, 78, 79, 80, 81, 84, 85, 86, 88, 90, 91, 92, 94, 96], "data_to_wrap": [19, 34, 63], "data_transform": [38, 47, 48], "data_url": [23, 42, 66, 80], "datacamp": 10, "datafram": [13, 14, 15, 16, 17, 18, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 48, 49, 50, 51, 52, 53, 54, 55, 58, 59, 60, 61, 62, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 80, 81, 84, 86, 87, 88, 89, 90, 92, 93, 94, 95, 96], "dataload": [32, 38, 47, 48, 75], "datapoint": [21, 64], "dataquest": 10, "dataset": [9, 12, 13, 15, 16, 19, 25, 26, 27, 28, 29, 31, 34, 37, 38, 39, 41, 44, 45, 46, 47, 48, 50, 53, 56, 57, 58, 60, 61, 68, 69, 70, 71, 72, 74, 77, 79, 80, 83, 84, 86, 92], "dataset2": [28, 71], "dataset_s": [32, 38, 47, 48, 75], "dataviz": [35, 54, 55, 78], "date": [8, 11, 13, 15, 30, 31, 34, 37, 50, 51, 58, 59, 73, 74, 77, 79, 82, 84, 90, 96, 98], "date_rang": [33, 76], "dates_rain": [52, 76, 90, 96], "datetim": [33, 53, 77], "datetime64": [33, 52, 76, 96], "datetimeindex": [33, 76], "datum": 51, "dau": 58, "daughter": [20, 56, 57, 79, 80], "daum\u00e9": 1, "daunt": [30, 73], "dave": [31, 51, 74], "david": [1, 31, 35, 50, 51, 55, 58, 74, 78, 89, 95], "dawn": 20, "day_nam": [33, 52, 76, 90, 96], "daylight": [52, 76, 90, 96], "dayofweek": [33, 76], "days_sinc": [33, 52, 76, 96], "dbscan": [12, 79], "dbscan_label": 48, "dc": [34, 52, 76, 77, 96], "dcc": [21, 64], "dd": [52, 76, 90, 96], "de": [31, 33, 50, 51, 74, 76], "deactiv": 11, "dead": 20, "deadlin": [8, 98], "deal": [0, 15, 16, 17, 18, 23, 24, 34, 39, 50, 51, 53, 55, 58, 60, 61, 62, 67, 74, 77, 78, 84, 87, 93], "dealer": 58, "dear": 58, "death": 98, "debat": [9, 13, 26, 45, 69], "debug": [4, 26, 45, 69, 98], "dec": 1, "decad": [32, 58, 75], "decemb": [1, 15, 33, 37, 52, 76, 96], "decid": [9, 13, 14, 16, 21, 25, 26, 27, 28, 29, 31, 33, 34, 44, 45, 46, 50, 51, 58, 59, 61, 64, 68, 69, 70, 71, 72, 74, 76, 77, 82, 84], "decim": 94, "decis": [1, 2, 7, 13, 18, 20, 22, 25, 27, 31, 32, 35, 39, 40, 42, 44, 50, 58, 60, 62, 65, 66, 68, 70, 74, 75, 80, 81, 83, 84, 85, 87, 88, 91, 93, 94], "decision_boundari": 83, "decision_funct": [23, 42, 66], "decision_function_shap": [41, 42, 63, 65], "decisiontreeclassifi": [15, 16, 18, 19, 21, 22, 26, 38, 39, 41, 45, 60, 61, 62, 63, 64, 65, 69, 85, 86, 87, 88, 91, 92, 93, 94], "decisiontreeclassifierdecisiontreeclassifi": 25, "decisiontreeregressor": [14, 15, 24, 37, 43, 59, 67, 85, 86, 91, 92], "decisiontreeregressorifit": 37, "decisiontreeregressorifitteddecisiontreeregressor": 15, "deck": 10, "decod": [31, 50, 74], "decode_error": [40, 41, 63, 65], "decomposit": [29, 30, 31, 34, 49, 50, 51, 72, 73, 74], "decor": 18, "decreas": [15, 21, 22, 25, 26, 28, 37, 44, 45, 60, 64, 65, 68, 69, 71, 86, 92], "deduct": 8, "dee_learning_cod": [32, 75], "deem": 7, "deep": [2, 10, 13, 22, 26, 27, 31, 34, 45, 46, 50, 51, 53, 58, 65, 69, 70, 74, 77, 79], "deep_learning_cod": [32, 75], "deepen": [31, 50, 74, 84, 98], "deeper": [2, 13, 22, 23, 24, 26, 41, 42, 43, 45, 65, 66, 67, 69], "deepexplain": [26, 45, 69], "deepmind": [31, 74], "def": [16, 18, 20, 22, 23, 24, 26, 28, 29, 30, 31, 33, 34, 38, 40, 41, 42, 43, 45, 47, 48, 49, 50, 51, 52, 56, 57, 60, 61, 62, 65, 66, 67, 69, 71, 72, 73, 74, 76, 79, 85, 86, 90, 91, 92, 96], "default": [6, 8, 11, 13, 14, 15, 19, 21, 22, 23, 24, 25, 28, 29, 31, 33, 34, 35, 38, 42, 43, 44, 50, 53, 55, 59, 60, 63, 64, 65, 66, 67, 68, 71, 72, 74, 76, 77, 78, 83, 90, 94, 96, 98], "default_threshold": [23, 42, 66], "defaultdict": [30, 49, 73], "defend": 58, "defin": [13, 16, 17, 18, 19, 25, 26, 28, 29, 30, 31, 32, 39, 40, 44, 45, 46, 47, 49, 50, 52, 56, 57, 58, 59, 60, 61, 62, 63, 66, 68, 69, 71, 72, 73, 74, 75, 76, 79, 90, 96], "definit": [9, 16, 26, 28, 45, 51, 52, 61, 69, 71, 76, 82, 83, 84, 85, 91], "degrad": 31, "degre": [23, 41, 42, 63, 65, 66], "degrees_freedom": [34, 77], "degrees_of_freedom": [34, 77], "del": [25, 44, 68], "delai": 70, "delayed_func": 34, "deleg": [51, 82], "delet": [4, 8, 18, 35, 55, 62, 78], "delgado": [25, 44, 68], "delight": [31, 50, 51, 74], "deliver": 8, "deliveri": 58, "delud": 58, "delv": [12, 31, 50, 51, 74], "demco": 1, "demo": [1, 5, 13, 25, 35, 44, 68, 78], "demograph": [14, 30, 49, 59, 73], "demonstr": [14, 17, 18, 20, 21, 22, 24, 25, 28, 30, 31, 38, 39, 40, 43, 44, 49, 50, 51, 58, 59, 60, 62, 64, 65, 67, 68, 70, 71, 73, 74, 80], "dendrogram": 48, "denholm": 20, "denomin": [24, 43, 67], "denot": [14, 30, 59, 73], "dens": [17, 29, 31, 50, 51, 72, 74], "densenet": [32, 38, 47, 48, 75], "densenet121": [32, 38, 47, 48, 75], "densenet121_weight": [32, 38, 47, 48, 75], "densiti": [26, 29, 45, 69, 72, 84], "dep": [51, 82], "depart": [5, 58], "departur": 70, "depend": [2, 6, 9, 14, 16, 19, 22, 24, 25, 26, 27, 28, 29, 31, 32, 33, 34, 35, 43, 44, 45, 46, 50, 51, 53, 55, 59, 60, 61, 63, 65, 67, 68, 69, 71, 72, 74, 75, 76, 77, 78, 80, 81, 82, 88, 94], "dependence_plot": [26, 45, 69], "dependents_no": [34, 53, 77], "dependents_y": [34, 53, 77], "deploi": [15, 23, 30, 35, 37, 42, 49, 55, 60, 66, 73, 78, 84], "deploy": [1, 12, 26, 33, 45, 52, 69, 76], "deprec": [23, 24, 39, 40, 41, 42, 43, 44, 45, 50, 53, 62, 63, 65, 67, 68, 69, 74, 75, 77, 80, 83, 94], "deprecationwarn": [25, 44, 53, 68, 77], "depress": 58, "depth": [1, 14, 15, 22, 25, 29, 37, 44, 58, 59, 60, 65, 68, 72, 85, 86, 91, 92], "dequ": [25, 26, 44, 45, 68, 69, 88, 94], "deriv": [0, 14, 21, 30, 34, 59, 64, 66, 73, 77, 84], "descend": [9, 20, 29, 40, 72, 84], "descent": [33, 76], "descr": [21, 64], "describ": [9, 12, 13, 14, 15, 16, 17, 18, 21, 23, 24, 30, 31, 32, 37, 39, 42, 43, 49, 50, 51, 52, 58, 59, 60, 61, 62, 64, 66, 67, 73, 74, 75, 76, 79, 86, 87, 89, 90, 92, 95, 96], "descript": [1, 24, 28, 34, 43, 53, 67, 77, 86, 92], "desenet": 38, "deserv": 7, "design": [12, 14, 26, 29, 31, 35, 45, 50, 54, 55, 58, 59, 69, 72, 74, 78, 98], "desir": [17, 23, 34, 39, 42, 51, 66, 77, 87, 93], "desk": 98, "despit": [27, 31, 46, 50, 51, 58, 70, 74], "destroi": [20, 45], "det": [20, 31, 50, 51, 74, 82], "detach": [38, 47, 48], "detail": [5, 7, 16, 19, 23, 25, 31, 32, 37, 44, 50, 51, 56, 57, 58, 61, 63, 68, 74, 75, 79, 98], "detect": [13, 14, 20, 23, 24, 28, 29, 31, 33, 37, 42, 52, 58, 59, 66, 67, 71, 72, 74, 76, 79, 80], "detector": [32, 75], "determin": [14, 16, 28, 29, 31, 34, 35, 38, 50, 51, 55, 61, 71, 72, 74, 77, 78, 86, 88, 89, 92, 94, 95, 98], "determinist": [13, 58], "detriment": [30, 66, 73], "dev": [60, 83], "develop": [1, 5, 6, 10, 12, 13, 15, 18, 19, 20, 22, 23, 24, 25, 26, 31, 32, 42, 43, 44, 50, 51, 55, 56, 57, 58, 60, 62, 63, 65, 66, 67, 68, 74, 75, 78, 79, 84], "devianc": [34, 77], "deviat": [7, 15, 18, 25, 26, 40, 44, 45, 60, 62, 68, 69], "devic": [25, 31, 32, 34, 38, 44, 47, 48, 50, 68, 74, 75], "deviceprotect": [34, 53, 77], "deviceprotection_no": [34, 53, 77], "deviceprotection_y": [34, 53, 77], "df": [13, 17, 18, 19, 22, 23, 24, 26, 27, 32, 33, 34, 35, 37, 39, 42, 43, 45, 46, 52, 53, 54, 55, 56, 57, 58, 59, 60, 62, 63, 65, 66, 67, 69, 70, 75, 76, 77, 78, 79, 80, 85, 90, 91, 94, 96], "df_binari": [89, 95], "df_concat": [13, 58], "df_float_1": 9, "df_float_2": 9, "df_hour_week_ohe_poli": [33, 76], "df_locat": 52, "df_sim": [31, 50, 74], "df_transform": 39, "di": [34, 53, 58, 77], "diagnos": [26, 45, 60, 69, 84], "diagnosi": 66, "diagnost": [34, 53, 77, 79], "diagon": [16, 23, 26, 42, 45, 61, 66, 69], "diagram": [19, 22, 25, 26, 41, 44, 63, 65, 68, 69], "dialogu": [20, 40, 51, 58], "dict": [30, 49, 66, 73, 94], "dict_kei": [25, 44, 68], "dictat": 58, "dictatorship": 58, "dictionari": [9, 18, 22, 23, 25, 26, 41, 42, 44, 45, 56, 57, 62, 65, 66, 68, 69, 79], "did": [7, 13, 14, 16, 17, 20, 23, 26, 28, 31, 33, 42, 45, 50, 51, 52, 58, 59, 61, 69, 71, 74, 76, 82, 86, 88, 92, 94], "didn": [17, 22, 25, 26, 29, 34, 38, 39, 41, 44, 45, 51, 52, 53, 65, 68, 69, 72, 76, 77, 82], "diet": [14, 31, 50, 51, 59, 74], "diff": [52, 76, 90, 96], "differ": [1, 2, 6, 8, 9, 12, 13, 14, 15, 16, 17, 19, 20, 21, 25, 27, 28, 29, 30, 31, 32, 33, 34, 35, 37, 39, 44, 46, 47, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 63, 64, 66, 68, 70, 71, 72, 73, 74, 75, 76, 77, 78, 80, 82, 83, 85, 86, 88, 89, 90, 91, 92, 94, 95, 96], "differenti": [12, 13, 14, 31, 58, 74], "difficult": [7, 8, 26, 27, 28, 35, 54, 55, 58, 66, 70, 71, 78], "difficulti": [26, 28, 71, 84], "diffid": 58, "dig": [23, 24, 42, 43, 66, 67], "dighton": 58, "digit": [33, 35, 55, 76, 78], "dilemma": [30, 49, 73], "dilut": 58, "dim": [18, 38], "dime": 95, "dimens": [9, 21, 27, 46, 64, 70], "dimension": [2, 9, 14, 21, 22, 23, 25, 27, 28, 31, 38, 41, 42, 44, 46, 50, 51, 58, 64, 65, 66, 68, 70, 71, 74], "dine": 79, "direct": [18, 20, 21, 26, 27, 29, 40, 45, 51, 58, 64, 69, 72, 76, 81], "direct_bilirubin": 58, "directli": [1, 9, 17, 19, 24, 32, 34, 39, 43, 56, 57, 63, 67, 75, 77, 79, 98], "director": [30, 49, 58, 73], "directori": [18, 38, 58, 59, 60, 62], "dirichlet": [31, 32, 50, 51, 74, 75], "dirti": [17, 58], "disabl": [31, 50, 51, 74], "disadvantag": [22, 25, 29, 30, 44, 49, 65, 68, 72, 73, 87, 93], "disagre": 30, "disappoint": [20, 58], "disast": 58, "discard": [27, 31, 46, 50, 51, 70, 74], "disciplin": [27, 46, 66, 70], "disclos": 98, "discomfort": [20, 40], "discourag": 9, "discours": [30, 73], "discov": [27, 28, 46, 58, 70, 71, 81], "discoveri": [13, 58], "discret": [14, 17, 27, 39, 46, 59, 70], "discrete_scatt": [14, 16, 21, 28, 29, 32, 38, 59, 60, 61, 64, 71, 72, 75, 83, 85, 86, 91, 92], "discretization_feat": [27, 46, 70], "discrimin": [44, 68], "discuss": [4, 16, 18, 21, 23, 26, 27, 28, 29, 33, 37, 42, 45, 49, 50, 52, 60, 61, 62, 64, 69, 70, 71, 72, 76, 84, 86, 87, 88, 89, 90, 92, 93, 94, 95, 96, 98], "diseas": [14, 23, 34, 42, 59, 66, 77], "dishonesti": 98, "disk": 31, "dislik": [17, 35, 39, 55, 78], "dismiss": 58, "disp": [53, 77], "disparti": [31, 50, 74], "displac": 40, "displaci": [51, 82], "displai": [8, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 25, 26, 29, 30, 31, 32, 33, 34, 37, 38, 39, 40, 41, 42, 44, 45, 49, 50, 52, 58, 59, 60, 61, 62, 63, 64, 65, 66, 68, 69, 72, 73, 74, 75, 76, 80, 81, 85, 86, 87, 89, 90, 91, 92, 93, 95, 96], "display_heatmap": [22, 41, 65], "display_label": [23, 42, 66], "displaystyl": [31, 50, 51, 74], "disput": 51, "disrespect": 4, "dissemin": 79, "dist": [16, 28, 29, 38, 48, 61, 71, 72], "dist_nam": [41, 65], "distanc": [9, 18, 29, 30, 31, 38, 39, 47, 48, 49, 50, 51, 62, 70, 72, 73, 74], "distilbert": [31, 50, 74], "distinct": [23, 27, 33, 35, 42, 47, 48, 55, 66, 76, 78, 81, 95], "distinguish": [14, 16, 19, 23, 31, 38, 42, 59, 60, 61, 63, 66, 74, 86, 92], "distort": 39, "distract": 98, "distribut": [0, 11, 15, 17, 23, 26, 27, 29, 32, 37, 39, 42, 45, 46, 51, 52, 60, 66, 69, 70, 72, 75, 76, 90, 96, 98], "district": [18, 21, 62, 64], "districtdatalab": [28, 71], "dists_df": 48, "disturb": 58, "dive": [13, 26, 45, 58, 69], "divers": [5, 12, 25, 28, 30, 33, 44, 49, 68, 71, 73, 76], "divid": [21, 25, 26, 33, 44, 45, 64, 68, 69, 76, 80, 86, 92], "divis": [14, 26, 45, 69], "divorc": [25, 26, 44, 45, 68, 69], "dkhundlei": [89, 95], "dktal": [34, 53, 77], "dlwqn": [34, 53, 77], "dmp": [1, 98], "do": [0, 4, 6, 8, 9, 11, 13, 14, 15, 16, 19, 20, 21, 24, 28, 29, 30, 31, 32, 33, 34, 37, 38, 41, 43, 47, 49, 50, 51, 52, 53, 56, 57, 58, 59, 60, 61, 64, 67, 71, 72, 73, 74, 75, 76, 77, 79, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 98], "dobj": [51, 82], "doc": [9, 10, 16, 20, 22, 31, 40, 50, 51, 56, 57, 74, 79, 82], "doc_id": [31, 50, 51, 74], "docker": [56, 57, 79], "doctor": [25, 26, 44, 45, 66, 68, 69, 98], "document": [0, 1, 8, 13, 15, 17, 18, 19, 20, 22, 23, 24, 25, 26, 27, 31, 32, 33, 34, 35, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 50, 51, 53, 54, 55, 59, 60, 62, 63, 65, 66, 67, 68, 69, 70, 74, 75, 76, 77, 78, 82, 84, 88, 94, 98], "document_top": [31, 50, 51, 74], "documentari": [30, 49, 73], "doe": [6, 9, 13, 16, 17, 18, 20, 22, 24, 25, 26, 27, 28, 30, 31, 33, 34, 39, 41, 43, 45, 46, 49, 51, 52, 53, 56, 57, 58, 60, 61, 62, 65, 67, 68, 69, 70, 71, 73, 76, 77, 79, 81, 82, 84, 86, 88, 90, 92, 94, 96, 98], "doesn": [8, 9, 15, 18, 19, 23, 24, 25, 26, 28, 29, 30, 32, 34, 35, 42, 43, 44, 45, 47, 49, 51, 53, 55, 58, 60, 62, 63, 66, 67, 68, 69, 71, 72, 73, 75, 77, 78, 82, 84], "dog": [32, 38, 66, 75], "dolist": 79, "dollar": [4, 21, 24, 35, 43, 54, 55, 64, 67, 78], "domain": [0, 26, 28, 31, 45, 46, 51, 69, 71, 74], "domin": [18, 20, 24, 32, 43, 62, 67, 75], "domingo": [1, 27, 60, 70], "dominican_republ": [31, 50, 51, 74], "domino": 58, "don": [4, 5, 11, 13, 15, 17, 19, 20, 22, 25, 26, 27, 29, 30, 31, 32, 33, 34, 35, 37, 38, 39, 41, 44, 45, 46, 49, 50, 51, 53, 55, 56, 57, 58, 60, 63, 65, 66, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 98], "done": [13, 15, 19, 20, 22, 32, 35, 41, 52, 54, 55, 58, 60, 63, 65, 66, 75, 76, 78, 87, 93], "dont": [31, 50, 74], "doom": [20, 58], "door": [32, 58, 75], "dosa": 51, "dot": [16, 21, 23, 26, 27, 29, 31, 42, 44, 45, 46, 51, 61, 64, 66, 68, 69, 70, 72, 74], "dot_product": 51, "dot_product_similar": [31, 74], "doubl": [20, 22, 65], "down": [15, 17, 23, 26, 34, 35, 39, 42, 45, 51, 53, 55, 58, 60, 66, 69, 77, 78, 82, 86, 88, 92, 94, 98], "downfal": [30, 49, 73], "download": [6, 8, 11, 13, 15, 18, 21, 23, 24, 26, 31, 32, 35, 37, 42, 43, 45, 50, 51, 54, 55, 58, 59, 62, 64, 66, 67, 69, 74, 75, 78, 82, 86, 88, 89, 92, 94, 95], "downright": [35, 54, 55, 78], "downturn": 58, "dpi": [27, 38, 46, 70, 97], "dr": [5, 51, 82], "draft": 1, "drag": [8, 58], "drama": [30, 49, 58, 73], "dramat": 40, "drastic": 66, "draw": [21, 22, 35, 41, 51, 55, 64, 65, 78], "drawback": [12, 26, 30, 45, 69, 73], "drawn": [25, 44, 68], "dream": [32, 75], "dreampharmaceut": [31, 50, 51, 74], "drink": [35, 54, 55, 78], "drinker": [31, 51, 74], "drive": [13, 20, 26, 40, 45, 58, 69], "driven": [22, 23, 42, 65, 66], "driver": [13, 58], "droit": [31, 50, 51, 74], "drop": [8, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 33, 34, 35, 37, 39, 41, 42, 43, 44, 45, 52, 53, 54, 55, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 76, 77, 78, 80, 84, 86, 87, 88, 89, 90, 92, 93, 94, 95, 96, 98], "drop_dupl": [16, 22, 41, 61, 65], "drop_feat": [17, 19, 39, 63, 84], "drop_featur": [24, 25, 26, 34, 35, 43, 44, 45, 52, 53, 54, 55, 66, 67, 68, 69, 76, 77, 78, 90, 96], "dropdown": 11, "dropdrop": [17, 19, 24, 25, 35, 39, 43, 44, 54, 55, 63, 68, 78], "dropdropdecisiontreeclassifi": [44, 68], "dropdroplgbmclassifi": [44, 68], "dropdroplogisticregress": [44, 68], "dropdroppipelin": [45, 67, 69], "dropdroprandomforestclassifi": [44, 68], "dropdropsvc": 63, "dropdropxgbclassifi": [44, 68], "drope": [18, 62], "dropna": [52, 56, 57, 76, 79, 80, 90, 96], "dropoff": [28, 71], "drought": 40, "drug": [13, 58, 79], "dsci": [1, 10, 26, 35, 55, 78, 83], "dsl": [34, 53, 77], "dt": [15, 37, 86, 92, 94], "dt_best": [86, 92], "dt_final": [15, 37], "dt_pipe": [22, 65], "dt_regr": [15, 37], "dt_score": 94, "dtype": [14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 29, 30, 31, 33, 34, 37, 39, 40, 41, 42, 43, 44, 45, 46, 50, 51, 52, 53, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 76, 77, 79, 80, 82, 88, 91, 92, 94, 96], "dtypelik": 34, "dual": [40, 42, 44, 66, 68, 75, 94], "duck": [32, 35, 54, 55, 75, 78], "duckbil": [32, 75], "dud": 58, "due": [8, 11, 13, 20, 25, 27, 30, 31, 44, 49, 50, 68, 73, 74, 81, 92, 98], "duffel": 20, "dull": [20, 58], "dumb": 58, "dummi": [14, 15, 16, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 32, 33, 34, 35, 37, 40, 41, 42, 43, 44, 45, 46, 52, 53, 54, 55, 59, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 76, 77, 78, 80, 81, 85, 87, 88, 90, 91, 92, 93, 94, 96], "dummy_clf": [14, 59, 85, 91], "dummy_regr": [15, 37, 92], "dummy_scor": [16, 61], "dummy_valid_accuraci": [16, 61], "dummyclassifi": [15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 26, 27, 32, 33, 35, 38, 39, 40, 41, 42, 45, 46, 53, 54, 55, 60, 61, 62, 63, 64, 65, 66, 67, 69, 70, 78, 79, 80, 81, 85, 86, 87, 88, 90, 91, 92, 93, 94, 96], "dummyregressor": [15, 19, 25, 26, 27, 35, 37, 44, 45, 46, 54, 55, 63, 68, 69, 70, 78, 79, 87, 88, 92, 93, 94], "dump": [56, 57, 79], "dun": 58, "dung": 58, "dunham": 20, "dunno": 58, "duplex": [24, 43, 67], "duplic": [9, 31], "durat": [33, 34, 53, 70, 76, 77], "duration_col": [34, 53, 77], "duration_m": [18, 22, 41, 61, 62, 65], "dure": [1, 5, 7, 9, 13, 14, 15, 16, 19, 21, 22, 25, 26, 30, 37, 44, 45, 49, 51, 58, 59, 61, 63, 64, 65, 68, 69, 70, 73, 79, 82, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 98], "durn": 58, "duti": 98, "dwell": [24, 43, 67], "dynam": [50, 74], "d\u00e3": 20, "e": [5, 7, 8, 9, 11, 12, 13, 14, 15, 16, 18, 19, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 37, 41, 42, 43, 44, 45, 46, 49, 50, 51, 52, 53, 54, 55, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 82, 83, 84, 90, 93, 96, 98], "e737c5242822": [34, 53, 77], "e_": [15, 60], "each": [7, 8, 9, 13, 14, 15, 16, 17, 18, 19, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 37, 38, 39, 41, 42, 43, 44, 45, 46, 47, 49, 50, 51, 52, 53, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 82, 83, 84, 85, 86, 88, 89, 90, 91, 92, 94, 95, 96, 98], "eager": [31, 50, 74, 79], "earl": 58, "earli": [5, 26, 31, 34, 35, 50, 53, 55, 69, 74, 77, 78], "earlier": [17, 18, 25, 27, 31, 33, 34, 44, 46, 50, 52, 53, 58, 62, 68, 70, 74, 76, 77], "early_stopping_round": [25, 44, 68], "earnest": [58, 98], "easi": [8, 16, 18, 21, 25, 26, 28, 29, 31, 35, 44, 45, 46, 50, 51, 55, 61, 62, 64, 68, 69, 70, 71, 72, 74, 78], "easier": [8, 23, 26, 27, 30, 35, 42, 45, 46, 47, 49, 55, 66, 69, 70, 73, 78, 80], "easiest": [26, 34, 45, 53, 69, 77], "easili": [13, 20, 25, 27, 35, 44, 52, 55, 56, 57, 58, 68, 70, 76, 78, 79, 85, 90, 91, 96], "east": [17, 39, 58], "eat": 58, "eat_out_freq": [17, 39], "eccentr": 58, "echidna": [32, 75], "econom": [19, 33, 63, 76], "ecosystem": [32, 75], "eda": [17, 31, 34, 37, 39, 50, 51, 60, 74, 77, 84, 90, 96], "edamam": [32, 75], "edg": [14, 22, 58, 59, 65], "edgecolor": [22, 41, 52, 65, 76, 90, 96], "edi": 40, "edinburgh": 58, "edit": [5, 16, 31, 50, 51, 65, 74], "edmund": 58, "edu": 10, "educ": [25, 26, 30, 31, 44, 45, 49, 50, 66, 68, 69, 73, 74], "education_level": [25, 26, 44, 45, 66, 68, 69], "edvard": 25, "edward": 58, "eeri": 58, "effect": [15, 16, 20, 21, 22, 24, 26, 27, 28, 29, 30, 31, 32, 33, 37, 38, 45, 46, 50, 51, 61, 64, 65, 66, 67, 69, 70, 71, 72, 73, 74, 75, 76, 79, 80, 84, 86, 92, 98], "effici": [22, 31, 41, 65], "effort": [4, 22, 27, 28, 30, 32, 46, 65, 70, 71, 73, 75, 98], "egg": [28, 71], "ei": 58, "either": [4, 14, 16, 19, 23, 26, 28, 29, 31, 32, 33, 38, 42, 45, 51, 58, 59, 60, 61, 63, 66, 69, 71, 72, 75, 76, 86, 92], "elast": [34, 53, 77], "elbow": [29, 72, 89, 95], "elect": [31, 50, 51, 74], "electr": [24, 26, 35, 43, 45, 54, 55, 67, 69, 78], "electrical_engin": [31, 50, 51, 74], "electrical_fusea": [24, 35, 67, 69], "electrical_fusef": [24, 35, 67, 69], "electrical_fusep": [24, 35, 67, 69], "electrical_miss": [24, 35, 67, 69, 78], "electrical_mix": [24, 35, 67, 69, 78], "electrical_sbrkr": [24, 35, 67, 69, 78], "electron": [34, 53, 77, 98], "eleg": [18, 31, 35, 50, 51, 55, 62, 74, 78], "elegantli": [50, 51, 74], "element": [0, 1, 10, 17, 19, 20, 31, 39, 40, 50, 51, 60, 63, 74, 82, 85, 91], "eleph": 58, "eli5": [45, 69], "elif": [14, 34, 52, 59, 76, 77, 96], "elimin": 12, "elizabeth": 58, "elliott": 20, "els": [14, 18, 19, 23, 32, 34, 38, 42, 47, 48, 52, 59, 63, 66, 75, 76, 77, 84, 90, 96], "elw": 20, "email": [1, 13, 15, 23, 42, 58, 60, 66, 98], "emb": [8, 16, 23, 28, 29, 42, 61, 66, 71, 72], "embed": [1, 12, 19, 32, 63, 75, 79, 84], "emma": 20, "emoji": 40, "emot": [13, 20, 31, 50, 58, 74], "emoticon": [27, 28, 46, 70, 71], "emp": [26, 44, 69], "empathi": [31, 50, 51, 74], "emphas": [5, 12], "emphasi": [79, 98], "emploi": [33, 34, 38, 76, 77, 79, 84], "employ": [30, 49, 73], "employe": [14, 59], "empti": [21, 38, 51, 52, 64, 76, 90, 96], "en": [31, 34, 35, 52, 53, 55, 76, 77, 78, 96], "en_core_web_lr": 51, "en_core_web_md": [31, 50, 51, 74, 82], "enabl": [30, 31, 33, 38, 50, 51, 73, 74, 76], "enable_categor": [25, 44, 68], "enable_halving_search_cv": [22, 41, 65], "enc": [18, 19, 33, 62, 63, 76], "encapsul": 39, "enclosedporch": [24, 26, 35, 43, 45, 54, 55, 67, 69, 78], "encod": [13, 15, 17, 20, 22, 23, 24, 26, 30, 31, 34, 37, 39, 40, 41, 42, 43, 45, 49, 50, 58, 60, 65, 66, 67, 69, 73, 74, 77, 80, 84, 87, 90, 93, 96], "encoded_missing_valu": [39, 44, 45, 63, 67, 68, 69], "encoder_attention_mask": [50, 74], "encompass": [34, 53, 55, 77, 78, 84], "encount": [19, 63], "end": [4, 9, 12, 13, 15, 16, 20, 21, 22, 23, 27, 28, 29, 30, 31, 33, 34, 35, 42, 46, 50, 51, 53, 55, 58, 59, 60, 61, 62, 63, 64, 65, 66, 70, 71, 72, 73, 74, 76, 77, 78, 79, 86, 92, 93, 95], "endors": 0, "endpoint": [34, 77], "enemi": 58, "energi": [18, 22, 33, 41, 61, 62, 65, 76, 86, 92], "energy_df": [86, 92], "enforc": 40, "engag": [58, 98], "engin": [1, 10, 12, 19, 23, 24, 28, 30, 31, 34, 42, 43, 49, 50, 51, 63, 66, 67, 71, 73, 74, 77, 79, 90, 96], "england": 58, "english": [17, 18, 20, 22, 31, 32, 39, 40, 41, 50, 51, 56, 57, 58, 62, 65, 74, 75, 79, 80, 82], "enhanc": 98, "enjoi": [1, 20, 21, 40, 64], "enjoy_class": [19, 63], "enjoy_cours": [19, 63, 84], "enjoy_course_enc": [19, 63], "enjoy_the_mo": [56, 57, 79, 80], "enough": [8, 16, 23, 24, 25, 26, 28, 30, 42, 43, 44, 49, 61, 63, 66, 67, 68, 71, 73, 80, 84, 86, 90, 92, 96, 98], "enrich": 58, "enrol": 5, "ensambl": 32, "ensembl": [1, 12, 18, 24, 26, 27, 30, 33, 34, 35, 43, 45, 46, 49, 52, 53, 54, 55, 56, 57, 67, 69, 70, 72, 73, 76, 77, 78, 79, 88, 90, 94, 96], "ensiti": [29, 72], "ensur": [8, 12, 18, 25, 37, 44, 52, 62, 68, 76, 89, 90, 95, 96, 98], "ensure_2d": [18, 34], "ensure_all_finit": [18, 34], "ensure_min_featur": [18, 34], "ensure_min_sampl": [18, 34], "ensure_non_neg": [18, 34], "ent": [51, 82], "enter": [6, 11, 19, 34, 35, 53, 55, 63, 77, 78], "entertain": [31, 51, 74], "enthusiast": [13, 35, 55, 58, 78], "entir": [4, 9, 13, 15, 20, 24, 32, 33, 35, 40, 43, 52, 55, 56, 57, 58, 60, 67, 75, 76, 78, 79, 88, 94, 98], "entiti": [27, 30, 46, 51, 70, 73, 82], "entitl": [19, 63], "entlebuch": [32, 58, 75], "entri": [16, 17, 18, 19, 21, 23, 24, 27, 30, 34, 42, 43, 46, 49, 52, 53, 61, 62, 63, 64, 66, 67, 70, 73, 76, 77, 92, 94, 96], "entropi": [14, 35, 55, 59, 78], "enumer": [25, 44, 68, 89, 95], "env": [11, 14, 16, 18, 19, 25, 26, 28, 31, 32, 34, 45, 50, 53, 59, 60, 63, 69, 74, 77, 83], "environ": [3, 6, 9, 13, 15, 17, 18, 19, 20, 22, 23, 24, 25, 26, 27, 31, 32, 34, 35, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 50, 51, 53, 54, 55, 58, 62, 63, 65, 66, 67, 68, 69, 70, 74, 75, 77, 78, 80, 94, 98], "environment": [31, 50, 74, 84], "ep": [16, 21, 29, 48, 59, 60, 61, 64, 72, 85, 91], "epic": 58, "episod": [20, 40], "epoch": [33, 76], "epsilon": [29, 35, 55, 72, 78], "equal": [9, 16, 23, 24, 25, 26, 29, 30, 33, 42, 43, 44, 45, 49, 52, 61, 63, 66, 67, 68, 69, 72, 73, 76, 80, 84, 90, 96, 98], "equat": [4, 13, 21, 64], "equip": [16, 34, 61, 77, 98], "equival": [9, 17, 25, 44, 66, 68], "erik": [31, 50, 51, 74], "err": [50, 51, 74], "error": [4, 5, 7, 8, 9, 12, 14, 16, 17, 18, 19, 21, 25, 26, 27, 31, 34, 35, 39, 44, 45, 46, 50, 51, 53, 55, 56, 57, 59, 61, 63, 64, 68, 69, 70, 74, 77, 78, 79, 84, 86, 88, 92, 94], "error_": [15, 60], "error_scor": [41, 65], "erupt": 58, "erythrocebu": [32, 58, 75], "es": [52, 76, 96], "escap": [20, 59], "eskimo": 66, "esl": 1, "especi": [2, 14, 16, 20, 22, 25, 26, 27, 30, 33, 46, 49, 52, 58, 59, 61, 65, 66, 68, 70, 73, 76], "essai": [13, 58], "essenti": [5, 11, 34, 76, 77, 84, 98], "establish": [37, 89, 95], "estat": [14, 59], "estim": [16, 19, 21, 22, 27, 28, 34, 35, 41, 46, 54, 55, 60, 61, 63, 64, 65, 70, 71, 77, 78, 79, 84, 88, 94, 95], "estimator_nam": 18, "estimators_": [25, 44, 68], "et": [25, 31, 44, 50, 51, 68, 74], "etc": [1, 2, 8, 9, 14, 27, 32, 33, 34, 44, 46, 51, 52, 53, 55, 56, 57, 59, 70, 75, 76, 77, 78, 79, 82, 98], "ethic": [1, 12, 13, 31, 50, 58, 74, 79], "ethnic": 58, "euclidean": [28, 29, 31, 51, 71, 72, 74], "euclidean_dist": [16, 18, 28, 29, 31, 48, 51, 61, 62, 71, 72, 74], "ev": [32, 75], "eva": [30, 49, 73], "eva_model": [30, 49, 73], "eval": [47, 48], "eval_metr": [25, 26, 44, 45, 68, 69], "eval_on_featur": [33, 76], "evalu": [1, 9, 12, 15, 22, 26, 28, 33, 35, 37, 39, 41, 45, 55, 58, 59, 60, 65, 67, 69, 71, 76, 78, 79, 86, 88, 89, 92, 94, 95], "evapor": [52, 76, 90, 96], "even": [0, 8, 12, 13, 14, 15, 17, 20, 21, 28, 29, 30, 31, 33, 34, 35, 39, 41, 49, 50, 55, 58, 59, 60, 64, 65, 66, 70, 71, 72, 73, 74, 76, 77, 78, 80, 84, 86, 87, 92, 93, 96, 98], "event": [0, 24, 58, 67, 80, 98], "event_col": [34, 53, 77], "event_observ": [34, 53, 77], "ever": [14, 20, 58, 59, 83], "everi": [5, 9, 13, 14, 15, 20, 25, 29, 32, 33, 44, 58, 59, 60, 68, 72, 75, 76, 86, 92], "everydai": [9, 13, 31, 51, 58, 74], "everyon": [7, 26, 45, 53, 55, 69, 78, 84], "everyth": [13, 19, 23, 30, 31, 33, 42, 49, 50, 56, 57, 58, 63, 66, 73, 74, 76, 79, 88, 94], "everytown": 58, "everywher": [33, 76], "evil": 58, "evo": 79, "evocarshar": 79, "evok": [31, 50, 51, 74], "evolv": 40, "ex": [24, 26, 31, 35, 43, 45, 50, 54, 55, 67, 69, 74, 78], "ex1_idx": [26, 45, 69], "ex2_idx": [26, 45, 69], "ex_df": [20, 40], "exact": [4, 34, 77], "exactli": [8, 13, 14, 20, 26, 31, 32, 40, 45, 50, 58, 60, 69, 74, 75, 86, 92, 93], "exagger": [35, 54, 55, 78], "exam": [1, 7, 13, 22, 35, 55, 78, 79], "examin": [15, 16, 17, 18, 21, 25, 26, 27, 28, 29, 30, 31, 32, 33, 37, 38, 39, 44, 45, 46, 48, 49, 50, 51, 60, 61, 62, 64, 66, 68, 69, 70, 71, 72, 73, 74, 75, 76, 79, 80, 83, 90, 96], "exampl": [0, 4, 6, 7, 8, 9, 15, 17, 20, 24, 29, 30, 33, 38, 39, 40, 41, 43, 46, 49, 52, 53, 54, 67, 70, 72, 73, 76, 79, 80, 82, 83, 84, 85, 86, 90, 91, 92, 93, 96, 98], "example1": [14, 59], "example2": [14, 59], "excel": [19, 20, 21, 24, 26, 34, 40, 43, 45, 53, 58, 63, 64, 67, 69, 77, 84, 87, 93], "except": [0, 1, 5, 8, 9, 34, 52, 53, 58, 60, 76, 77, 90, 96, 98], "exception": 4, "exchang": [23, 42, 66], "excit": [13, 30, 31, 49, 50, 58, 73, 74], "execut": [4, 8, 16, 20, 25, 26, 28, 56, 57, 71, 79], "exercis": [1, 8, 10, 13, 51, 56, 57, 79, 80, 82, 86, 87, 88, 89, 90, 92, 93, 94, 95, 96], "exerciseangina": [88, 94], "exist": [9, 11, 27, 34, 46, 56, 57, 66, 70, 77, 79], "exmapl": [31, 74], "exp": [21, 34, 35, 55, 64, 77, 78], "expand": [1, 14, 59, 98], "expect": [1, 4, 5, 8, 9, 11, 13, 15, 16, 18, 19, 21, 22, 24, 26, 27, 28, 29, 30, 32, 34, 38, 39, 45, 51, 52, 53, 58, 60, 61, 62, 63, 64, 65, 66, 67, 69, 70, 71, 72, 73, 75, 76, 77, 83, 86, 90, 92, 96, 98], "expected_valu": [26, 45, 69], "expenditur": [33, 52, 76], "expens": [23, 24, 27, 28, 30, 42, 43, 46, 49, 58, 66, 67, 70, 71, 73, 95], "experi": [13, 22, 25, 30, 31, 41, 47, 50, 51, 58, 65, 73, 74, 92, 98], "experienc": 98, "experiment": [20, 22, 41, 65, 79], "expert": [14, 15, 22, 26, 27, 45, 46, 58, 59, 60, 65, 69, 70], "expertis": [13, 58], "explain": [4, 5, 8, 12, 13, 14, 15, 16, 18, 19, 21, 22, 24, 25, 27, 28, 29, 30, 31, 32, 33, 34, 43, 49, 50, 51, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 70, 71, 72, 73, 74, 75, 76, 77, 79, 82, 84, 88, 89, 94, 95, 98], "explan": [4, 16, 60, 61, 66, 84, 98], "explanatori": [14, 59], "explicit": [23, 34, 42, 66, 77, 80], "explicitli": [9, 13, 56, 57, 58, 79], "explod": [32, 75], "exploit": [7, 58], "explor": [15, 19, 20, 22, 23, 26, 27, 30, 31, 32, 37, 38, 40, 41, 42, 45, 46, 48, 50, 51, 56, 57, 58, 59, 60, 63, 65, 66, 69, 73, 74, 75, 79, 81, 86, 92, 95], "exploratori": [24, 34, 43, 67, 77, 79, 84], "expm1": [24, 35, 43, 54, 55, 67, 78], "expon": [22, 41, 65], "exponenti": [22, 41, 65], "export_graphviz": [14, 59, 85, 91], "expos": [20, 40], "exposur": [30, 73], "express": [0, 9, 19, 20, 21, 27, 31, 35, 46, 48, 50, 51, 55, 63, 64, 70, 74, 78, 82], "extend": [32, 51, 75, 82, 83, 98], "extend_block": [34, 77], "extens": [1, 11, 13, 16, 23, 26, 28, 29, 31, 33, 38, 42, 45, 50, 51, 52, 61, 66, 69, 71, 72, 74, 76, 80, 86, 92, 98], "extent": [28, 31, 50, 51, 71, 74], "extercond": [24, 26, 35, 43, 45, 54, 55, 67, 69, 78], "exterior": [26, 45, 58, 69], "exterior1st": [24, 26, 35, 43, 45, 54, 55, 67, 69, 78], "exterior1st_asbshng": [24, 67, 69], "exterior1st_asphshn": [24, 67, 69], "exterior1st_brkcomm": [24, 67, 69], "exterior1st_brkfac": [24, 67, 69], "exterior1st_cblock": [24, 67, 69], "exterior1st_cemntbd": [24, 67, 69], "exterior1st_hdboard": [24, 67, 69], "exterior1st_imstucc": [24, 45, 67, 69], "exterior1st_metalsd": [24, 67, 69], "exterior1st_plywood": [24, 67, 69], "exterior1st_ston": [24, 67, 69], "exterior1st_stucco": [24, 67, 69], "exterior1st_vinylsd": [24, 67, 69], "exterior1st_wd": [24, 67, 69], "exterior1st_wdsh": [24, 67, 69], "exterior2nd": [24, 26, 35, 43, 45, 54, 55, 67, 69, 78], "exterior2nd_asbshng": [24, 67, 69], "exterior2nd_asphshn": [24, 67, 69], "exterior2nd_brk": [24, 67, 69], "exterior2nd_brkfac": [24, 67, 69], "exterior2nd_cblock": [24, 67, 69], "exterior2nd_cmentbd": [24, 67, 69], "exterior2nd_hdboard": [24, 67, 69], "exterior2nd_imstucc": [24, 67, 69], "exterior2nd_metalsd": [24, 67, 69], "exterior2nd_oth": [24, 67, 69], "exterior2nd_plywood": [24, 67, 69], "exterior2nd_ston": [24, 67, 69], "exterior2nd_stucco": [24, 67, 69], "exterior2nd_vinylsd": [24, 67, 69], "exterior2nd_wd": [24, 67, 69], "extern": [16, 25, 26, 28], "external_tool": 79, "exterqu": [24, 26, 35, 43, 45, 54, 55, 67, 69, 78], "extra": [4, 5, 11, 28, 52, 56, 57, 71, 76, 79, 90, 96, 98], "extract": [27, 28, 30, 31, 32, 38, 46, 47, 48, 50, 51, 52, 70, 71, 73, 74, 75, 82, 90, 96, 98], "extractor": [47, 84], "extraordinari": 58, "extrapol": [33, 34, 76, 77], "extratreesclassifi": [44, 68], "extrem": [7, 20, 23, 25, 26, 30, 31, 34, 42, 45, 49, 50, 53, 63, 66, 68, 69, 73, 74, 77, 92], "ey": 58, "f": [9, 11, 13, 14, 15, 16, 18, 19, 20, 23, 26, 27, 28, 29, 31, 32, 33, 34, 38, 42, 45, 51, 52, 56, 57, 58, 59, 60, 61, 62, 63, 66, 69, 71, 72, 74, 75, 76, 77, 79, 81, 86, 88, 90, 92, 94, 96], "f1": [12, 45, 67, 80, 84], "f1_score": [23, 42, 66], "fa": [24, 26, 35, 43, 45, 54, 55, 67, 69, 78], "fabric": 58, "face": [13, 20, 30, 38, 39, 48, 58, 59, 61, 73, 75], "facebook": [30, 31, 49, 50, 51, 73, 74, 98], "facial": [20, 48, 61], "facil": 98, "facilit": [9, 98], "fact": [22, 23, 25, 32, 33, 34, 35, 42, 44, 52, 53, 55, 58, 65, 66, 68, 75, 76, 77, 78, 90, 92, 96], "factor": [14, 22, 26, 27, 29, 30, 34, 41, 45, 59, 65, 69, 70, 72, 73, 77], "fail": [8, 9, 11, 18, 19, 27, 29, 31, 34, 35, 50, 51, 55, 60, 62, 63, 70, 72, 74, 77, 78], "failur": [8, 13, 34, 58, 77, 88, 94, 98], "fair": [7, 18, 24, 26, 28, 43, 45, 60, 62, 67, 69, 71, 79, 84, 98], "fairli": [15, 22, 26, 30, 41, 45, 56, 57, 58, 60, 65, 66, 69, 79], "faith": 58, "fake": [16, 20, 40, 61], "fake_review": [20, 40], "fall": [16, 28, 31, 50, 51, 52, 61, 71, 74, 76], "fals": [9, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 31, 32, 33, 34, 35, 37, 39, 40, 41, 42, 43, 44, 45, 46, 50, 51, 52, 53, 54, 55, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 74, 75, 76, 77, 78, 84, 85, 88, 90, 91, 94, 96], "famili": [13, 17, 20, 22, 24, 25, 26, 28, 40, 41, 43, 44, 45, 58, 65, 66, 67, 68, 69, 71, 79, 98], "familiar": [6, 9, 12, 14, 18, 35, 55, 58, 59, 62, 78, 89, 90, 95, 96, 98], "famou": [1, 10, 20, 31, 32, 40, 50, 51, 74, 75], "fan": [20, 58], "fanat": 40, "fanci": [4, 41, 58, 65], "fancier": [27, 70], "fantast": [20, 58], "far": [16, 18, 19, 21, 23, 26, 28, 29, 31, 32, 33, 34, 42, 45, 50, 51, 53, 58, 59, 61, 62, 63, 64, 66, 69, 70, 71, 72, 74, 75, 76, 77, 83, 84, 86, 88, 92, 94], "farm": 66, "farther": [50, 74], "farthest": [14, 59], "fascin": [31, 50, 74], "fascist": 58, "fashion": [14, 20, 25, 31, 40, 44, 50, 51, 68, 74], "fast": [5, 15, 20, 21, 25, 26, 34, 44, 45, 51, 53, 60, 61, 64, 68, 69, 77, 79, 82], "faster": [16, 22, 25, 27, 32, 41, 44, 46, 65, 68, 70, 75], "fastest": [25, 44, 68], "fastingb": [88, 94], "fasttext": [31, 50, 51, 74], "favorit": [20, 58], "favour": 79, "favourit": [51, 58], "fc": [21, 64], "fcluster": [29, 48, 72], "fear": [20, 31, 50, 74], "feat": [17, 33, 39, 65, 76], "feat1": [28, 71], "feat2": [28, 71], "feat_nam": [17, 33, 76], "feat_vec": [20, 30, 40, 49, 73], "feat_vect": 20, "featur": [1, 12, 15, 20, 23, 25, 28, 29, 31, 34, 37, 38, 40, 42, 44, 47, 50, 51, 53, 60, 66, 68, 71, 72, 74, 77, 79, 80, 83, 86, 87, 88, 89, 91, 92, 93, 94, 95, 98], "feature_extract": [13, 17, 19, 20, 21, 22, 31, 39, 40, 41, 50, 51, 56, 57, 58, 63, 64, 65, 74, 79, 80], "feature_import": 37, "feature_importances_": [27, 37, 46, 70], "feature_nam": [14, 15, 20, 21, 25, 26, 27, 31, 37, 40, 44, 45, 46, 50, 51, 59, 60, 64, 68, 69, 70, 74, 85, 91], "feature_name_combin": [39, 41, 44, 45, 63, 65, 67, 68, 69, 94], "feature_names_in_": 37, "feature_names_out": [19, 63], "feature_select": [27, 46, 70, 81], "feature_typ": [25, 44, 68], "feature_weight": [25, 44, 68], "features_lag": [33, 76], "features_nonzero": [33, 76], "features_poli": [33, 76], "februari": [15, 33, 37, 52, 76, 96], "feder": [26, 31, 33, 45, 50, 51, 66, 69, 74, 76], "feed": [17, 32, 38, 39, 75, 98], "feedback": [14, 59, 79, 84], "feedforward": [32, 75], "feel": [7, 17, 31, 39, 50, 58, 60, 71, 74, 84], "feli": [32, 58, 75], "felin": [31, 50, 74], "felix": [1, 98], "fell": [21, 64], "fellow": 58, "felt": [17, 31, 39, 50, 74], "femal": [25, 26, 34, 44, 45, 53, 58, 66, 68, 69, 77], "female_cm": 66, "female_pr": 66, "fenc": [24, 26, 32, 35, 43, 45, 54, 55, 67, 69, 75, 78], "fens": 20, "fernandez": [25, 44, 68], "festiv": 58, "fetch_california_h": [21, 64], "few": [1, 9, 17, 20, 21, 24, 27, 30, 31, 32, 33, 34, 35, 39, 40, 43, 50, 51, 58, 64, 67, 68, 70, 73, 74, 75, 76, 77, 79, 82, 84, 85, 88, 89, 91, 94, 95, 96], "fewer": [25, 27, 29, 44, 46, 66, 68, 70, 72, 92], "fewest": [88, 94], "feynman": [35, 55, 78], "fiber": [34, 53, 77], "fiction": 58, "field": [2, 4, 12, 13, 19, 31, 32, 33, 50, 51, 52, 58, 63, 74, 75, 76, 79], "fifa": 25, "fig": [16, 21, 27, 28, 29, 32, 38, 46, 60, 61, 64, 66, 70, 71, 72, 75, 85, 86, 91, 92], "fight": [20, 40], "figsiz": [14, 16, 17, 18, 21, 26, 27, 28, 29, 32, 33, 34, 35, 38, 39, 46, 47, 48, 52, 53, 54, 55, 59, 60, 61, 62, 64, 66, 69, 70, 71, 72, 75, 76, 77, 78, 85, 86, 89, 91, 92, 95, 97], "figur": [4, 9, 13, 14, 16, 22, 24, 26, 27, 28, 29, 32, 33, 34, 35, 38, 39, 41, 43, 45, 46, 47, 48, 52, 53, 54, 55, 58, 59, 61, 65, 66, 67, 69, 70, 71, 72, 75, 76, 77, 78, 86, 89, 92, 95, 97], "file": [0, 1, 4, 6, 8, 9, 11, 13, 16, 18, 19, 20, 23, 25, 26, 28, 31, 32, 34, 42, 45, 56, 57, 59, 63, 66, 69, 75, 77, 79, 80, 86, 90, 92, 96], "file_download": 31, "file_nam": [38, 47, 48], "filenam": [32, 75], "fill": [15, 16, 17, 21, 22, 30, 37, 38, 39, 49, 56, 57, 61, 64, 65, 73, 79, 86, 88, 92, 94, 98], "fill_diagon": [16, 48, 61], "fill_valu": [17, 24, 25, 26, 35, 39, 43, 44, 45, 52, 54, 55, 62, 63, 66, 67, 68, 69, 76, 78, 90, 96], "film": [20, 40, 51, 58], "filmic": 58, "filmmak": 58, "filter": [4, 12, 13, 15, 28, 32, 52, 58, 60, 71, 75, 76, 84, 90, 96], "filterwarn": [15, 16, 25, 26, 27, 28, 29, 34, 53, 61, 77, 88, 94], "filth": 58, "final": [1, 5, 7, 8, 13, 15, 18, 25, 26, 27, 34, 35, 37, 44, 46, 55, 58, 60, 62, 66, 68, 70, 78, 79, 85, 87, 88, 91, 93, 94, 95], "final_estim": [25, 44, 68], "final_estimator_": [25, 44, 68, 88, 94], "financ": [31, 32, 33, 74, 75, 76], "find": [1, 5, 8, 9, 13, 17, 18, 20, 22, 24, 25, 26, 28, 29, 30, 31, 32, 35, 38, 39, 40, 41, 43, 44, 45, 46, 50, 51, 55, 58, 59, 62, 65, 67, 68, 69, 71, 72, 73, 74, 75, 78, 83, 86, 92], "fine": [8, 11, 17, 18, 19, 20, 30, 32, 33, 49, 52, 56, 57, 62, 63, 66, 73, 75, 76, 79, 88, 94], "finetun": [31, 50, 74], "finger": 58, "fingertip": 40, "finish": [24, 43, 58, 67], "fira": 0, "firasm": [23, 42, 66, 80], "fire": [20, 38], "firefox": 13, "fireplac": [24, 26, 35, 43, 45, 54, 55, 67, 69, 78], "fireplacequ": [24, 26, 35, 43, 45, 54, 55, 67, 69, 78], "first": [1, 4, 5, 9, 14, 16, 17, 19, 20, 21, 22, 25, 26, 28, 29, 30, 31, 32, 33, 34, 35, 39, 40, 41, 44, 45, 49, 50, 51, 53, 55, 58, 59, 61, 63, 64, 65, 66, 68, 69, 71, 72, 73, 74, 75, 76, 77, 78, 85, 88, 89, 91, 92, 94, 95, 98], "first_cal": 34, "first_dai": [52, 76, 96], "first_day_retail": [33, 76], "first_pass_isfinit": 18, "firth": [31, 50, 51, 74], "fish": [26, 44, 45, 66, 69], "fist": [33, 76], "fit": [0, 13, 15, 16, 17, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 37, 38, 39, 40, 41, 42, 43, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 60, 61, 63, 64, 65, 66, 67, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 83, 85, 86, 88, 90, 91, 92, 94, 95, 96], "fit_intercept": [40, 42, 44, 66, 67, 68, 75, 94], "fit_method": [18, 34], "fit_param": 34, "fit_predict": [29, 48, 72, 95], "fit_resampl": 80, "fit_tim": [15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 33, 34, 38, 39, 40, 42, 43, 44, 45, 46, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 76, 77, 80, 92, 93, 94], "fit_transform": [17, 18, 19, 20, 25, 26, 27, 29, 30, 31, 33, 34, 39, 40, 44, 45, 46, 49, 50, 51, 62, 63, 66, 68, 69, 70, 72, 73, 74, 76, 84, 89, 93, 95], "fittedcolumntransform": [17, 19, 25], "fittedpipelin": [22, 24], "fittedvotingclassifi": 25, "fitter": [53, 77], "five": [22, 65], "fix": [18, 19, 34, 39, 44, 53, 62, 63, 66, 68, 77, 79, 83, 86, 92, 98], "flag": [25, 34, 66, 77], "flaki": 80, "flash": 58, "flashcard": 84, "flask": [56, 57, 79], "flat": [29, 48, 58, 72, 94], "flatten": [20, 25, 26, 29, 32, 38, 40, 44, 45, 47, 52, 68, 69, 72, 75, 76, 88, 94, 96], "flatten_dataload": 47, "flatten_imag": 47, "flatten_train": 47, "flatten_transform": [44, 47, 68, 94], "flatter": 21, "flavour": 95, "flaw": [15, 17, 18, 60, 62], "flawless": [20, 21, 40, 64], "flesh": 58, "flexibl": [13, 27, 32, 58, 70, 75, 84], "flibbertigibbet": [31, 50, 51, 74], "flick": 58, "flight": [27, 46, 58, 70], "flip": [1, 23, 24, 42, 43, 60, 66, 67], "flip_i": 80, "float": [9, 24, 34, 43, 46, 53, 67, 70, 77, 92], "float32": [31, 50, 51, 74, 82], "float64": [16, 17, 18, 19, 22, 23, 24, 25, 26, 27, 30, 34, 38, 39, 41, 42, 43, 44, 45, 46, 52, 53, 59, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 72, 73, 76, 77, 80, 92, 94, 96], "floatlogslid": [16, 61, 86, 92], "floatslid": [16, 23, 28, 29, 42, 61, 66, 71, 72, 86, 92], "floor": [15, 37, 58, 59], "flourish": 58, "flower": [16, 38, 56, 57, 61, 79, 80, 86, 92], "fly": 58, "fmt": [22, 65], "fn": [23, 42, 66], "fnlwgt": [25, 26, 44, 45, 66, 68, 69], "focu": [1, 5, 12, 13, 18, 19, 21, 26, 29, 31, 33, 39, 45, 50, 51, 58, 62, 63, 64, 69, 72, 73, 74, 76, 84, 86, 87, 88, 92, 93, 94, 98], "focus": [13, 20, 21, 28, 31, 32, 51, 58, 64, 71, 74, 75, 84, 90, 96], "fold": [15, 18, 19, 22, 24, 39, 41, 43, 44, 60, 62, 63, 65, 66, 67, 68, 79, 86, 92], "folder": [6, 11, 45, 56, 57, 62, 69, 79], "folk": [34, 53, 58, 77, 98], "follow": [0, 1, 5, 6, 7, 8, 9, 11, 14, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 31, 32, 33, 34, 35, 37, 39, 40, 41, 42, 44, 45, 46, 48, 50, 51, 55, 56, 57, 58, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 74, 75, 76, 77, 78, 79, 83, 84, 86, 89, 92, 95, 98], "fond": 58, "font": [13, 14, 15, 28, 29, 30, 33, 34, 35, 49, 52, 53, 54, 55, 58, 59, 60, 71, 72, 73, 76, 77, 78, 89, 95], "font_scal": [26, 69], "fontsiz": [14, 15, 16, 23, 25, 26, 28, 32, 35, 37, 38, 42, 44, 45, 55, 59, 60, 61, 66, 68, 69, 71, 75, 78, 85, 86, 89, 91, 92, 95], "food": [17, 28, 31, 32, 39, 47, 48, 51, 71, 74, 75, 98], "food_class": [47, 48], "food_input": [47, 48], "food_typ": [17, 39], "food_type_canadian": [17, 39], "food_type_chines": [17, 39], "food_type_fus": [17, 39], "food_type_indian": [17, 39], "food_type_italian": [17, 39], "food_type_mexican": [17, 39], "food_type_nan": [17, 39], "food_type_oth": [17, 39], "food_type_quebecoi": [17, 39], "food_type_thai": [17, 39], "foot": [24, 26, 43, 45, 67, 69], "footag": [21, 64, 86, 92], "footstal": [32, 75], "forc": [26, 44, 45, 58, 69, 80, 86, 92], "force_all_finit": [18, 34], "force_int_remainder_col": [39, 41, 44, 45, 63, 65, 67, 68, 69, 94], "force_plot": [26, 45, 69], "force_writ": [18, 34], "forecast": [12, 14, 34, 35, 52, 55, 59, 77, 78, 84, 90, 96], "forest": [12, 24, 32, 33, 34, 53, 67, 75, 76, 77, 79, 80, 84, 88, 94], "forestcolumntransform": [25, 44, 68, 94], "forev": [33, 76], "forg": [24, 25, 26, 31, 34, 43, 44, 45, 50, 51, 53, 67, 68, 69, 74, 77, 80], "forget": [14, 19, 25, 31, 44, 50, 59, 63, 68, 74, 88, 94], "forgotten": 58, "form": [1, 13, 16, 19, 22, 27, 29, 30, 31, 34, 35, 39, 46, 50, 51, 55, 56, 57, 63, 66, 70, 72, 73, 74, 77, 78, 79, 82, 84], "formal": [13, 40, 58, 98], "format": [0, 1, 14, 15, 17, 18, 19, 20, 23, 29, 31, 33, 34, 37, 41, 42, 48, 50, 51, 52, 53, 59, 65, 66, 72, 74, 76, 77, 82, 90, 96, 98], "former": [34, 53, 77], "formerli": [31, 74], "formul": [4, 22, 65], "formula": [21, 24, 32, 43, 64, 66, 67, 75, 83], "fortun": 58, "forum": 13, "forw": 98, "forward": [32, 34, 46, 50, 53, 56, 57, 70, 74, 75, 77, 79], "foul": 58, "found": [1, 8, 15, 18, 19, 22, 24, 28, 30, 31, 37, 43, 49, 50, 51, 60, 63, 65, 67, 71, 73, 74, 88, 89, 94, 95, 98], "foundat": [1, 10, 12, 24, 26, 35, 43, 45, 50, 54, 55, 67, 69, 74, 78, 80], "foundation_brktil": [24, 43, 67, 69], "foundation_cblock": [24, 43, 67, 69], "foundation_pconc": [24, 43, 67, 69], "foundation_slab": [24, 43, 67, 69], "foundation_ston": [24, 43, 67, 69], "foundation_wood": [24, 43, 67, 69], "fountain": [32, 75], "four": [14, 27, 29, 46, 59, 60, 66, 70, 72, 79, 84, 98], "fourth": [29, 72], "foxhound": [32, 58, 75], "foyer": [24, 43, 67], "fp": [23, 42, 66], "fpr": [23, 42, 66], "fpr_lr": [23, 42, 66], "fpr_svc": [23, 42, 66], "frac": [14, 21, 23, 24, 28, 31, 32, 42, 43, 51, 59, 64, 66, 67, 71, 74, 75], "fractal": [27, 46, 70], "fraction": [19, 23, 30, 42, 49, 63, 66, 73], "fragment": [86, 92], "fraker": 58, "frame": [17, 18, 19, 23, 24, 27, 34, 35, 42, 43, 46, 52, 53, 55, 58, 62, 63, 66, 67, 70, 76, 77, 78, 79, 92, 94, 96], "framework": [22, 59, 65], "frank": [20, 58], "frankli": 58, "fraud": [14, 23, 24, 28, 31, 33, 42, 52, 59, 66, 67, 71, 74, 76, 80], "fraudul": [14, 23, 35, 42, 55, 59, 66, 78], "free": [0, 6, 19, 24, 31, 34, 39, 43, 50, 51, 53, 63, 67, 74, 77], "freedom": 0, "freelanc": [31, 50, 74], "french": [18, 31, 50, 51, 62, 74], "french_fri": [32, 75], "freq": [33, 52, 76, 96], "frequenc": [19, 31, 34, 41, 50, 51, 52, 63, 65, 74, 76, 77, 84, 90, 96], "frequent": [3, 14, 18, 30, 34, 51, 59, 62, 73, 77, 82], "fresh": [30, 31, 49, 50, 51, 73, 74], "fri": [33, 76, 98], "fridai": 1, "friend": [13, 14, 26, 29, 30, 45, 49, 56, 57, 58, 59, 60, 69, 72, 73, 79, 80, 84, 98], "frighteningli": 58, "frisco": 58, "frolick": 58, "from": [0, 1, 2, 4, 6, 7, 8, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 32, 33, 34, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 51, 52, 53, 54, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 75, 76, 77, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 98], "from_block": [34, 77], "from_estim": [23, 42, 66, 80], "front": 98, "fruit": [31, 50, 51, 74], "fruiti": 95, "frustrat": [4, 7, 22, 65], "fry": 58, "fsc": 98, "fu": [1, 98], "full": [5, 15, 20, 22, 25, 31, 32, 33, 34, 37, 44, 50, 58, 65, 68, 74, 75, 76, 77, 98], "fullbath": [24, 26, 35, 43, 45, 54, 55, 67, 69, 78], "fulli": [29, 32, 72, 75], "fun": [20, 31, 32, 50, 51, 74, 75, 80], "func": [9, 17, 19, 21, 24, 34, 35, 43, 54, 55, 63, 64, 67, 78], "function": [2, 13, 14, 15, 16, 17, 19, 22, 23, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 38, 42, 44, 45, 46, 47, 49, 50, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 63, 65, 66, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 81, 83, 84, 85, 86, 89, 90, 91, 92, 95, 96], "functiontransform": [17, 19, 34, 39, 53, 63, 77], "functiontransformerfunctiontransform": 17, "fundament": [1, 2, 5, 10, 12, 18, 21, 22, 24, 27, 32, 34, 43, 46, 62, 64, 65, 67, 70, 75, 77, 86, 92], "funni": [25, 44, 58, 68], "furnish": 0, "furnitur": 84, "further": [15, 27, 28, 32, 34, 37, 44, 46, 51, 53, 66, 68, 70, 71, 75, 77, 79, 82, 86, 92], "furthermor": [35, 55, 78], "fusion": [17, 39], "futur": [12, 13, 15, 22, 23, 24, 31, 32, 34, 41, 42, 43, 50, 52, 53, 58, 60, 62, 65, 67, 74, 75, 77, 79, 84, 90, 96], "futurewarn": [23, 24, 26, 42, 43, 45, 50, 62, 67, 69, 74, 83], "futurist": 58, "fuzzi": [13, 58], "fyi": [34, 53, 77], "g": [5, 7, 8, 9, 11, 12, 13, 14, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 37, 41, 42, 43, 44, 45, 46, 50, 51, 52, 53, 54, 55, 58, 59, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 82, 83, 84, 90, 93, 96, 98], "g26r0dcx4b35vf3nk31216hc0000gr": [45, 62, 69], "gaffer": 40, "gain": [7, 12, 14, 25, 26, 44, 45, 58, 59, 66, 68, 69], "game": [14, 26, 31, 45, 50, 51, 58, 59, 69, 74], "gamma": [21, 22, 25, 35, 38, 41, 42, 44, 55, 63, 64, 65, 68, 78, 86, 92], "gamma_log": [16, 38, 61, 86, 92], "gamma_widget": [16, 61, 86, 92], "gap": [15, 33, 34, 37, 52, 55, 60, 76, 77, 78, 84, 86, 92], "garagearea": [24, 26, 35, 43, 45, 54, 55, 67, 69, 78], "garagecar": [24, 26, 35, 43, 45, 54, 55, 67, 69, 78], "garagecond": [24, 26, 35, 43, 45, 54, 55, 67, 69, 78], "garagefinish": [24, 26, 35, 43, 45, 54, 55, 67, 69, 78], "garagefinish_fin": [24, 55, 67, 69], "garagefinish_miss": [24, 55, 67, 69], "garagefinish_rfn": [24, 55, 67, 69], "garagefinish_unf": [24, 43, 55, 67, 69], "garagequ": [24, 26, 35, 43, 45, 54, 55, 67, 69, 78], "garagetyp": [24, 26, 35, 43, 45, 54, 55, 67, 69, 78], "garagetype_2typ": [24, 67, 69], "garagetype_attchd": [24, 67, 69], "garagetype_bas": [24, 67, 69], "garagetype_builtin": [24, 67, 69], "garagetype_carport": [24, 67, 69], "garagetype_detchd": [24, 67, 69], "garagetype_miss": [24, 67, 69], "garageyrblt": [24, 26, 35, 43, 45, 54, 55, 67, 69, 78], "garbag": 58, "garlic": 71, "gassman": 58, "gaurav": [1, 98], "gauss": [31, 50, 51, 74], "gaussian": [29, 72], "gaussianmixtur": [29, 72], "gave": [17, 20, 30, 39, 52, 58, 73, 76], "gb": [31, 50, 74], "gbdt": [44, 45, 68, 69, 94], "gbm": 94, "gbr": 9, "gca": [28, 29, 34, 53, 71, 72, 77], "gd": [24, 26, 35, 43, 45, 54, 55, 58, 67, 69, 78], "gdprv": [24, 26, 35, 43, 45, 54, 55, 67, 69, 78], "gdtmp": 34, "gdwo": [24, 26, 35, 43, 45, 54, 55, 67, 69, 78], "gear": 58, "geez": 58, "gelbart": [0, 1, 14, 51, 59, 82], "gemini": [31, 50, 74, 98], "genai": 98, "gender": [13, 31, 33, 34, 50, 51, 53, 58, 63, 66, 74, 76, 77], "gender_femal": [34, 53, 77], "gender_mal": [34, 53, 77], "gener": [6, 8, 10, 13, 14, 18, 19, 22, 24, 26, 29, 31, 32, 33, 34, 35, 37, 41, 43, 45, 46, 50, 51, 52, 53, 55, 58, 59, 62, 63, 65, 66, 67, 69, 72, 74, 75, 76, 77, 78, 79, 80, 83, 84, 86, 90, 92, 96, 97], "genet": [27, 46, 70, 81], "geniu": 58, "genom": [27, 70], "genr": [20, 30, 49, 73], "gensim": [31, 50, 51, 74], "gentl": 12, "gentli": 84, "geograph": [21, 64, 79], "geometr": 59, "georg": [51, 82], "geq": [21, 64], "ger": 9, "german": [51, 82], "germani": 25, "get": [4, 7, 11, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 37, 38, 39, 40, 41, 42, 43, 44, 46, 47, 48, 49, 50, 51, 52, 53, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 82, 83, 84, 86, 87, 88, 90, 92, 93, 94, 95, 96, 98], "get_cluster_imag": [47, 48], "get_cmap": 62, "get_depth": [15, 37, 86, 92], "get_dummi": [18, 62], "get_featur": [32, 38, 47, 48, 75], "get_feature_nam": 20, "get_feature_names_out": [17, 18, 19, 20, 24, 25, 26, 27, 31, 33, 34, 35, 39, 40, 43, 44, 45, 46, 50, 51, 52, 53, 54, 55, 62, 63, 66, 67, 68, 69, 70, 74, 76, 77, 78, 90, 93, 96], "get_lr_data_per_us": [30, 49, 73], "get_param": 38, "get_permutation_import": [26, 45, 69], "get_season": [52, 76, 96], "get_stat": [30, 49, 73], "get_text": 59, "get_user_profil": [30, 49, 73], "getattr": [34, 77], "ghassemi": [1, 98], "gif": [28, 29, 31, 50, 71, 72, 74], "gigaword": [31, 50, 51, 74], "gini": [14, 26, 35, 44, 45, 55, 59, 68, 69, 78, 94], "giogio": 40, "girl": 58, "git": [3, 9, 13], "github": [0, 1, 8, 10, 11, 13, 15, 17, 18, 19, 20, 22, 23, 24, 25, 26, 27, 32, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 54, 55, 56, 57, 58, 62, 63, 65, 66, 67, 68, 69, 70, 75, 78, 79, 80, 89, 94, 95], "githubusercont": 9, "gitim": 20, "gitlf": [23, 42, 66], "giulia": [0, 1, 14, 16, 19, 25, 26, 28, 31, 32, 98], "give": [0, 6, 13, 14, 15, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 34, 35, 37, 38, 40, 41, 42, 43, 44, 45, 46, 49, 50, 51, 53, 55, 58, 59, 60, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 77, 78, 79, 80, 85, 86, 91, 92, 98], "given": [0, 15, 16, 18, 19, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 37, 41, 42, 43, 44, 45, 46, 47, 49, 50, 51, 52, 55, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 78, 79, 81, 83, 85, 86, 90, 91, 92, 96], "gladwel": [28, 71], "glanc": 92, "glass": [35, 54, 55, 78], "glob": [13, 32, 38, 47, 48, 58, 75], "global": [18, 23, 25, 28, 42, 44, 50, 51, 62, 66, 68, 71, 74, 84], "global_skip_valid": [18, 34], "glorious": 58, "glove": [12, 31, 50, 51, 74], "glove_wiki_vector": [31, 50, 74], "glq": [24, 26, 35, 43, 45, 54, 55, 67, 69, 78], "gmail": [13, 28, 58, 71], "go": [6, 8, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 29, 30, 31, 32, 33, 34, 35, 38, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 72, 73, 74, 75, 76, 77, 78, 79, 81, 83, 85, 86, 88, 89, 90, 91, 92, 94, 95, 96], "goal": [2, 12, 13, 16, 18, 22, 23, 28, 29, 30, 31, 32, 42, 49, 50, 51, 58, 61, 62, 65, 66, 71, 72, 73, 74, 75, 79, 88, 90, 94, 96], "god": 58, "goe": [2, 13, 15, 16, 19, 23, 26, 29, 30, 32, 35, 42, 44, 45, 55, 56, 57, 58, 60, 61, 63, 66, 68, 69, 72, 73, 75, 78, 79], "gogo": 58, "gold": 9, "goldcoast": [52, 76, 96], "golden": [20, 37, 39, 40, 61, 79, 84, 86, 92], "gone": 58, "good": [10, 14, 15, 16, 17, 18, 19, 20, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 37, 39, 41, 42, 43, 44, 45, 46, 47, 49, 50, 51, 52, 53, 56, 57, 58, 59, 60, 61, 62, 63, 65, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 79, 80, 83, 84, 87, 88, 90, 91, 92, 93, 94, 96], "good_serv": [17, 39], "good_server_y": 39, "goof": 58, "googl": [1, 4, 13, 14, 16, 22, 23, 25, 28, 31, 35, 42, 44, 50, 51, 54, 55, 58, 59, 68, 70, 71, 74, 78], "google_news_vector": [31, 50, 51, 74], "googlenew": [31, 50, 74], "goosebump": 58, "gorgeou": 20, "got": [16, 20, 21, 22, 24, 32, 34, 40, 43, 58, 61, 64, 65, 67, 75, 80], "gotten": [15, 34, 53, 77, 88, 94], "gov": [25, 26, 44, 45, 66, 68, 69], "govern": [31, 50, 51, 58, 74, 98], "governor": 58, "gpe": [51, 82], "gpt": [30, 31, 49, 50, 51, 73, 74], "gpu": [25, 31, 32, 44, 50, 51, 68, 74, 75], "grad": [25, 26, 44, 45, 66, 68, 69], "grade": [3, 8, 15, 19, 20, 22, 35, 37, 55, 58, 60, 63, 65, 78, 84, 86, 87, 88, 89, 90, 92, 93, 94, 95, 96], "grader": 7, "grades_df": 84, "gradescop": [1, 5, 7, 13, 98], "gradient": [32, 75, 79, 84], "gradientboostingclassifi": [25, 44, 68], "gradientboostingregressor": [25, 35, 44, 54, 55, 68, 78], "gradientexplain": [26, 45, 69], "gradual": [32, 75], "graduat": [5, 32, 75], "grain": [21, 26, 45, 64, 69], "gram": [50, 51, 74], "grammar": [31, 50, 74], "grammat": [51, 82], "grand": 95, "grander": 58, "grandma": [27, 81], "grandmoth": [56, 57, 79, 80], "grant": [0, 98], "grant_macewan": [31, 50, 51, 74], "granular": [29, 72], "grapefruit": 97, "graph": [1, 33, 38, 47, 48, 76], "graphic": [32, 75], "graphic_design": [31, 50, 51, 74], "graphviz": [14, 59, 85, 91], "grasp": 12, "gravita": 40, "great": [13, 16, 17, 19, 20, 21, 26, 27, 31, 32, 33, 35, 39, 40, 45, 46, 47, 50, 51, 52, 55, 58, 59, 61, 63, 64, 69, 70, 74, 75, 76, 78], "greater": [11, 27, 28, 46, 70, 71], "greater_is_bett": [24, 43, 67], "greedili": [29, 72], "greek": 20, "green": [16, 22, 28, 35, 41, 55, 61, 65, 71, 78, 83, 97], "grei": 98, "grew": 92, "grid": [21, 24, 32, 34, 43, 52, 53, 64, 67, 75, 76, 77, 84, 89, 90, 95, 96, 97], "grid_result": [35, 55, 78], "grid_search": [22, 35, 41, 55, 65, 78], "gridsearchcv": [16, 25, 26, 44, 45, 54, 61, 68, 69, 88, 94], "gridsearchcvifit": [41, 65], "gridsearchcvifittedgridsearchcv": 22, "gridspec_kw": [85, 91], "grinberg": [56, 57, 79], "grip": 51, "grlivarea": [24, 26, 35, 43, 45, 54, 55, 67, 69, 78], "groak": [31, 50, 51, 74], "groceri": [32, 75], "groin": [32, 75], "ground": [21, 27, 29, 30, 46, 49, 60, 70, 72, 73, 81, 98], "ground_truth_categori": [56, 57, 79, 80], "group": [5, 8, 12, 14, 16, 20, 21, 25, 31, 37, 38, 50, 59, 61, 63, 64, 68, 70, 74, 76, 84, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 98], "groupbi": [52, 76, 90, 95, 96], "grow": [22, 25, 27, 41, 44, 58, 65, 68, 81, 91], "grow_polici": [25, 44, 68], "grown": 58, "growth": [33, 34, 53, 76, 77], "groyn": [32, 75], "gruesom": 58, "grumpi": [31, 50, 74], "grv": [24, 43, 67, 69], "gsc": [35, 55, 78], "gt": [17, 19, 20, 21, 24, 25, 39, 40, 41, 44, 45, 58, 63, 64, 65, 66, 67, 68, 69, 94], "gtl": [26, 45, 69], "gtoti": 1, "guam": 44, "guarante": [22, 23, 25, 28, 32, 42, 44, 65, 66, 68, 71, 75], "guenon": [32, 75], "guerra": [1, 98], "guess": [16, 18, 31, 50, 51, 61, 62, 74], "gui": 58, "guid": [1, 6, 8, 10, 11, 13, 27, 32, 70, 75, 79], "guidanc": [26, 45, 69], "guidelin": [26, 27, 45, 46, 69, 70, 79], "guido": 1, "guin": 58, "gun": 58, "gunman": 58, "gustav": 25, "gusto": 58, "gz": [31, 50, 74], "h": [15, 20, 25, 26, 28, 31, 32, 37, 44, 45, 50, 51, 53, 56, 57, 66, 68, 69, 71, 74, 75, 77, 79], "ha": [2, 5, 7, 14, 15, 16, 18, 19, 20, 21, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 40, 42, 43, 44, 45, 46, 49, 50, 51, 52, 55, 59, 60, 62, 63, 64, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 78, 81, 82, 83, 86, 88, 89, 90, 91, 92, 94, 95, 96, 98], "hab": [31, 50, 51, 74], "habit": [19, 20, 35, 63, 78, 79], "hacki": [32, 75, 83], "had": [18, 19, 20, 21, 26, 32, 33, 34, 49, 51, 52, 53, 56, 57, 58, 62, 63, 64, 73, 75, 76, 77, 79, 80, 82], "hadn": [34, 51, 53, 77, 82], "haidilao": [17, 39], "hair": 48, "hal": 1, "half": [1, 7, 13, 14, 21, 27, 29, 58, 59, 64, 70, 72], "halfbath": [24, 26, 35, 43, 45, 54, 55, 67, 69, 78], "hallidai": 40, "halloween": [58, 89, 95], "hallucin": 5, "halvingrandomsearchcv": [22, 41, 65], "halvingrandomsearchcvifit": [41, 65], "ham": [13, 58], "hand": [4, 5, 10, 12, 17, 23, 30, 31, 39, 42, 49, 50, 58, 66, 73, 74, 98], "hand_picked_clust": 48, "handi": [23, 42, 66], "handl": [12, 15, 18, 25, 26, 29, 31, 32, 34, 37, 39, 44, 45, 50, 53, 56, 57, 58, 68, 69, 72, 74, 77, 79, 83, 84, 86, 92, 93], "handle_unknow": [19, 63, 94], "handle_unknown": [17, 18, 19, 22, 24, 25, 26, 34, 35, 39, 41, 43, 44, 45, 52, 53, 54, 55, 62, 63, 65, 66, 67, 68, 69, 76, 77, 78, 84, 88, 90, 93, 94, 96], "handler": [26, 45, 66, 69], "handrail": [32, 75], "handwritten": [35, 55, 78, 80], "hang": 80, "hapless": 58, "happen": [4, 7, 16, 17, 19, 20, 22, 23, 25, 26, 27, 30, 31, 33, 34, 39, 40, 42, 44, 45, 46, 49, 50, 52, 53, 55, 58, 61, 63, 65, 68, 69, 70, 73, 74, 76, 77, 78, 84, 90, 93, 95, 96, 98], "happi": [15, 17, 23, 28, 31, 34, 37, 39, 42, 50, 66, 71, 74, 77], "happier": [79, 98], "happydb": [56, 57, 79, 80], "har": 58, "hard": [9, 13, 15, 16, 18, 21, 22, 23, 24, 25, 27, 28, 29, 30, 31, 32, 35, 42, 44, 46, 49, 50, 51, 55, 58, 60, 61, 62, 64, 65, 66, 67, 68, 70, 71, 72, 73, 74, 75, 78, 79, 84, 88, 94, 95], "hardli": [30, 49, 58, 73], "hardwar": [32, 75], "harm": [31, 50, 74, 98], "harmon": [23, 42, 66], "harri": [1, 51, 58, 98], "has_nan_error": 18, "hasattr": 34, "hasn": [4, 30, 34, 49, 51, 58, 73, 77, 82], "hassl": [9, 26, 33, 45, 52, 69, 76], "hat": [21, 24, 43, 44, 49, 64, 67, 68], "have": [0, 4, 5, 6, 7, 8, 9, 11, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 27, 28, 29, 30, 31, 32, 33, 34, 37, 38, 39, 40, 41, 42, 43, 46, 47, 49, 50, 51, 52, 53, 54, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 70, 71, 72, 73, 74, 75, 76, 77, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 90, 91, 92, 94, 95, 96, 98], "haven": [17, 34, 39, 51, 53, 55, 60, 77, 78, 79, 82, 84], "haylei": [14, 59], "haystack": [31, 50, 74], "hazard": 12, "hc_truncation_toy_demo": [29, 72], "hdbscan": [29, 72], "he": [1, 15, 19, 20, 51, 58, 60, 63, 82, 98], "head": [9, 13, 14, 15, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 29, 30, 32, 33, 34, 35, 40, 41, 42, 43, 44, 45, 46, 49, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 72, 73, 75, 76, 77, 78, 79, 80, 84, 87, 88, 89, 90, 93, 94, 95, 96], "header": [56, 57, 79], "headlin": [31, 35, 51, 55, 74, 78], "health": [31, 50, 51, 74], "healthcar": [26, 31, 45, 69, 74], "healthi": [31, 35, 51, 74, 78], "heap": 58, "hear": [58, 79], "heard": [13, 15, 58, 60], "hearsai": 58, "heart": [14, 20, 31, 40, 50, 58, 59, 74, 88, 94], "heart_df": [88, 94], "heartdiseas": [88, 94], "hearti": [17, 39], "heat": [22, 24, 26, 35, 41, 43, 45, 54, 55, 58, 65, 67, 69, 78], "heating_floor": [24, 67, 69], "heating_gasa": [24, 67, 69], "heating_gasw": [24, 67, 69], "heating_grav": [24, 67, 69], "heating_othw": [24, 45, 67, 69], "heating_wal": [24, 67, 69], "heatingqc": [24, 26, 35, 43, 45, 54, 55, 67, 69, 78], "heatmap": [26, 45, 69], "heavi": [25, 44, 68], "heavili": [20, 30, 32, 33, 73, 75, 76], "hedg": 58, "heeren": [51, 82], "hei": 40, "height": [14, 15, 31, 38, 50, 51, 59, 60, 66, 74, 85, 91], "heist": 40, "helm": 58, "helmsmen": 58, "help": [1, 3, 6, 8, 11, 13, 14, 15, 17, 18, 22, 23, 26, 28, 29, 30, 31, 32, 33, 34, 35, 39, 41, 42, 45, 46, 50, 51, 52, 53, 55, 56, 57, 58, 60, 62, 63, 65, 66, 69, 71, 72, 73, 74, 75, 76, 77, 78, 79, 81, 84, 85, 86, 87, 89, 90, 91, 92, 93, 95, 96, 98], "helpless": [31, 50, 74], "henc": [23, 24, 26, 28, 42, 43, 45, 67, 69, 71], "henri": 58, "her": [13, 20, 30, 31, 50, 51, 58, 73, 74, 82], "here": [1, 4, 5, 6, 8, 9, 10, 11, 13, 14, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 54, 55, 56, 57, 58, 59, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 78, 79, 82, 83, 84, 85, 86, 87, 89, 90, 91, 92, 96, 98], "herebi": 0, "hero": 58, "heroin": 58, "herself": [51, 82], "hershey\u00f5": 95, "herta": 61, "hesist": [35, 55, 78], "hesit": [35, 55, 78], "heurist": [14, 22, 59, 65], "hf_hub_disable_symlinks_warn": 31, "hi": [20, 40, 51, 58, 82, 86, 92], "hidden": [27, 31, 32, 35, 50, 51, 55, 58, 74, 75, 78, 81], "hide": [9, 31, 32, 50, 59, 74, 75], "hier_label": [29, 72], "hier_labels1": [29, 72], "hier_labels2": [29, 72], "hierarch": [12, 84], "hierarchi": [14, 29, 59, 72], "high": [7, 12, 13, 14, 15, 16, 17, 20, 21, 22, 23, 24, 25, 26, 27, 29, 30, 31, 33, 34, 35, 39, 41, 42, 43, 44, 45, 50, 51, 55, 58, 59, 60, 61, 64, 65, 66, 67, 68, 69, 70, 72, 73, 74, 76, 77, 78, 79, 81, 92], "high_corr": [26, 45, 69], "higher": [14, 15, 16, 21, 23, 24, 25, 26, 27, 28, 30, 34, 35, 42, 43, 44, 45, 53, 55, 59, 60, 61, 64, 66, 67, 68, 69, 70, 71, 73, 77, 78, 79, 80, 86, 92, 97], "highest": [20, 25, 26, 30, 31, 32, 35, 40, 44, 45, 49, 50, 51, 55, 68, 69, 73, 74, 75, 78, 83, 86, 92], "highli": [1, 18, 20, 26, 30, 40, 45, 49, 62, 69, 73, 84, 93], "highlight": [4, 35, 55, 78], "hight": 66, "highwai": [21, 64], "hilari": [20, 58], "him": [20, 51, 58, 82], "himanshu": [1, 98], "himself": [51, 58, 82], "hindi": [18, 62], "hint": [26, 69, 86, 92], "hire": 58, "hist": [17, 18, 22, 24, 27, 34, 39, 41, 43, 46, 53, 62, 65, 67, 70, 77], "histgradientboostingclassifi": [18, 25, 44, 68], "histgradientboostingregressor": [25, 44, 68], "histogram": [34, 41, 53, 65, 77], "histor": 84, "histori": [13, 21, 30, 33, 49, 52, 58, 64, 73, 76, 98], "hit": [22, 58, 65], "hl": [24, 26, 35, 43, 45, 54, 55, 67, 69, 78], "hmid": [56, 57, 79, 80], "hmmm": [34, 53, 58, 77], "hobart": 96, "hockei": [31, 50, 51, 74], "hold": [17, 20, 31, 35, 39, 50, 55, 58, 74, 78, 79], "holder": 0, "holdout": 66, "hole": 58, "holi": [35, 55, 78], "holidai": [30, 49, 73, 98], "holist": [89, 95], "holliman": 58, "home": [14, 17, 21, 32, 39, 56, 57, 59, 64, 75, 79, 80], "homemak": [31, 50, 51, 74], "homepag": 1, "homework": [1, 3, 4, 6, 7, 9, 11, 22, 51, 56, 57, 61, 65, 79, 84, 98], "honest": [35, 54, 55, 78], "honestli": 58, "honour": 98, "hood": [15, 17, 39, 50, 58, 60, 74, 79], "hook": [20, 40], "hoot": 40, "hope": [15, 31, 35, 50, 55, 58, 60, 74, 78, 79], "hopefulli": 79, "hopeless": [27, 70], "hopelessli": [16, 58, 61], "horizont": [14, 17, 19, 39, 59, 63], "horror": 20, "host": [6, 31, 34, 50, 56, 57, 74, 77, 79], "hot": [15, 17, 19, 20, 26, 33, 39, 40, 60, 63, 69, 84, 90, 96], "hotchkin": 58, "hound": [32, 58, 75], "hour": [4, 5, 6, 11, 25, 26, 30, 33, 44, 45, 49, 66, 68, 69, 70, 73, 76, 79, 84, 98], "hourli": [34, 77, 84], "hous": [14, 24, 26, 27, 34, 35, 37, 43, 44, 45, 46, 54, 55, 67, 69, 70, 77, 78], "houseag": [21, 64], "household": [18, 21, 27, 46, 62, 63, 64, 70, 87, 93], "housestyl": [24, 26, 35, 43, 45, 54, 55, 67, 69, 78], "housestyle_1": [24, 67, 69], "housestyle_1stori": [24, 67, 69], "housestyle_2": [24, 67, 69], "housestyle_2stori": [24, 67, 69], "housestyle_sfoy": [24, 67, 69], "housestyle_slvl": [24, 67, 69], "housewif": [31, 50, 51, 74], "housing_df": [15, 18, 27, 37, 46, 59, 62, 63, 70, 87, 93], "housing_median_ag": [18, 27, 46, 62, 63, 70, 93], "how": [0, 3, 9, 12, 13, 19, 20, 22, 23, 24, 28, 30, 31, 33, 34, 37, 38, 41, 42, 43, 47, 49, 50, 51, 52, 53, 54, 58, 63, 65, 66, 67, 71, 73, 74, 76, 77, 79, 81, 82, 83, 84, 85, 86, 88, 89, 90, 91, 92, 94, 95, 96, 98], "howard": [28, 71], "howarth": 58, "howev": [2, 6, 9, 18, 19, 20, 24, 26, 28, 30, 33, 34, 38, 43, 52, 53, 56, 57, 58, 62, 63, 66, 67, 69, 71, 73, 76, 77, 79, 83, 86, 92, 93, 98], "hp": [16, 25, 26, 28], "href": [23, 42], "hsjcy": [34, 77], "hstack": [33, 76], "ht": [16, 25, 26, 28], "html": [8, 10, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 32, 34, 35, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 75, 77, 78, 79, 80, 81, 85, 87, 91, 93, 94], "http": [0, 6, 9, 10, 11, 13, 15, 16, 18, 20, 21, 22, 23, 29, 31, 32, 33, 34, 35, 38, 40, 42, 47, 50, 53, 55, 56, 57, 60, 62, 64, 66, 74, 75, 76, 77, 78, 79, 80, 89, 95], "hub": [6, 31], "hug": [30, 49, 73], "huge": [19, 24, 31, 32, 33, 34, 43, 51, 52, 53, 63, 67, 74, 75, 76, 77, 90, 96], "huggingfac": 31, "huggingface_hub": 31, "human": [0, 13, 18, 19, 20, 21, 22, 26, 27, 28, 31, 32, 40, 45, 46, 48, 50, 51, 58, 61, 62, 63, 64, 65, 66, 69, 70, 71, 74, 75], "humidity3pm": [52, 76, 90, 96], "humidity3pm_lag1": [52, 76, 90, 96], "humidity9am": [52, 76, 90, 96], "hummu": [31, 50, 51, 71, 74], "humor": 58, "humour": [1, 20, 51], "hundlei": [89, 95], "hundr": [21, 31, 50, 64, 74], "hungri": [17, 39], "hurdl": 39, "hurrai": [88, 94], "hurrican": 58, "husband": [25, 26, 44, 45, 66, 68, 69], "hussar": [32, 58, 75], "hw": 58, "hw1": [1, 4, 91], "hw2": [1, 18, 61, 62], "hw3": 1, "hw4": 1, "hw5": 1, "hw6": [1, 31, 50, 74], "hw6a": 8, "hw6b": 8, "hw7": 1, "hw8": 1, "hw9": 1, "hybrid": [30, 73], "hyper": [35, 41, 55, 78], "hyperband": [22, 41, 65], "hyperopt": [22, 41, 65], "hyperparamet": [1, 20, 23, 29, 30, 31, 32, 35, 38, 40, 42, 49, 50, 51, 55, 60, 66, 72, 73, 74, 75, 78, 79, 91], "hyperparameter_": [35, 55, 78], "hyperparamt": [15, 22, 34, 60, 65, 77], "hyperparlan": [21, 64], "hyperplan": [21, 64], "hypothesi": [34, 51, 77, 79], "hypothet": [21, 27, 28, 64, 71, 97], "i": [0, 1, 2, 6, 7, 8, 9, 10, 11, 12, 14, 16, 17, 20, 21, 24, 29, 32, 33, 34, 37, 38, 39, 40, 41, 43, 47, 48, 49, 50, 52, 53, 54, 59, 61, 64, 67, 72, 75, 76, 77, 80, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 98], "i1": [44, 68], "i2": [44, 68], "ic": [31, 50, 51, 74], "icc": [1, 98], "ici": 58, "iclick": [1, 5], "icon": 20, "id": [13, 15, 24, 26, 27, 30, 34, 35, 37, 43, 45, 49, 54, 55, 58, 59, 67, 69, 73, 78, 98], "idea": [9, 14, 15, 17, 18, 20, 22, 23, 26, 28, 29, 30, 32, 33, 34, 37, 38, 39, 42, 45, 46, 49, 51, 52, 53, 56, 57, 58, 59, 60, 62, 65, 69, 70, 71, 72, 73, 75, 76, 77, 79, 84, 86, 90, 92, 96], "ideal": [4, 8, 17, 23, 25, 27, 30, 34, 39, 42, 44, 49, 53, 56, 57, 66, 68, 70, 73, 77, 79], "ident": [13, 32, 38, 47, 48, 51, 58, 75], "identif": [13, 58], "identifi": [11, 12, 14, 15, 18, 20, 22, 23, 24, 28, 29, 31, 32, 34, 35, 37, 40, 42, 43, 48, 50, 51, 52, 54, 55, 59, 61, 62, 65, 66, 67, 71, 72, 74, 75, 76, 78, 79, 82, 84, 89, 90, 93, 95, 96], "idf": [19, 31, 50, 63, 74], "idli": 51, "idx": 38, "idxmax": [15, 16, 37, 40, 61], "if_binari": [17, 19, 25, 26, 39, 44, 45, 63, 66, 68, 69, 84, 87, 88, 93, 94], "ifram": [15, 31, 50, 60, 66, 74], "igloo": 51, "ignor": [14, 15, 16, 17, 18, 19, 21, 22, 23, 24, 25, 26, 27, 28, 29, 31, 32, 34, 35, 39, 41, 42, 43, 44, 45, 50, 51, 52, 53, 54, 55, 58, 59, 61, 62, 63, 64, 65, 66, 67, 68, 69, 74, 75, 76, 77, 78, 82, 84, 88, 90, 93, 94, 96], "ignore_index": 9, "ii": [23, 42, 66], "iidqv": 34, "iii": 1, "ij": [20, 21, 30, 40, 49, 64, 73], "ik": [44, 68], "iliad": 40, "ill": 98, "illus": 66, "illustr": [29, 33, 72, 76], "iloc": [9, 14, 16, 18, 19, 20, 25, 26, 31, 40, 44, 45, 50, 51, 52, 59, 60, 61, 62, 63, 68, 69, 74, 85, 88, 91, 94], "im": [31, 50, 74], "imag": [8, 12, 18, 23, 26, 27, 28, 29, 32, 33, 35, 42, 45, 46, 48, 52, 55, 60, 66, 69, 70, 71, 72, 75, 76, 78, 80, 81, 84], "image2": [31, 50, 74], "image_dataset": [32, 38, 47, 48, 75], "image_fil": [38, 47, 48], "image_s": [38, 47, 48], "image_shap": 47, "imagefold": [38, 47, 48], "imagenet": [32, 75, 83], "imagenet1k_v1": [32, 38, 47, 48, 75], "imagenet_class": [13, 32, 58, 75], "imagin": [1, 13, 14, 18, 21, 23, 26, 27, 28, 31, 34, 35, 42, 45, 46, 50, 51, 55, 58, 59, 60, 62, 64, 66, 69, 70, 71, 74, 77, 78, 79, 84, 85, 91], "imaginari": [15, 51, 60, 84], "imbal": [23, 28, 34, 42, 71, 77], "imbalanc": [23, 24, 42, 66, 67, 80, 83], "imblearn": 80, "imdb": [13, 20, 40], "imdb_df": [13, 20, 40, 58], "imdb_mast": [13, 20, 40, 58], "img": [13, 32, 38, 47, 58, 75], "img_classifi": [13, 58], "img_ind": 38, "img_path": [13, 58], "imit": 58, "immacul": 58, "immatur": [31, 50, 74], "immedi": [17, 26, 30, 34, 39, 49, 69, 73, 98], "imp": [18, 33, 62, 63, 76], "impact": [12, 19, 21, 25, 26, 29, 31, 33, 35, 44, 45, 50, 55, 63, 64, 68, 69, 72, 74, 76, 78, 86, 90, 92, 96], "implement": [2, 4, 18, 24, 25, 27, 29, 30, 31, 34, 35, 39, 43, 44, 49, 50, 51, 53, 55, 59, 62, 67, 68, 70, 72, 73, 74, 77, 78, 79, 80, 83], "impli": [0, 34, 77], "implic": [12, 17, 18, 58, 62, 79, 84], "implicit": [31, 50, 51, 74], "import": [9, 12, 20, 47, 48, 80, 81, 82, 83, 87, 88, 89, 93, 94, 95, 97, 98], "importance_typ": [25, 44, 45, 68, 69, 94], "importances_mean": [26, 45, 69], "impos": [18, 58, 62], "imposs": [28, 58, 71], "impr": 20, "impress": [26, 45, 58, 69], "impression": 20, "improv": [12, 15, 17, 18, 22, 23, 24, 25, 27, 28, 29, 30, 32, 33, 34, 35, 37, 39, 42, 43, 44, 46, 52, 55, 58, 65, 66, 67, 68, 70, 71, 72, 73, 75, 76, 77, 78, 79, 81, 84, 91], "impur": [14, 15, 25, 37, 44, 45, 59, 68, 85, 91], "imput": [15, 17, 19, 20, 21, 22, 24, 25, 26, 27, 28, 33, 34, 35, 39, 41, 43, 44, 45, 46, 52, 53, 54, 55, 60, 63, 64, 65, 66, 67, 68, 69, 70, 71, 76, 77, 78, 79, 84, 87, 88, 90, 93, 94, 96], "imread": [32, 75], "imshow": [13, 32, 38, 47, 48, 58, 75], "imtiaz": 1, "inabl": 13, "inappropri": 76, "inbox": [15, 60], "inc": [26, 44, 51, 69, 82], "incept": [30, 32, 49, 73, 75], "inception": [32, 75], "inch": 58, "incl": [24, 43, 67], "includ": [0, 1, 2, 4, 5, 6, 7, 8, 9, 11, 12, 13, 14, 18, 19, 23, 24, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 38, 41, 42, 43, 46, 50, 51, 52, 53, 55, 59, 62, 63, 66, 67, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 82, 84, 86, 87, 88, 89, 90, 92, 93, 94, 95, 96, 98], "include_bia": [27, 33, 46, 70, 76], "incom": [15, 21, 25, 26, 28, 44, 45, 60, 64, 66, 68, 69], "incomplet": [34, 77], "inconsist": [1, 19, 63], "incorpor": [5, 22, 24, 27, 34, 43, 46, 53, 65, 67, 70, 77, 79, 84], "incorrect": [34, 35, 53, 55, 77, 78], "incorrectli": [13, 23, 42, 58, 66], "increament": 79, "increas": [9, 15, 16, 19, 20, 21, 25, 26, 27, 28, 29, 32, 37, 40, 44, 45, 46, 60, 61, 63, 64, 68, 69, 70, 71, 72, 75, 86, 91, 92], "increasingli": [13, 58], "incred": [32, 75], "incredibli": 20, "increment": [41, 65, 79, 89, 95], "inde": [26, 45, 58, 69], "independ": [9, 10, 14, 22, 24, 25, 27, 31, 32, 33, 41, 43, 44, 50, 58, 59, 65, 67, 68, 74, 75, 76, 81, 93], "index": [13, 14, 15, 16, 17, 18, 19, 20, 21, 23, 24, 25, 26, 27, 29, 30, 31, 32, 33, 34, 35, 37, 38, 39, 40, 42, 43, 44, 45, 46, 48, 49, 50, 52, 53, 54, 55, 58, 59, 60, 61, 62, 63, 64, 66, 67, 68, 69, 70, 72, 73, 74, 75, 76, 77, 78, 86, 88, 90, 92, 94, 95, 96], "index_col": [9, 18, 22, 30, 41, 49, 56, 57, 61, 62, 65, 73, 79, 80], "india": 51, "indian": [17, 39, 66], "indian_liver_pati": [13, 58], "indic": [0, 17, 19, 20, 28, 30, 33, 34, 39, 40, 47, 48, 49, 50, 51, 53, 63, 71, 73, 74, 76, 77, 90, 96], "indirectli": [55, 78], "individu": [17, 25, 26, 28, 30, 31, 34, 39, 44, 45, 50, 51, 53, 68, 69, 71, 73, 74, 77, 79, 88, 94, 95, 98], "induc": 58, "industri": [25, 27, 31, 32, 46, 51, 58, 68, 70, 74, 75, 82, 92], "inequ": 66, "inertia_": [28, 71], "inertia_valu": [28, 71], "inf": [16, 34, 48, 61, 77], "infatu": 58, "infeas": [22, 41, 65], "infer": [31, 32, 33, 50, 51, 52, 59, 74, 75, 76, 79, 85, 91], "infiltr": 40, "infin": [16, 35, 55, 61, 78], "infinit": [22, 65], "inflamm": 10, "inflat": [26, 45, 69], "inflect": [28, 31, 50, 51, 71, 74, 82], "influenc": [14, 15, 20, 22, 26, 28, 30, 34, 41, 45, 53, 59, 60, 65, 69, 71, 73, 76, 77, 86, 92], "info": [1, 9, 17, 18, 19, 23, 24, 27, 31, 34, 42, 43, 46, 50, 51, 52, 53, 62, 63, 66, 67, 70, 74, 76, 77, 86, 87, 88, 90, 92, 94, 96], "infom": [31, 50, 51, 74], "infor_m": [31, 50, 51, 74], "inform": [1, 4, 5, 8, 14, 17, 18, 19, 21, 22, 23, 24, 25, 27, 28, 29, 30, 31, 32, 34, 35, 38, 39, 41, 42, 44, 46, 49, 50, 51, 52, 53, 55, 56, 57, 58, 59, 62, 63, 64, 65, 66, 67, 68, 70, 71, 72, 73, 74, 75, 77, 78, 79, 81, 82, 86, 87, 88, 89, 90, 92, 94, 95, 96, 98], "informa_t": [31, 50, 51, 74], "informaion": [31, 50, 51, 74], "informaiton": [31, 50, 51, 74], "informationabout": [31, 50, 51, 74], "informationon": [31, 50, 51, 74], "ingrid": 20, "inhabit": 98, "inher": [14, 33, 34, 66, 76, 77], "initi": [29, 38, 72], "initj": [26, 45, 69], "inject": [27, 30, 46, 49, 73, 81, 84], "ink": [35, 54, 55, 78], "inland": [18, 27, 46, 62, 63, 70, 93], "inlin": [13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 29, 37, 38, 39, 40, 41, 42, 43, 44, 45, 49, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 72, 73, 80, 81, 85, 86, 88, 89, 91, 92, 94, 95], "inner": [19, 22, 31, 41, 50, 51, 63, 65, 74], "innoc": 58, "inplac": [9, 13, 20, 22, 41, 58, 59, 65], "input": [9, 14, 17, 18, 21, 25, 26, 29, 31, 32, 33, 34, 38, 39, 40, 41, 44, 47, 48, 50, 51, 52, 56, 57, 59, 62, 63, 64, 65, 68, 69, 72, 74, 75, 76, 79, 82, 84, 90, 95, 96], "input_img": [32, 75], "input_nam": [18, 34], "insid": [10, 11, 19, 23, 39, 42, 58, 63, 66], "insight": [2, 12, 16, 23, 26, 28, 42, 45, 61, 66, 69, 71], "insist": 58, "inspct": [44, 66], "inspect": [26, 29, 45, 69, 72], "inspir": [25, 44, 59, 68, 80, 89, 95], "instagram": [13, 58], "instal": [3, 13, 23, 24, 25, 26, 28, 31, 32, 34, 38, 42, 43, 44, 45, 47, 48, 50, 51, 53, 56, 57, 58, 61, 66, 67, 68, 69, 71, 74, 75, 77, 79, 80], "instanc": [13, 14, 15, 18, 19, 20, 21, 23, 28, 29, 30, 32, 33, 34, 38, 42, 49, 51, 58, 59, 60, 63, 64, 66, 71, 72, 73, 75, 76, 80, 82, 83], "instanti": [15, 22, 37, 41, 65, 86, 92], "instead": [6, 9, 11, 13, 14, 17, 18, 19, 21, 22, 23, 24, 25, 27, 28, 29, 30, 31, 32, 34, 35, 42, 43, 44, 46, 49, 50, 51, 53, 54, 55, 58, 59, 60, 62, 63, 64, 65, 66, 67, 68, 70, 71, 72, 73, 74, 75, 76, 77, 78, 80, 83, 86, 88, 90, 92, 94, 96], "instinct": [31, 50, 74], "institut": [51, 58, 82], "instruct": [3, 4, 5, 6, 11, 13, 35, 55, 56, 57, 61, 78, 79, 98], "instructor": [4, 5, 7, 11, 13, 35, 55, 58, 78, 79, 98], "instrument": [18, 22, 41, 61, 62, 65], "insuffici": 58, "int": [18, 19, 25, 26, 31, 33, 44, 45, 50, 51, 52, 62, 63, 66, 68, 69, 74, 76, 88, 89, 90, 92, 94, 95, 96], "int32": [29, 33, 61, 71, 72, 76], "int64": [14, 15, 17, 19, 20, 23, 24, 25, 30, 31, 33, 34, 37, 39, 40, 41, 42, 43, 50, 51, 52, 53, 56, 57, 58, 59, 61, 62, 63, 65, 66, 67, 73, 74, 75, 76, 77, 79, 92, 94, 96], "integ": [9, 18, 22, 25, 26, 33, 44, 45, 62, 65, 68, 69, 76, 93], "integr": [12, 31, 74, 79, 98], "intellig": [1, 13, 31, 50, 51, 58, 74], "intelligen": 51, "intend": [0, 35, 55, 78, 98], "intens": [20, 31, 50, 51, 74], "intent": [50, 74], "intention": 97, "interact": [10, 13, 16, 22, 23, 26, 28, 29, 30, 33, 38, 42, 45, 49, 56, 57, 61, 65, 66, 69, 71, 72, 73, 76, 79, 86, 92], "interaction_constraint": [25, 44, 68], "interaction_onli": [27, 33, 46, 70, 76], "interactive_plot": [16, 61, 86, 92], "intercept": [26, 32, 45, 69, 75, 83], "intercept_": [21, 25, 32, 44, 64, 68, 75, 83], "intercept_sc": [40, 42, 44, 66, 68, 75, 94], "interest": [2, 13, 15, 17, 22, 23, 24, 25, 26, 27, 29, 30, 31, 32, 33, 34, 39, 42, 43, 44, 49, 51, 52, 53, 58, 60, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 79, 80, 82, 88, 90, 94, 96], "interfac": [6, 25, 31, 44, 50, 56, 57, 68, 74, 79], "intermedi": [29, 32, 72, 75], "intern": [0, 1, 14, 32, 33, 34, 59, 75, 76, 77], "internet": [34, 35, 53, 54, 55, 56, 57, 77, 78, 79], "internetservic": [34, 53, 77], "internetservice_dsl": [34, 53, 77], "internetservice_fib": [34, 53, 77], "internetservice_no": [34, 53, 77], "internship": [13, 58], "interpret": [1, 11, 12, 16, 18, 23, 24, 25, 27, 29, 30, 31, 32, 34, 35, 37, 42, 43, 44, 46, 49, 50, 51, 53, 61, 62, 66, 67, 68, 70, 71, 72, 73, 74, 75, 77, 78, 89, 95], "interrupt": 34, "interv": [12, 33, 34, 53, 76, 77, 84], "interweb": [56, 57, 79], "intraop": 32, "intrigu": 58, "intrins": [33, 76], "intro": [1, 32, 51, 75], "introduc": [19, 31, 34, 50, 63, 74, 77, 80], "introduct": [1, 10, 11, 12, 15, 33, 34, 37, 51, 53, 76, 77], "intslid": [16, 61, 86, 92], "intuit": [12, 16, 18, 19, 22, 24, 26, 28, 29, 31, 32, 34, 43, 45, 50, 53, 61, 62, 63, 65, 67, 69, 71, 72, 74, 75, 77, 84], "invad": [31, 50, 74], "invalid": 59, "invari": [32, 75], "invent": 58, "inventor": 58, "inventori": 84, "invers": [21, 24, 43, 64, 67], "inverse_func": [24, 35, 43, 54, 55, 67, 78], "invest": 40, "investig": [16, 26, 38, 45, 61, 69, 86, 92], "involv": [2, 4, 13, 22, 24, 25, 29, 31, 32, 35, 41, 43, 44, 45, 51, 58, 65, 67, 68, 72, 74, 75], "io": [10, 18, 32, 34, 38, 47, 53, 62, 75, 77], "iprint": [53, 77], "ipykernel_24444": 34, "ipykernel_24648": 62, "ipykernel_27559": 69, "ipykernel_35319": 45, "ipynb": [5, 8, 9, 11, 13, 51, 89, 95], "ipython": [13, 14, 15, 16, 18, 19, 20, 21, 23, 31, 42, 50, 51, 58, 59, 60, 61, 62, 63, 64, 66, 74, 80, 81, 85, 87, 91, 93], "ipywidget": [16, 38, 61, 86, 92], "ir1": [24, 26, 35, 43, 45, 54, 55, 67, 69, 78], "ir2": [24, 26, 35, 43, 45, 54, 55, 67, 69, 78], "iri": [16, 38, 61, 86, 92], "iris_df": [16, 38, 61, 86, 92], "irregular": [12, 76], "irregularli": 84, "irrelev": [16, 27, 31, 46, 50, 51, 61, 70, 74, 81, 92], "irrelevant_po": [31, 50, 51, 74], "irrespect": [15, 21, 60, 64, 98], "is_avail": [32, 38, 47, 48, 75], "is_classifi": 18, "is_leap_year": [52, 76, 90, 96], "is_stop": [31, 50, 51, 74], "is_year_end": [52, 76, 90, 96], "isinst": [18, 34, 77], "island": [18, 62, 63], "isn": [11, 16, 24, 25, 43, 44, 51, 55, 58, 60, 61, 66, 67, 68, 78, 82], "isna": 20, "isnul": [17, 18, 39, 62], "iso": [13, 20, 40, 58], "isol": [11, 24, 26, 35, 67, 69, 78, 80], "issu": [7, 13, 25, 30, 32, 34, 37, 44, 45, 49, 68, 70, 73, 75, 77, 84, 98], "issubclass": [34, 77], "itali": [25, 51, 82], "italian": [17, 39], "item": [13, 25, 26, 28, 30, 31, 34, 38, 44, 45, 49, 51, 58, 68, 69, 71, 73, 74, 77, 84, 88, 94], "item_inverse_mapp": [30, 49, 73], "item_kei": [30, 49, 73], "item_mapp": [30, 49, 73], "iter": [22, 27, 28, 29, 32, 34, 38, 41, 46, 47, 48, 65, 70, 71, 72, 75, 76, 79, 89, 95], "iterable_with_config": [19, 34], "iterable_with_config_and_warning_filt": 63, "iterrow": [30, 49, 73], "its": [9, 12, 13, 16, 17, 18, 19, 20, 21, 26, 28, 29, 31, 32, 33, 34, 38, 39, 50, 51, 52, 53, 58, 60, 61, 63, 64, 66, 69, 71, 72, 74, 75, 76, 77, 80, 82, 83, 86, 89, 91, 92, 95, 98], "itself": [8, 25, 29, 44, 51, 58, 66, 68, 72, 82], "j": [9, 21, 26, 27, 28, 30, 32, 45, 46, 49, 64, 69, 70, 71, 73, 75], "jackin": 65, "jackpot": [19, 63], "jaguar": [32, 58, 75], "jake": [20, 40], "jalebi": 51, "jam": 65, "jame": [31, 34, 50, 51, 53, 74, 77], "jane": 58, "januari": [33, 52, 76, 96], "japan": [31, 50, 51, 74], "jargon": [14, 59], "jason": [1, 27, 70], "javascript": [26, 45, 69], "jazz_musician": [31, 50, 51, 74], "jellyfish": [32, 75], "jerki": 58, "jerri": [30, 49, 73], "jest": [31, 50, 74], "jet": 62, "jetti": [32, 75], "jieba": [51, 82], "jim": [30, 49, 73], "jmlr": [22, 41, 65], "joan_baez": [31, 50, 51, 74], "joanna": 20, "job": [19, 20, 34, 47, 52, 58, 63, 76, 77, 90, 96], "joblib": [16, 19, 25, 26, 28, 34, 56, 57, 63, 79], "jobson": 40, "joei": [17, 39], "john": [20, 25, 44, 58, 68], "johnny_cash": [31, 50, 51, 74], "joi": [31, 50, 74], "join": [13, 14, 15, 16, 17, 18, 19, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 88, 89, 90, 91, 92, 94, 95, 96], "jointli": [33, 76], "joke": [20, 30, 58, 73], "jon": 20, "joni_mitchel": [31, 50, 51, 74], "joseph": [1, 98], "joss": 20, "journal": [31, 50, 51, 74], "journei": [1, 29, 31, 50, 72, 74, 98], "joy": [31, 50, 74], "jpg": [32, 38, 47, 48, 75], "jr": 58, "json": [56, 57, 79], "ju": 58, "jubatu": [32, 58, 75], "judg": [27, 46, 70], "judgment": [35, 55, 78], "juic": [31, 50, 51, 74], "juli": [52, 76, 96], "jump": [13, 58], "jun": [1, 98], "june": [52, 76, 96], "junior": 95, "jupyt": [1, 8, 9, 10, 11, 15, 17, 18, 19, 20, 22, 23, 24, 25, 26, 27, 32, 35, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 54, 55, 56, 57, 58, 62, 63, 65, 66, 67, 68, 69, 70, 75, 78, 79, 94], "jupyter_notebook": [34, 77], "jupyterlab": [5, 26, 38, 45, 69], "jurafski": [31, 50, 51, 74], "juri": 98, "jurisdict": [31, 50, 51, 74], "just": [4, 8, 9, 13, 14, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 31, 33, 34, 35, 38, 39, 40, 42, 43, 44, 45, 46, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 74, 76, 77, 78, 79, 81, 82, 86, 88, 90, 92, 93, 94, 96, 98], "justic": [26, 45, 51, 69], "justif": [88, 94], "justifi": 5, "k": [1, 8, 12, 15, 20, 21, 24, 27, 31, 32, 34, 38, 40, 43, 44, 46, 47, 48, 50, 51, 53, 60, 64, 67, 68, 70, 74, 75, 76, 77, 79, 80, 83, 86, 90, 92, 96], "k_neighbor": 80, "k_valu": [16, 61], "kaggl": [13, 18, 23, 24, 25, 26, 27, 35, 38, 42, 43, 45, 46, 54, 55, 59, 62, 66, 67, 68, 69, 70, 75, 78, 88, 89, 94, 95], "kaggler": [27, 46, 70], "kangaroo": [32, 75], "kanwal": [1, 98], "kaplan": 12, "kaplanmeierfitt": [34, 53, 77], "katherin": 96, "kathleen": 20, "kazmi": [1, 98], "kb": [17, 19, 24, 34, 43, 53, 63, 67, 77, 92, 94], "kbinsdiscret": [27, 46, 70], "kbinsdiscretizer__latitude_0": [27, 46, 70], "kbinsdiscretizer__latitude_1": [27, 46, 70], "kbinsdiscretizer__latitude_2": [27, 46, 70], "kbinsdiscretizer__latitude_3": [27, 46, 70], "kbinsdiscretizer__latitude_4": [27, 46, 70], "kbinsdiscretizer__latitude_5": [27, 46, 70], "kbinsdiscretizer__latitude_6": [27, 46, 70], "kbinsdiscretizer__latitude_7": [27, 46, 70], "kbinsdiscretizer__latitude_8": [27, 46, 70], "kbinsdiscretizer__latitude_9": [27, 46, 70], "kbinsdiscretizer__longitude_11": [27, 46, 70], "kbinsdiscretizer__longitude_12": [27, 46, 70], "kbinsdiscretizer__longitude_13": [27, 46, 70], "kbinsdiscretizer__longitude_14": [27, 46, 70], "kbinsdiscretizer__longitude_15": [27, 46, 70], "kbinsdiscretizer__longitude_16": [27, 46, 70], "kbinsdiscretizer__longitude_17": [27, 46, 70], "kbinsdiscretizer__longitude_18": [27, 46, 70], "kbinsdiscretizer__longitude_19": [27, 46, 70], "kbinsdiscretizerkbinsdiscret": [27, 46, 70], "kc_house_data": [13, 15, 37, 58, 59], "kdtree": 18, "keep": [1, 5, 11, 15, 16, 18, 19, 20, 23, 25, 26, 27, 30, 31, 34, 37, 39, 42, 44, 45, 46, 49, 50, 51, 53, 58, 60, 61, 62, 63, 66, 68, 69, 70, 71, 73, 74, 77, 79, 86, 87, 92, 93], "keep_empty_featur": [30, 39, 44, 45, 49, 62, 63, 67, 68, 69, 73], "kei": [5, 6, 10, 12, 14, 16, 18, 22, 23, 24, 25, 30, 31, 34, 41, 42, 43, 44, 49, 50, 51, 53, 59, 61, 62, 65, 66, 67, 68, 73, 74, 77, 88, 94, 98], "keith": 58, "kelbowvisu": [28, 71, 89, 95], "kellei": [21, 64], "kept": [15, 60], "kera": [26, 45, 69], "kernel": [1, 8, 11, 18, 21, 22, 26, 27, 32, 35, 38, 41, 42, 45, 46, 55, 62, 63, 64, 65, 69, 70, 75, 78, 86, 92], "kernelexplain": [26, 45, 69], "keyedvector": [31, 50, 74], "keyword": [4, 22, 65], "kfold": 66, "kick": [31, 51, 74], "kid": 58, "kiddi": 40, "kidnappe": 40, "kilian": [26, 45, 69], "kill": [34, 58, 77], "killer": [20, 58], "kimia": [1, 98], "kind": [0, 13, 14, 15, 18, 19, 20, 21, 23, 24, 26, 28, 29, 30, 32, 33, 34, 42, 43, 45, 52, 58, 59, 60, 62, 63, 64, 66, 67, 69, 71, 72, 73, 75, 76, 77, 79, 80, 83, 87], "king": [15, 30, 31, 37, 49, 50, 51, 73, 74], "kingdom": 58, "kingslei": 20, "kiss": [25, 95], "kitchenabvgr": [24, 26, 35, 43, 45, 54, 55, 67, 69, 78], "kitchenqu": [24, 26, 35, 43, 45, 54, 55, 67, 69, 78], "kiwi": [31, 50, 51, 74, 97], "kk": [28, 71], "klbuhzv_ofw": [31, 50, 74], "klimt": 25, "km": [34, 47, 48, 50, 53, 55, 74, 77, 78, 84], "km_flatten": 47, "km_label": [28, 71], "kmean": [28, 29, 47, 48, 50, 71, 72, 74, 84, 89, 95], "kmeans_bow": [50, 74], "kmeans_bow_label": [50, 74], "kmeansifittedkmean": [47, 48], "kmf": [34, 53, 77], "kmqfw": [34, 77], "kneighbor": 38, "kneighborregressor": [18, 62], "kneighborsclassifi": [17, 18, 19, 21, 27, 39, 46, 62, 63, 64, 70, 86, 87, 92, 93, 94], "kneighborsclassifierifit": 39, "kneighborsclassifierifittedkneighborsclassifi": 17, "kneighborsclassifierkneighborsclassifi": 17, "kneighborsregressor": [17, 18, 19, 21, 62, 63, 64, 87, 93], "kneighborsregressorkneighborsregressor": 18, "knew": [28, 31, 50, 71, 74], "knn": [2, 15, 16, 18, 21, 26, 27, 30, 32, 45, 46, 49, 60, 61, 62, 63, 64, 69, 70, 73, 75, 79, 83, 84, 88, 94], "knn1": [16, 61], "knn100": [16, 61], "knn_pipe": [63, 93], "knn_scale": [18, 62], "knn_score": 94, "knn_unscal": [18, 62], "knn_valid_accuraci": [16, 61], "knncolumntransform": 94, "knnimput": [30, 49, 73], "knob": [14, 35, 55, 59, 78], "knock": [20, 58], "know": [1, 9, 11, 13, 14, 16, 18, 19, 21, 22, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 40, 41, 43, 44, 45, 46, 49, 50, 51, 52, 53, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 81, 83, 84, 85, 89, 90, 91, 95, 96, 98], "knowledg": [9, 13, 14, 19, 22, 27, 28, 31, 35, 46, 50, 51, 55, 58, 59, 63, 65, 70, 71, 74, 78, 84], "knowleg": 84, "known": [30, 34, 38, 49, 51, 53, 66, 73, 77, 82], "koala": [32, 75], "kolhatkar": [0, 1, 14, 51, 82, 98], "ksatr": [34, 77], "kvarada": [1, 45, 50, 51, 53, 59, 60, 63, 69, 74, 75, 77, 82, 83], "kwantlen": [31, 50, 51, 74], "kwarg": [16, 18, 19, 25, 26, 28, 34, 60, 62, 63, 77], "l": [11, 20, 53, 77], "l1": [34, 53, 77], "l123": 4, "l17": 4, "l1_ratio": [40, 42, 44, 66, 68, 75, 94], "l2": [31, 34, 40, 42, 44, 51, 53, 66, 68, 74, 75, 77, 94], "l6": [31, 50, 74], "l9": 4, "la": [35, 55, 78], "lab": [11, 13, 28, 59, 60, 71], "lab1": [14, 15, 19, 59, 60, 63, 84], "lab2": [14, 15, 19, 59, 60, 63, 84], "lab3": [14, 15, 19, 59, 60, 63, 84], "lab4": [14, 15, 19, 59, 60, 63, 84], "label": [8, 9, 14, 15, 16, 18, 19, 23, 24, 26, 27, 29, 30, 31, 32, 33, 34, 37, 38, 39, 42, 43, 44, 45, 46, 48, 50, 51, 52, 53, 54, 59, 60, 61, 62, 63, 66, 67, 68, 69, 70, 72, 73, 74, 75, 76, 77, 82, 87, 89, 91, 93, 95, 97], "label_": [51, 82], "label_encod": [25, 26, 44, 45, 68, 69], "label_n_clust": [29, 72], "labelencod": [25, 26, 44, 45, 68, 69], "labels": [23, 28, 42, 66, 71], "labels_": [28, 29, 50, 71, 72, 74], "laboratori": 58, "lack": [15, 30, 32, 35, 49, 55, 58, 60, 73, 75, 78], "lag": [34, 77, 84], "lag_df": [33, 76], "lai": 58, "lakehead_univers": [31, 50, 51, 74], "lakeshor": [32, 75], "lakesid": [32, 75], "lakshmi25npathi": 13, "lamb": [17, 39], "lambda": [9, 14, 17, 21, 29, 33, 34, 39, 47, 52, 59, 64, 72, 76, 96], "land": [34, 77], "landcontour": [24, 26, 35, 43, 45, 54, 55, 67, 69, 78], "landcontour_bnk": [24, 43, 67, 69], "landcontour_hl": [24, 67, 69], "landcontour_low": [24, 67, 69], "landcontour_lvl": [24, 67, 69], "landmark": 84, "landsburi": 40, "landscap": [28, 31, 50, 51, 71, 74], "landslop": [24, 26, 35, 43, 45, 54, 55, 67, 69, 78], "landslope_gtl": [24, 26, 35, 45, 67, 69], "landslope_mod": [24, 26, 35, 45, 67, 69], "landslope_sev": [24, 26, 35, 45, 67, 69], "lang": 58, "langara_colleg": [31, 50, 51, 74], "langchain": [31, 50, 74], "languag": [2, 10, 18, 19, 30, 32, 49, 62, 63, 73, 75, 79, 82], "language_enc": [18, 62], "language_english": [18, 62], "language_french": [18, 62], "language_hindi": [18, 62], "language_mandarin": [18, 62], "language_spanish": [18, 62], "language_vietnames": [18, 62], "laptop": [6, 11, 13, 56, 57, 58, 79], "lar": 58, "larg": [13, 15, 16, 18, 20, 21, 23, 24, 28, 29, 32, 37, 40, 41, 42, 43, 51, 56, 57, 58, 60, 61, 62, 64, 66, 67, 71, 72, 75, 79, 80, 84, 86, 92], "larger": [16, 18, 21, 22, 24, 25, 26, 28, 29, 31, 34, 41, 43, 44, 45, 50, 53, 59, 60, 61, 62, 64, 65, 67, 68, 69, 71, 72, 74, 77], "largest": [24, 43, 67, 86, 92], "larvatu": [32, 58, 75], "last": [9, 13, 14, 15, 17, 18, 19, 20, 26, 30, 31, 32, 34, 38, 42, 45, 47, 48, 49, 50, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 66, 69, 73, 74, 75, 76, 77, 78, 79, 80, 86, 87, 88, 90, 92, 94, 96, 98], "last_row": 9, "lastp": [29, 72], "lat": [15, 37, 58, 59], "late": [13, 20, 80, 98], "latent": [30, 31, 32, 50, 51, 73, 74, 75], "latentdirichletalloc": [31, 50, 51, 74], "later": [11, 14, 19, 23, 32, 33, 42, 58, 59, 63, 66, 75, 76, 79], "latest": [19, 34, 45, 53, 63, 69, 77], "latex": [4, 8, 13], "latin": [13, 23, 42, 58, 66, 80], "latitud": [16, 18, 21, 27, 46, 60, 61, 62, 63, 64, 70, 93], "latitude_0": [27, 46, 70], "latitude_1": [27, 46, 70], "latitude_10": [27, 46, 70], "latitude_11": [27, 46, 70], "latitude_12": [27, 46, 70], "latitude_13": [27, 46, 70], "latitude_14": [27, 46, 70], "latitude_15": [27, 46, 70], "latitude_16": [27, 46, 70], "latitude_17": [27, 46, 70], "latitude_18": [27, 46, 70], "latitude_19": [27, 46, 70], "latitude_2": [27, 46, 70], "latitude_3": [27, 46, 70], "latitude_4": [27, 46, 70], "latitude_5": [27, 46, 70], "latitude_6": [27, 46, 70], "latitude_7": [27, 46, 70], "latitude_8": [27, 46, 70], "latitude_9": [27, 46, 70], "latter": [24, 43, 67], "laudabl": 58, "laugh": [20, 58], "laughabl": 58, "launceston": 96, "launch": [11, 13, 38], "laura": 58, "law": [17, 31, 39, 50, 51, 74, 82], "lawsuit": [31, 50, 51, 74], "lawyer": [31, 50, 74], "layer": [13, 32, 38, 47, 48, 58, 75], "layout": [16, 61, 86, 92], "lazi": [16, 61], "lbfg": [40, 42, 44, 66, 68, 75, 94], "lda": [32, 75], "ldot": [22, 41, 65], "lead": [9, 15, 21, 24, 29, 30, 34, 35, 43, 51, 53, 55, 60, 64, 67, 72, 73, 77, 78], "leaf": [14, 29, 31, 50, 51, 59, 72, 74], "leaf_siz": [38, 39, 62, 63, 94], "leagu": [31, 50, 51, 74], "leak": [17, 18, 34, 39, 62, 77, 84], "leakag": 84, "leaner": 60, "learn": [2, 5, 10, 17, 39, 41, 44, 45, 46, 47, 49, 50, 51, 53, 56, 57, 80, 83, 84, 85, 86, 87, 88, 90, 91, 92, 93, 94, 96, 98], "learner": [16, 25, 44, 60, 61, 68], "learning_method": [31, 50, 51, 74], "learning_r": [25, 44, 45, 68, 69, 94], "learnxinyminut": 10, "least": [1, 4, 6, 14, 15, 16, 20, 23, 24, 26, 27, 28, 29, 40, 42, 43, 45, 46, 55, 58, 60, 61, 66, 67, 69, 70, 71, 72, 78, 88, 90, 94, 95, 96], "least_confident_i": [21, 64], "least_confident_x": [21, 64], "leav": [8, 14, 29, 32, 34, 35, 53, 55, 59, 72, 75, 77, 78, 83], "lectur": [6, 8, 9, 11, 84], "lecun": [26, 45, 69], "lee": [20, 26, 45, 69], "left": [8, 13, 22, 23, 24, 26, 28, 29, 31, 33, 34, 35, 41, 42, 43, 50, 51, 53, 55, 58, 65, 66, 67, 71, 72, 74, 76, 77, 78], "legal": [0, 31, 50, 51, 74], "legend": [8, 9, 16, 21, 23, 24, 27, 28, 32, 33, 34, 35, 42, 43, 46, 52, 53, 54, 55, 61, 64, 66, 67, 70, 71, 75, 76, 77, 78, 83, 89, 95], "legitim": 98, "leisur": [56, 57, 79, 80], "lemma": [31, 50, 51, 74, 82], "lemma_": [31, 50, 51, 74, 82], "lemmat": [31, 50, 51, 74, 82], "lemon": 71, "len": [13, 18, 22, 24, 25, 26, 29, 30, 31, 32, 33, 35, 38, 41, 42, 43, 44, 45, 47, 48, 49, 50, 51, 52, 54, 55, 60, 62, 65, 66, 67, 68, 69, 72, 73, 74, 75, 76, 78], "length": [14, 15, 16, 20, 21, 24, 26, 28, 29, 31, 33, 34, 37, 38, 43, 45, 50, 51, 52, 59, 60, 61, 64, 67, 69, 71, 72, 74, 76, 77, 86, 92, 96], "lens": 58, "leo": [25, 44, 68], "leoni": 20, "leopard": [32, 58, 75], "leq": [27, 28, 46, 70, 71], "less": [1, 7, 16, 19, 21, 22, 24, 25, 26, 27, 29, 30, 34, 35, 43, 44, 45, 46, 49, 53, 55, 58, 61, 63, 64, 65, 66, 67, 68, 69, 70, 72, 73, 77, 78, 84, 86, 92], "lesson": [10, 18, 59, 60, 61, 62, 63], "lesssim": [15, 60], "let": [6, 14, 15, 20, 21, 22, 25, 27, 28, 29, 30, 31, 32, 33, 34, 37, 38, 40, 41, 44, 46, 48, 49, 50, 51, 52, 53, 56, 57, 58, 59, 60, 64, 65, 68, 70, 71, 72, 73, 74, 75, 76, 77, 79, 80, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 98], "letter": [21, 64], "lev": [24, 43, 67], "level": [12, 13, 16, 21, 24, 26, 27, 29, 31, 33, 35, 43, 45, 48, 50, 51, 55, 58, 59, 61, 64, 66, 67, 68, 69, 70, 72, 74, 76, 78, 79], "leverag": [26, 30, 45, 49, 69, 73], "lexic": [31, 51, 74], "lgbm": [12, 25, 26, 44, 45, 68, 69, 84], "lgbm_classifi": 94, "lgbm_score": 94, "lgbmclassifi": [13, 25, 26, 44, 45, 58, 68, 69, 88, 94], "lgbmclassifierifit": [45, 69], "lgbmclassifierifittedlgbmclassifi": [26, 58], "lgbmclassifierlgbmclassifi": 25, "lgbmregressor": [13, 25, 44, 58, 68], "li": [21, 64], "liabil": 0, "liabl": 0, "liao": 58, "lib": [14, 16, 18, 19, 25, 26, 28, 31, 32, 34, 45, 50, 53, 59, 60, 63, 69, 74, 77, 83], "librari": [4, 5, 9, 15, 17, 26, 27, 31, 32, 33, 35, 37, 39, 45, 46, 50, 51, 55, 60, 69, 70, 74, 75, 76, 78, 80, 82, 86, 92], "libtorch_1741738354177": 32, "licens": [31, 50, 74], "licensor": 0, "licenti": 40, "lie": [50, 74], "life": [20, 21, 28, 30, 31, 35, 39, 49, 50, 55, 56, 57, 58, 59, 64, 71, 73, 74, 78, 79, 85, 91, 98], "lifelin": [12, 34, 53, 77], "lifetim": [34, 53, 77], "lift": 58, "light": [20, 40, 48, 94], "lighter": [22, 41, 65], "lightgbm": [13, 26, 45, 58, 69, 79, 88, 94], "lightgbmcolumntransform": [25, 44, 68, 94], "lightweight": [11, 51, 82], "likabl": 20, "like": [1, 2, 4, 6, 8, 9, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 39, 40, 41, 42, 43, 44, 45, 46, 47, 49, 50, 51, 52, 53, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 86, 88, 89, 92, 93, 94, 95, 98], "likelihood": [23, 34, 42, 53, 77], "likewis": 8, "lime": [26, 45, 69], "limit": [0, 15, 19, 25, 26, 31, 32, 35, 44, 45, 50, 55, 59, 60, 63, 68, 69, 74, 75, 78, 79, 84, 85, 89, 91, 92, 95], "linalg": [31, 51, 74], "line": [4, 9, 11, 13, 14, 16, 18, 19, 20, 21, 22, 24, 25, 26, 28, 32, 33, 34, 35, 41, 43, 51, 53, 55, 58, 59, 63, 64, 65, 67, 71, 75, 76, 77, 78, 80, 82, 86, 92, 97], "line2d": 9, "linear": [1, 22, 23, 25, 27, 29, 30, 32, 33, 34, 41, 42, 44, 46, 49, 53, 55, 65, 66, 68, 70, 72, 73, 75, 76, 77, 78, 79, 81, 83, 84, 93], "linear_model": [13, 20, 21, 23, 24, 25, 26, 27, 30, 31, 32, 33, 34, 35, 40, 42, 43, 44, 45, 46, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 64, 66, 67, 68, 69, 70, 73, 74, 75, 76, 77, 78, 79, 80, 81, 83, 88, 90, 94, 96], "linear_svc": [21, 64], "linearli": [21, 27, 33, 46, 64, 70, 76], "linearregress": [21, 24, 27, 34, 43, 46, 53, 64, 67, 70, 77], "linestyl": [28, 52, 71, 76, 90, 96, 97], "linewidth": [33, 35, 55, 76, 78], "linger": 61, "lingual": [51, 82], "linguist": [19, 50, 63, 74], "link": [0, 4, 6, 8, 13, 23, 29, 34, 35, 42, 55, 56, 57, 72, 77, 78, 79], "linkag": [29, 72], "linkage_arrai": [29, 72], "linkage_typ": [29, 72], "linkedin": [30, 73], "linspac": [21, 22, 24, 27, 35, 41, 43, 46, 55, 64, 65, 67, 70, 78], "linux": [6, 11], "lion": [30, 49, 73], "list": [4, 8, 9, 15, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 30, 31, 32, 34, 35, 37, 40, 41, 42, 43, 44, 45, 49, 50, 51, 53, 54, 55, 58, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 71, 73, 74, 75, 76, 77, 78, 82, 88, 89, 90, 93, 94, 95, 96, 98], "listedcolormap": [21, 64], "listen": [13, 58], "literatur": [25, 68], "littl": [9, 20, 23, 31, 32, 35, 40, 42, 50, 55, 56, 57, 58, 66, 74, 75, 78, 79], "live": [1, 5, 13, 18, 19, 22, 28, 34, 35, 41, 53, 55, 56, 57, 58, 61, 62, 63, 65, 71, 77, 78, 79], "liver": [14, 59], "livestream": 98, "ll": [1, 5, 6, 7, 8, 11, 13, 14, 16, 17, 18, 19, 20, 22, 23, 24, 25, 26, 27, 28, 30, 31, 32, 33, 34, 35, 37, 38, 39, 40, 41, 42, 43, 44, 45, 47, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 61, 62, 63, 65, 66, 67, 68, 69, 70, 71, 73, 74, 75, 76, 77, 78, 79, 82, 83, 84, 86, 90, 92, 96, 98], "llama": [31, 50, 74], "llazx": [34, 77], "load": [9, 13, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 31, 32, 35, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 50, 51, 54, 55, 58, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 74, 75, 78, 80, 82, 86, 87, 92, 93, 94], "load_breast_canc": [27, 46, 70], "load_citibik": [33, 76], "load_dataset": [31, 50, 74], "load_digit": [35, 55, 78], "load_iri": [16, 38, 61, 86, 92], "load_word2vec_format": [31, 50, 74], "loan": 66, "loc": [9, 16, 21, 23, 26, 30, 33, 34, 35, 42, 45, 49, 52, 53, 54, 55, 61, 64, 66, 69, 73, 76, 77, 78, 90, 96], "local": [6, 8, 18, 23, 25, 26, 27, 31, 32, 34, 38, 42, 44, 45, 46, 50, 58, 66, 68, 69, 74, 75, 81], "localhost": 38, "locat": [1, 9, 19, 28, 30, 38, 49, 51, 52, 63, 71, 73, 76, 82, 88, 89, 90, 94, 95, 96, 98], "location_katherin": [52, 76, 96], "location_mountginini": [52, 76, 96], "location_townsvil": [52, 76, 96], "location_witchcliff": [52, 76, 96], "location_wollongong": [52, 76, 96], "lock": [15, 60], "log": [6, 16, 17, 24, 25, 34, 35, 39, 41, 43, 44, 53, 55, 56, 57, 61, 65, 67, 68, 77, 78, 79, 86, 88, 92, 94], "log10": [24, 41, 43, 65, 67], "log1p": [24, 35, 43, 54, 55, 67, 78], "log2": [34, 77], "log_likelihood_ratio_test": [34, 53, 77], "log_loss": [35, 54, 55, 78], "logarithm": [16, 41, 61, 65, 86, 92], "logic": [13, 27, 31, 39, 46, 50, 58, 70, 74], "logical_xor": [27, 46, 70], "login": [13, 30, 49, 58, 73], "logisit": [32, 75], "logist": [20, 25, 26, 32, 34, 35, 40, 44, 45, 52, 53, 55, 68, 69, 75, 76, 77, 78, 79, 83, 84, 88, 90, 94, 96], "logisticregress": [13, 20, 21, 23, 24, 25, 26, 27, 31, 32, 33, 40, 42, 43, 44, 45, 46, 50, 51, 53, 56, 57, 58, 64, 67, 68, 69, 70, 74, 75, 79, 80, 81, 83, 88, 90, 94, 96], "logisticregressionifit": 75, "logisticregressionifittedlogisticregress": 32, "logisticregressionlogisticregress": [20, 23, 25, 66], "logloss": [26, 45, 69], "lognorm": [22, 41, 65], "logspac": [22, 38, 41, 65], "loguniform": [22, 41, 65], "loki": [16, 25, 26, 28], "lol": [19, 63], "lone": [29, 72], "long": [0, 14, 15, 21, 25, 29, 30, 31, 34, 37, 44, 49, 50, 53, 58, 59, 64, 68, 72, 73, 74, 77, 79, 80, 84, 98], "longer": [20, 22, 31, 32, 34, 35, 41, 50, 53, 55, 65, 66, 74, 75, 77, 78, 79], "longest": [14, 59], "longitud": [16, 18, 21, 27, 46, 60, 61, 62, 63, 64, 70, 93], "longitude_0": [27, 46, 70], "longitude_1": [27, 46, 70], "longitude_10": [27, 46, 70], "longitude_11": [27, 46, 70], "longitude_12": [27, 46, 70], "longitude_13": [27, 46, 70], "longitude_14": [27, 46, 70], "longitude_15": [27, 46, 70], "longitude_16": [27, 46, 70], "longitude_17": [27, 46, 70], "longitude_18": [27, 46, 70], "longitude_19": [27, 46, 70], "longitude_2": [27, 46, 70], "longitude_3": [27, 46, 70], "longitude_4": [27, 46, 70], "longitude_5": [27, 46, 70], "longitude_6": [27, 46, 70], "longitude_7": [27, 46, 70], "longitude_8": [27, 46, 70], "longitude_9": [27, 46, 70], "look": [1, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 24, 25, 26, 27, 29, 30, 31, 32, 33, 34, 35, 39, 40, 41, 43, 44, 45, 46, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 67, 68, 69, 70, 72, 73, 74, 75, 76, 77, 78, 79, 84, 85, 86, 88, 91, 92, 94], "lookatm": 58, "loop": [22, 33, 44, 65, 68, 76, 83, 84], "loos": [29, 72, 79], "lose": [7, 19, 63], "loss": [2, 24, 25, 26, 32, 34, 43, 44, 45, 50, 51, 53, 66, 67, 68, 69, 74, 75, 77], "lost": [20, 58], "lot": [6, 10, 13, 14, 15, 16, 17, 19, 20, 21, 22, 24, 26, 27, 29, 32, 33, 34, 35, 39, 42, 43, 45, 46, 52, 53, 55, 58, 59, 61, 63, 64, 65, 66, 67, 69, 70, 72, 75, 76, 77, 78, 79, 80, 98], "lotarea": [24, 26, 35, 43, 45, 54, 55, 67, 69, 78], "lotconfig": [24, 26, 35, 43, 45, 54, 55, 67, 69, 78], "lotconfig_corn": [24, 67, 69], "lotconfig_culdsac": [24, 67, 69], "lotconfig_fr2": [24, 67, 69], "lotconfig_fr3": [24, 67, 69], "lotconfig_insid": [24, 67, 69], "lotfrontag": [24, 26, 35, 43, 45, 54, 55, 67, 69, 78], "lotshap": [24, 26, 35, 43, 45, 54, 55, 67, 69, 78], "lotshape_ir1": [24, 67, 69], "lotshape_ir2": [24, 67, 69], "lotshape_ir3": [24, 67, 69], "lotshape_reg": [24, 67, 69], "loud": [17, 18, 22, 39, 41, 61, 62, 65, 84], "loui": [33, 76], "lourenzutti": [22, 65], "lousiest": 40, "love": [20, 31, 40, 50, 56, 57, 58, 74, 79], "low": [7, 15, 16, 17, 22, 23, 24, 26, 27, 29, 34, 35, 37, 39, 41, 42, 43, 54, 55, 56, 57, 60, 61, 65, 66, 67, 69, 70, 71, 72, 77, 78, 79, 81, 92], "lower": [15, 16, 23, 24, 26, 28, 30, 31, 34, 35, 42, 43, 45, 49, 50, 51, 53, 55, 60, 61, 66, 67, 69, 71, 73, 74, 77, 78, 82, 92], "lowerbound_peopl": [17, 39], "lowercas": [17, 18, 19, 40, 41, 62, 63, 65], "lowest": [58, 86, 92, 98], "lowqualfinsf": [24, 26, 35, 43, 45, 54, 55, 67, 69, 78], "lr": [21, 23, 24, 26, 32, 33, 34, 40, 42, 43, 45, 53, 64, 66, 67, 69, 75, 76, 77, 83, 94], "lr_1": [27, 46, 70], "lr_2": [27, 46, 70], "lr_3": [27, 46, 70], "lr_classifi": 94, "lr_coef": [26, 34, 45, 52, 53, 69, 76, 77, 90, 96], "lr_coefs_landslop": [26, 45, 69], "lr_item": [30, 49, 73], "lr_pipe": [24, 26, 43, 45, 52, 67, 69, 76, 96], "lr_pred": [23, 24, 42, 43, 66, 67], "lr_scale": [26, 45, 69], "lr_score": 94, "lr_x": [30, 49, 73], "lr_y": [30, 49, 73], "ls15hb": 58, "lstm": [31, 33, 50, 52, 74, 76], "lt": [15, 17, 18, 19, 20, 24, 25, 26, 27, 34, 39, 40, 41, 44, 45, 46, 58, 60, 62, 63, 65, 66, 67, 68, 69, 70, 77, 93, 94], "ltorgo": [21, 64], "luck": 79, "lucki": [16, 22, 61, 65, 92], "luckili": [88, 94], "luddit": 58, "lundberg": [26, 45, 69], "luster": [29, 72], "luxuri": 58, "lvert": [31, 51, 74], "lvh": 94, "lvl": [24, 26, 35, 43, 45, 54, 55, 67, 69, 78], "lwq": [24, 26, 35, 43, 45, 54, 55, 67, 69, 78], "lynch": 58, "lynx": [32, 58, 75], "lyric": 58, "l\u00e3": 20, "l\u00e9cuyer": [51, 82], "m": [15, 22, 24, 25, 26, 27, 29, 30, 33, 34, 35, 37, 38, 39, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 55, 56, 57, 58, 60, 65, 67, 68, 69, 70, 71, 72, 73, 74, 76, 77, 78, 79, 82, 83, 94, 95], "m_neighbor": 80, "ma": [51, 82], "macaqu": [32, 58, 75], "macdougal": 58, "mach": [31, 50, 51, 74], "machin": [2, 5, 10, 12, 17, 18, 19, 22, 24, 25, 26, 27, 30, 31, 32, 33, 34, 35, 38, 39, 41, 43, 45, 46, 49, 50, 51, 52, 55, 56, 57, 62, 63, 65, 67, 68, 69, 70, 73, 74, 75, 76, 77, 78, 84, 86, 90, 92, 96, 98], "machine_learn": [35, 55, 78], "mackendrick": 58, "mackworth": 1, "maco": 11, "macro": [23, 42, 66], "mad": 58, "made": [0, 7, 8, 9, 14, 23, 26, 30, 31, 32, 33, 35, 42, 44, 45, 49, 50, 51, 55, 58, 59, 66, 68, 69, 73, 74, 75, 76, 78, 79], "madsen": 20, "magazin": [31, 51, 74], "magic": 58, "magnitud": [18, 20, 22, 24, 26, 31, 40, 41, 45, 51, 52, 65, 67, 69, 74, 76, 90, 96], "maguir": [30, 49, 73], "mai": [0, 5, 6, 8, 9, 11, 13, 14, 15, 16, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 33, 34, 41, 42, 43, 44, 45, 46, 50, 51, 52, 53, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 71, 72, 73, 74, 76, 77, 79, 81, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 98], "mail": [34, 53, 77], "main": [9, 11, 13, 14, 15, 16, 19, 25, 28, 29, 31, 32, 37, 44, 58, 59, 61, 63, 68, 71, 72, 74, 75, 84, 89, 95, 98], "mainland": [21, 64], "mainli": 98, "maintain": [25, 30, 35, 44, 49, 68, 73, 78, 84], "mainten": [25, 44, 68], "maj1": [24, 26, 35, 43, 45, 54, 55, 67, 69, 78], "maj2": [24, 26, 35, 43, 45, 54, 55, 67, 69, 78], "major": [2, 15, 16, 18, 19, 20, 25, 31, 51, 60, 61, 62, 63, 74, 84, 85, 88, 91, 94], "major_biologi": [19, 63], "major_comput": [19, 63], "major_econom": [19, 63], "major_linguist": [19, 63], "major_mathemat": [19, 63], "major_mechan": [19, 63], "major_phys": [19, 63], "major_psychologi": [19, 63], "make": [2, 4, 5, 6, 7, 8, 11, 12, 13, 14, 16, 17, 18, 19, 20, 22, 23, 24, 25, 26, 27, 28, 29, 31, 32, 33, 34, 37, 39, 40, 42, 43, 44, 45, 46, 50, 51, 52, 53, 54, 56, 57, 58, 59, 60, 61, 62, 63, 65, 66, 67, 68, 69, 70, 71, 72, 74, 75, 76, 77, 79, 81, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 98], "make_blob": [16, 28, 29, 32, 61, 71, 72, 75, 83], "make_circl": [29, 72], "make_classif": [16, 61, 80], "make_column_transform": [17, 22, 24, 25, 26, 27, 33, 34, 35, 39, 41, 43, 44, 45, 46, 52, 53, 54, 55, 65, 66, 67, 68, 69, 70, 76, 77, 78, 87, 88, 89, 90, 93, 94, 95, 96], "make_forg": [16, 61], "make_grid": [32, 38, 47, 48, 75], "make_imb_pipelin": 80, "make_moon": [29, 72], "make_num_tree_plot": [25, 44, 68], "make_pipelin": [13, 19, 20, 21, 22, 23, 24, 25, 26, 27, 31, 32, 33, 34, 35, 39, 40, 41, 42, 43, 44, 45, 46, 50, 51, 52, 53, 54, 55, 56, 57, 58, 63, 64, 65, 66, 67, 68, 69, 70, 74, 75, 76, 77, 78, 79, 80, 81, 87, 88, 89, 90, 93, 94, 95, 96], "make_scor": [24, 27, 43, 46, 67, 70], "maker": [55, 78], "malcolm": [28, 30, 49, 71, 73], "malcom": [28, 71], "male": [25, 26, 34, 44, 45, 53, 66, 68, 69, 77], "male_cm": 66, "male_pr": 66, "mall": 58, "mal\u00e3": 40, "man": [20, 30, 31, 49, 50, 51, 58, 73, 74], "manag": [6, 11, 12, 33, 34, 35, 55, 58, 76, 77, 78, 84], "manageri": 44, "mandarin": [18, 62], "mango": [31, 50, 51, 74], "mani": [1, 2, 5, 6, 9, 13, 14, 15, 16, 17, 18, 19, 20, 21, 23, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 37, 38, 39, 42, 44, 45, 46, 49, 50, 51, 52, 53, 55, 56, 57, 58, 59, 60, 61, 62, 64, 66, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 81, 82, 83, 84, 86, 88, 90, 92, 94, 96], "manipul": [35, 54, 55, 78], "mankind": 58, "manner": [0, 25, 44, 58, 68], "manual": [11, 14, 19, 23, 27, 28, 29, 31, 38, 42, 46, 50, 51, 63, 66, 70, 71, 72, 74], "manual_se": [38, 47, 48], "manufactur": [32, 75], "map": [1, 14, 15, 19, 20, 22, 30, 40, 41, 49, 53, 59, 60, 63, 65, 73, 76, 77, 90, 96], "mape": [79, 84], "mape_scor": [24, 43, 67], "maple_leaf": [31, 50, 51, 74], "mapper": [30, 49, 73], "marathon": 58, "march": [52, 76, 96], "margareta": 58, "marit": [25, 26, 44, 45, 66, 68, 69], "mark": [7, 8, 22, 23, 29, 42, 65, 66, 72, 98], "markdown": 13, "marker": [16, 21, 28, 61, 64, 71], "markers": [21, 23, 42, 64, 66], "market": [13, 28, 31, 32, 33, 35, 54, 55, 58, 71, 74, 75, 76, 78, 79], "marketplac": 11, "markov": 51, "marri": [25, 26, 44, 45, 66, 68, 69], "martin": [31, 50, 51, 74], "marvel": 58, "masculin": 20, "mask": [22, 41, 65], "massei": 58, "massiv": [19, 22, 31, 50, 58, 63, 65, 74], "master": [9, 22, 23, 25, 26, 31, 41, 42, 44, 45, 50, 51, 65, 66, 68, 69, 74, 80, 82], "masterpiec": 58, "masvnrarea": [24, 26, 35, 43, 45, 54, 55, 67, 69, 78], "masvnrtyp": [24, 26, 35, 43, 45, 54, 55, 67, 69, 78], "masvnrtype_brkcmn": [24, 55, 67, 69], "masvnrtype_brkfac": [24, 55, 67, 69], "masvnrtype_miss": [24, 55, 67, 69], "masvnrtype_ston": [24, 55, 67, 69], "mat": [31, 50, 74], "match": [19, 21, 23, 25, 26, 32, 42, 44, 45, 52, 63, 64, 66, 68, 69, 75, 76, 88, 89, 90, 94, 95, 96], "mate": 58, "materi": [6, 9, 11, 13, 15, 16, 31, 34, 50, 51, 53, 58, 59, 60, 61, 71, 74, 77, 84, 98], "matern": [27, 81], "math": [2, 28, 30, 34, 49, 71, 73, 77], "mathcal": 61, "mathemat": [2, 19, 25, 31, 44, 50, 63, 68, 74, 79, 84], "mathematician": [31, 50, 51, 74], "matlab": 9, "matplotlib": [13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 32, 33, 34, 35, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 52, 53, 54, 55, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 75, 76, 77, 78, 80, 81, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97], "matplotlibdeprecationwarn": [45, 69], "matric": [13, 16, 30, 49, 61, 66, 73], "matrix": [17, 19, 20, 29, 31, 39, 40, 50, 51, 63, 72, 74, 79, 84], "mattei": [20, 40], "matter": [18, 19, 20, 25, 29, 35, 44, 55, 58, 62, 63, 66, 68, 72, 78, 84], "max": [9, 15, 17, 18, 20, 21, 22, 23, 24, 25, 28, 29, 33, 37, 39, 40, 42, 43, 44, 52, 60, 62, 64, 65, 66, 67, 68, 71, 72, 76, 92, 95, 96], "max_bin": [25, 44, 68], "max_cat_threshold": [25, 44, 68], "max_cat_to_onehot": [25, 44, 68], "max_categori": [39, 41, 44, 45, 63, 65, 67, 68, 69, 94], "max_clust": [29, 72], "max_colwidth": [13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 29, 30, 37, 38, 39, 40, 41, 42, 49, 58, 59, 60, 61, 62, 63, 64, 65, 66, 72, 73, 80, 81, 85, 86, 87, 91, 92, 93], "max_delta_step": [25, 44, 68], "max_depth": [15, 16, 22, 25, 26, 35, 37, 38, 41, 44, 45, 55, 60, 61, 65, 68, 69, 78, 85, 86, 91, 92, 94], "max_depth_widget": [16, 61, 86, 92], "max_df": [19, 40, 41, 63, 65], "max_displai": [26, 45, 69], "max_featur": [13, 17, 19, 20, 22, 25, 35, 37, 39, 40, 41, 44, 55, 58, 63, 65, 68, 78, 94], "max_it": [13, 20, 23, 25, 26, 27, 31, 32, 34, 35, 40, 41, 42, 44, 45, 46, 50, 51, 52, 53, 55, 56, 57, 58, 63, 65, 66, 67, 68, 69, 70, 74, 75, 76, 77, 78, 79, 80, 81, 83, 94, 96], "max_leaf_nod": [14, 35, 37, 44, 55, 59, 68, 78, 94], "max_leav": [25, 44, 68], "max_opt": [16, 23, 28, 29, 42, 61, 66, 71, 72], "max_resourc": [41, 65], "max_row": 34, "max_sampl": [35, 44, 55, 68, 78, 94], "maxabsscal": [17, 39], "maxclust": [29, 48, 72], "maxent": 83, "maxhr": [88, 94], "maxim": [13, 24, 28, 43, 58, 66, 67, 71], "maximum": [14, 17, 18, 20, 24, 25, 28, 29, 39, 40, 43, 44, 59, 62, 67, 68, 71, 72, 86, 92], "maxtemp": [52, 76, 90, 96], "may": 1, "mayb": [26, 33, 35, 45, 55, 66, 69, 76, 78, 98], "maybe_coerce_valu": [34, 77], "ma\u00e3": 40, "mb": [18, 23, 27, 34, 42, 46, 52, 53, 62, 63, 66, 70, 76, 77, 96], "mcld": 98, "mcml158": 98, "md": [11, 51, 59, 82], "me": [9, 13, 20, 22, 31, 35, 40, 50, 51, 54, 55, 58, 65, 74, 78, 82, 98], "mean": [6, 7, 9, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 25, 26, 27, 30, 34, 37, 38, 39, 40, 41, 42, 44, 45, 46, 48, 49, 52, 53, 58, 59, 60, 61, 62, 63, 64, 65, 66, 68, 69, 70, 73, 76, 77, 79, 80, 81, 82, 83, 84, 86, 88, 92, 93, 94, 96, 98], "mean_absolute_error": [56, 57, 79], "mean_absolute_percentage_error": [24, 43, 67], "mean_cv_error": 60, "mean_cv_scor": [16, 20, 21, 22, 38, 40, 61, 64, 65], "mean_fit_tim": [22, 24, 41, 43, 65, 67], "mean_scor": [18, 22, 60, 62, 65], "mean_score_tim": [22, 24, 41, 65], "mean_squared_error": [24, 27, 43, 46, 67, 70], "mean_std_cross_val_scor": [18, 25, 26, 34, 44, 45, 60, 62, 63, 68, 69, 77], "mean_test_neg_mean_squared_error": 24, "mean_test_scor": [22, 24, 41, 43, 65, 67], "mean_train_error": 60, "mean_train_neg_mean_squared_error": 24, "mean_train_scor": [16, 20, 21, 22, 24, 38, 40, 41, 43, 61, 64, 65, 67], "meaning": [12, 16, 19, 23, 26, 28, 38, 42, 45, 51, 61, 63, 66, 69, 71, 87, 93], "meaningfulli": [31, 50, 74], "meaningless": [29, 72], "meant": 58, "measur": [0, 13, 14, 15, 16, 23, 24, 26, 27, 28, 29, 30, 32, 33, 34, 35, 42, 43, 45, 49, 50, 51, 52, 53, 55, 58, 59, 60, 61, 66, 67, 69, 71, 72, 73, 75, 76, 77, 78, 79, 81, 84, 86, 88, 90, 92, 94, 96], "meat": [17, 39, 58], "mechan": [19, 63, 84, 98], "mechanical_engin": [31, 50, 51, 74], "medal": 9, "media": [35, 54, 55, 78], "median": [14, 17, 18, 21, 24, 26, 27, 34, 35, 39, 43, 45, 46, 52, 53, 54, 55, 59, 62, 63, 64, 67, 69, 70, 76, 77, 78, 89, 90, 93, 95, 96], "median_house_valu": [18, 27, 46, 62, 63, 70, 87, 93], "median_incom": [18, 27, 46, 62, 63, 70, 93], "mediat": [55, 78], "medic": [28, 31, 32, 66, 71, 74, 75, 98], "medinc": [21, 64], "medit": [56, 57, 79, 80], "mediterranean": 58, "medium": [0, 16, 17, 34, 39, 53, 61, 77, 84], "meek": 58, "meet": [31, 50, 51, 74], "mehreen": [1, 98], "meier": 12, "mel": 20, "melbourn": 96, "melbourneairport": [52, 76, 96], "mele": 58, "melodrama": 58, "member": [21, 25, 64, 68, 98], "membership": [19, 28, 29, 63, 71, 72], "memori": [9, 17, 18, 19, 23, 24, 25, 27, 31, 32, 34, 40, 41, 42, 43, 44, 46, 50, 52, 53, 62, 63, 65, 66, 67, 68, 70, 74, 75, 76, 77, 84, 92, 93, 94, 96], "men": 20, "menstrual": [31, 50, 74], "mental": [35, 55, 78], "mention": [0, 4, 20, 21, 34, 35, 40, 53, 55, 58, 64, 77, 78], "menu": [11, 79], "merchant": 0, "mere": 58, "merg": [0, 6, 29, 72], "meshgrid": [27, 46, 70], "mess": [30, 34, 49, 58, 73], "messag": [4, 11, 15, 18, 19, 31, 34, 50, 53, 60, 63, 74, 77], "message_clsnam": 34, "messi": [27, 51, 70, 82], "met": [58, 98], "meta": [25, 44, 68], "metacademi": 1, "metal": [20, 32, 75], "method": [2, 5, 12, 14, 15, 16, 18, 20, 21, 23, 25, 26, 29, 30, 31, 32, 33, 34, 35, 37, 38, 40, 42, 44, 45, 46, 49, 50, 51, 52, 55, 56, 57, 59, 61, 62, 64, 66, 68, 69, 70, 72, 73, 74, 75, 76, 77, 78, 79, 80, 83, 84, 88, 89, 90, 94, 95, 96], "methodologi": [17, 18, 33, 62, 76], "metric": [1, 12, 16, 18, 19, 25, 26, 27, 28, 29, 30, 31, 34, 35, 38, 39, 44, 45, 46, 48, 49, 51, 53, 54, 55, 56, 57, 61, 62, 63, 68, 69, 70, 71, 72, 73, 74, 77, 78, 79, 81, 88, 94], "metric_param": [38, 39, 62, 63, 94], "metropoli": 58, "mexican": [17, 39], "mexico": 66, "mglearn": [14, 15, 16, 18, 19, 20, 21, 22, 23, 28, 31, 32, 33, 38, 40, 41, 42, 50, 51, 59, 60, 61, 62, 63, 64, 65, 66, 71, 74, 75, 76, 80, 81, 83, 85, 86, 89, 91, 92, 95], "mi": [13, 23, 35, 42, 47, 55, 58, 65, 66, 78], "mice": 40, "michael": 58, "microsoft": [31, 74], "mid": 58, "middl": [20, 40], "midnight": [33, 76], "midterm": [1, 5, 7, 13, 26], "might": [1, 13, 14, 15, 16, 17, 18, 19, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 33, 35, 38, 39, 41, 42, 43, 44, 45, 49, 50, 51, 53, 55, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 76, 78, 79, 80, 82, 84, 86, 87, 92, 98], "mightn": [51, 82], "miguel": [56, 57, 79], "mike": [0, 1, 10, 14, 59, 79], "mikolov": [31, 50, 51, 74], "mildli": 58, "mildura": 96, "milk": [31, 51, 74], "mill": [25, 44, 58, 68], "millennia": 98, "million": [32, 75], "min": [1, 17, 18, 21, 23, 24, 29, 31, 33, 37, 39, 42, 43, 48, 52, 64, 66, 67, 72, 76, 82, 92, 95, 96], "min1": [24, 26, 35, 43, 45, 54, 55, 67, 69, 78], "min2": [24, 26, 35, 43, 45, 54, 55, 67, 69, 78], "min_child_sampl": [44, 45, 68, 69, 94], "min_child_weight": [25, 44, 45, 68, 69, 94], "min_df": [19, 40, 41, 63, 65], "min_frequ": [39, 41, 44, 45, 63, 65, 67, 68, 69, 94], "min_impurity_decreas": [35, 37, 44, 55, 68, 78, 94], "min_impurity_split": [35, 55, 78], "min_resourc": [41, 65], "min_sampl": [29, 48, 72], "min_samples_leaf": [14, 35, 37, 44, 55, 59, 68, 78, 94], "min_samples_split": [14, 35, 37, 44, 55, 59, 68, 78, 94], "min_split_gain": [44, 45, 68, 69, 94], "min_token_len": [31, 50, 51, 74], "min_token_length": [31, 50, 51, 74], "min_weight_fraction_leaf": [35, 37, 44, 55, 68, 78, 94], "mind": [5, 15, 18, 25, 26, 30, 31, 34, 35, 44, 45, 49, 50, 55, 58, 60, 62, 63, 68, 69, 73, 74, 77, 78, 84], "mine": 1, "minibatchkmean": [29, 72], "miniconda3": 11, "miniforge3": [11, 45, 50, 53, 59, 60, 63, 69, 74, 77, 83], "minilm": [31, 50, 74], "minim": [5, 14, 24, 28, 29, 31, 35, 43, 50, 55, 59, 67, 71, 72, 74, 78], "minimum": [9, 15, 18, 29, 31, 50, 51, 60, 62, 72, 74], "minkowski": [38, 39, 62, 63, 94], "minmaxscal": [17, 18, 19, 35, 39, 54, 55, 62, 63, 78], "minor": [5, 7, 34, 77], "mint": 95, "mintemp": [52, 76, 90, 96], "minut": [4, 5, 13, 14, 30, 34, 59, 70, 77, 84], "mir": 1, "misc": 77, "miscfeatur": [24, 26, 35, 43, 45, 54, 55, 67, 69, 78], "miscfeature_gar2": [24, 26, 54, 67, 69, 78], "miscfeature_miss": [24, 26, 54, 55, 67, 69, 78], "miscfeature_othr": [24, 26, 54, 67, 69, 78], "miscfeature_sh": [24, 26, 54, 67, 69, 78], "miscfeature_tenc": [24, 26, 54, 55, 67, 69, 78], "misconduct": 98, "miscval": [24, 26, 35, 43, 45, 54, 55, 67, 69, 78], "mishaal": [1, 98], "mishra": [1, 98], "misinform": [31, 50, 74], "mislead": [15, 23, 42, 60, 66], "miss": [11, 16, 17, 18, 19, 20, 21, 23, 24, 25, 26, 27, 28, 30, 33, 34, 35, 37, 39, 42, 43, 44, 45, 49, 52, 53, 54, 55, 58, 61, 62, 63, 64, 66, 67, 68, 69, 71, 73, 76, 77, 78, 81, 84, 86, 90, 92, 96, 98], "missing_valu": [39, 44, 45, 62, 63, 67, 68, 69], "mission": 58, "mistak": [17, 18, 25, 34, 35, 44, 55, 58, 62, 68, 77, 78, 86, 92], "misus": 98, "mit": [0, 1], "mitig": [12, 30, 73], "mitlp": [34, 77], "mitt": 51, "mitten": 51, "mix": [5, 13, 20, 24, 35, 43, 54, 55, 67, 78, 79, 95], "mixtur": [29, 31, 32, 50, 51, 58, 72, 74, 75], "ml": [1, 2, 5, 10, 12, 14, 18, 22, 25, 29, 31, 32, 39, 44, 50, 51, 59, 62, 68, 72, 74, 75, 79, 82, 86, 92], "ml_experi": [14, 15, 19, 59, 60, 63, 84], "mlpclassifi": [32, 75], "mlpregressor": [32, 75], "mm": [52, 76, 90, 96], "mmsto": 58, "mn": [24, 26, 35, 43, 45, 54, 55, 67, 69, 78], "mnli": [31, 50, 74], "mnprv": [24, 26, 35, 43, 45, 54, 55, 67, 69, 78], "mnww": [24, 26, 35, 43, 45, 54, 55, 67, 69, 78], "mo": [31, 50, 51, 74], "mobil": [19, 32, 63, 75], "mobilenet": [32, 75], "mock": 58, "mod": [24, 26, 35, 43, 45, 54, 55, 67, 69, 78], "mode": [18, 22, 31, 41, 61, 62, 65, 94], "model": [1, 2, 12, 16, 22, 28, 29, 30, 33, 35, 41, 47, 48, 49, 52, 55, 65, 66, 71, 72, 73, 76, 78, 80, 81, 82, 83, 85, 90, 91, 93, 94, 95, 96], "model_nam": [30, 31, 49, 50, 73, 74], "model_path": [31, 50, 74], "model_select": [13, 15, 16, 17, 18, 19, 20, 21, 23, 24, 25, 26, 27, 30, 32, 33, 34, 35, 37, 38, 39, 40, 42, 43, 44, 45, 46, 49, 52, 53, 54, 55, 56, 57, 58, 60, 61, 62, 63, 64, 66, 67, 68, 69, 70, 73, 75, 76, 77, 78, 79, 80, 81, 83, 86, 87, 88, 90, 92, 93, 94, 96], "modern": [1, 16, 31, 35, 50, 51, 54, 55, 58, 61, 74, 78], "modif": [34, 77], "modifi": [0, 15, 34, 53, 56, 57, 77, 79, 80], "modul": [10, 14, 15, 18, 38, 50, 59, 60, 66, 74], "moe": [22, 41, 65], "mole": [32, 75], "molla": 40, "mom": [27, 81], "moment": [20, 58, 80, 84, 88, 89, 94, 95, 98], "moment_predictor": [56, 57, 79], "mon": [33, 76], "monarch": [31, 50, 51, 74], "monarchi": [31, 50, 51, 74], "mondai": [1, 33, 76, 98], "mone": [20, 40], "monei": [9, 20, 34, 40, 53, 77], "monet": 25, "monitor": [51, 82], "monkei": [32, 58, 75], "monotone_constraint": [25, 44, 68], "monotonic_cst": [37, 44, 68, 94], "monster": 58, "month": [19, 24, 27, 33, 34, 43, 60, 63, 67, 90, 96], "month_jun": 96, "month_mai": 96, "month_march": 96, "month_nam": [15, 33, 37, 52, 76, 90, 96], "month_novemb": 96, "month_octob": 96, "month_septemb": 96, "monthli": [27, 34, 53, 77], "monthlycharg": [27, 34, 53, 77], "montreal": [31, 50, 51, 74], "mood": 58, "moon": [29, 72], "moosvi": [0, 51, 82], "moral": [0, 58, 71], "more": [1, 2, 7, 8, 9, 13, 20, 22, 23, 25, 26, 28, 30, 31, 32, 33, 34, 35, 37, 38, 39, 41, 43, 44, 45, 46, 47, 49, 50, 51, 53, 55, 56, 57, 58, 60, 65, 68, 69, 71, 73, 74, 75, 77, 78, 79, 80, 82, 83, 84, 85, 86, 88, 91, 92, 94, 95, 98], "morn": 58, "morpholog": [51, 82], "morri": 20, "moskowitz": [28, 71], "mosold": [24, 26, 35, 43, 45, 54, 55, 67, 69, 78], "mosold_1": [24, 67, 69], "mosold_10": [24, 26, 67, 69], "mosold_11": [24, 26, 67, 69], "mosold_12": [24, 26, 67, 69], "mosold_2": [24, 67, 69], "mosold_3": [24, 67, 69], "mosold_4": [24, 67, 69], "mosold_5": [24, 67, 69], "mosold_6": [24, 67, 69], "mosold_7": [24, 67, 69], "mosold_8": [24, 26, 67, 69], "mosold_9": [24, 26, 67, 69], "most": [8, 9, 13, 14, 15, 16, 17, 18, 19, 22, 25, 26, 27, 28, 29, 30, 31, 32, 34, 35, 37, 38, 39, 41, 44, 45, 46, 49, 50, 51, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 65, 66, 68, 69, 70, 71, 72, 73, 74, 75, 77, 78, 79, 82, 83, 88, 91, 94, 95, 98], "most_confident_i": [21, 64], "most_confident_x": [21, 64], "most_frequ": [14, 16, 17, 18, 23, 24, 26, 35, 39, 42, 43, 45, 54, 55, 59, 61, 62, 66, 67, 69, 78, 85, 91, 96], "most_neg": 20, "most_negative_id": 40, "most_posit": 20, "most_positive_id": 40, "most_similar": [31, 50, 51, 74], "mostli": [9, 19, 33, 37, 58, 63, 76, 95], "motiv": [13, 19, 63], "mound": 95, "mountgambi": 96, "mountginini": [52, 76, 96], "move": [8, 20, 21, 26, 27, 40, 44, 45, 46, 58, 64, 69, 70, 85, 86, 88, 91, 92, 94], "movi": [20, 21, 31, 40, 50, 51, 64, 74], "movie_feat": 49, "movie_feats_df": [30, 49, 73], "movie_id": [30, 49, 73], "movie_nam": [30, 49, 73], "movies_rated_by_pat": [30, 49, 73], "movies_to_pr": [30, 49, 73], "mp": [47, 48, 50, 74], "mpimg": [32, 75], "mr": [20, 40, 58], "mri": 84, "mrtssm448usn": [33, 76], "mse": [14, 30, 49, 59, 73, 79, 84], "msg": [19, 34, 63, 77], "msg_dtype": 18, "msg_err": 18, "mssubclass": [24, 26, 35, 43, 45, 54, 55, 67, 69, 78], "mssubclass_120": [24, 67, 69], "mssubclass_160": [24, 67, 69], "mssubclass_180": [24, 67, 69], "mssubclass_190": [24, 35, 67, 69], "mssubclass_20": [24, 67, 69], "mssubclass_30": [24, 67, 69], "mssubclass_40": [24, 67, 69], "mssubclass_45": [24, 67, 69], "mssubclass_50": [24, 67, 69], "mssubclass_60": [24, 67, 69], "mssubclass_70": [24, 67, 69], "mssubclass_75": [24, 67, 69], "mssubclass_80": [24, 67, 69], "mssubclass_85": [24, 67, 69], "mssubclass_90": [24, 67, 69], "mszone": [24, 26, 35, 43, 45, 54, 55, 67, 69, 78], "mszoning_c": [24, 45, 67, 69], "mszoning_fv": [24, 67, 69], "mszoning_rh": [24, 67, 69], "mszoning_rl": [24, 67, 69], "mszoning_rm": [24, 67, 69], "much": [4, 9, 14, 15, 16, 18, 19, 23, 25, 26, 28, 29, 30, 32, 33, 34, 35, 42, 44, 45, 49, 51, 52, 53, 55, 56, 57, 58, 59, 60, 61, 62, 63, 66, 68, 69, 71, 72, 73, 75, 76, 77, 78, 79, 82, 86, 92, 98], "mueller": 1, "multi": [5, 13, 24, 26, 28, 31, 33, 43, 45, 50, 51, 56, 57, 58, 66, 67, 69, 71, 74, 76, 79, 82], "multi_class": [40, 42, 44, 66, 68, 75, 83, 94], "multi_output": 18, "multi_strategi": [25, 44, 68], "multiclass": [32, 56, 57, 75, 79, 83], "multicoliniar": [26, 45, 69], "multicultur": [51, 82], "multilevel": [24, 43, 67], "multimod": [28, 71], "multinomi": 83, "multinomin": [32, 75], "multipl": [5, 8, 9, 15, 21, 22, 25, 32, 33, 34, 37, 44, 45, 50, 51, 52, 53, 60, 64, 65, 68, 69, 74, 75, 76, 77, 90, 95, 96], "multiplelin": [34, 53, 77], "multiplelines_no": [34, 53, 77], "multiplelines_y": [34, 53, 77], "multipli": [21, 22, 25, 27, 34, 41, 44, 46, 53, 64, 65, 68, 70, 77, 80], "munch": 25, "murder": 20, "museum": 40, "music": [17, 30, 39, 58, 73], "musket": 95, "musqueam": 98, "must": [0, 7, 8, 9, 13, 14, 18, 20, 25, 26, 29, 31, 32, 34, 39, 45, 50, 51, 53, 58, 59, 60, 62, 69, 72, 74, 75, 77, 98], "mustn": [51, 82], "mutil": 58, "mutual": [29, 72], "my": [7, 15, 20, 31, 35, 50, 51, 55, 56, 57, 58, 65, 66, 71, 74, 78, 79, 80, 82, 98], "my_heatmap": [22, 41, 65], "my_map": [24, 43, 67], "myer": [20, 58], "mypreprocessor": [31, 50, 51, 74], "myself": [20, 31, 35, 50, 51, 55, 58, 59, 74, 78, 82], "m\u00fcller": 10, "n": [1, 14, 16, 18, 20, 21, 22, 24, 25, 26, 27, 29, 30, 31, 33, 34, 35, 38, 40, 41, 43, 44, 45, 46, 49, 50, 51, 52, 54, 55, 59, 61, 64, 65, 67, 68, 69, 70, 72, 73, 74, 76, 78, 82, 83, 86, 90, 92, 94, 95, 96], "n_bin": [27, 46, 70], "n_candid": [41, 65], "n_class": [16, 61, 66, 80], "n_cluster": [28, 29, 47, 48, 50, 71, 72, 74, 95], "n_clusters_per_class": 80, "n_compon": [31, 50, 51, 74], "n_constitu": [25, 44, 68], "n_estim": [27, 33, 34, 35, 45, 46, 54, 55, 69, 70, 76, 77, 78, 81, 94], "n_estimators_valu": [35, 54, 55, 78], "n_exampl": [28, 71], "n_feat": [16, 61], "n_featur": [16, 28, 61, 71, 80], "n_features_to_select": [27, 46, 70, 81], "n_imag": [38, 47, 48], "n_img": [47, 48], "n_inform": 80, "n_init": [28, 47, 48, 71, 95], "n_job": [19, 24, 25, 34, 35, 38, 39, 40, 42, 43, 44, 45, 55, 62, 63, 66, 67, 68, 69, 75, 78, 80, 94], "n_neighbor": [30, 38, 39, 49, 62, 63, 73, 86, 92, 94], "n_neighbors_selector": [16, 61], "n_neighbors_widget": [16, 61, 86, 92], "n_peopl": [17, 39], "n_redund": 80, "n_rental": [33, 76], "n_rentalsin3hour": [33, 76], "n_rentalsin6hour": [33, 76], "n_repeat": [26, 45, 69], "n_resourc": [41, 65], "n_sampl": [16, 28, 29, 32, 41, 61, 65, 66, 71, 72, 75, 80, 83], "n_samples_seen_": 34, "n_split": [33, 76], "n_threshold": [42, 66], "n_top_feat": 40, "n_top_featur": [20, 40], "n_topic": [31, 50, 51, 74], "n_train": [33, 76], "n_word": [31, 50, 51, 74], "na": [24, 26, 35, 43, 45, 54, 55, 67, 69, 78], "nadir": 58, "nafter": [51, 82], "nah": [19, 63], "nail": 58, "naiv": [39, 72], "name": [1, 4, 5, 8, 9, 11, 13, 14, 16, 17, 18, 19, 20, 22, 23, 25, 26, 27, 28, 32, 33, 34, 35, 37, 39, 40, 41, 42, 44, 45, 46, 51, 52, 53, 55, 56, 57, 58, 59, 61, 62, 63, 65, 66, 68, 69, 70, 71, 75, 76, 77, 78, 79, 82, 86, 88, 89, 90, 92, 94, 95, 96, 98], "named_estimators_": [25, 44, 68], "named_step": [17, 20, 21, 24, 25, 26, 27, 35, 40, 43, 44, 45, 46, 52, 54, 55, 64, 66, 67, 68, 69, 70, 76, 78, 90, 96], "named_transformers_": [17, 19, 24, 25, 26, 27, 34, 35, 39, 43, 45, 46, 52, 54, 55, 63, 66, 67, 68, 69, 70, 76, 78, 90, 93, 96], "namespac": 34, "nan": [17, 18, 19, 24, 25, 26, 27, 30, 33, 34, 35, 39, 41, 43, 44, 45, 46, 49, 52, 53, 54, 55, 62, 63, 65, 66, 67, 68, 69, 70, 73, 76, 77, 78, 84, 90, 92, 96], "nanmax": 48, "nanmean": [30, 49, 73], "nanosecond": [33, 76], "nap": 94, "narcot": 58, "narr": 51, "narrat": 20, "narrow": [13, 30, 35, 54, 55, 73, 78], "nasali": [32, 58, 75], "nation": [1, 58, 98], "nativ": [18, 25, 26, 32, 44, 45, 66, 68, 69, 75, 83], "natur": [2, 12, 17, 19, 25, 27, 32, 39, 44, 50, 56, 57, 58, 63, 68, 70, 75, 79, 80, 82, 83], "navig": [8, 11, 56, 57, 79], "nazism": 58, "nbsp": [37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 54, 55, 58, 62, 63, 65, 66, 67, 68, 69, 70, 75, 78, 94], "nbviewer": [15, 17, 18, 19, 20, 22, 23, 24, 25, 26, 27, 32, 35, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 54, 55, 58, 62, 63, 65, 66, 67, 68, 69, 70, 75, 78, 94], "nc": 1, "ncluster": 95, "ncol": [21, 64], "ndarrai": [9, 19, 34, 63], "ndframe": [27, 34, 46, 70, 77], "ndim": [9, 18], "ne": [52, 76, 96], "nearbi": [16, 28, 61, 71], "nearest": [29, 38, 72, 80, 86, 92], "nearestneighbor": 38, "nearestneighborsifit": 38, "nearing": 58, "nearli": [15, 37, 58], "necessari": [0, 8, 17, 21, 22, 39, 58, 59, 65, 84, 87, 93], "necessarili": [15, 24, 25, 30, 43, 44, 49, 60, 67, 68, 73, 79], "necvq": [34, 53, 77], "need": [6, 8, 9, 11, 13, 14, 15, 16, 17, 19, 20, 23, 24, 25, 26, 27, 28, 29, 30, 31, 33, 34, 35, 37, 38, 39, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 61, 63, 66, 67, 68, 69, 70, 71, 72, 73, 74, 76, 77, 78, 79, 80, 82, 83, 84, 86, 87, 88, 90, 92, 93, 94, 96, 98], "needn": [51, 82], "neg": [13, 14, 15, 16, 21, 24, 25, 26, 31, 34, 43, 44, 45, 50, 51, 52, 53, 58, 59, 60, 61, 64, 67, 68, 69, 74, 76, 77, 86, 90, 92, 96], "neg_mean_absolute_percentage_error": [24, 43, 67], "neg_mean_squared_error": [24, 35, 43, 55, 67, 78], "neg_prob": [20, 40], "neg_root_mean_square_error": [24, 43, 67], "neg_root_mean_squared_error": [24, 43, 67], "negative300": [31, 50, 74], "neglig": 58, "nehotencoder__major_comput": 63, "neigh": [16, 38, 61], "neighbor": [14, 16, 17, 18, 19, 21, 27, 29, 31, 38, 39, 46, 50, 61, 62, 63, 64, 70, 72, 74, 80, 86, 87, 92, 93, 94], "neighborhood": [21, 24, 26, 35, 43, 45, 54, 55, 64, 67, 69, 78], "neighborhood_blmngtn": [24, 67, 69], "neighborhood_bluest": [24, 67, 69], "neighborhood_brdal": [24, 67, 69], "neighborhood_brksid": [24, 67, 69], "neighborhood_clearcr": [24, 67, 69], "neighborhood_collgcr": [24, 43, 67, 69], "neighborhood_crawfor": [24, 67, 69], "neighborhood_edward": [24, 43, 67, 69], "neighborhood_gilbert": [24, 43, 67, 69], "neighborhood_idotrr": [24, 67, 69], "neighborhood_meadowv": [24, 67, 69], "neighborhood_mitchel": [24, 67, 69], "neighborhood_nam": [24, 67, 69], "neighborhood_noridg": [24, 43, 67, 69], "neighborhood_npkvil": [24, 67, 69], "neighborhood_nridght": [24, 43, 45, 67, 69], "neighborhood_nwam": [24, 67, 69], "neighborhood_oldtown": [24, 67, 69], "neighborhood_sawy": [24, 67, 69], "neighborhood_sawyerw": [24, 67, 69], "neighborhood_somerst": [24, 67, 69], "neighborhood_stonebr": [24, 45, 67, 69], "neighborhood_swisu": [24, 67, 69], "neighborhood_timb": [24, 67, 69], "neighborhood_veenk": [24, 67, 69], "neighborsbas": 18, "neighbour": [28, 29, 31, 37, 38, 45, 50, 51, 60, 69, 71, 72, 74, 86, 89, 92, 95], "neighbourhood": [21, 27, 29, 46, 64, 70, 72, 87, 93], "neither": [15, 19, 30, 49, 60, 63, 73], "nelson": 20, "neo": [1, 98], "nep": 48, "neq": [26, 30, 45, 69, 73], "ner": [31, 50, 51, 74], "nervou": [14, 59], "nest": [22, 41, 65, 84], "net": [32, 34, 53, 75, 77], "netflix": [30, 44, 49, 73], "netherland": 44, "network": [1, 12, 13, 19, 25, 27, 28, 30, 31, 33, 44, 47, 49, 50, 51, 52, 56, 57, 58, 63, 68, 70, 71, 73, 74, 76, 79], "neural": [1, 12, 13, 27, 31, 33, 50, 52, 58, 70, 74, 76], "neuron": [32, 75], "never": [25, 26, 30, 31, 32, 34, 39, 44, 45, 49, 50, 53, 58, 66, 68, 69, 73, 74, 75, 77, 98], "nevertheless": 98, "new": [1, 6, 11, 13, 14, 15, 16, 17, 18, 20, 21, 22, 23, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 38, 39, 40, 41, 42, 44, 45, 46, 49, 50, 51, 52, 53, 58, 59, 60, 61, 62, 63, 64, 65, 66, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 81, 84, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96], "new_cent": [28, 71], "new_column": [24, 26, 34, 35, 43, 45, 52, 53, 54, 55, 67, 69, 76, 77, 78, 90, 96], "new_data": [34, 77], "new_df": 52, "new_exampl": [14, 28, 59, 71], "new_feature_nam": [52, 76, 90, 96], "new_text": 59, "new_valu": [34, 77], "newaxi": 9, "newcastl": 96, "newer": [24, 43, 67], "newli": [18, 24, 27, 29, 43, 46, 62, 67, 70, 72], "newsgroup": 51, "newswir": 51, "newtonian": 40, "next": [1, 14, 16, 17, 18, 22, 23, 24, 25, 31, 32, 33, 34, 35, 38, 42, 43, 44, 47, 48, 50, 51, 52, 55, 58, 59, 60, 61, 62, 63, 66, 67, 68, 74, 75, 76, 78, 87, 88, 93, 94, 98], "nfeat": [16, 61], "nfeats_accuraci": [16, 61], "ng": [1, 10, 22, 27, 65, 70], "ngram": [27, 46, 70], "ngram_rang": [19, 40, 41, 63, 65], "nhil": 96, "nhl": 51, "nhqxu": [34, 77], "nice": [4, 13, 20, 23, 25, 26, 29, 32, 34, 35, 41, 42, 44, 45, 53, 55, 56, 57, 65, 66, 68, 69, 72, 75, 77, 78, 79], "nicki": 65, "nifti": 20, "night": [33, 56, 57, 76, 79, 80], "nightmar": [35, 55, 78], "nlemma": [51, 82], "nlp": [19, 32, 63, 75], "nltk": [31, 50, 51, 74, 82], "nltk_data": [31, 50, 51, 74, 82], "nmax": [35, 54, 55, 78], "nn": [1, 18, 20, 32, 38, 40, 47, 48, 50, 62, 74, 75, 86, 92], "nne": [52, 76, 96], "nnw": [52, 76, 96], "nnz": [19, 63], "no_class": 1, "no_grad": [38, 47, 48], "no_label": 48, "no_val_i": 34, "no_val_x": [18, 34], "nobodi": 58, "node": [25, 29, 32, 44, 59, 68, 72, 75, 85, 91], "nois": [17, 29, 48, 72, 84, 86, 92], "noise_cat": [17, 39], "noise_level": [17, 39], "noise_ord": [17, 39], "non": [1, 9, 13, 14, 15, 17, 18, 21, 22, 23, 24, 25, 26, 27, 29, 30, 32, 33, 34, 42, 43, 44, 46, 49, 52, 53, 58, 59, 60, 62, 64, 65, 66, 67, 68, 70, 72, 73, 75, 76, 77, 79, 80, 81, 84, 92, 94, 96, 98], "noncommerci": 1, "none": [1, 15, 18, 19, 21, 22, 25, 27, 29, 33, 34, 35, 37, 38, 39, 40, 41, 42, 44, 45, 55, 60, 62, 63, 64, 65, 66, 67, 68, 69, 72, 75, 76, 77, 78, 80, 81, 85, 88, 90, 91, 94, 96], "noninfring": 0, "nonzero": [19, 63], "noodl": [17, 39], "nope": 58, "noqa": [22, 41, 65], "nor": [8, 15, 19, 51, 60, 63, 82], "norahhead": 96, "norfolkisland": 96, "norg": [51, 82], "norm": [17, 22, 31, 39, 41, 51, 65, 74], "normal": [7, 11, 17, 18, 23, 24, 25, 26, 28, 29, 31, 32, 33, 35, 38, 39, 41, 42, 43, 44, 45, 47, 48, 51, 52, 54, 55, 65, 66, 67, 68, 69, 71, 72, 74, 75, 76, 78, 82, 88, 94, 97], "north": [31, 50, 51, 74], "north_america": [17, 39], "north_america_don": [17, 39], "north_america_no": [17, 39], "north_america_y": [17, 39], "norvig": 1, "nose": 20, "notat": 61, "note": [0, 1, 3, 5, 8, 10, 11, 13, 14, 15, 16, 17, 18, 19, 21, 22, 23, 25, 26, 27, 30, 31, 41, 42, 44, 45, 46, 49, 50, 51, 52, 58, 59, 61, 62, 63, 64, 65, 66, 68, 69, 70, 73, 74, 79, 83, 84, 90, 96, 98], "notebook": [5, 6, 8, 10, 15, 17, 18, 19, 20, 22, 23, 24, 25, 26, 27, 32, 35, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 51, 54, 55, 58, 59, 60, 61, 62, 63, 65, 66, 67, 68, 69, 70, 75, 78, 87, 89, 90, 93, 94, 95, 96], "noth": 58, "nothin": 20, "notic": [0, 17, 19, 21, 24, 39, 43, 58, 63, 64, 66, 67, 70], "notion": [16, 22, 28, 30, 31, 32, 49, 50, 61, 65, 71, 73, 74, 75], "notna": [52, 76, 90, 96], "nougat": 95, "noun": [31, 50, 51, 74, 82], "nov": [1, 52, 76], "novel": 58, "novemb": [1, 33, 52, 76, 96], "novic": 10, "now": [9, 11, 13, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 30, 31, 32, 33, 35, 38, 39, 40, 42, 43, 44, 45, 46, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 73, 74, 75, 76, 78, 79, 81, 82, 85, 86, 87, 88, 89, 91, 92, 93, 94, 95], "nowher": 58, "np": [9, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 80, 81, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97], "npie": 9, "npo": [51, 82], "npr": [27, 31, 46, 50, 51, 70, 74, 84], "npt": 34, "nsubj": [51, 82], "ntest": [16, 22, 61, 65, 86, 92], "ntoken": [51, 82], "ntree": [25, 44, 68], "nuclear": 58, "null": [17, 18, 19, 23, 24, 27, 34, 42, 43, 46, 52, 53, 62, 63, 66, 67, 70, 76, 77, 92, 94, 96], "null_distribut": [34, 77], "num": [25, 26, 44, 45, 66, 68, 69], "num_leav": [44, 45, 68, 69, 94], "num_parallel_tre": [25, 44, 68], "num_sent": [56, 57, 79, 80], "num_thread": 32, "num_work": [38, 47, 48], "number": [1, 4, 8, 9, 13, 14, 15, 16, 18, 19, 21, 22, 23, 24, 26, 27, 29, 30, 31, 32, 33, 34, 39, 41, 42, 43, 45, 46, 47, 48, 49, 50, 51, 53, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 69, 70, 72, 73, 74, 75, 77, 79, 80, 82, 84, 86, 89, 90, 92, 93, 95, 96, 97, 98], "number_test": [22, 65], "numberbatch": [31, 50, 51, 74], "numer": [2, 14, 17, 18, 19, 21, 23, 24, 25, 30, 31, 33, 34, 35, 38, 39, 42, 43, 44, 49, 51, 52, 53, 55, 59, 62, 63, 64, 66, 67, 68, 73, 74, 76, 77, 78, 86, 87, 90, 92, 93, 96], "numeric_feat": [17, 19, 22, 27, 39, 41, 46, 63, 65, 70, 84], "numeric_featur": [24, 25, 26, 34, 35, 43, 44, 45, 52, 53, 54, 55, 63, 66, 67, 68, 69, 76, 77, 78, 88, 90, 93, 94, 96], "numeric_looking_column": [24, 43, 67], "numeric_onli": 95, "numeric_transform": [17, 24, 25, 26, 35, 39, 43, 44, 45, 52, 54, 55, 63, 66, 67, 68, 69, 76, 78, 88, 90, 93, 94, 96], "numpi": [10, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 80, 81, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97], "numpy_dtyp": [34, 77], "nuriootpa": 96, "nutrit": [31, 50, 51, 74], "nw": [52, 76, 96], "nwith": [16, 61], "nyre": 20, "nyt": [35, 54, 55, 78], "o": [13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96], "obelisk": [32, 75], "object": [15, 17, 18, 19, 20, 21, 22, 24, 26, 27, 28, 37, 39, 40, 41, 43, 44, 45, 46, 50, 51, 52, 53, 55, 60, 62, 63, 64, 65, 66, 67, 69, 70, 71, 80, 82, 84, 85, 86, 91, 92, 94, 96], "obscur": 14, "observ": [13, 14, 16, 25, 26, 28, 29, 33, 34, 38, 44, 45, 58, 59, 60, 61, 68, 69, 71, 72, 76, 77, 84, 86, 88, 90, 92, 94, 96], "obsess": [40, 58], "obtain": [0, 20, 21, 28, 29, 30, 34, 38, 40, 49, 64, 71, 72, 73, 77, 86, 92], "obviou": [29, 31, 50, 51, 72, 74], "obvious": 58, "occas": 58, "occasion": [23, 42, 66], "occup": [25, 26, 44, 45, 66, 68, 69, 92], "occupation_adm": 44, "occupation_arm": 44, "occupation_craft": 44, "occupation_exec": 44, "occupation_farm": [26, 44, 45, 69], "occupation_handl": 44, "occupation_machin": 44, "occupation_miss": [26, 44, 45, 69], "occupation_oth": 44, "occupation_priv": [26, 44, 45, 69], "occupation_prof": 44, "occupation_protect": 44, "occupation_sal": 44, "occupation_tech": 44, "occupation_transport": 44, "occupi": 98, "occur": [9, 14, 19, 34, 51, 59, 60, 63, 77, 82], "occurr": [31, 34, 50, 51, 74, 77, 98], "ocean": [18, 27, 46, 62, 63, 70, 93], "ocean_proxim": [18, 27, 46, 62, 63, 70, 87, 93], "ocean_proximity_": [18, 62, 93], "ocean_proximity_inland": [18, 62, 93], "ocean_proximity_island": [18, 62, 93], "ocean_proximity_near": [18, 62, 93], "oct": 1, "octob": [15, 37, 52, 76, 96], "odd": [31, 50, 58, 74], "odditi": 58, "oe": [19, 63, 84], "oe_encod": 84, "off": [12, 20, 21, 22, 23, 24, 27, 28, 32, 34, 35, 38, 41, 42, 43, 47, 48, 51, 53, 54, 55, 58, 64, 65, 66, 67, 70, 71, 75, 77, 78, 82, 84], "off_shelf": [88, 94], "offens": 4, "offer": [9, 20, 25, 30, 34, 40, 44, 51, 68, 73, 77, 98], "offic": [4, 5, 6, 11, 31, 74, 84, 98], "offici": [5, 11, 31, 50, 51, 74, 98], "offlin": [30, 49, 73], "offset": [21, 64], "often": [5, 9, 13, 15, 16, 18, 19, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 35, 41, 42, 44, 45, 46, 49, 50, 51, 52, 55, 56, 57, 58, 60, 61, 62, 63, 64, 65, 66, 68, 69, 70, 71, 72, 73, 74, 75, 76, 78, 79, 83, 84, 86, 92, 95], "ogunrind": 58, "oh": [1, 17, 26, 27, 32, 33, 34, 39, 45, 46, 52, 53, 58, 69, 70, 75, 76, 77, 79, 84, 90, 96, 98], "ohe_column": [24, 26, 35, 43, 54, 55, 67, 78], "ohe_enc": [19, 63], "ohe_encod": 84, "ohe_feat": [17, 39], "ohe_feat_nam": [17, 39], "ohe_feature_nam": [26, 52, 76, 90, 96], "ohehotencod": [19, 63], "ois": [29, 72], "ok": [13, 16, 24, 33, 34, 43, 52, 53, 56, 57, 58, 61, 67, 76, 77, 79, 84, 90, 96], "okai": [56, 57, 71, 79], "ola": [51, 82], "old": [10, 20, 40, 44, 45, 58, 68, 69], "old_cent": [28, 71], "older": [24, 43, 67], "oldpeak": [88, 94], "olymp": 9, "omit": [26, 45, 69], "omnibu": 58, "omp_num_thread": [13, 32], "omw": [51, 82], "onc": [1, 6, 7, 8, 9, 11, 14, 15, 18, 19, 22, 27, 29, 30, 31, 32, 38, 46, 49, 50, 51, 56, 57, 58, 59, 60, 62, 63, 65, 70, 72, 73, 74, 75, 79, 82, 88, 94, 98], "onca": [32, 58, 75], "one": [5, 6, 7, 9, 10, 11, 13, 14, 15, 16, 17, 18, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33, 34, 35, 37, 38, 39, 41, 42, 43, 44, 45, 49, 50, 51, 52, 53, 55, 58, 59, 60, 61, 62, 64, 65, 66, 67, 68, 69, 71, 72, 73, 74, 75, 76, 77, 78, 80, 81, 82, 83, 84, 86, 88, 89, 90, 92, 94, 95, 96, 98], "one_c": [16, 61], "one_ex_preprocess": [26, 45, 69], "one_ex_preprocessed_perturb": [26, 45, 69], "one_exampl": [26, 45, 69], "one_example_perturb": [26, 45, 69], "onedr": 32, "onehot": [19, 27, 46, 63, 70], "onehotencod": [17, 18, 21, 22, 24, 25, 26, 27, 33, 34, 35, 39, 41, 43, 44, 45, 46, 52, 53, 54, 55, 62, 64, 65, 66, 67, 68, 69, 70, 76, 77, 78, 84, 87, 88, 90, 93, 94, 96], "onehotencoder__major_biologi": [19, 63], "onehotencoder__major_comput": [19, 63], "onehotencoder__major_econom": [19, 63], "onehotencoder__major_linguist": [19, 63], "onehotencoder__major_mathemat": [19, 63], "onehotencoder__major_mechan": [19, 63], "onehotencoder__major_phys": [19, 63], "onehotencoder__major_psychologi": [19, 63], "onehotencoder__ocean_proximity_": 63, "onehotencoder__ocean_proximity_inland": 63, "onehotencoder__ocean_proximity_island": 63, "onehotencoder__ocean_proximity_near": 63, "onehotencoderonehotencod": [17, 19, 22, 24, 25, 35, 43, 54, 55, 78], "ones": [9, 16, 18, 25, 26, 28, 30, 31, 34, 37, 38, 45, 49, 50, 51, 58, 61, 62, 68, 69, 71, 73, 74, 86, 88, 92, 94], "onevsoneclassifi": 83, "onevsrestclassifi": 83, "onli": [2, 4, 5, 6, 9, 13, 14, 15, 16, 17, 18, 20, 21, 22, 23, 25, 26, 27, 28, 29, 30, 31, 32, 33, 35, 38, 39, 40, 41, 42, 44, 45, 46, 49, 50, 51, 52, 53, 55, 58, 59, 60, 61, 62, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 78, 79, 81, 82, 84, 86, 87, 91, 92, 93, 98], "onlin": [3, 6, 8, 14, 28, 31, 50, 51, 59, 74, 98], "online_act": 28, "onlinebackup": [34, 53, 77], "onlinebackup_no": [34, 53, 77], "onlinebackup_y": [34, 53, 77], "onlinesecur": [34, 53, 77], "onlinesecurity_no": [34, 53, 77], "onlinesecurity_y": [34, 53, 77], "onrend": 79, "ontario": [31, 50, 51, 74], "ontonot": 51, "oob_scor": [35, 44, 55, 68, 78, 94], "op": [44, 66], "open": [5, 6, 7, 13, 32, 56, 57, 58, 75, 79, 98], "openai": [31, 50, 74], "openai_api_kei": [50, 74], "openporchsf": [24, 26, 35, 43, 45, 54, 55, 67, 69, 78], "oper": [4, 6, 9, 11, 19, 27, 31, 46, 50, 51, 63, 70, 74, 79], "opera": [20, 40], "operand": 9, "opinion": [25, 44, 58, 68], "opportun": [15, 30, 37, 49, 73, 98], "oppos": [24, 25, 43, 44, 67, 68], "opposit": [9, 24, 25, 26, 44, 67, 68, 69, 90, 93, 96], "opt": [25, 44, 68], "optic": [34, 53, 77], "optim": [1, 2, 14, 16, 20, 23, 25, 26, 27, 28, 29, 32, 34, 35, 38, 40, 42, 44, 45, 55, 59, 60, 61, 63, 66, 68, 69, 70, 71, 72, 75, 77, 78, 79], "optimist": [22, 31, 50, 65, 74], "optimized_c": [20, 40], "option": [1, 8, 9, 14, 24, 25, 35, 43, 50, 51, 55, 59, 67, 70, 71, 74, 76, 78, 88, 90, 94, 96, 98], "oral": 98, "orang": [21, 64], "ord_enc": 17, "ord_imput": 17, "order": [6, 8, 9, 13, 14, 15, 17, 18, 19, 20, 21, 22, 23, 24, 26, 28, 29, 30, 31, 33, 34, 35, 39, 40, 41, 42, 43, 45, 50, 51, 54, 55, 58, 59, 60, 62, 63, 64, 65, 66, 67, 69, 70, 71, 72, 73, 74, 76, 78, 79, 82, 84, 89, 95], "ordering_ordinal_oth": [24, 26, 35, 43, 45, 54, 55, 67, 69, 78], "ordering_ordinal_reg": [24, 26, 35, 43, 45, 54, 55, 67, 69, 78], "ordin": [24, 43, 67, 84, 87, 93], "ordinal_feat": [17, 19, 39, 63], "ordinal_featur": [25, 26, 44, 45, 66, 68, 69], "ordinal_features_oth": [24, 26, 35, 43, 45, 54, 55, 67, 69, 78], "ordinal_features_reg": [24, 26, 35, 43, 45, 54, 55, 67, 69, 78], "ordinal_transform": [17, 25, 26, 39, 44, 45, 66, 68, 69], "ordinal_transformer_oth": [24, 26, 35, 43, 45, 54, 55, 67, 69, 78], "ordinal_transformer_reg": [24, 26, 35, 43, 45, 54, 55, 67, 69, 78], "ordinalencod": [17, 18, 19, 24, 25, 26, 27, 33, 34, 35, 39, 43, 44, 45, 46, 52, 53, 54, 55, 62, 63, 66, 67, 68, 69, 70, 76, 77, 78, 84, 87, 88, 90, 93, 94, 96], "ordinalencoder__class_attend": 63, "ordinalencoderordinalencod": [17, 19, 24, 25, 35, 43, 54, 55, 78], "ordinari": [24, 43, 58, 67], "oreilli": [32, 33, 75, 76], "org": [10, 15, 17, 18, 19, 20, 22, 23, 24, 25, 26, 27, 32, 35, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 51, 54, 55, 58, 60, 62, 63, 65, 66, 67, 68, 69, 70, 75, 78, 82, 94], "organ": [14, 18, 31, 35, 51, 55, 59, 62, 74, 78, 79], "orgin": 9, "orig_featur": [52, 76, 90, 96], "orig_pr": [26, 45, 69], "orig_scor": 66, "origin": [13, 17, 18, 19, 25, 26, 30, 31, 32, 34, 44, 45, 49, 50, 51, 52, 53, 62, 63, 66, 68, 69, 70, 71, 73, 74, 75, 76, 77, 80, 86, 89, 90, 92, 95, 96, 98], "original_hm": [56, 57, 79, 80], "ornithorhynchu": [32, 75], "oscar": [21, 64], "osp_misc": 77, "ostblom": [51, 82], "other": [0, 1, 4, 5, 6, 7, 8, 11, 13, 14, 15, 17, 18, 19, 20, 21, 22, 23, 25, 26, 29, 30, 31, 32, 37, 38, 39, 40, 41, 42, 44, 45, 47, 49, 50, 54, 56, 57, 58, 59, 60, 62, 63, 64, 65, 66, 68, 69, 70, 72, 73, 74, 75, 79, 83, 84, 86, 88, 89, 90, 92, 94, 95, 96, 98], "otherwis": [0, 8, 11, 19, 32, 58, 63, 75, 98], "ouid": 22, "ounc": [32, 58, 75], "our": [5, 6, 7, 9, 13, 14, 15, 16, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 37, 38, 39, 40, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 59, 61, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 80, 82, 84, 85, 86, 87, 88, 89, 90, 91, 92, 94, 95, 96, 98], "ourselv": [14, 23, 32, 42, 51, 52, 59, 66, 75, 76, 82], "out": [0, 1, 4, 5, 8, 9, 13, 14, 15, 16, 17, 19, 20, 22, 23, 24, 25, 26, 28, 29, 30, 31, 33, 34, 37, 39, 41, 42, 43, 44, 45, 47, 49, 50, 51, 52, 53, 56, 57, 58, 59, 60, 61, 63, 65, 66, 67, 68, 69, 71, 72, 73, 74, 76, 77, 80, 81, 82, 84, 86, 88, 90, 92, 94, 96, 98], "out_col": [18, 60, 62], "out_step": 80, "outburst": 40, "outcom": 43, "outdat": 11, "outlier": [17, 24, 29, 39, 43, 67, 72, 79, 84], "outlook": 34, "output": [5, 8, 9, 13, 14, 15, 17, 19, 21, 23, 25, 26, 31, 32, 33, 34, 35, 39, 42, 44, 45, 47, 48, 50, 51, 55, 58, 59, 60, 63, 64, 66, 68, 69, 74, 75, 76, 78, 79, 84, 88, 90, 94, 96], "outset": 58, "outsid": [8, 21, 23, 25, 26, 30, 31, 33, 34, 42, 44, 45, 49, 50, 51, 66, 68, 69, 73, 74, 76, 77], "outstand": 58, "over": [20, 22, 24, 31, 32, 33, 34, 35, 43, 50, 51, 53, 55, 58, 60, 65, 67, 74, 75, 76, 77, 78, 79, 82, 84, 98], "over_confident_i": [21, 64], "over_confident_x": [21, 64], "over_sampl": 80, "overal": [8, 17, 20, 26, 28, 31, 32, 35, 39, 40, 45, 47, 51, 55, 66, 69, 71, 74, 75, 78, 84, 88, 94, 98], "overallcond": [24, 26, 35, 43, 45, 54, 55, 67, 69, 78], "overallqu": [24, 26, 35, 43, 45, 54, 55, 67, 69, 78], "overconfid": [26, 27, 45, 46, 69, 70, 79, 81], "overfit": [1, 12, 16, 20, 21, 24, 25, 27, 37, 38, 39, 40, 43, 44, 46, 61, 64, 67, 68, 70, 79, 86, 88, 92, 94], "overflow": 8, "overhead": [19, 34, 63], "overlap": [2, 15, 21, 28, 60, 71, 79], "overli": [16, 22, 38, 61, 65, 86, 92], "overload": [30, 34, 73, 77], "overpredict": [24, 67], "oversampl": 66, "oversample_pip": 80, "overshadow": [31, 50, 51, 74], "overst": [35, 55, 78], "overus": [25, 44, 68, 98], "overview": [13, 28, 29, 30, 49, 51, 58, 71, 72, 73], "overwhelm": 71, "overzeal": 7, "ovr": [41, 42, 63, 65], "own": [4, 9, 11, 13, 18, 23, 24, 26, 27, 28, 29, 30, 31, 32, 33, 35, 42, 43, 45, 46, 50, 51, 52, 54, 55, 56, 57, 58, 60, 62, 66, 67, 69, 70, 71, 72, 74, 75, 76, 78, 79, 82, 83, 98], "oz": [20, 40], "p": [11, 20, 21, 29, 34, 38, 39, 40, 41, 48, 51, 62, 63, 64, 65, 72, 77, 79, 82, 94], "p_i": [28, 71], "p_value_threshold": [34, 77], "pace": [5, 20, 21, 31, 50, 51, 58, 64, 71, 74], "packag": [6, 9, 11, 12, 14, 16, 18, 19, 22, 23, 25, 26, 28, 29, 30, 31, 32, 34, 41, 42, 45, 50, 51, 53, 56, 57, 59, 60, 63, 65, 66, 69, 71, 72, 73, 74, 75, 77, 79, 82, 83], "packagenam": 11, "packet": 95, "pad": [32, 38, 47, 48, 75], "page": [1, 4, 8, 13, 15, 17, 18, 19, 20, 22, 23, 24, 25, 26, 27, 31, 32, 35, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 50, 51, 54, 55, 58, 62, 63, 65, 66, 67, 68, 69, 70, 74, 75, 78, 82, 86, 88, 89, 92, 94, 95, 98], "pai": [26, 27, 31, 44, 50, 58, 69, 74, 79], "paid": [27, 58], "pain": [4, 32, 35, 52, 55, 75, 76, 78, 90, 96], "paint": [25, 58], "pair": [14, 29, 31, 50, 51, 58, 72, 74, 83], "pairwis": [16, 29, 31, 48, 50, 61, 72, 74], "paladin": 20, "palett": 11, "panda": [10, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 31, 32, 33, 34, 35, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 74, 75, 76, 77, 78, 79, 80, 81, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96], "pane": [16, 61, 86, 92], "panel": [16, 23, 26, 28, 29, 38, 42, 45, 61, 66, 69, 71, 72, 86, 92], "panther": [32, 58, 75], "panthera": [32, 58, 75], "papa": 58, "paper": [8, 26, 27, 31, 32, 34, 45, 46, 50, 51, 53, 69, 70, 74, 75, 77, 79, 80], "paperlessbil": [34, 53, 77], "paperlessbilling_no": [34, 53, 77], "paperlessbilling_y": [34, 53, 77], "paradigm": [13, 14, 28, 51, 58, 59, 71], "paradox": [30, 49, 73], "paragraph": [31, 50, 51, 74], "paraleg": [31, 50, 51, 74], "parallel": [19, 22, 25, 31, 32, 34, 41, 44, 50, 63, 65, 68, 74], "paralleln": 32, "param": [16, 19, 22, 24, 34, 41, 61, 63, 65, 86, 92], "param_columntransformer__countvectorizer__max_featur": [22, 41, 65], "param_dist": [22, 41, 65], "param_distribut": [22, 41, 65], "param_grid": [16, 22, 24, 35, 41, 43, 55, 60, 61, 65, 67, 78], "param_grid1": [22, 41, 65], "param_grid2": [22, 41, 65], "param_grid3": [22, 41, 65], "param_grid4": [22, 41, 65], "param_ridge__alpha": [24, 43, 67], "param_svc__c": [22, 41, 65], "param_svc__gamma": [22, 41, 65], "paramet": [16, 18, 19, 25, 28, 29, 31, 32, 33, 34, 35, 37, 38, 39, 40, 42, 44, 45, 50, 51, 52, 55, 61, 62, 63, 67, 68, 69, 71, 72, 74, 75, 76, 77, 78, 85, 86, 88, 90, 91, 92, 94, 96], "parametr": [29, 72], "params_": [34, 53, 77], "params_str": [22, 41, 65], "paramter": [16, 61], "parapsychologist": 40, "pardu": [32, 58, 75], "parent": [20, 29, 40, 72], "park": [27, 32, 46, 70, 75, 79], "pars": [51, 82], "parse_d": [9, 33, 52, 76, 90, 96], "parser": [31, 50, 51, 74], "part": [1, 4, 10, 18, 20, 21, 22, 23, 25, 26, 27, 29, 31, 32, 33, 35, 41, 42, 44, 45, 46, 50, 51, 52, 55, 56, 57, 58, 62, 63, 64, 65, 66, 68, 69, 70, 72, 74, 75, 76, 78, 79, 81, 82, 88, 94, 98], "part1": [30, 49, 73], "part2": [30, 49, 73], "parti": [31, 50, 51, 58, 74], "partial": [4, 34, 35, 53, 55, 77, 78], "partial_fit": 34, "particip": [5, 13, 98], "particular": [0, 10, 15, 18, 19, 22, 25, 26, 27, 28, 30, 31, 32, 33, 34, 35, 39, 41, 44, 49, 50, 51, 52, 55, 56, 57, 58, 62, 63, 65, 66, 68, 69, 71, 73, 74, 75, 76, 77, 78, 79, 80, 81, 86, 92], "particularli": [25, 30, 31, 44, 50, 58, 68, 73, 74, 89, 92, 95], "partit": [19, 28, 29, 63, 71, 72], "partner": [34, 53, 77, 98], "partner_no": [34, 53, 77], "partner_y": [34, 53, 77], "pass": [9, 15, 16, 17, 18, 19, 21, 23, 24, 25, 26, 27, 28, 31, 32, 39, 42, 43, 44, 45, 46, 47, 50, 51, 58, 60, 61, 62, 63, 64, 66, 67, 68, 69, 70, 71, 74, 75, 86, 92, 98], "passthrough": [19, 22, 34, 41, 53, 63, 65, 77, 88, 89, 94, 95], "passthrough__ml_experi": [19, 63], "passthrough_feat": [19, 22, 41, 63, 65, 84], "passthrough_featur": [34, 53, 77, 88, 94], "passthroughpassthrough": [19, 22], "passthroughpassthroughcountvectorizersong_titlecountvector": [41, 65], "passthroughpassthroughdecisiontreeclassifi": 94, "passthroughpassthroughkneighborsclassifi": 94, "passthroughpassthroughlgbmclassifi": 94, "passthroughpassthroughlogisticregress": 94, "passthroughpassthroughonehotencod": 63, "passthroughpassthroughrandomforestclassifi": 94, "password": 6, "past": [5, 14, 15, 33, 34, 35, 54, 55, 58, 59, 60, 68, 76, 77, 78, 84, 90, 96, 98], "pat": [6, 30, 49, 73], "pat_i": [30, 49, 73], "pat_model": [30, 49, 73], "pat_x": [30, 49, 73], "pata": [32, 58, 75], "path": [9, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96], "patial": [29, 72], "patient": [14, 59, 79, 88, 94], "patio": [32, 75], "patric": [26, 45, 69], "pattern": [13, 14, 15, 19, 22, 28, 31, 32, 33, 35, 37, 50, 51, 52, 54, 55, 58, 59, 60, 63, 65, 70, 71, 74, 75, 76, 78, 86, 90, 92, 96], "paul": 25, "paus": [13, 58], "pav_bhaji": 51, "pave": [24, 26, 35, 43, 45, 54, 55, 67, 69, 78], "paveddr": [24, 26, 35, 43, 45, 54, 55, 67, 69, 78], "paveddrive_i": [24, 67, 69], "paveddrive_n": [24, 67, 69], "paveddrive_p": [24, 67, 69], "paydai": 95, "payment": 27, "paymentmethod": [27, 34, 53, 77], "paymentmethod_bank": [34, 53, 77], "paymentmethod_credit": [34, 53, 77], "paymentmethod_electron": [34, 53, 77], "paymentmethod_mail": [34, 53, 77], "pca": [23, 29, 30, 42, 49, 66, 72, 73], "pcarter": 10, "pd": [9, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96], "pdf": [8, 10], "peac": [31, 50, 51, 74], "peanut": 95, "peanutyalmondi": 95, "pearceraaf": 96, "pedest": [32, 58, 75], "pedro": [1, 27, 60, 70], "peek": [50, 60, 74, 90, 96], "peer": [5, 58, 79, 98], "pembrok": [32, 58, 75], "penal": [7, 34, 53, 77], "penalti": [31, 40, 42, 44, 50, 51, 66, 68, 74, 75, 94, 98], "penrith": 96, "peopl": [4, 14, 15, 18, 20, 21, 25, 28, 30, 31, 32, 33, 34, 35, 39, 48, 49, 50, 51, 53, 55, 56, 57, 59, 60, 62, 64, 66, 68, 71, 73, 74, 75, 76, 77, 78, 79, 84, 86, 92, 98], "per": [5, 9, 21, 24, 25, 26, 28, 30, 31, 32, 35, 43, 44, 45, 49, 50, 52, 54, 55, 64, 66, 67, 68, 69, 73, 74, 75, 76, 78, 83, 84, 90, 96], "perceiv": 7, "percent": [24, 43, 67], "percent_error": [24, 43, 67], "percentag": [14, 30, 35, 55, 59, 66, 73, 78, 89, 95], "perfect": [7, 14, 15, 20, 23, 24, 26, 30, 34, 37, 38, 40, 42, 43, 45, 49, 53, 58, 59, 60, 66, 67, 69, 73, 77], "perfectli": [2, 49, 51, 58, 73], "perform": [12, 13, 14, 15, 16, 17, 18, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 33, 35, 37, 38, 41, 42, 43, 44, 45, 46, 50, 51, 55, 56, 57, 58, 59, 60, 61, 62, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 76, 78, 79, 80, 84, 85, 87, 88, 90, 91, 93, 94, 96], "performac": 60, "perhap": [24, 33, 43, 52, 58, 67, 76, 83], "perimet": [27, 46, 70], "period": [33, 34, 51, 58, 76, 77, 82, 90, 96, 98], "perm_sorted_idx": [26, 45, 69], "perman": 9, "permiss": [0, 98], "permit": [0, 17, 18, 62, 66, 98], "permut": [26, 69], "perpetu": 40, "perplex": [31, 74], "persist": [30, 49, 73], "person": [0, 1, 4, 6, 7, 11, 13, 23, 30, 31, 32, 33, 34, 42, 50, 51, 52, 53, 58, 66, 71, 74, 75, 76, 77, 79, 82, 98], "perspect": [25, 30, 44, 68, 73], "perth": 96, "perthairport": [52, 76, 96], "perturb": [17, 26, 29, 39, 45, 69, 72], "perturbed_pr": [26, 45, 69], "pertwe": 20, "perus": 58, "pete_seeg": [31, 50, 51, 74], "peter": [1, 20], "petter": [20, 40], "ph": [51, 82], "pharma": 79, "phascolarcto": [32, 75], "phase": [15, 60], "phd": [51, 82], "phdei": [34, 77], "phenomenon": [30, 34, 49, 73, 77, 86, 92], "philosoph": 51, "phone": [34, 53, 58, 77, 98], "phoneservic": [34, 53, 77], "phoneservice_no": [34, 53, 77], "phoneservice_y": [34, 53, 77], "photo": [13, 58, 84], "photograph": 98, "phrase": [31, 50, 51, 74], "physic": [19, 33, 63, 76], "pi": 9, "piazza": [1, 8, 13], "pick": [14, 21, 23, 26, 27, 28, 29, 32, 35, 37, 41, 42, 44, 45, 46, 54, 55, 56, 57, 59, 64, 66, 68, 69, 70, 71, 72, 75, 78, 79, 80, 81, 83, 85, 86, 88, 91, 92, 94], "pictur": [25, 26, 29, 31, 32, 33, 35, 44, 45, 51, 55, 58, 66, 68, 69, 72, 74, 75, 76, 78], "pid": [16, 25, 26, 28], "pie": 9, "piec": [21, 31, 34, 50, 58, 64, 74, 77], "pierr": 20, "pil": [13, 38, 47, 48, 58], "pimpl": 58, "pin": [8, 32, 75], "pineappl": [31, 50, 51, 74, 82], "pip": [11, 26, 31, 32, 45, 50, 51, 56, 57, 69, 74, 75, 79], "pipe": [17, 18, 19, 21, 22, 23, 31, 41, 42, 44, 50, 51, 62, 63, 64, 65, 66, 68, 74], "pipe_bestalpha": [24, 43, 67], "pipe_bigalpha": [24, 43, 67], "pipe_catboost": [25, 44, 68], "pipe_dt": [25, 26, 44, 45, 68, 69, 88, 94], "pipe_forward": [27, 81], "pipe_knn": [17, 39, 88, 94], "pipe_lgbm": [25, 26, 44, 45, 68, 69, 88, 94], "pipe_lr": [20, 23, 25, 26, 40, 42, 44, 45, 56, 57, 66, 68, 69, 75, 79, 80, 88, 94], "pipe_lr_all_feat": [27, 46, 70], "pipe_lr_balanc": 66, "pipe_lr_model_bas": [27, 46, 70], "pipe_lr_weight": 66, "pipe_ohe_knn": [17, 39], "pipe_ordinal_knn": [17, 39], "pipe_rf": [25, 26, 44, 45, 68, 69, 88, 94], "pipe_rf_demo": [25, 44, 68], "pipe_ridg": [21, 24, 43, 64, 67], "pipe_sklearn_gb": [25, 44, 68], "pipe_sklearn_histgb": [25, 44, 68], "pipe_smallalpha": [24, 43, 67], "pipe_svc": [23, 42, 66], "pipe_svm": [22, 41, 65], "pipe_xgb": [25, 26, 44, 45, 68, 69], "pipe_xor": [27, 46, 70], "pipelin": [1, 2, 12, 13, 15, 19, 20, 21, 22, 23, 24, 25, 26, 27, 32, 33, 34, 35, 40, 41, 42, 43, 44, 45, 46, 52, 53, 54, 55, 56, 57, 58, 60, 63, 64, 65, 66, 67, 68, 69, 70, 75, 76, 77, 78, 79, 80, 81, 82, 87, 88, 89, 90, 93, 94, 95, 96], "pipeline__bedrooms_per_household": 63, "pipeline__household": 63, "pipeline__housing_median_ag": 63, "pipeline__lab1": [19, 63], "pipeline__lab2": [19, 63], "pipeline__lab3": [19, 63], "pipeline__lab4": [19, 63], "pipeline__latitud": 63, "pipeline__longitud": 63, "pipeline__median_incom": 63, "pipeline__population_per_household": 63, "pipeline__quiz1": [19, 63], "pipeline__rooms_per_household": [27, 46, 63, 70], "pipeline__university_year": [19, 63], "pipelinecolumntransform": [41, 65], "pipelineifit": [40, 42, 62, 63, 65], "pipelineifittedpipelin": [17, 18, 19, 20, 22, 23, 27, 46, 66, 70], "pipelineinot": [22, 24, 41, 63, 65, 67], "pipelinepipelin": 22, "piper": 58, "pitch": [35, 55, 78], "pitfal": [33, 35, 76, 78], "pitt": 20, "pixel": [26, 32, 45, 69, 75], "pizza": [32, 51, 58, 75], "pla": [31, 50, 51, 74], "place": [14, 20, 33, 51, 52, 58, 66, 76, 89, 95, 98], "plagiar": [13, 58], "plai": [13, 14, 16, 20, 22, 26, 29, 31, 32, 41, 45, 50, 51, 58, 59, 61, 65, 69, 72, 74, 75, 85, 86, 91, 92], "plain": [28, 71], "plan": [13, 24, 25, 34, 43, 46, 53, 58, 67, 70, 77, 79, 87, 88, 93, 94, 98], "plane": [14, 21, 64], "plant": 84, "plaster": 40, "plastic": 51, "platform": [4, 6, 7, 11], "platypu": [32, 75], "plausibl": [31, 50, 74], "player": [26, 31, 32, 45, 50, 51, 69, 74, 75], "pleas": [1, 4, 5, 8, 13, 15, 17, 18, 19, 20, 22, 23, 24, 25, 26, 27, 32, 35, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 54, 55, 58, 62, 63, 65, 66, 67, 68, 69, 70, 75, 78, 94, 98], "plenti": 20, "plinth": [32, 75], "plot": [8, 14, 15, 16, 17, 18, 20, 21, 22, 23, 24, 27, 29, 30, 31, 32, 33, 35, 37, 38, 39, 40, 41, 42, 43, 46, 49, 50, 51, 52, 54, 55, 58, 59, 60, 61, 62, 64, 65, 66, 67, 70, 72, 73, 74, 75, 76, 78, 79, 85, 86, 89, 90, 91, 92, 95, 96, 97], "plot_2d_scor": [21, 64], "plot_2d_separ": [16, 21, 38, 61, 64, 86, 92], "plot_coeff_exampl": [20, 40], "plot_confusion_matrix": 66, "plot_confusion_matrix_exampl": [23, 42, 66], "plot_cross_valid": [15, 33, 60, 76], "plot_dbscan": [29, 72], "plot_dbscan_with_label": [29, 72], "plot_dendrogram_clust": [29, 72], "plot_distribut": [41, 65], "plot_elbow": [28, 71], "plot_example_dist": [28, 71], "plot_fruit_tre": 59, "plot_grid_search_overview": [22, 41, 65], "plot_improper_process": [17, 39], "plot_k_means_dbscan_comparison": [29, 72], "plot_km_initi": [28, 71], "plot_km_it": [28, 71], "plot_km_iter": [28, 71], "plot_kmean": [29, 72], "plot_knn_clf": [16, 61], "plot_knn_decision_boundari": [16, 61], "plot_knn_regress": [16, 61], "plot_lda_w_vector": [50, 51, 74], "plot_linkage_criteria": [29, 72], "plot_logistic_regress": [21, 64], "plot_logistic_regression_graph": [32, 75], "plot_loss_diagram": [35, 55, 78], "plot_multiclass_lr_ovr": 83, "plot_original_clust": [29, 72], "plot_partial_effects_on_outcom": [34, 53, 77], "plot_proper_process": [17, 39], "plot_result": [16, 38, 61, 86, 92], "plot_sample_img": [38, 47, 48], "plot_scal": [18, 62], "plot_silhouette_dist": [28, 71], "plot_single_hidden_layer_graph": [32, 75], "plot_support_vector": [16, 61], "plot_survival_funct": [34, 53, 77], "plot_svc_c": [16, 61], "plot_svc_gamma": [16, 61], "plot_time_spacing_distribut": [52, 76, 90, 96], "plot_train_test_point": [16, 61], "plot_tre": [15, 37], "plot_tree_decision_boundari": [60, 85, 91], "plot_tree_decision_boundary_and_tre": [14, 15, 59, 60, 85, 91], "plot_two_hidden_layer_graph": [32, 75], "plot_typ": [26, 45, 69], "plot_x_dendrogram": [29, 72], "plotli": [27, 46, 50, 51, 70, 74], "plotting_funct": [14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 25, 26, 28, 29, 30, 32, 35, 37, 38, 39, 40, 41, 42, 44, 45, 47, 49, 54, 55, 59, 60, 61, 62, 63, 64, 65, 66, 68, 69, 71, 72, 73, 75, 78, 80, 81, 83, 85, 86, 87, 88, 91, 92, 93, 94], "plotting_functions_unsup": [28, 29, 30, 31, 47, 48, 49, 50, 51, 71, 72, 73, 74], "plt": [9, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 32, 33, 34, 35, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 52, 53, 54, 55, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 75, 76, 77, 78, 80, 81, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97], "plu": [20, 21, 32, 64, 75], "plural": [19, 63], "pluribu": 95, "pm": [1, 13, 52, 76, 90, 96, 98], "pmltt": 1, "pn": [16, 23, 28, 29, 38, 42, 61, 66, 71, 72, 86, 92], "po": [13, 20, 21, 24, 26, 31, 35, 40, 43, 45, 50, 51, 54, 55, 62, 64, 67, 69, 74, 78, 82], "pobox": 58, "poet": [31, 50, 51, 74], "point": [1, 4, 5, 12, 13, 14, 15, 17, 18, 19, 20, 21, 22, 24, 27, 29, 34, 35, 37, 39, 41, 43, 46, 47, 48, 53, 55, 58, 59, 60, 62, 63, 64, 65, 67, 70, 72, 77, 78, 79, 80, 83, 84, 86, 92, 98], "point_ind": [28, 71], "point_index": [28, 71], "poison": 17, "pole": [32, 75], "polic": 58, "polici": [3, 4, 5, 8, 13, 98], "polit": [30, 31, 32, 49, 50, 51, 58, 73, 74, 75], "politician": 58, "poll": 35, "poly_transform": [33, 76], "polynomialfeatur": [27, 33, 46, 70, 76], "pomegran": [32, 75], "ponder": 58, "pool": [1, 40], "poolarea": [24, 26, 35, 43, 45, 54, 55, 67, 69, 78], "poolqc": [24, 26, 35, 43, 45, 54, 55, 67, 69, 78], "poor": [19, 24, 27, 43, 46, 63, 67, 70, 84, 87, 93], "poorli": [16, 20, 24, 29, 33, 43, 61, 67, 72, 76], "pop": 95, "pope": [31, 51, 74], "popen": [16, 25, 26, 28], "popenarg": [16, 25, 26, 28], "popul": [18, 21, 27, 33, 46, 62, 63, 64, 70, 76, 87, 93], "popular": [9, 12, 16, 18, 19, 21, 23, 24, 25, 28, 29, 30, 31, 32, 35, 42, 43, 44, 45, 49, 50, 51, 54, 55, 60, 61, 62, 63, 64, 66, 67, 68, 69, 71, 72, 73, 74, 75, 78, 82, 89, 95], "population_per_household": [18, 62, 63, 87, 93], "port": [56, 57, 79], "portent": 58, "porter": [20, 51, 82], "porterstemm": [51, 82], "portion": [0, 15, 18, 20, 22, 24, 26, 35, 40, 43, 45, 54, 55, 60, 62, 65, 67, 69, 78, 88, 90, 94, 96], "portland": 96, "portrai": 58, "portrait": [20, 40], "portug": [26, 45, 66, 69], "pos_": [31, 50, 51, 74, 82], "pos_label": 67, "pos_prob": [20, 40], "posit": [13, 15, 16, 21, 24, 25, 26, 31, 32, 33, 34, 43, 44, 45, 50, 51, 52, 53, 58, 59, 60, 61, 62, 64, 67, 68, 69, 74, 75, 76, 77, 90, 96], "posix": [34, 77], "possess": [55, 78], "possibl": [4, 6, 7, 9, 13, 14, 15, 17, 18, 20, 22, 23, 25, 26, 27, 29, 30, 32, 34, 35, 37, 39, 40, 42, 44, 45, 46, 47, 49, 51, 54, 55, 58, 59, 60, 62, 65, 66, 68, 69, 70, 72, 73, 75, 77, 78, 82, 84, 86, 87, 89, 92, 93, 95, 98], "possibli": [8, 31, 50, 51, 74, 95], "post": [1, 4, 7, 8, 9, 13, 26, 31, 33, 50, 51, 52, 56, 57, 74, 76, 79, 98], "postprocess": [32, 75], "postur": 58, "potenti": [12, 16, 18, 28, 31, 35, 37, 50, 51, 55, 56, 57, 61, 62, 71, 74, 78, 79], "powder": [31, 51, 74], "powel": 58, "power": [9, 15, 17, 25, 30, 31, 32, 35, 39, 40, 50, 51, 54, 55, 60, 68, 73, 74, 75, 78, 82], "pplicat": [29, 72], "pr": 84, "practic": [0, 1, 5, 7, 10, 13, 15, 17, 18, 27, 32, 35, 54, 55, 58, 60, 62, 66, 70, 75, 78, 79, 84, 86, 87, 89, 92, 93, 95, 98], "practition": [35, 55, 78], "prai": 58, "prairielearn": [1, 5, 7, 13, 98], "pre": [1, 5, 13, 25, 27, 35, 38, 44, 46, 47, 51, 54, 55, 58, 68, 70, 78, 79, 84], "pre_dispatch": [41, 65], "precipit": 79, "precis": [12, 24, 35, 67, 78, 79, 80, 84], "precision_lr": [23, 42, 66], "precision_recall_curv": [23, 42, 66], "precision_scor": [23, 42, 66], "precision_svc": [23, 42, 66], "precisionrecallcurvedisplai": [23, 42, 66], "precisionrecalldisplai": [23, 42, 66], "pred": [23, 24, 30, 33, 34, 42, 43, 49, 53, 66, 67, 73, 76, 77, 80], "pred_df": [13, 30, 49, 58, 73], "pred_dict": [13, 58], "pred_g": [30, 49, 73], "pred_lin_reg": [30, 49, 73], "pred_train": [24, 43, 67], "pred_x": [30, 49, 73], "prediciton": [34, 53, 77], "predict": [2, 12, 15, 16, 17, 18, 19, 20, 22, 23, 24, 25, 27, 28, 29, 33, 35, 37, 39, 40, 41, 42, 43, 46, 51, 52, 55, 56, 57, 60, 61, 62, 65, 66, 67, 70, 71, 72, 76, 78, 79, 80, 81, 84, 86, 87, 88, 89, 90, 92, 93, 94, 95, 96, 97], "predict_expect": [34, 53, 77], "predict_for_usr": [30, 49, 73], "predict_prob": 94, "predict_proba": [20, 23, 25, 26, 32, 40, 42, 44, 45, 66, 68, 69, 75, 83, 88, 94], "predict_survival_funct": [34, 53, 77], "predicted_categori": [56, 57, 79, 80], "predicted_n_rent": [33, 76], "predicted_quiz2": [14, 59], "predicted_sal": [33, 76], "predicted_target": [13, 58], "predicted_valu": 97, "predictor": [14, 59, 84], "preexec_fn": [16, 25, 26, 28], "prefer": [6, 11, 13, 25, 28, 30, 44, 49, 58, 68, 71, 73, 98], "prefer_skip_nested_valid": [18, 34], "prefix": [9, 63], "preliminari": [18, 27, 62, 70], "prepar": [18, 27, 62, 70], "preprocess": [1, 12, 15, 16, 17, 21, 22, 23, 25, 26, 27, 29, 30, 31, 32, 33, 34, 37, 38, 39, 41, 42, 44, 45, 46, 49, 50, 53, 60, 61, 64, 65, 66, 68, 69, 70, 72, 73, 74, 75, 77, 80, 81, 86, 87, 88, 92, 93, 94], "preprocess_featur": [52, 76, 90, 96], "preprocessing_fin": [34, 53, 77], "preprocessing_notenur": [34, 77], "preprocessor": [17, 22, 24, 25, 26, 34, 35, 39, 40, 41, 43, 44, 45, 52, 53, 54, 55, 63, 65, 66, 67, 68, 69, 76, 77, 78, 87, 88, 90, 93, 94, 96], "preprocessor1": [27, 46, 70], "preprocessor2": [27, 46, 70], "preprocessor3": [27, 46, 70], "prereq": 79, "prerequisit": [2, 34, 53, 77, 98], "preschool": [25, 26, 44, 45, 66, 68, 69], "presenc": [19, 23, 26, 34, 45, 58, 63, 69, 77], "present": [8, 16, 20, 30, 31, 32, 34, 35, 38, 40, 50, 51, 52, 54, 55, 58, 60, 73, 74, 75, 76, 77, 78, 79, 80, 84, 86, 90, 92, 96], "preserv": [28, 58, 66, 71], "pressburg": 58, "pressure3pm": [52, 76, 90, 96], "pressure9am": [52, 76, 90, 96], "presum": 58, "pretend": [15, 33, 59, 60, 76], "pretrain": [32, 47, 51, 75], "pretti": [14, 17, 21, 23, 25, 28, 31, 33, 34, 39, 42, 44, 47, 51, 52, 59, 63, 64, 66, 68, 71, 74, 76, 77, 80, 90, 91, 96], "prevent": [22, 34, 51, 53, 65, 77], "preview": 5, "previou": [13, 14, 15, 24, 25, 28, 29, 31, 33, 34, 35, 37, 44, 50, 52, 55, 59, 67, 68, 71, 72, 74, 76, 77, 78, 84, 90, 96], "previous": [17, 30, 32, 33, 73, 75, 76], "price": [9, 14, 15, 17, 18, 21, 24, 26, 34, 35, 37, 39, 43, 45, 46, 54, 55, 62, 64, 67, 69, 70, 77, 78, 89, 95], "pricei": 95, "priceperc": [89, 95], "primari": [9, 16, 20, 40, 61], "primarili": [13, 14, 26, 32, 45, 59, 69, 75, 79], "princ": [31, 50, 51, 74], "princess": [31, 50, 51, 74], "principl": [10, 12, 54, 59, 84], "print": [8, 9, 13, 14, 15, 16, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 38, 40, 41, 42, 43, 44, 45, 46, 48, 49, 50, 51, 52, 53, 54, 55, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 80, 82, 83, 86, 90, 92, 95, 96], "print_dbscan_clust": 48, "print_dbscan_noise_imag": 48, "print_hierarchical_clust": 48, "print_progress": 34, "print_top": [31, 50, 51, 74], "prior": [28, 33, 71, 76, 84], "priorit": [5, 27, 70, 84], "privaci": [0, 12, 28, 31, 50, 56, 57, 71, 74, 79], "privat": [5, 6, 8, 25, 26, 44, 45, 66, 68, 69], "privileg": 7, "prize": [19, 44, 63], "pro": [20, 28, 35, 45, 55, 58, 71, 78], "prob": [21, 25, 44, 64, 68, 94], "proba": [32, 75], "probabilist": [2, 31, 50, 51, 74], "probabl": [13, 16, 17, 18, 20, 23, 24, 25, 26, 27, 29, 31, 32, 34, 35, 39, 40, 42, 43, 44, 45, 46, 50, 51, 52, 53, 55, 56, 57, 58, 61, 62, 63, 66, 67, 68, 69, 70, 72, 74, 75, 76, 77, 78, 79, 81, 82, 84, 88, 90, 91, 94, 96], "problem": [1, 4, 5, 7, 12, 13, 17, 19, 20, 21, 23, 24, 25, 26, 28, 29, 31, 32, 34, 35, 37, 39, 42, 43, 44, 45, 46, 50, 51, 53, 55, 56, 57, 58, 63, 64, 66, 67, 68, 69, 70, 71, 72, 74, 75, 77, 78, 80, 83, 84, 86, 88, 90, 92, 93, 94, 96, 98], "problemat": [11, 26, 34, 53, 66, 69, 77], "probosci": [32, 58, 75], "proce": [38, 86, 92, 98], "procedur": [44, 68], "proceed": [60, 90, 96], "process": [2, 6, 8, 12, 14, 16, 18, 19, 22, 25, 26, 27, 28, 29, 32, 35, 37, 38, 41, 46, 50, 55, 59, 61, 62, 63, 65, 70, 71, 72, 75, 78, 79, 82, 86, 89, 92, 95, 98], "process_rout": 34, "procfil": [56, 57, 79], "proclaim": 58, "prod": [19, 22, 41, 63, 65], "produc": [2, 5, 8, 14, 17, 24, 26, 32, 34, 39, 55, 67, 69, 72, 75, 77, 78, 84, 86, 92], "product": [20, 22, 30, 31, 35, 40, 41, 49, 51, 55, 65, 73, 74, 78], "prof": [25, 26, 44, 45, 66, 68, 69], "profession": [30, 73, 79], "profil": [24, 43, 67], "profile_df": [30, 49, 73], "profilereport": [24, 43, 67], "profit": [55, 78], "program": [0, 4, 5, 10, 13, 31, 50, 51, 58, 74, 82, 98], "programm": [31, 50, 51, 74], "progress": 71, "project": [11, 17, 18, 27, 32, 35, 55, 62, 68, 70, 75, 78, 79, 84], "promin": [31, 50, 51, 74], "promis": [13, 33, 37, 51, 52, 56, 57, 58, 76, 79, 95], "promot": [34, 77], "prompt": [11, 31, 50, 74, 98], "pron": [31, 50, 51, 74, 82], "prone": [22, 58, 65], "proper": [32, 75, 85, 91], "properli": [8, 13, 34, 35, 54, 55, 77, 78], "properti": [14, 24, 26, 40, 43, 45, 46, 59, 67, 69, 70], "prophet": [33, 52, 76], "propn": [51, 82], "proport": [12, 14, 15, 19, 21, 23, 24, 25, 26, 35, 42, 43, 44, 45, 54, 55, 58, 59, 60, 63, 64, 66, 67, 68, 69, 78, 80, 94], "proportional_hazard_test": [34, 77], "prostitut": [31, 51, 74], "protagonist": 58, "protect": [31, 50, 58, 74], "protocol": [56, 57, 79], "prototyp": [79, 84], "prove": 80, "provid": [0, 5, 6, 8, 12, 14, 15, 19, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 33, 35, 38, 42, 43, 45, 46, 49, 50, 51, 55, 59, 60, 63, 64, 65, 66, 67, 69, 70, 71, 72, 73, 74, 76, 78, 84, 88, 89, 90, 92, 94, 95, 96, 98], "provinc": [19, 51, 63, 82], "provinci": [31, 50, 51, 74], "proxi": [15, 60], "proxim": [21, 50, 51, 64, 74, 98], "prune": 70, "psychic": 20, "psychologi": [19, 63, 84], "pt": [21, 32, 64, 65, 75], "public": [0, 6, 8, 31, 50, 51, 74], "publish": [0, 21, 31, 50, 51, 64, 74], "puck": [31, 50, 51, 74], "pud": [24, 43, 67], "pull": [6, 11, 21, 31, 50, 51, 64, 74], "pump": 58, "punct": [31, 50, 51, 74, 82], "punctuat": [19, 31, 50, 51, 63, 74, 82], "punish": [35, 55, 78], "purchas": [30, 38, 58, 73, 79], "pure": [14, 33, 37, 59, 76], "purpos": [0, 14, 15, 18, 20, 30, 31, 33, 40, 49, 50, 51, 56, 57, 58, 59, 60, 62, 73, 74, 76, 79, 82, 84, 85, 86, 88, 91, 92, 94, 98], "pursu": 58, "pursuit": [35, 55, 58, 78], "push": [6, 8, 26, 45, 69], "put": [8, 9, 15, 17, 18, 19, 20, 27, 28, 29, 30, 31, 38, 39, 40, 46, 50, 56, 57, 58, 59, 60, 62, 63, 66, 70, 71, 72, 73, 74, 79], "px": [27, 46, 50, 51, 70, 74], "py": [14, 16, 18, 19, 25, 26, 28, 29, 31, 32, 34, 44, 45, 47, 50, 53, 56, 57, 59, 60, 62, 63, 68, 69, 71, 72, 74, 75, 77, 79, 83], "pybo": [22, 41, 65], "pydata": [27, 70], "pyplot": [9, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 32, 33, 34, 35, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 52, 53, 54, 55, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 75, 76, 77, 78, 80, 81, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97], "pysurviv": [34, 53, 77], "python": [1, 3, 4, 5, 12, 22, 24, 30, 31, 32, 33, 34, 35, 43, 49, 50, 51, 52, 53, 55, 56, 57, 58, 65, 67, 73, 74, 75, 76, 77, 78, 79, 98], "python3": [10, 45, 50, 53, 59, 60, 63, 69, 74, 77, 83], "pythonwarn": [23, 24, 42, 43, 67], "pytorch": [13, 32, 47, 48, 58, 75], "pyviz": [23, 42, 66], "q": 1, "qualit": [17, 39], "qualiti": [23, 26, 27, 28, 29, 35, 42, 45, 50, 54, 55, 58, 66, 69, 71, 72, 74, 78, 81], "quantifi": 66, "quantil": [17, 39], "quantit": [17, 39], "quarter": 95, "quebecoi": [17, 39], "queen": [31, 50, 51, 74], "queen_consort": [31, 50, 51, 74], "queri": [18, 25, 28, 31, 33, 34, 38, 44, 49, 50, 51, 52, 53, 62, 66, 68, 71, 73, 74, 76, 77, 90, 96], "query_img": 38, "query_point": [16, 61], "quest": [27, 46, 70], "question": [1, 3, 7, 8, 43, 50, 53, 89, 95, 98], "queuepredictor": 79, "quick": [4, 13, 31, 50, 51, 56, 57, 58, 74, 79, 98], "quickli": [14, 16, 17, 18, 22, 29, 31, 34, 41, 50, 53, 58, 59, 61, 62, 65, 72, 74, 77, 84, 98], "quickstart": 10, "quirk": [15, 60], "quirki": 20, "quit": [7, 13, 14, 18, 20, 22, 24, 26, 27, 29, 32, 33, 34, 35, 38, 41, 43, 45, 46, 47, 48, 51, 53, 55, 58, 59, 62, 65, 66, 67, 69, 70, 72, 75, 76, 77, 78, 82, 86, 92], "quiz": [1, 13, 25, 51, 82, 98], "quiz1": [14, 15, 19, 59, 60, 63, 84], "quiz2": [15, 19, 60, 63, 84], "quizz": [14, 59], "r": [12, 14, 15, 19, 21, 23, 33, 35, 40, 42, 52, 54, 55, 59, 63, 64, 66, 76, 78, 88, 94], "r1": [25, 44, 68], "r2": [15, 24, 25, 37, 43, 44, 67, 68, 84, 86, 92], "r2_score": [24, 27, 43, 46, 67, 70], "r4": [44, 68], "rabi": 40, "race": [25, 26, 44, 45, 63, 66, 68, 69], "rachel": 58, "radial": [16, 61], "radiu": [27, 29, 38, 46, 70, 72], "rag": [31, 50, 74], "rail": [32, 75], "rain": [52, 76, 90, 96], "rain_df": [52, 76, 90, 96], "rain_df_modifi": [52, 76, 90, 96], "rainfal": [52, 76, 90, 96], "rainfall_ahead1": 76, "rainfall_lag1": [52, 76, 90, 96], "rainfall_lag2": [52, 76, 90, 96], "rainfall_lag3": [52, 76, 90, 96], "raintodai": [52, 76, 90, 96], "raintoday_miss": [52, 76, 96], "raintoday_no": [52, 76, 96], "raintoday_y": [52, 76, 96], "raintomorrow": [52, 76, 90, 96], "rais": [7, 13, 18, 19, 23, 34, 42, 52, 58, 63, 66, 76, 77, 90, 96], "ralph": 58, "rand": [9, 25, 44, 68], "randint": [22, 41, 65], "randn": [21, 27, 46, 64, 70], "random": [7, 9, 12, 15, 16, 21, 23, 27, 28, 29, 30, 31, 32, 33, 34, 38, 42, 46, 47, 48, 49, 50, 51, 53, 60, 61, 64, 66, 70, 71, 72, 73, 74, 75, 76, 77, 79, 80, 81, 83, 84, 88, 89, 94, 95, 97], "random_forest_data": [25, 68], "random_search": [22, 41, 65], "random_st": [13, 15, 16, 17, 18, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 53, 54, 55, 56, 57, 58, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 83, 86, 87, 88, 92, 93, 94, 95], "randomforestclassifi": [26, 27, 33, 35, 45, 46, 52, 53, 54, 55, 69, 70, 76, 78, 81, 88, 90, 94, 96], "randomforestclassifierrandomforestclassifi": 25, "randomforestregressor": [24, 25, 26, 27, 33, 34, 35, 43, 44, 45, 46, 53, 54, 55, 56, 57, 67, 68, 69, 70, 76, 77, 78, 79, 88, 94], "randomizedsearchcv": [16, 25, 26, 35, 44, 45, 55, 61, 68, 69, 78, 88, 94], "randomizedsearchcvifit": [41, 65], "randomizedsearchcvifittedrandomizedsearchcv": 22, "randomli": [15, 21, 22, 23, 25, 42, 44, 60, 64, 65, 66, 68, 77], "randomoversampl": 80, "randomst": [27, 29, 46, 70, 72], "randomundersampl": 80, "rang": [4, 9, 12, 16, 17, 18, 19, 21, 25, 28, 30, 31, 32, 33, 34, 35, 39, 44, 47, 48, 49, 50, 51, 54, 55, 60, 61, 62, 63, 64, 68, 71, 73, 74, 75, 76, 77, 78, 89, 93, 95], "rangeindex": [19, 27, 34, 46, 52, 53, 63, 70, 76, 77, 92, 94, 96], "rank": [23, 27, 30, 31, 34, 42, 46, 51, 53, 66, 70, 73, 74, 77], "rank_test_mape_scor": [24, 43, 67], "rank_test_neg_mean_squared_error": 24, "rank_test_scor": [22, 24, 41, 43, 65, 67], "ranking_": [27, 46, 70], "rapidli": 58, "rare": [24, 28, 51, 63, 66, 67, 71, 80, 84], "rate": [13, 21, 23, 25, 28, 34, 35, 42, 44, 53, 55, 58, 64, 66, 68, 71, 77, 78, 84], "rated_item": [30, 49, 73], "rather": [13, 17, 19, 20, 22, 24, 25, 26, 28, 31, 32, 39, 41, 43, 44, 45, 50, 51, 58, 63, 65, 66, 67, 68, 69, 71, 74, 75, 80, 86, 92, 98], "ratings_df": [30, 49, 73], "ratio": [25, 34, 44, 50, 51, 68, 74, 77, 80], "rational": 8, "ravel": [20, 23, 38, 40, 42, 66, 84], "raven": 58, "raw": [9, 19, 23, 26, 27, 32, 35, 39, 42, 45, 51, 55, 58, 63, 66, 69, 70, 75, 78, 80, 83], "raw_model_output": [21, 64], "raw_scor": [26, 45, 69], "rayat": 1, "raymond": 58, "rbf": [1, 15, 18, 21, 22, 25, 26, 27, 35, 41, 42, 44, 45, 46, 55, 60, 62, 63, 64, 65, 68, 69, 70, 78, 79, 84, 86, 92], "rcparam": [13, 14, 15, 23, 28, 29, 30, 33, 34, 35, 42, 49, 52, 53, 54, 55, 58, 59, 60, 66, 71, 72, 73, 76, 77, 78, 85, 90, 91, 96], "re": [4, 5, 6, 8, 9, 11, 13, 14, 15, 19, 20, 22, 24, 25, 26, 28, 30, 31, 32, 33, 34, 40, 41, 43, 44, 45, 49, 50, 51, 52, 53, 56, 57, 58, 59, 60, 63, 65, 66, 67, 68, 69, 71, 73, 74, 75, 76, 77, 79, 82, 84, 85, 90, 91, 96], "reach": [1, 5, 7, 28, 58, 71, 98], "react": [32, 75], "read": [1, 4, 5, 8, 13, 16, 18, 19, 23, 24, 25, 26, 31, 32, 35, 38, 42, 43, 44, 45, 50, 51, 52, 54, 55, 58, 61, 62, 63, 67, 68, 69, 74, 75, 76, 78, 79, 80, 88, 89, 90, 92, 94, 95, 96], "read_csv": [9, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 30, 31, 33, 34, 35, 37, 39, 40, 41, 42, 43, 44, 45, 46, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 73, 74, 76, 77, 78, 79, 80, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96], "read_data": [32, 75], "read_excel": 9, "read_html": 9, "read_img_dataset": [38, 47, 48], "read_json": 9, "readabl": [0, 9], "reader": [12, 31, 50, 74], "readi": [6, 8, 11, 13, 15, 16, 18, 21, 39, 60, 61, 62, 64], "readlin": [32, 75], "readm": [34, 77], "readthedoc": [34, 53, 77], "real": [5, 14, 15, 16, 17, 18, 19, 21, 26, 28, 29, 30, 31, 32, 35, 39, 45, 49, 50, 51, 55, 58, 60, 61, 62, 63, 64, 66, 69, 71, 72, 73, 74, 75, 78, 82, 84], "realis": 58, "realism": [20, 40], "realist": [18, 33, 38, 62, 76, 79, 90, 96], "realiti": [24, 34, 43, 50, 60, 67, 74, 77], "realiz": [55, 78], "realli": [9, 13, 15, 20, 21, 22, 27, 29, 30, 32, 33, 34, 44, 46, 49, 53, 58, 60, 64, 65, 68, 70, 72, 73, 75, 76, 77, 79, 81], "reanim": 20, "rear": 58, "reason": [0, 2, 4, 5, 9, 12, 15, 18, 22, 23, 24, 26, 28, 30, 31, 33, 34, 35, 42, 43, 45, 49, 50, 51, 53, 55, 58, 60, 62, 65, 66, 67, 69, 71, 73, 74, 76, 77, 78, 79, 84, 98], "rec": [24, 26, 35, 43, 45, 54, 55, 67, 69, 78], "recal": [12, 15, 18, 19, 21, 24, 28, 31, 33, 39, 43, 50, 56, 57, 58, 59, 60, 61, 62, 63, 64, 67, 71, 74, 76, 79, 80, 84], "recall_lr": [23, 42, 66], "recall_scor": [23, 42, 66], "recall_svc": [23, 42, 66], "recap": 19, "receiv": [5, 7, 8, 13, 19, 29, 31, 32, 50, 52, 56, 57, 63, 72, 74, 75, 76, 79, 80, 98], "recent": [9, 11, 13, 18, 19, 24, 27, 30, 31, 33, 34, 43, 49, 50, 51, 52, 58, 63, 70, 73, 74, 76, 77], "recip": [15, 31, 50, 60, 74], "reclin": 40, "recogn": [12, 15, 20, 29, 31, 33, 35, 55, 60, 72, 74, 78, 98], "recognit": [13, 51, 58, 59, 61, 80, 82, 98], "recommend": [1, 2, 5, 9, 12, 15, 20, 22, 23, 26, 28, 31, 32, 38, 40, 41, 50, 51, 55, 58, 60, 61, 65, 66, 71, 74, 75, 78, 79, 80, 81, 88, 89, 94, 95], "reconcili": 1, "reconstruct": 49, "record": [14, 34, 45, 59, 77], "recreat": [90, 96], "rectangular": [28, 71], "recurr": [31, 33, 50, 52, 74, 76], "recurs": 12, "red": [14, 16, 23, 26, 27, 28, 31, 33, 42, 45, 46, 50, 52, 58, 59, 61, 66, 69, 70, 71, 74, 76, 97], "redbon": [22, 41, 65], "redeem": 58, "redefin": [34, 53, 77], "redistribut": [0, 98], "reduc": [8, 9, 13, 16, 22, 24, 25, 26, 27, 30, 32, 43, 44, 45, 46, 51, 58, 61, 65, 66, 67, 68, 69, 70, 73, 75, 82, 83, 86, 92, 98], "reduct": [2, 23, 25, 27, 28, 42, 44, 58, 66, 68, 70, 71], "redund": [21, 26, 45, 64, 69], "ref": [23, 34, 42, 66, 77, 80], "refer": [4, 9, 13, 14, 15, 16, 18, 19, 21, 26, 28, 30, 31, 32, 45, 50, 51, 59, 60, 61, 62, 63, 64, 66, 69, 71, 73, 74, 75, 82, 86, 92, 97, 98], "referenti": [31, 51, 74], "refin": [16, 38, 61, 86, 92], "refit": [24, 41, 43, 65, 67], "reflect": [16, 24, 26, 31, 43, 45, 50, 51, 61, 67, 69, 74, 86, 92, 98], "reflection_period": [56, 57, 79, 80], "reg": [14, 25, 44, 59, 68, 88, 94], "reg_alpha": [44, 45, 68, 69, 94], "reg_lambda": [44, 45, 68, 69, 94], "reg_model": [14, 59], "regard": [20, 58], "regardless": 8, "regex": [51, 82], "regim": 79, "region": [14, 29, 32, 52, 59, 72, 75, 76, 79, 80, 83, 90, 96], "region_data": [52, 76, 90, 96], "regist": [13, 56, 57, 79, 98], "registered_nurs": [31, 50, 51, 74], "regrad": [7, 13], "regress": [1, 2, 12, 13, 15, 17, 18, 19, 20, 25, 26, 30, 32, 33, 34, 35, 40, 45, 49, 52, 53, 55, 58, 62, 63, 69, 70, 73, 75, 76, 77, 78, 79, 83, 84, 86, 88, 90, 92, 94, 96], "regression_df": [14, 59], "regressioncolumntransform": [25, 44, 68, 94], "regressor": [14, 15, 17, 18, 19, 24, 33, 37, 59, 62, 63, 67, 76, 87, 88, 92, 93, 94], "regular": [16, 19, 21, 33, 34, 44, 51, 53, 55, 61, 63, 64, 68, 76, 77, 78, 82, 84, 98], "regularli": 5, "regulatori": [26, 45, 69], "rei": [1, 98], "reinforc": [13, 28, 58, 71, 84], "reinstal": 11, "reject": 66, "rel": [15, 17, 21, 26, 29, 39, 44, 45, 51, 64, 69, 72, 82, 83], "relabel": [28, 71], "relat": [2, 7, 13, 20, 21, 24, 25, 26, 27, 28, 30, 31, 33, 34, 40, 43, 45, 46, 50, 51, 53, 58, 64, 67, 68, 69, 70, 71, 73, 74, 76, 77, 80, 88, 94, 98], "relationship": [12, 25, 26, 27, 31, 33, 44, 45, 46, 50, 51, 52, 55, 58, 66, 68, 69, 70, 74, 76, 78, 81, 84, 85, 86, 89, 90, 91, 92, 95, 96, 98], "relationship_husband": [26, 44, 45, 69], "relationship_not": 44, "relationship_oth": 44, "relationship_own": [26, 44, 45, 69], "relationship_unmarri": 44, "relationship_wif": 44, "relearn": [32, 75], "releas": [1, 8], "relev": [1, 4, 9, 12, 14, 16, 18, 22, 26, 41, 45, 46, 52, 59, 61, 62, 65, 69, 76, 80], "reli": [13, 15, 16, 27, 29, 30, 33, 38, 46, 58, 60, 61, 70, 72, 73, 76, 86, 92, 98], "reliabl": [13, 15, 28, 58, 71], "religi": [51, 58], "reluct": 58, "remad": 58, "remain": [17, 24, 27, 30, 33, 35, 43, 46, 49, 54, 55, 67, 70, 73, 76, 78], "remaind": [7, 39, 41, 44, 45, 63, 65, 67, 68, 69, 94], "remak": 58, "rememb": [8, 13, 16, 19, 20, 22, 23, 26, 27, 29, 31, 32, 34, 40, 41, 42, 45, 46, 50, 52, 53, 58, 61, 63, 65, 66, 69, 70, 72, 74, 75, 76, 77, 85, 86, 90, 91, 92, 96, 98], "remind": [85, 91], "remix": 0, "remov": [8, 11, 18, 25, 26, 27, 31, 32, 34, 38, 44, 45, 46, 47, 48, 50, 51, 53, 62, 66, 68, 69, 70, 74, 75, 77, 81, 82, 83, 90, 96], "renam": [13, 33, 45, 52, 56, 57, 58, 69, 76, 79, 80, 95], "render": [4, 8, 13, 15, 17, 18, 19, 20, 22, 23, 24, 25, 26, 27, 28, 32, 35, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 51, 54, 55, 58, 62, 63, 65, 66, 67, 68, 69, 70, 71, 75, 78, 82, 94], "rent": [33, 58, 76], "rental": [33, 76, 79], "rentals_df": [33, 76], "rentals_lag5": [33, 76], "rentals_lag5_i": [33, 76], "rentals_lag5_x": [33, 76], "rentals_model": [33, 76], "renter": 40, "repair": [25, 26, 44, 45, 66, 68, 69], "repeat": [9, 27, 28, 29, 32, 46, 70, 71, 72, 75, 79, 81, 88, 92, 94], "repeatedli": 7, "rephras": [35, 55, 78], "replac": [13, 17, 18, 20, 25, 26, 34, 39, 40, 44, 45, 49, 53, 58, 62, 66, 68, 69, 73, 77, 80, 89, 95], "replace_tag": [20, 40], "replic": [58, 79], "repo": [1, 6, 23, 42, 56, 57, 66, 79], "report": [7, 14, 15, 22, 24, 27, 31, 43, 46, 50, 52, 59, 65, 66, 67, 70, 74, 76], "repositori": [0, 1, 6, 11, 13, 17, 21, 23, 36, 38, 39, 42, 56, 57, 64, 66, 79], "repres": [14, 15, 16, 18, 19, 21, 23, 25, 26, 27, 28, 29, 30, 31, 32, 33, 35, 42, 45, 49, 50, 51, 53, 55, 58, 59, 60, 61, 62, 63, 64, 66, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 82, 84, 88, 94], "represent": [14, 15, 17, 18, 20, 22, 23, 24, 25, 26, 27, 28, 29, 32, 35, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 51, 54, 55, 56, 57, 58, 59, 62, 65, 66, 67, 68, 69, 70, 71, 72, 75, 78, 79, 84, 94], "reproduc": [4, 5, 15, 22, 25, 41, 44, 60, 65, 68, 79, 97, 98], "republ": [26, 44, 45, 69], "request": [7, 13, 31, 51, 74, 98], "requir": [6, 8, 11, 16, 17, 18, 22, 23, 25, 26, 27, 28, 29, 30, 31, 32, 34, 35, 38, 39, 41, 42, 44, 45, 46, 50, 51, 55, 56, 57, 58, 61, 62, 65, 66, 68, 69, 70, 71, 72, 73, 74, 75, 77, 78, 80, 84, 89, 90, 95, 96, 98], "rerun": [15, 17, 18, 19, 20, 22, 23, 24, 25, 26, 27, 32, 35, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 54, 55, 58, 62, 63, 65, 66, 67, 68, 69, 70, 75, 78, 94], "res_mean": 60, "resampl": 80, "research": [5, 15, 22, 30, 41, 49, 50, 51, 58, 60, 65, 73, 74, 79], "resembl": 58, "reserv": [33, 76, 98], "reset": [18, 32, 34, 84, 96], "reset_index": [13, 58, 95], "reshap": [9, 17, 21, 22, 33, 39, 41, 47, 64, 65, 76], "reshape_for_countvector": [17, 39], "resid": [21, 64], "residenti": 92, "residu": [44, 68], "resiz": [38, 47, 48], "resnet": [32, 75], "resolut": [51, 82], "resolv": 98, "resort": [21, 64], "resourc": [1, 3, 5, 6, 25, 26, 31, 32, 41, 44, 45, 50, 51, 56, 57, 58, 59, 68, 69, 74, 75, 79, 84], "respect": [21, 22, 25, 26, 41, 42, 44, 45, 58, 64, 65, 66, 68, 69, 89, 95], "respons": [4, 5, 8, 14, 31, 35, 50, 51, 55, 58, 59, 71, 74, 78, 98], "responsibli": [5, 98], "rest": [20, 21, 22, 31, 32, 34, 45, 50, 53, 56, 57, 58, 64, 65, 74, 75, 77, 79, 84, 90, 92, 96], "restart": [8, 11], "restaur": [17, 30, 39, 73, 79], "restaurant_df": [17, 39], "restaurant_nam": [17, 39], "restingbp": [88, 94], "restingecg": [88, 94], "restrain": 58, "restraint": 58, "restrict": [0, 24, 25, 31, 43, 44, 50, 51, 67, 68, 74], "resubmit": 13, "result": [2, 5, 8, 9, 12, 13, 14, 15, 16, 17, 18, 19, 21, 23, 24, 25, 26, 27, 29, 32, 33, 34, 37, 38, 39, 42, 44, 45, 46, 52, 53, 60, 61, 62, 63, 64, 66, 67, 68, 69, 70, 71, 72, 75, 76, 77, 79, 86, 88, 89, 90, 92, 94, 95, 96, 98], "result_block": [34, 77], "result_img": [32, 75], "results_df": [15, 16, 20, 21, 37, 38, 40, 60, 61, 64, 86, 92], "results_dict": [16, 18, 22, 38, 60, 61, 62, 63, 65], "results_proba": 94, "results_single_valid_df": [15, 37, 86, 92], "retail": 84, "retail_df": [33, 76], "retail_df_test": [33, 76], "retail_df_train": [33, 76], "retail_lag_5": [33, 76], "retail_model": [33, 76], "retail_test_5": [33, 76], "retail_test_5_pr": [33, 76], "retail_train_5": [33, 76], "retail_train_5_d": [33, 76], "retail_train_5_i": [33, 76], "retail_train_5_x": [33, 76], "retent": [34, 77], "retrain": [22, 65, 79], "retriev": [31, 50, 74], "return": [6, 9, 11, 14, 15, 16, 18, 19, 20, 23, 24, 27, 28, 29, 30, 31, 32, 33, 34, 38, 40, 42, 43, 47, 48, 49, 50, 51, 52, 53, 56, 57, 59, 60, 61, 62, 63, 66, 67, 71, 72, 73, 74, 75, 76, 77, 79, 81, 84, 86, 90, 92, 96], "return_gener": [19, 34, 63], "return_predict": [56, 57, 79], "return_train_scor": [15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 33, 34, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 76, 77, 81, 86, 88, 92, 93, 94], "return_tupl": 34, "reus": 66, "reveal": 84, "revenu": [30, 49, 73], "revers": [19, 24, 43, 63, 67], "review": [4, 21, 31, 35, 54, 55, 64, 71, 74, 78, 84, 88, 94, 98], "review_pp": [20, 40], "revisit": [23, 42, 66, 84], "revok": 0, "revolv": 58, "reward": [13, 19, 28, 58, 63, 71], "reynold": 58, "rf": [33, 34, 76, 77, 94], "rf_classifi": 94, "rf_imp_df": [26, 45, 69], "rf_score": 94, "rfe_cv": [27, 46, 70], "rfe_pip": [27, 46, 70], "rfecv": [27, 46, 70], "rgb": [13, 58], "rhode_island": [31, 50, 51, 74], "rich": [5, 26, 34, 45, 51, 53, 55, 69, 77, 78, 84], "richard": [35, 55, 78], "richardson": 58, "richer": [31, 74], "richmond": 96, "rickman": 20, "rico": [26, 44, 45, 69], "rid": [17, 19, 25, 26, 34, 39, 44, 45, 51, 63, 68, 69, 77, 82], "ridg": [26, 27, 30, 33, 34, 35, 45, 46, 49, 53, 54, 55, 69, 70, 73, 76, 77, 78, 79], "ridge__alpha": [24, 43, 67], "ridge_pr": [24, 43, 67], "ridge_tun": [24, 43, 67], "ridgecv": [27, 46, 70], "ridgecv_pip": [24, 43, 67], "ridgeridg": [24, 27, 46, 67, 70], "ridicul": 40, "right": [0, 1, 11, 12, 13, 15, 17, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 35, 37, 39, 40, 41, 42, 43, 46, 49, 51, 53, 55, 58, 64, 65, 66, 67, 70, 71, 72, 73, 74, 78, 79, 84, 92], "rightarrow": [16, 21, 23, 24, 25, 28, 29, 30, 31, 32, 42, 43, 44, 49, 50, 51, 55, 56, 57, 59, 61, 64, 66, 67, 68, 71, 72, 73, 74, 75, 78, 79, 84], "rindfleischetikettierungs\u00fcberwachungsaufgaben\u00fcbertragungsgesetz": [51, 82], "rip": 20, "rise": [27, 46, 51, 70, 82], "risk": [23, 27, 31, 35, 42, 50, 55, 66, 70, 74, 78, 86, 88, 92, 94], "riti": 29, "river": [21, 64], "rl": [24, 26, 35, 43, 45, 54, 55, 67, 69, 78], "rmse": [30, 49, 73, 84], "rng": [27, 29, 46, 70, 72], "rnn": [31, 33, 50, 52, 74, 76], "ro": 80, "roam": 31, "roast": 71, "robberi": 20, "roberta": [31, 50, 74], "robin": 20, "robot": [30, 31, 49, 50, 51, 73, 74], "robust": [13, 15, 16, 17, 18, 22, 25, 29, 39, 44, 58, 60, 61, 62, 65, 68, 72, 86, 92], "robustscal": [17, 39], "roc": [12, 79, 84], "roc_auc": [23, 42, 66, 80], "roc_auc_scor": [23, 42, 66], "roc_curv": [23, 42, 66], "roc_lr": [23, 42, 66], "roc_svc": [23, 42, 66], "roccurvedisplai": [23, 42, 66], "rock": 20, "rodolfo": [22, 65], "rodr\u00edguez": [51, 82], "roger": [27, 46, 58, 70], "role": [20, 21, 22, 26, 31, 32, 41, 45, 58, 64, 65, 69, 74, 75], "roll": 58, "roman": [30, 49, 73], "romanc": [30, 49, 73], "romant": [30, 49, 73], "ronald": [21, 64], "roof": [45, 69], "roofmatl": [24, 26, 35, 43, 45, 54, 55, 67, 69, 78], "roofmatl_clytil": [24, 43, 45, 67, 69], "roofmatl_compshg": [24, 45, 67, 69], "roofmatl_membran": [24, 67, 69], "roofmatl_met": [24, 67, 69], "roofmatl_rol": [24, 67, 69], "roofmatl_tar": [24, 67, 69], "roofmatl_wdshak": [24, 67, 69], "roofmatl_wdshngl": [24, 45, 67, 69], "roofstyl": [24, 26, 35, 43, 45, 54, 55, 67, 69, 78], "roofstyle_flat": [24, 67, 69], "roofstyle_g": [24, 43, 67, 69], "roofstyle_gambrel": [24, 67, 69], "roofstyle_hip": [24, 67, 69], "roofstyle_mansard": [24, 67, 69], "roofstyle_sh": [24, 67, 69], "room": [14, 17, 21, 24, 27, 39, 43, 46, 58, 59, 64, 67, 70, 98], "rooms_per_household": [18, 27, 46, 62, 63, 70, 87, 93], "rooms_per_household_0": [27, 46, 70], "rooms_per_household_1": [27, 46, 70], "rooms_per_household_10": [27, 46, 70], "rooms_per_household_11": [27, 46, 70], "rooms_per_household_12": [27, 46, 70], "rooms_per_household_13": [27, 46, 70], "rooms_per_household_14": [27, 46, 70], "rooms_per_household_15": [27, 46, 70], "rooms_per_household_16": [27, 46, 70], "rooms_per_household_17": [27, 46, 70], "rooms_per_household_18": [27, 46, 70], "rooms_per_household_19": [27, 46, 70], "rooms_per_household_2": [27, 46, 70], "rooms_per_household_3": [27, 46, 70], "rooms_per_household_4": [27, 46, 70], "rooms_per_household_5": [27, 46, 70], "rooms_per_household_6": [27, 46, 70], "rooms_per_household_7": [27, 46, 70], "rooms_per_household_8": [27, 46, 70], "rooms_per_household_9": [27, 46, 70], "root": [16, 30, 38, 45, 47, 48, 49, 59, 61, 73, 84, 91], "rose": [51, 82], "rostin": [1, 98], "rotat": [33, 52, 76, 90, 96], "rotten": [31, 50, 74], "rough": 4, "roughli": [32, 51, 60, 75, 79, 82, 84], "round": [9, 16, 18, 22, 23, 25, 29, 31, 38, 41, 42, 44, 50, 61, 62, 65, 66, 68, 72, 74, 86, 92, 94], "rounder": 20, "rout": [14, 33, 52, 59, 76], "routed_param": [34, 63], "row": [14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 29, 30, 31, 32, 33, 34, 35, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 48, 49, 50, 51, 52, 53, 54, 55, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 72, 73, 74, 75, 76, 77, 78, 79, 80, 86, 88, 89, 90, 91, 92, 93, 94, 95, 96, 98], "rry": [50, 51, 74], "rsh": [22, 41, 65], "ru": [9, 80], "rube": 40, "rubia": [1, 98], "rubric": [13, 21, 64], "rug": [31, 50, 74], "rule": [1, 5, 9, 13, 14, 20, 21, 37, 39, 40, 44, 51, 58, 59, 61, 64, 66, 68, 79, 82, 84, 86, 91, 92, 98], "run": [1, 4, 5, 6, 8, 13, 16, 19, 22, 23, 24, 25, 26, 28, 29, 31, 32, 34, 38, 41, 42, 43, 45, 47, 48, 50, 51, 54, 56, 57, 58, 60, 61, 63, 65, 66, 67, 69, 71, 72, 74, 75, 79, 82, 83, 85, 86, 88, 91, 92, 94], "ruscorpora": [31, 50, 51, 74], "rush": 70, "russel": 1, "rusti": 5, "rv": [22, 41, 65], "rv_continuous_frozen": [41, 65], "rv_discrete_frozen": [41, 65], "rvert_2": [31, 51, 74], "s1": [9, 51], "s1600": [31, 50, 74], "s19": [18, 62], "s2": [9, 51], "s_lag": 52, "sa": 1, "sabr": [31, 50, 51, 74], "sabrina": 1, "sad": [31, 50, 74], "sadli": [31, 50, 51, 58, 74], "safe": [18, 62], "safeti": [32, 75], "saga": 58, "sai": [9, 14, 16, 18, 19, 20, 24, 25, 26, 33, 35, 43, 44, 45, 51, 55, 58, 59, 61, 62, 63, 66, 67, 68, 69, 76, 78, 84, 91, 93], "said": [6, 18, 21, 26, 29, 30, 31, 35, 45, 50, 51, 55, 60, 62, 64, 69, 72, 73, 74, 78], "sail": 58, "saint": 20, "sal": [24, 26, 35, 43, 45, 54, 55, 67, 69, 78], "sale": [9, 15, 24, 33, 37, 43, 55, 66, 67, 76, 78, 96], "salecondit": [24, 26, 35, 43, 45, 54, 55, 67, 69, 78], "salecondition_abnorml": [24, 67, 69], "salecondition_adjland": [24, 67, 69], "salecondition_alloca": [24, 67, 69], "salecondition_famili": [24, 67, 69], "salecondition_norm": [24, 67, 69], "salecondition_parti": [24, 67, 69], "salepric": [24, 26, 35, 43, 45, 54, 55, 67, 69, 78], "sales_data": [33, 76], "saleswoman": [31, 50, 51, 74], "saletyp": [24, 26, 35, 43, 45, 54, 55, 67, 69, 78], "saletype_cod": [24, 67, 69], "saletype_con": [24, 67, 69], "saletype_conld": [24, 67, 69], "saletype_conli": [24, 67, 69], "saletype_conlw": [24, 67, 69], "saletype_cwd": [24, 67, 69], "saletype_new": [24, 67, 69], "saletype_oth": [24, 67, 69], "saletype_wd": [24, 43, 67, 69], "salmongum": 96, "salt": [21, 26, 45, 64, 69], "salvador": 44, "salvag": 58, "sam": [30, 49, 73], "same": [7, 8, 13, 14, 15, 16, 17, 18, 19, 21, 22, 23, 24, 27, 28, 29, 30, 31, 32, 33, 34, 35, 37, 42, 43, 46, 49, 50, 51, 52, 53, 54, 55, 59, 60, 61, 62, 63, 64, 65, 66, 67, 70, 71, 72, 73, 74, 75, 76, 77, 78, 80, 81, 82, 84, 85, 86, 90, 91, 92, 93, 95, 96], "samosa": 51, "sampl": [13, 14, 15, 16, 18, 21, 22, 26, 29, 32, 33, 34, 35, 38, 41, 44, 45, 47, 48, 55, 59, 61, 62, 64, 65, 66, 69, 72, 75, 76, 77, 78, 79, 85, 86, 88, 90, 91, 92, 94, 95, 96], "sample_df": [56, 57, 79, 80], "sample_weight": 34, "samples_x": 94, "sampling_method": [44, 68], "sampling_strategi": 80, "samuel": [13, 58], "sand": [32, 75], "sandbar": [32, 75], "sandhu": [1, 98], "sane": 58, "saniti": [14, 34, 53, 59, 77], "sarah": 1, "sarcast": 58, "sat": [31, 33, 50, 74, 76], "satir": 58, "satisfactori": [28, 71], "satisfi": [28, 71], "satur": [35, 54, 55, 78], "saturdai": [33, 76], "sauc": [17, 39], "save": [8, 9, 19, 22, 26, 32, 35, 41, 45, 51, 52, 55, 63, 65, 69, 75, 76, 78, 86, 87, 90, 92, 93, 96], "saw": [18, 20, 21, 22, 29, 31, 32, 50, 62, 64, 65, 66, 72, 74, 75, 84], "sayid": 40, "sb": [27, 46, 70, 89, 95], "scalabl": [29, 72], "scalar": 9, "scale": [15, 16, 19, 22, 23, 24, 25, 27, 29, 31, 32, 34, 35, 37, 41, 42, 43, 44, 46, 50, 53, 55, 56, 57, 60, 61, 63, 65, 66, 67, 68, 70, 72, 74, 75, 77, 78, 79, 84, 86, 87, 89, 92, 93, 95], "scale_pos_weight": [25, 44, 68], "scaler": [17, 18, 26, 27, 34, 39, 45, 46, 62, 69, 70], "scan": 84, "scare": 20, "scari": [56, 57, 58, 79], "scariest": 58, "scatter": [24, 26, 27, 43, 45, 46, 62, 67, 69, 70, 89, 95, 97], "scatter_3d": [27, 46, 70], "scatterplot": [27, 46, 70, 79, 89, 95, 97], "scc": [31, 50, 51, 74], "scenario": [12, 15, 19, 26, 27, 29, 33, 34, 60, 63, 68, 69, 70, 72, 76, 77, 79, 84], "scene": 58, "scenic": 58, "sceptic": 58, "schafer": [56, 57, 79], "schedul": [5, 7, 53, 77, 84, 98], "schmidt": [22, 65], "scholarship": [13, 58], "school": [25, 26, 30, 44, 45, 49, 58, 66, 68, 69, 73], "schoolteach": [31, 50, 51, 74], "scienc": [1, 2, 5, 6, 10, 12, 19, 28, 31, 33, 35, 50, 55, 58, 63, 71, 74, 76, 78, 84], "scientif": [30, 31, 51, 58, 73, 74], "scientist": [1, 10, 29, 72], "scikit": [5, 10, 12, 14, 16, 21, 22, 23, 25, 28, 29, 32, 33, 35, 41, 42, 44, 55, 59, 61, 64, 65, 66, 68, 71, 72, 75, 76, 78, 80, 83], "scipi": [22, 29, 31, 41, 50, 51, 65, 72, 74, 77], "scm": 6, "scope": [13, 31, 33, 50, 51, 58, 74, 76], "score": [12, 15, 16, 17, 18, 19, 20, 25, 26, 29, 30, 31, 32, 33, 34, 35, 37, 38, 39, 40, 41, 44, 45, 46, 50, 51, 52, 53, 54, 55, 56, 57, 58, 61, 62, 63, 68, 69, 70, 72, 74, 75, 76, 77, 78, 79, 80, 83, 84, 85, 86, 88, 90, 91, 92, 93, 94, 95, 96, 98], "score_func": [24, 43, 67], "score_gb_test": [35, 54, 55, 78], "score_gb_train": [35, 54, 55, 78], "score_lr_print_coeff": [52, 76, 90, 96], "score_param": [19, 63], "score_rf_test": [35, 54, 55, 78], "score_rf_train": [35, 54, 55, 78], "score_tim": [15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 33, 34, 38, 39, 40, 42, 43, 44, 45, 46, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 76, 77, 80, 92, 93, 94], "scorer": [19, 24, 43, 63, 67], "scores_averag": [88, 94], "scores_dict": [20, 21, 40, 64], "scores_imag": [21, 64], "scores_stack": [88, 94], "scoring_method": [34, 53, 77], "scoring_metr": [25, 26, 44, 45, 68, 69], "scotland": [51, 82], "scott": [35, 55, 58, 78], "scratch": [2, 32, 75, 79], "screen": [8, 20, 40], "screenplai": 51, "screenporch": [24, 26, 35, 43, 45, 54, 55, 67, 69, 78], "screenshot": [35, 54, 55, 78], "script": 58, "sdng": [24, 43, 67, 69], "se": [34, 52, 76, 77, 96], "sea": [32, 75], "seaborn": [26, 27, 28, 29, 30, 45, 46, 49, 69, 70, 71, 72, 73, 89, 95], "seacoast": [32, 75], "seamless": 58, "search": [4, 6, 11, 24, 31, 43, 50, 51, 67, 74, 82, 84, 86, 92], "search_multi": [24, 43, 67], "seashor": [32, 75], "season": [90, 96], "season_autumn": [52, 76, 96], "season_fal": [52, 76], "season_spr": 96, "season_summ": [52, 76, 96], "season_wint": [52, 76, 96], "seat": [5, 32, 75, 98], "seawal": [32, 75], "second": [4, 7, 13, 14, 21, 25, 26, 29, 31, 32, 33, 35, 44, 45, 50, 55, 59, 64, 68, 69, 72, 74, 75, 76, 78], "secondari": 58, "section": [1, 8, 13, 14, 27, 46, 58, 59, 60, 70, 88, 94, 98], "secur": [26, 31, 45, 50, 56, 57, 69, 74, 79, 98], "see": [1, 4, 7, 8, 9, 11, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 31, 32, 33, 34, 35, 37, 38, 39, 42, 43, 44, 45, 47, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 71, 72, 74, 75, 76, 77, 78, 79, 84, 85, 86, 88, 89, 90, 91, 92, 94, 95, 96, 98], "seed": [21, 22, 28, 29, 38, 41, 47, 48, 64, 65, 71, 72, 79, 97], "seem": [14, 16, 18, 19, 20, 21, 22, 24, 25, 26, 28, 30, 33, 34, 40, 41, 43, 44, 45, 47, 49, 52, 53, 58, 59, 61, 62, 63, 64, 65, 66, 67, 68, 69, 71, 73, 76, 77, 80, 83, 86, 92, 95], "seemingli": 66, "seen": [9, 13, 16, 18, 19, 20, 21, 25, 27, 29, 30, 31, 34, 46, 49, 50, 58, 60, 61, 62, 63, 64, 70, 72, 73, 74, 77, 81, 84, 86, 88, 91, 92, 94], "segment": [12, 32, 34, 51, 58, 75, 77, 79, 80, 82, 84], "segmentspher": 79, "select": [1, 5, 6, 12, 14, 15, 16, 18, 19, 21, 22, 23, 24, 25, 26, 32, 33, 34, 35, 37, 40, 41, 42, 44, 55, 58, 60, 61, 62, 63, 64, 65, 66, 67, 68, 75, 76, 77, 78, 79, 80], "select_dtyp": [24, 43, 67, 89, 95], "select_knn": [27, 46, 70], "select_rf": [27, 46, 70], "select_svc": [27, 46, 70], "selectfrommodel": [27, 46, 70], "self": [13, 16, 17, 18, 19, 25, 26, 28, 31, 34, 39, 50, 53, 58, 63, 74, 77, 98], "sell": [0, 9, 14, 55, 58, 59, 78], "semant": [12, 28, 29, 50, 51, 71, 72, 74], "semest": [5, 13, 98], "semi": [1, 51], "semicolon": 9, "semilogx": [24, 43, 67], "send": [4, 58], "senior": [34, 53, 77], "seniorcitizen": [34, 53, 77], "sens": [7, 15, 19, 20, 21, 24, 26, 27, 28, 30, 31, 33, 34, 40, 43, 45, 46, 49, 50, 51, 52, 53, 58, 60, 63, 64, 66, 67, 69, 70, 71, 73, 74, 76, 77, 79, 83, 87, 93], "sensibl": [8, 79], "sensit": [5, 15, 18, 22, 23, 24, 28, 34, 41, 42, 43, 53, 60, 62, 65, 66, 67, 71, 77, 89, 93, 95, 98], "sent": [51, 58, 82], "sent_token": [31, 50, 51, 74, 82], "sentenc": [35, 51, 55, 78, 82], "sentence_transform": [31, 50, 74], "sentencetransform": [31, 50, 74], "sentiment": [20, 21, 40, 51, 59, 64], "sentiment_predict": [13, 58], "sep": [1, 13], "sepal": [16, 38, 61, 86, 92], "separ": [11, 14, 15, 17, 18, 19, 21, 23, 27, 28, 30, 31, 33, 39, 42, 46, 49, 50, 51, 52, 59, 60, 62, 63, 64, 66, 70, 71, 73, 74, 76, 82, 83, 84, 85, 86, 87, 91, 92, 93], "sept": [1, 13], "septemb": [13, 33, 52, 76, 96], "sequel": 58, "sequenc": [15, 19, 31, 32, 33, 50, 52, 58, 59, 60, 63, 74, 75, 76], "sequenti": [14, 25, 33, 34, 44, 59, 68, 76, 77, 84], "sequentialfeatureselector": [27, 81], "ser": [34, 62, 77], "seri": [1, 2, 12, 18, 19, 23, 27, 32, 34, 42, 46, 56, 57, 58, 60, 62, 63, 66, 70, 75, 77, 79], "serial": [25, 44, 68], "seriou": [7, 30, 31, 34, 51, 56, 57, 58, 73, 74, 77, 79, 80], "serious": 98, "serv": [12, 14, 26, 44, 45, 59, 69], "server": [31, 38, 50, 74], "servic": [17, 25, 26, 30, 31, 34, 39, 44, 45, 53, 68, 69, 73, 74, 77], "session": [5, 71, 84, 98], "set": [1, 6, 8, 9, 10, 14, 15, 16, 17, 18, 19, 20, 21, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 38, 39, 41, 42, 43, 44, 45, 49, 50, 51, 52, 53, 54, 55, 58, 59, 61, 62, 63, 64, 67, 68, 69, 71, 72, 73, 74, 75, 76, 77, 78, 80, 81, 82, 84, 86, 87, 88, 89, 90, 92, 93, 94, 95, 96, 97], "set_axis_off": [85, 91], "set_config": [22, 25, 41, 44, 65, 68], "set_index": [16, 22, 23, 24, 38, 41, 42, 43, 60, 61, 65, 66, 67], "set_num_thread": 32, "set_opt": [13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 29, 30, 37, 38, 39, 40, 41, 42, 49, 58, 59, 60, 61, 62, 63, 64, 65, 66, 72, 73, 80, 81, 85, 86, 87, 91, 92, 93], "set_properti": [13, 58], "set_se": [38, 47, 48], "set_titl": [16, 21, 32, 38, 61, 64, 66, 75, 86, 92], "set_xlabel": [16, 21, 28, 38, 61, 64, 71, 86, 89, 92, 95], "set_ylabel": [16, 21, 28, 38, 61, 64, 71, 86, 89, 92, 95], "set_ylim": [89, 95], "setosa": [32, 75], "settl": 84, "setup": [3, 8, 11, 13, 49, 50, 74, 91], "sev": [24, 26, 35, 43, 45, 54, 55, 67, 69, 78], "sever": [18, 21, 28, 29, 31, 32, 50, 51, 52, 62, 64, 71, 72, 74, 75, 76, 83, 90, 96, 98], "sewag": 58, "sex": [25, 26, 27, 44, 45, 66, 68, 69, 81, 88, 94], "sex_mal": [44, 45, 69], "sexual": 98, "sfu": [31, 50, 51, 74], "shall": [0, 31, 50, 51, 58, 74], "shallow": [25, 40, 44, 68], "shame": 58, "shan": [51, 82], "shap": 79, "shape": [14, 15, 16, 17, 18, 19, 20, 22, 23, 24, 26, 27, 28, 30, 31, 32, 33, 34, 35, 37, 38, 39, 40, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 59, 60, 61, 62, 63, 65, 66, 67, 68, 69, 70, 71, 73, 74, 75, 76, 77, 78, 80, 83, 84, 86, 90, 92, 96], "shape_df": 60, "shape_dict": 60, "share": [0, 5, 16, 17, 18, 20, 22, 27, 39, 56, 57, 58, 79, 81, 98], "sharealik": 1, "sharex": 62, "sharki": 58, "sharp": 58, "she": [13, 20, 30, 49, 51, 58, 73, 82], "shed": [20, 24, 26, 35, 43, 45, 54, 55, 67, 69, 78], "sheet": [10, 56, 57, 79, 84], "shelf": [25, 44, 51, 68, 82], "shell": [10, 13], "sheriff": 20, "shift": [11, 31, 33, 50, 52, 58, 74, 76, 90, 96], "shipyard": [17, 39], "shitti": [31, 50, 74], "shiver": 40, "shng": [24, 43, 67, 69], "shock": 20, "shoe": 58, "shoot": 58, "shop": [30, 31, 50, 73, 74], "short": [1, 11, 22, 25, 31, 35, 41, 44, 50, 51, 58, 60, 65, 68, 74, 98], "shorter": [34, 58, 77], "shorthand": [17, 18, 62], "shortli": [8, 56, 57, 79], "shot": [20, 27, 31, 46, 50, 58, 70, 74], "should": [5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 19, 21, 23, 26, 27, 28, 31, 32, 33, 34, 37, 38, 39, 40, 42, 45, 46, 49, 50, 51, 52, 56, 57, 58, 59, 60, 61, 62, 63, 64, 66, 69, 70, 71, 74, 75, 76, 77, 79, 80, 81, 82, 84, 85, 86, 87, 88, 90, 91, 92, 93, 94, 96, 98], "shouldn": [23, 25, 42, 44, 51, 66, 68, 80, 82, 86, 92], "shove": 58, "show": [4, 8, 13, 15, 17, 18, 19, 20, 22, 23, 24, 25, 27, 28, 29, 30, 31, 32, 33, 34, 37, 38, 39, 40, 41, 42, 43, 44, 46, 47, 48, 50, 52, 53, 54, 58, 60, 62, 63, 65, 66, 67, 68, 70, 71, 72, 73, 74, 75, 76, 77, 79, 84, 85, 86, 88, 90, 91, 92, 94, 95, 96, 97], "show_nearest_neighbor": 38, "show_plot": [34, 77], "showcas": [31, 50, 51, 74], "shown": [8, 13, 14, 16, 23, 25, 28, 29, 33, 35, 42, 44, 52, 55, 58, 59, 61, 66, 68, 71, 72, 76, 78], "showtim": 58, "shrink": [22, 27, 35, 41, 42, 55, 63, 65, 78, 81], "shuffl": [15, 38, 45, 47, 48, 52, 60, 76, 90, 96], "si": 58, "sibl": [27, 81], "sick": [28, 71], "side": [7, 17, 32, 35, 55, 58, 75, 78], "sidnei": 58, "sift": [30, 73], "sigma": [32, 75], "sign": [4, 20, 24, 26, 32, 40, 43, 45, 67, 69, 75, 86, 88, 92, 94, 98], "signal": [15, 51, 60], "signific": [12, 17, 18, 32, 35, 39, 55, 62, 75, 78, 86, 92], "significantli": [19, 30, 63, 66, 73], "sigoptsearchcv": [22, 41, 65], "silhouett": [29, 72, 89, 95], "silhouettevisu": [28, 29, 71, 72, 89, 95], "silicon": 11, "silli": 58, "silva": 58, "sim": [26, 45, 69], "sim_word": [31, 50, 51, 74], "simard": [26, 45, 69], "similar": [1, 11, 13, 14, 15, 19, 21, 22, 23, 24, 25, 27, 28, 29, 30, 32, 34, 35, 38, 41, 42, 43, 44, 46, 49, 50, 51, 53, 55, 59, 60, 63, 64, 65, 66, 67, 68, 70, 71, 72, 73, 75, 77, 78, 82, 83, 89, 95], "similarity_": [31, 51, 74], "similarli": [24, 26, 28, 34, 45, 53, 69, 71, 77], "simon_fras": [31, 50, 51, 74], "simp": [33, 76], "simpl": [1, 6, 14, 16, 17, 18, 24, 25, 26, 27, 29, 30, 32, 33, 34, 35, 44, 45, 46, 49, 51, 55, 56, 57, 58, 59, 61, 62, 66, 67, 68, 69, 70, 72, 73, 75, 76, 77, 78, 79, 80, 84, 85, 91, 98], "simplefilt": [25, 26, 44, 45, 68, 69], "simpleimput": [18, 19, 21, 22, 24, 25, 26, 27, 33, 34, 35, 41, 43, 44, 45, 46, 52, 53, 54, 55, 62, 63, 64, 65, 66, 67, 68, 69, 70, 76, 77, 78, 84, 87, 88, 90, 93, 94, 96], "simpleimputersimpleimput": [17, 18, 19, 24, 25, 27, 35, 43, 46, 54, 55, 70, 78], "simpler": [15, 16, 21, 22, 37, 64, 65, 79, 86, 92], "simplest": [19, 47, 63], "simpli": [18, 20, 27, 28, 31, 46, 50, 51, 62, 70, 71, 74, 81, 92], "simplic": [14, 19, 30, 49, 59, 63, 73], "simplist": [16, 20, 26, 38, 40, 61, 69, 86, 92], "simul": [27, 46, 70, 81], "sin": [9, 58], "sinatra": 58, "sinc": [6, 13, 21, 24, 26, 27, 28, 30, 32, 33, 34, 35, 38, 43, 45, 46, 49, 52, 53, 54, 55, 58, 64, 67, 69, 70, 71, 73, 75, 76, 77, 78, 83, 84, 85, 90, 91, 92, 93, 96], "singer_songwriter_bob_dylan": [31, 50, 51, 74], "singl": [9, 16, 18, 21, 22, 23, 25, 26, 29, 31, 33, 34, 38, 39, 42, 44, 45, 50, 52, 58, 61, 62, 64, 65, 66, 68, 69, 72, 74, 76, 77, 84, 85, 86, 91, 92], "sit": [5, 17, 20, 39, 40, 98], "sitarist_ravi_shankar": [31, 50, 51, 74], "site": [14, 16, 18, 19, 25, 26, 28, 31, 32, 34, 45, 50, 53, 59, 60, 63, 69, 74, 77, 83, 98], "situat": [7, 13, 23, 28, 32, 34, 42, 44, 58, 66, 68, 71, 75, 77, 98], "six": [25, 33, 60, 68, 76, 79], "size": [13, 14, 15, 16, 19, 22, 23, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 38, 41, 42, 44, 48, 49, 50, 51, 52, 53, 54, 55, 58, 59, 60, 61, 63, 65, 66, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 84, 85, 86, 88, 89, 90, 91, 92, 94, 95, 96, 97, 98], "skeleton": [35, 55, 78], "skeptic": [35, 78], "skew": [24, 43, 67], "skill": [5, 12, 58, 68, 79], "skin": 48, "skinhead": 40, "skip": [11, 58], "skip_check_arrai": [18, 34], "skip_parameter_valid": [18, 34], "skipna": [34, 77], "sklearn": [1, 13, 15, 16, 20, 21, 23, 24, 27, 28, 29, 30, 31, 32, 33, 34, 35, 37, 38, 40, 42, 43, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 60, 61, 64, 67, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96], "sklearn_gb": [25, 44, 68], "sklearn_histgb": [25, 44, 68], "sktime": [33, 52, 76], "skyblu": [52, 76, 90, 96], "skyscrap": [33, 76], "sl": [31, 50, 51, 74], "slash": 58, "slasher": 58, "slate": [90, 96], "slice": 9, "slide": [1, 10, 16, 18, 19, 32, 36, 62, 75, 98], "slight": 58, "slightli": [19, 21, 23, 25, 31, 34, 38, 39, 42, 44, 50, 51, 53, 58, 63, 64, 66, 68, 74, 77, 95], "slipper": [35, 54, 55, 78], "slope": [21, 64], "sloppi": [18, 62], "slow": [16, 25, 27, 31, 32, 44, 46, 50, 58, 61, 68, 70, 74, 75], "slower": [20, 25, 28, 40, 44, 68, 71], "slowest": [88, 94], "sm": [13, 19, 58, 63], "smac": [22, 41, 65], "small": [15, 16, 17, 19, 22, 24, 25, 26, 28, 30, 32, 34, 38, 39, 41, 43, 44, 45, 47, 48, 50, 58, 60, 61, 63, 65, 67, 68, 69, 70, 71, 73, 74, 75, 77, 84, 86, 88, 89, 92, 94, 95], "small_citi": [16, 61], "small_train_df": [16, 61], "smallalpha_coeff": [24, 43, 67], "smaller": [15, 16, 18, 19, 21, 23, 24, 25, 26, 27, 28, 29, 31, 33, 34, 35, 37, 42, 43, 44, 45, 46, 52, 55, 61, 62, 63, 64, 66, 67, 68, 69, 70, 71, 72, 74, 76, 77, 78, 86, 92], "smallest": [21, 24, 28, 29, 31, 41, 43, 50, 64, 65, 67, 71, 72, 74], "smart": [28, 35, 55, 71, 78], "smooth": [16, 61, 86, 92], "smoothli": 11, "smote": 66, "smote_pip": 80, "sms_df": [13, 58], "sn": [26, 28, 29, 45, 69, 71, 72], "snake": [21, 32, 64, 75], "snake_length": [21, 64], "snakes_df": [21, 64], "snippet": [8, 13], "snort": 58, "snow": [32, 58, 75], "snp": [27, 81], "snub": 20, "so": [0, 1, 4, 5, 8, 9, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 39, 40, 41, 42, 43, 44, 45, 46, 47, 49, 50, 51, 52, 53, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 86, 87, 88, 89, 90, 92, 93, 94, 95, 96, 98], "soap": [20, 40, 58], "soccer": 25, "social": [28, 29, 30, 33, 49, 58, 71, 72, 73, 76], "socialist": 58, "societ": 12, "societi": [31, 50, 51, 66, 74], "sofist": [86, 92], "soft": [17, 21, 25, 39, 44, 64, 68, 88, 94], "softmax": 84, "softwar": [1, 6, 11, 34, 53, 77], "sohail": 40, "sohbat": [1, 98], "solar": [30, 49, 73], "sold": [9, 24, 43, 67], "sole": [29, 66, 72], "solid": [20, 84], "solidifi": 84, "solut": [8, 13, 14, 15, 28, 34, 35, 53, 55, 58, 59, 60, 68, 71, 77, 78, 79, 84, 91, 92, 93, 94, 96, 98], "solv": [4, 13, 14, 16, 27, 31, 35, 46, 50, 51, 55, 58, 61, 70, 74, 78, 79, 86, 92, 98], "solver": [40, 42, 44, 53, 66, 67, 68, 75, 77, 94], "sombr": 58, "some": [4, 5, 6, 7, 8, 9, 11, 13, 15, 16, 17, 18, 19, 20, 21, 23, 24, 26, 28, 29, 30, 31, 32, 33, 34, 35, 37, 38, 39, 40, 41, 43, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 60, 61, 62, 63, 64, 67, 69, 71, 72, 73, 74, 75, 76, 77, 78, 80, 81, 82, 83, 85, 86, 87, 89, 90, 91, 92, 93, 95, 96, 97, 98], "somebodi": 20, "someon": [14, 15, 27, 34, 35, 55, 58, 59, 60, 77, 78, 81, 84], "someth": [4, 8, 14, 15, 19, 23, 24, 26, 28, 31, 33, 34, 35, 42, 43, 44, 45, 50, 52, 53, 54, 55, 56, 57, 58, 59, 63, 66, 67, 68, 69, 71, 74, 76, 77, 78, 79, 80], "sometim": [7, 11, 14, 15, 19, 20, 21, 22, 25, 26, 31, 35, 40, 41, 44, 50, 51, 54, 55, 56, 57, 59, 60, 63, 64, 65, 66, 68, 69, 74, 78, 79, 82], "somewhat": [20, 24, 67], "somewher": [13, 24, 43, 58, 67], "song": [13, 18, 30, 58, 61, 62, 73], "song_titl": [18, 22, 41, 61, 62, 65], "soo": [1, 98], "soon": [16, 18, 33, 52, 56, 57, 58, 61, 62, 76, 79], "sooooooo": 20, "sopha": 58, "sophist": [22, 26, 41, 45, 51, 65, 69, 82], "sort": [1, 15, 18, 20, 22, 23, 26, 30, 31, 32, 33, 40, 42, 45, 49, 50, 51, 52, 56, 57, 59, 60, 62, 69, 73, 74, 75, 76, 79, 90, 96], "sort_index": [9, 22, 24, 33, 41, 43, 52, 65, 67, 76, 90, 96], "sort_valu": [17, 18, 19, 20, 21, 22, 24, 25, 26, 27, 33, 34, 37, 40, 43, 44, 45, 46, 52, 53, 62, 63, 64, 65, 67, 68, 69, 70, 76, 77, 88, 90, 94, 96], "sorted_bow": 17, "sound": [26, 27, 45, 58, 69, 70, 86, 92], "soundtrack": 51, "sourc": [13, 14, 15, 17, 18, 19, 22, 25, 27, 28, 29, 30, 31, 32, 39, 41, 44, 45, 47, 50, 51, 58, 59, 60, 61, 62, 63, 65, 68, 69, 70, 71, 72, 73, 74, 75, 85, 91], "south": [25, 63], "space": [5, 11, 14, 16, 21, 22, 27, 28, 29, 31, 41, 46, 50, 51, 61, 64, 65, 71, 72, 74, 81, 82, 90, 96, 98], "spaci": [27, 31, 46, 50, 70, 74, 82], "spam": [15, 23, 28, 42, 60, 66, 71], "spam_predict": [13, 58], "span": [33, 51, 76, 82], "spanish": [18, 62], "spars": [13, 16, 17, 20, 21, 25, 30, 31, 39, 40, 44, 49, 50, 51, 61, 64, 68, 73, 74, 84], "sparse_output": [17, 18, 19, 24, 25, 26, 34, 35, 39, 41, 43, 44, 45, 52, 53, 54, 55, 62, 63, 65, 66, 67, 68, 69, 76, 77, 78, 84, 88, 90, 94, 96], "sparse_output_": 34, "sparse_threshold": [39, 41, 44, 45, 63, 65, 67, 68, 69, 94], "spatial": [21, 32, 64, 75], "spawn": 58, "speak": 79, "spearmint": [22, 41, 65], "speci": [16, 38, 47, 61, 84, 86, 92], "special": [12, 13, 19, 30, 31, 32, 33, 34, 50, 51, 58, 63, 73, 74, 75, 76, 77], "specialti": [25, 26, 44, 45, 66, 68, 69], "specif": [9, 12, 14, 15, 18, 22, 26, 28, 30, 31, 32, 33, 34, 35, 41, 45, 50, 51, 55, 56, 57, 59, 60, 65, 66, 69, 71, 73, 74, 75, 76, 77, 78, 79, 80, 81, 84, 86, 88, 92, 94], "specifi": [9, 14, 15, 17, 19, 22, 28, 29, 32, 35, 38, 41, 55, 56, 57, 59, 60, 63, 65, 66, 71, 72, 75, 78, 79, 88, 94, 98], "spectacl": 58, "spectacular": 58, "spectrogram": [27, 70], "speech": [13, 27, 31, 46, 50, 51, 58, 70, 74, 82], "speechi": [18, 22, 41, 61, 62, 65], "speed": [9, 14, 20, 25, 32, 40, 44, 56, 57, 59, 68, 75, 79, 98], "spend": [13, 17, 18, 20, 27, 28, 39, 40, 55, 58, 62, 70, 78], "spending_scor": 28, "spent": [7, 18, 27, 46, 62, 70], "spheric": [29, 72, 84], "spici": [28, 71], "spini": [32, 75], "spit": [32, 75], "split": [12, 14, 16, 19, 20, 21, 22, 23, 24, 25, 27, 30, 34, 40, 42, 43, 44, 45, 46, 49, 51, 59, 61, 63, 64, 65, 67, 68, 69, 70, 73, 77, 79, 82, 84, 88, 90, 91, 94, 96, 98], "split0_test_r2": 24, "split0_test_scor": [22, 41, 65], "split0_train_neg_mean_squared_error": 24, "split0_train_scor": [22, 41, 65], "split1_test_r2": 24, "split1_test_scor": [22, 41, 65], "split1_train_neg_mean_squared_error": 24, "split1_train_scor": [22, 41, 65], "split2_test_r2": 24, "split2_test_scor": [22, 41, 65], "split2_train_neg_mean_squared_error": 24, "split2_train_scor": [22, 41, 65], "split3_test_r2": 24, "split3_test_scor": [22, 41, 65], "split3_train_neg_mean_squared_error": 24, "split3_train_scor": [22, 41, 65], "split4_test_scor": [22, 41, 65], "split4_train_neg_mean_squared_error": 24, "split4_train_scor": [22, 41, 65], "splitter": [37, 44, 68, 94], "spoil": [20, 58], "spoiler": 58, "spoken": [19, 63], "spooki": 58, "sport": [31, 32, 33, 50, 51, 74, 75, 76], "spot": [23, 24, 40, 42, 58, 66, 67, 79, 80, 86, 92], "spotifi": [13, 30, 41, 58, 61, 73], "spotify_df": [18, 22, 41, 61, 62, 65], "spotlight": 6, "spous": [25, 26, 44, 45, 66, 68, 69], "spout": 58, "spread": [29, 72], "spring": 96, "spring_month": [52, 76, 96], "spring_rol": [32, 75], "sqft": [26, 45, 69, 92], "sqft_abov": [15, 37, 58, 59], "sqft_basement": [15, 37, 58, 59], "sqft_live": [15, 37, 58, 59], "sqft_living15": [15, 37, 58, 59], "sqft_lot": [15, 37, 58, 59], "sqft_lot15": [15, 37, 58, 59], "sqrt": [16, 24, 26, 30, 31, 43, 44, 45, 49, 51, 61, 67, 68, 69, 73, 74, 94], "squar": [9, 12, 14, 16, 21, 26, 30, 34, 35, 45, 49, 55, 59, 61, 64, 69, 73, 77, 78, 84, 86, 92], "squared_error": 37, "squash": [21, 32, 64, 75], "squeez": [9, 17, 34, 39, 53, 77], "src": [15, 32, 60, 66], "sse": [52, 76, 96], "ssfbc": 34, "ssh": 6, "sst": [31, 50, 74], "ssw": [52, 76], "st": [33, 76, 94], "st_slope": [88, 94], "stabl": [11, 13, 15, 18, 25, 44, 58, 60, 66, 68, 86, 92], "stack": [8, 12, 17, 39, 79, 84], "stack_method": [88, 94], "stacking_model": [25, 44, 68, 88, 94], "stacking_model_tre": [25, 44, 68], "stackingclassifi": [25, 44, 68, 88, 94], "stackingregressor": [25, 44, 68], "staff": 7, "stage": 58, "stai": [11, 13, 20, 23, 34, 42, 53, 58, 66, 77, 98], "stair": 58, "stakehold": [12, 35, 55, 78, 79], "stale": [28, 71], "stand": [16, 22, 41, 51, 56, 57, 58, 61, 65, 79], "standard": [4, 7, 15, 18, 22, 25, 26, 27, 39, 44, 45, 46, 51, 60, 62, 65, 68, 69, 70, 76, 79], "standardscal": [17, 19, 21, 22, 23, 24, 25, 26, 27, 29, 30, 32, 33, 34, 35, 39, 41, 42, 43, 44, 45, 46, 49, 52, 53, 54, 55, 63, 64, 65, 66, 67, 68, 69, 70, 72, 73, 75, 76, 77, 78, 80, 81, 84, 87, 88, 89, 90, 93, 94, 95, 96], "standardscaler__lab1": 63, "standardscaler__lab3": 63, "standardscaler__lab4": 63, "standardscaler__quiz1": 63, "standardscaler__university_year": 63, "standardscalerstandardscal": [17, 18, 19, 22, 23, 24, 25, 27, 35, 43, 46, 54, 55, 66, 70, 78], "stanford": [31, 50, 51, 74], "stanisla": 20, "stanlei": 58, "star": [16, 28, 30, 49, 58, 61, 71, 73], "start": [5, 8, 9, 14, 15, 17, 20, 23, 25, 26, 27, 28, 29, 31, 32, 33, 34, 35, 39, 42, 44, 45, 46, 47, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 66, 68, 69, 70, 71, 72, 74, 75, 76, 77, 78, 79, 80, 84, 85, 86, 87, 89, 90, 91, 92, 93, 95, 96], "startl": 58, "startswith": [13, 20, 23, 26, 42, 45, 69], "starttim": [33, 76], "stat": [22, 34, 41, 65, 77], "state": [9, 15, 20, 25, 26, 30, 34, 44, 45, 51, 56, 57, 58, 60, 66, 68, 69, 73, 79, 82], "statement": [8, 14, 15, 16, 18, 19, 21, 22, 24, 32, 34, 35, 55, 60, 61, 62, 63, 64, 65, 66, 67, 70, 75, 77, 78], "static": [13, 56, 57, 79], "station": [33, 58, 76], "statist": [1, 10, 12, 14, 21, 26, 30, 34, 45, 50, 51, 53, 59, 64, 69, 73, 74, 77], "statistician": [16, 61], "statlib": [21, 64], "statsmodel": [33, 34, 52, 53, 76, 77], "statu": [20, 25, 26, 44, 45, 66, 68, 69], "status_divorc": 44, "status_marri": [26, 44, 45, 69], "status_nev": [26, 44, 45, 69], "status_separ": [44, 45, 69], "status_widow": 44, "std": [15, 16, 17, 18, 23, 24, 37, 38, 39, 42, 43, 52, 60, 61, 62, 66, 67, 76, 83, 92, 95, 96], "std_cv_error": 60, "std_cv_score": [16, 38, 61], "std_fit_tim": [22, 24, 41, 65], "std_score": [18, 60, 62], "std_score_tim": [22, 24, 41, 65], "std_test_neg_mean_squared_error": 24, "std_test_scor": [22, 41, 60, 65], "std_train_error": 60, "std_train_neg_mean_squared_error": 24, "std_train_scor": [16, 22, 38, 41, 60, 61, 65], "stdki": [34, 77], "steadi": 58, "steal": 20, "steeman": 20, "stellar": 58, "stem": [51, 82], "step": [8, 13, 15, 16, 17, 18, 19, 20, 22, 23, 24, 25, 26, 27, 28, 29, 31, 32, 33, 34, 35, 39, 40, 41, 42, 43, 44, 45, 46, 49, 50, 54, 55, 58, 60, 61, 62, 63, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 84, 86, 88, 89, 91, 92, 94, 95, 98], "stereotyp": [31, 50, 51, 74], "stick": [17, 33, 40, 52, 58, 76], "sticki": [31, 50, 74], "still": [4, 11, 14, 17, 20, 22, 24, 25, 27, 28, 31, 33, 34, 41, 44, 46, 47, 50, 52, 53, 58, 65, 66, 67, 68, 70, 71, 74, 76, 77, 87, 93], "stinker": [20, 58], "stipul": [35, 55, 78], "stochast": [27, 28, 46, 71, 81], "stock": [13, 33, 58, 76], "stomach": 40, "stop": [9, 15, 17, 28, 32, 34, 37, 39, 51, 53, 71, 75, 77, 82, 86, 92], "stop_word": [17, 20, 22, 31, 39, 40, 41, 50, 51, 56, 57, 63, 65, 74, 79, 80, 82], "stopword": [31, 50, 51, 74, 82], "storag": 61, "store": [8, 9, 16, 17, 18, 19, 20, 22, 23, 25, 26, 29, 30, 31, 32, 33, 34, 37, 39, 40, 42, 44, 45, 49, 50, 51, 61, 62, 63, 65, 66, 68, 69, 72, 73, 74, 75, 76, 77, 79], "stori": [20, 24, 25, 43, 58, 67, 68], "storylin": [31, 50, 51, 74], "storytel": 58, "str": [13, 20, 22, 23, 26, 31, 33, 34, 38, 41, 42, 45, 50, 51, 52, 65, 69, 74, 76, 77, 90, 96], "straight": [34, 56, 57, 77, 79], "straightforward": [26, 30, 45, 69], "strain": 8, "strang": [26, 34, 45, 53, 69, 77], "strata": [34, 77], "strategi": [14, 16, 17, 18, 19, 23, 24, 26, 28, 30, 34, 35, 39, 42, 43, 45, 49, 52, 53, 54, 55, 59, 61, 62, 63, 66, 67, 69, 71, 73, 76, 77, 78, 79, 84, 85, 87, 90, 91, 92, 93, 96], "stratif": [34, 77], "stratifi": [34, 77], "stratifiedkfold": [15, 60, 66], "stratton": 58, "strawberri": 95, "stream": [34, 77], "streamingmovi": [34, 53, 77], "streamingmovies_no": [34, 53, 77], "streamingmovies_y": [34, 53, 77], "streamingtv": [34, 53, 77], "streamingtv_no": [34, 53, 77], "streamingtv_y": [34, 53, 77], "street": [24, 26, 35, 43, 45, 54, 55, 67, 69, 78], "street_grvl": [24, 67, 69, 78], "street_pav": [24, 67, 69, 78], "strength": [20, 32, 51, 75, 82, 84], "stress": [58, 71, 84], "strftime": [33, 53, 76, 77], "strict": [40, 41, 63, 65], "strictli": 39, "string": [9, 16, 23, 24, 25, 26, 31, 34, 39, 42, 43, 44, 45, 50, 51, 52, 58, 61, 66, 67, 68, 69, 74, 76, 77, 82, 86, 88, 92, 94, 96], "strip": [26, 32, 45, 69, 75], "strip_acc": [40, 41, 63, 65], "strong": [25, 34, 44, 53, 68, 77], "stronger": [25, 44, 68], "strongli": [25, 44, 68], "struck": [20, 40], "structur": [9, 28, 31, 32, 51, 58, 71, 74, 75, 82], "struggl": [33, 71, 76], "stuart": [1, 25, 44, 68], "stuck": [4, 6, 9, 11], "student": [1, 4, 5, 7, 8, 12, 13, 14, 17, 21, 24, 26, 27, 28, 29, 30, 32, 56, 57, 58, 59, 64, 66, 67, 69, 70, 71, 72, 73, 75, 79, 98], "studi": [13, 19, 27, 31, 34, 50, 51, 53, 58, 63, 70, 74, 77, 82], "studio": 11, "stuff": [16, 32, 34, 38, 47, 48, 53, 58, 61, 75, 77], "stump": [14, 15, 16, 37, 44, 59, 60, 61, 68, 85, 91], "stun": [20, 40], "stunningli": 20, "stupid": 58, "style": [24, 27, 28, 30, 32, 43, 46, 48, 49, 51, 56, 57, 58, 67, 70, 71, 73, 75, 79, 82, 89, 95], "sub": [20, 28, 34, 40, 50, 51, 53, 59, 65, 71, 74, 77, 79, 84], "subdirectori": [26, 45, 56, 57, 69, 79], "subgroup": [34, 53, 77], "subject": [0, 1, 34, 77], "sublicens": 0, "submiss": [3, 58], "submit": [1, 9, 13, 56, 57, 79, 98], "subplot": [16, 21, 28, 32, 34, 35, 38, 53, 54, 55, 60, 61, 64, 66, 71, 75, 77, 78, 85, 86, 89, 91, 92, 95], "subplot_kw": [38, 60, 85, 91], "subplots_adjust": [89, 95], "subprocess": [16, 23, 24, 25, 26, 28, 42, 43, 67], "subsampl": [44, 45, 68, 69, 94], "subsample_for_bin": [44, 45, 68, 69, 94], "subsample_freq": [44, 45, 68, 69, 94], "subscrib": [34, 77], "subscript": [33, 34, 76, 77], "subset": [13, 14, 15, 22, 25, 32, 33, 38, 41, 44, 47, 48, 58, 59, 60, 65, 68, 75, 76, 83, 86, 90, 92, 96], "substanc": [20, 58], "substanti": 0, "substitut": [0, 5, 98], "subtl": [31, 51, 58, 74], "subtleti": [15, 24, 43, 60, 67], "subtract": [13, 16, 26, 42, 45, 61, 66, 69], "subword": [31, 50, 51, 74], "succe": [27, 70], "success": [5, 6, 9, 13, 25, 30, 31, 32, 33, 50, 51, 52, 58, 68, 73, 74, 75, 76, 79, 80, 98], "successfulli": [13, 58, 66], "suddenl": [20, 40], "suddenli": 58, "sudo": 6, "suei": 65, "suffer": [22, 65], "suffici": [8, 51, 82, 98], "sugari": 95, "sugarperc": [89, 95], "suggest": [0, 1, 14, 25, 30, 34, 49, 53, 59, 73, 77, 95], "suicid": [51, 58], "suit": [18, 30, 32, 58, 73, 75], "suitabl": [12, 13, 28, 30, 37, 58, 71, 73, 79, 84, 88, 94], "suitcas": 40, "sultan": [31, 50, 51, 74], "sum": [9, 16, 17, 18, 19, 20, 21, 25, 26, 28, 32, 44, 45, 58, 61, 62, 63, 64, 68, 69, 71, 75], "sum_": [16, 24, 28, 31, 32, 43, 51, 61, 67, 71, 74, 75], "sum_i": [26, 31, 45, 51, 69, 74], "sum_prob_ex1_class_0": [25, 44, 68], "sum_prob_ex1_class_1": [25, 44, 68], "summar": [1, 13, 21, 23, 24, 28, 31, 42, 43, 50, 51, 58, 64, 66, 67, 71, 74, 79], "summari": [0, 83, 84, 86, 89, 92, 95], "summary_plot": [26, 45, 69], "summat": [25, 35, 44, 55, 68, 78], "summer": [20, 30, 31, 40, 49, 50, 52, 73, 74, 76, 96], "summer_month": [52, 76, 96], "sun": [31, 33, 50, 51, 74, 76], "sundai": [33, 58, 76], "sundial": [32, 75], "sunshin": [52, 76, 90, 96], "super": [19, 31, 34, 50, 58, 63, 74, 84], "superb": 58, "superfici": [16, 61], "superior": 12, "supervis": [12, 18, 19, 22, 23, 24, 27, 29, 31, 33, 34, 42, 43, 46, 50, 51, 52, 53, 62, 63, 65, 66, 67, 70, 72, 74, 76, 77, 81, 84, 90, 96, 98], "suppli": 98, "support": [5, 11, 14, 18, 23, 25, 26, 29, 31, 34, 35, 38, 42, 44, 45, 46, 50, 51, 55, 59, 62, 66, 68, 69, 70, 72, 74, 78, 80, 82, 83, 84, 86, 92, 98], "support_": [16, 27, 46, 61, 70], "suppos": [13, 15, 16, 17, 18, 19, 21, 22, 23, 25, 26, 27, 28, 29, 30, 31, 35, 39, 41, 42, 45, 46, 49, 50, 51, 55, 58, 59, 60, 61, 62, 63, 64, 65, 66, 68, 69, 70, 71, 72, 73, 74, 78, 81, 84, 85, 91], "suppress": 9, "suprem": [31, 50, 51, 74], "supr\u00eam": [31, 50, 51, 74], "suptitl": [89, 95], "sure": [4, 5, 8, 9, 11, 16, 19, 23, 24, 25, 26, 29, 32, 34, 35, 42, 43, 44, 45, 52, 55, 56, 57, 60, 61, 63, 66, 67, 68, 69, 72, 75, 76, 78, 79, 86, 88, 89, 90, 92, 94, 95, 96, 98], "surfac": [14, 58], "surgeri": [34, 77], "surpass": 58, "surpris": [20, 26, 30, 31, 45, 49, 50, 69, 73, 74, 92], "surprisingli": [19, 21, 63, 64], "surround": [4, 12, 31, 35, 50, 74, 78], "survei": [17, 28, 39, 71], "surveil": 58, "surviv": [1, 2, 12, 55, 78, 79], "survival_function_": [34, 53, 77], "suscept": [29, 72, 79], "sushi": [32, 75], "suspect": [22, 58, 65, 98], "suspens": [20, 58], "svc": [16, 17, 18, 19, 21, 22, 25, 26, 27, 32, 38, 39, 41, 44, 45, 46, 61, 62, 63, 64, 65, 68, 69, 70, 75, 83, 86, 87, 88, 92, 93, 94], "svc__c": [22, 41, 65], "svc__gamma": [22, 41, 65], "svc_all_pip": [17, 39], "svc_num_cat_text_pip": [17, 39], "svc_pipe": [22, 41, 65], "svc_pred": [23, 42, 66], "svcsvc": [19, 22, 23, 66], "svm": [1, 15, 17, 18, 19, 22, 25, 26, 27, 32, 33, 35, 39, 41, 44, 45, 46, 55, 60, 62, 63, 65, 68, 69, 70, 75, 76, 78, 79, 83, 84, 86, 87, 88, 92, 93, 94], "svm_estim": 80, "svr": [16, 26, 35, 45, 55, 61, 63, 69, 78, 93], "svr_c_pipe": 63, "svr_pipe": 63, "sw": [52, 76, 96], "swai": 58, "swamp": [16, 61], "swan": [32, 75], "swcarpentri": 10, "sweep": [23, 42, 66], "sweet": [20, 58], "switch": [26, 28, 34, 35, 45, 52, 53, 55, 69, 71, 76, 77, 78, 90, 93, 96], "swoop": 58, "sy": [13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 25, 26, 27, 28, 29, 30, 31, 32, 34, 35, 37, 38, 39, 40, 41, 42, 44, 45, 46, 47, 48, 49, 50, 51, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 68, 69, 70, 71, 72, 73, 74, 75, 77, 78, 79, 80, 81, 83, 84, 85, 86, 87, 88, 89, 91, 92, 93, 94, 95], "sydnei": [52, 76, 96], "sydneyairport": 96, "syllabu": [3, 13], "symbol": [14, 59], "symlink": 31, "symmetri": [27, 46, 70], "sync": 6, "synonym": 51, "synopsi": [31, 50, 51, 74], "syntact": [50, 51, 74], "syntax": [4, 9, 13, 27, 31, 34, 46, 50, 53, 58, 70, 74, 77], "syntaxwarn": 59, "synthet": [27, 46, 70, 83], "syrupi": 40, "system": [1, 2, 4, 6, 7, 11, 12, 13, 15, 23, 26, 28, 31, 33, 38, 42, 45, 50, 55, 58, 60, 61, 63, 66, 69, 71, 74, 76, 78, 79], "systemat": [14, 22, 26, 31, 45, 50, 51, 59, 63, 65, 69, 74], "t": [1, 4, 5, 8, 9, 11, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 37, 38, 39, 41, 42, 43, 44, 45, 46, 47, 49, 50, 51, 52, 53, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 86, 88, 90, 92, 94, 96, 98], "t0f6lfzl": [31, 50, 74], "t1a": 98, "t1b": 98, "t1c": 98, "t1d": 98, "t1e": 98, "t1f": 98, "t1g": 98, "t1h": 98, "t1j": 98, "t1k": 98, "t1l": 98, "t5": [31, 50, 74], "ta": [5, 8, 13, 24, 26, 35, 43, 45, 54, 55, 58, 67, 69, 78, 79, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96], "tab": [1, 13], "tabbi": [32, 58, 75], "tabl": [1, 8, 17, 25, 31, 39, 50, 74, 88, 94], "tabular": [9, 13, 33, 38, 58, 76], "tackl": [17, 18, 29, 60, 62, 72, 74, 80], "taco": [27, 81], "tag": [4, 13, 31, 50, 51, 58, 74, 82], "tail": [9, 33, 76], "tailor": [12, 28, 35, 71, 78, 79], "take": [2, 4, 7, 13, 14, 15, 16, 17, 18, 21, 22, 24, 25, 26, 27, 28, 30, 31, 32, 34, 35, 39, 41, 42, 43, 44, 45, 46, 49, 50, 51, 52, 53, 55, 56, 57, 58, 59, 60, 61, 62, 64, 65, 66, 67, 68, 69, 70, 71, 73, 74, 75, 76, 77, 78, 79, 80, 83, 85, 86, 87, 88, 89, 90, 91, 92, 94, 95, 96, 98], "takeawai": [31, 50, 74], "taken": [33, 58, 76, 83, 98], "talent": 58, "talk": [14, 15, 18, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 42, 43, 44, 45, 49, 50, 51, 56, 57, 59, 60, 62, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 79, 80, 82, 83, 84, 86, 92, 98], "tall": [31, 50, 51, 74], "target": [15, 16, 17, 18, 20, 21, 22, 23, 25, 26, 27, 30, 32, 33, 34, 35, 37, 38, 39, 40, 41, 42, 44, 45, 46, 52, 53, 55, 56, 57, 60, 61, 62, 64, 65, 66, 68, 69, 70, 73, 75, 76, 77, 78, 79, 80, 84, 86, 87, 88, 90, 92, 93, 94, 96], "target_column": [25, 26, 34, 44, 45, 53, 68, 69, 77, 88, 94], "target_nam": [23, 42, 66, 80], "target_names_toi": 80, "target_tag": 18, "tariff": 51, "task": [12, 13, 18, 19, 21, 22, 26, 27, 28, 30, 31, 32, 33, 34, 35, 37, 38, 41, 45, 46, 50, 52, 55, 58, 62, 63, 64, 65, 69, 70, 71, 73, 74, 75, 76, 77, 78, 79, 81, 84, 86, 90, 92, 96, 98], "tast": [17, 28, 30, 39, 49, 71, 73], "tasti": [17, 39], "taught": [19, 31, 50, 51, 63, 74, 98], "tax": [35, 54, 55, 78], "tba": 1, "tea": 20, "teach": [4, 13, 18, 31, 50, 51, 58, 62, 74, 82, 84], "team": [4, 9, 13, 26, 31, 45, 50, 51, 58, 68, 69, 74, 82, 88, 94], "tech": [26, 45, 61, 66, 69], "technic": [31, 35, 50, 74, 78, 79, 98], "technician": [31, 50, 74], "techniqu": [1, 12, 16, 20, 22, 23, 27, 30, 32, 34, 40, 41, 42, 49, 58, 61, 65, 66, 70, 73, 75, 77, 79, 83], "technocrat": 58, "technolog": 0, "technologi": [31, 51, 58, 74], "techsupport": [34, 53, 77], "techsupport_no": [34, 53, 77], "techsupport_y": [34, 53, 77], "ted": [28, 71], "tediou": [29, 72], "telco": [34, 53, 77], "telecom": [34, 77], "telephon": [31, 50, 51, 74], "tell": [15, 18, 20, 21, 23, 26, 27, 30, 31, 34, 35, 40, 42, 45, 46, 49, 50, 51, 52, 53, 55, 56, 57, 60, 61, 62, 64, 66, 69, 70, 73, 74, 76, 77, 78, 79, 81, 86, 90, 92, 96], "temp": 34, "temp3pm": [52, 76, 90, 96], "temp9am": [52, 76, 90, 96], "temperatur": [14, 59, 92], "templat": [56, 57, 79], "tempo": [18, 22, 41, 61, 62, 65], "tempor": [34, 52, 77, 84, 90, 96], "ten": 58, "tend": [15, 16, 21, 25, 30, 31, 33, 34, 44, 49, 50, 53, 58, 60, 61, 64, 68, 70, 73, 74, 76, 77, 95, 98], "tendenc": [15, 60], "tension": 58, "tensor": 38, "tensorflow": [26, 32, 45, 69, 75], "tenur": [27, 34, 53, 55, 77, 78, 84], "tenure_lm": [34, 77], "tenure_predict": [34, 77], "term": [0, 2, 5, 6, 14, 16, 19, 21, 23, 26, 27, 30, 31, 34, 35, 37, 42, 45, 46, 49, 50, 51, 55, 58, 59, 61, 63, 64, 66, 69, 70, 73, 74, 77, 78, 79, 81, 82, 84, 98], "termin": [6, 11, 28, 56, 57, 58, 59, 71, 79], "terminologi": [42, 60, 66, 84, 85, 91], "terrac": [32, 75], "terribl": [20, 24, 30, 31, 40, 43, 49, 50, 67, 73, 74], "territori": 98, "terror": 58, "terrorist": 40, "tesoro": 65, "test": [1, 8, 9, 11, 13, 14, 16, 17, 18, 19, 20, 21, 23, 24, 25, 26, 29, 31, 34, 35, 38, 39, 40, 41, 42, 43, 44, 45, 50, 53, 54, 55, 56, 57, 58, 59, 61, 62, 63, 64, 66, 67, 68, 69, 72, 74, 77, 78, 79, 83, 84, 86, 88, 90, 91, 92, 94, 96, 98], "test_accuraci": [23, 42, 66], "test_average_precis": [23, 42, 66, 80], "test_df": [13, 15, 18, 20, 21, 23, 24, 25, 26, 27, 33, 34, 35, 40, 42, 43, 44, 45, 46, 52, 53, 54, 55, 56, 57, 58, 62, 63, 64, 66, 67, 68, 69, 70, 76, 77, 78, 79, 80, 87, 88, 90, 93, 94, 96], "test_df_churn": [34, 77], "test_df_nan": [25, 26, 44, 45, 66, 68, 69], "test_df_sort": [33, 52, 76], "test_df_surv": [34, 53, 77], "test_exampl": [25, 44, 68], "test_f1": [23, 42, 66], "test_format": [16, 61], "test_g50k": [25, 44, 68], "test_idx": 38, "test_imag": [13, 32, 58, 75], "test_l50k": [25, 44, 68], "test_mape_scor": [24, 67], "test_nam": [34, 77], "test_neg_mean_squared_error": [24, 67], "test_neg_root_mean_square_error": [24, 67], "test_point": [16, 61, 83], "test_precis": [23, 42, 66], "test_r2": [24, 67], "test_recal": [23, 42, 66], "test_roc_auc": [23, 42, 66, 80], "test_sampl": [88, 94], "test_scor": [15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 33, 34, 37, 38, 39, 40, 42, 43, 44, 45, 46, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 76, 77, 86, 92, 93, 94], "test_shap_valu": [26, 45, 69], "test_siz": [13, 15, 16, 17, 18, 20, 21, 22, 23, 24, 25, 26, 27, 30, 32, 33, 35, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 49, 54, 55, 56, 57, 58, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 73, 75, 76, 78, 79, 80, 83, 86, 87, 88, 92, 93, 94], "test_sklearn": [24, 67], "test_statist": [34, 77], "test_x": [34, 53, 77], "text": [1, 8, 12, 13, 14, 18, 20, 21, 22, 23, 24, 25, 26, 27, 30, 32, 35, 40, 41, 42, 43, 44, 45, 46, 49, 55, 56, 57, 58, 59, 64, 65, 66, 67, 68, 69, 70, 73, 75, 78, 79, 80, 84, 89, 95], "text_count": 17, "text_feat": [17, 22, 39, 41, 65], "text_pip": [17, 39], "text_pp": [31, 50, 51, 74], "text_transform": [17, 39], "textbook": [3, 10, 13, 35, 54, 55, 78], "textil": 58, "textrm": [15, 60], "textual": 12, "textur": [27, 46, 70], "tf": [19, 31, 50, 63, 74], "tfidfvector": [21, 40, 64], "th": [13, 21, 30, 64, 73], "thai": [17, 39], "than": [7, 13, 14, 15, 16, 17, 18, 20, 21, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33, 34, 38, 39, 40, 41, 42, 43, 44, 45, 46, 49, 50, 51, 53, 58, 59, 60, 61, 62, 64, 66, 67, 68, 69, 71, 72, 73, 74, 75, 76, 77, 80, 82, 83, 85, 86, 88, 91, 92, 94, 95, 98], "thank": [51, 58, 86, 92], "thankfulli": [52, 76, 90, 96], "theater": [20, 40, 58], "thei": [1, 8, 9, 14, 15, 16, 17, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 39, 40, 41, 42, 43, 45, 46, 49, 50, 51, 52, 53, 55, 58, 59, 60, 61, 64, 65, 66, 67, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 85, 86, 88, 89, 90, 91, 92, 94, 95, 96, 98], "theirs": [51, 82], "them": [1, 2, 4, 5, 8, 12, 14, 15, 16, 18, 19, 21, 22, 24, 25, 26, 27, 30, 31, 32, 33, 34, 35, 38, 43, 44, 45, 46, 49, 50, 51, 53, 54, 55, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 73, 74, 75, 76, 77, 78, 79, 81, 82, 84, 85, 86, 88, 91, 92, 93, 94, 98], "themat": 58, "theme": [17, 31, 51, 58, 74], "themselv": [28, 29, 51, 71, 72, 82], "theoret": [18, 25, 62, 66, 68, 84], "theori": [26, 45, 69], "thereaft": 20, "therefor": [86, 89, 92, 95], "theresult": [89, 95], "thermostat": [14, 59], "thi": [0, 1, 2, 4, 6, 7, 8, 11, 12, 14, 15, 16, 20, 21, 22, 24, 25, 27, 28, 29, 30, 31, 32, 33, 34, 38, 40, 41, 43, 44, 46, 47, 48, 49, 50, 51, 52, 53, 54, 56, 57, 59, 60, 61, 64, 65, 66, 67, 68, 70, 71, 72, 73, 74, 75, 76, 77, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 98], "thick": [17, 20, 28, 39, 71], "thing": [1, 5, 8, 9, 13, 14, 15, 16, 20, 22, 23, 26, 27, 28, 29, 30, 31, 32, 33, 34, 40, 41, 42, 45, 49, 50, 51, 52, 53, 58, 59, 60, 61, 65, 66, 69, 70, 71, 72, 73, 74, 75, 76, 77, 79, 81, 82, 86, 88, 90, 92, 93, 94, 96], "think": [4, 6, 13, 14, 15, 16, 17, 19, 20, 21, 24, 26, 27, 28, 30, 31, 32, 34, 35, 39, 40, 43, 45, 46, 49, 50, 52, 53, 55, 58, 59, 60, 61, 63, 64, 66, 67, 69, 70, 71, 73, 74, 75, 76, 77, 78, 79, 80, 84, 85, 86, 89, 90, 91, 92, 95, 96, 98], "third": [29, 72], "thk": 58, "thompson": 20, "thorough": [88, 94], "those": [9, 11, 12, 18, 20, 24, 25, 26, 30, 34, 35, 43, 44, 45, 49, 51, 53, 55, 56, 57, 58, 62, 63, 67, 68, 69, 73, 77, 78, 79, 82, 98], "thou": 58, "though": [14, 15, 17, 19, 21, 28, 29, 30, 39, 49, 50, 58, 60, 63, 64, 71, 72, 73, 74, 79, 91], "thought": [4, 16, 20, 34, 40, 53, 58, 61, 77], "thousand": [21, 29, 30, 64, 72, 73], "thrasher": [31, 50, 51, 74], "thread": 32, "threahold": [27, 46, 70], "three": [9, 11, 18, 21, 23, 25, 26, 27, 28, 29, 31, 32, 33, 38, 42, 44, 45, 46, 50, 51, 58, 59, 62, 64, 66, 68, 69, 70, 71, 72, 74, 75, 76, 81, 83, 84, 98], "thresh": 9, "threshold": [13, 14, 21, 25, 27, 29, 31, 34, 44, 46, 50, 51, 58, 59, 64, 68, 70, 72, 74, 77], "thresholds_lr": [23, 42, 66], "thresholds_svc": [23, 42, 66], "thriller": [20, 58], "throat": 20, "through": [1, 7, 13, 14, 22, 23, 24, 27, 29, 30, 31, 32, 42, 43, 46, 47, 50, 51, 55, 59, 66, 67, 70, 72, 73, 74, 75, 78, 82, 89, 95, 98], "throughout": [6, 15, 20, 35, 55, 60, 78], "throw": [19, 34, 53, 55, 63, 77, 78, 84], "thu": [1, 7, 22, 33, 34, 53, 65, 76, 77, 98], "thumb": [14, 59], "thursdai": [1, 13], "ti": [19, 58, 63], "tick": [33, 58, 76], "tick_label": [45, 69], "tick_param": [28, 71], "tid": [16, 25, 26, 28], "tiffin": 51, "tiger": [32, 58, 75], "tight": [16, 29, 61, 72, 86, 92], "tight_layout": [32, 35, 54, 55, 75, 78], "tightrop": [16, 38, 61, 86, 92], "tile": [45, 69], "till": [16, 31, 34, 50, 51, 61, 74, 77], "tim": 20, "timber": [51, 82], "time": [1, 2, 4, 5, 9, 12, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 35, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 53, 54, 55, 56, 57, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 78, 79, 80, 81, 83, 86, 87, 88, 89, 91, 92, 93, 94, 95, 98], "time_diff": [52, 76, 90, 96], "time_signatur": [18, 22, 41, 61, 62, 65], "timedelta": [52, 76, 96], "timeit": [9, 83], "timeless": 58, "timelin": [55, 78], "timeseri": [32, 52, 75, 76], "timeseriessplit": [33, 34, 52, 76, 77, 84, 90, 96], "timestamp": [33, 52, 76, 90, 96], "timezon": [1, 53, 77], "tinder": [30, 49, 73], "tini": [8, 15, 23, 29, 32, 42, 47, 48, 60, 66, 72, 75], "tip": [5, 11, 51, 82], "tire": [20, 31, 50, 74], "titan": [30, 49, 73], "titi": 58, "titl": [8, 15, 16, 21, 24, 25, 27, 29, 30, 32, 33, 34, 35, 37, 38, 41, 43, 46, 47, 48, 52, 53, 54, 55, 58, 60, 61, 64, 65, 67, 70, 72, 75, 76, 77, 78, 86, 89, 90, 92, 95, 96, 97], "tl": 5, "tldr": 13, "tn": [23, 42, 66], "to_datetim": [15, 37, 52, 76, 90, 96], "to_html": [13, 58, 59, 60], "to_list": [23, 42], "to_notebook_ifram": [24, 43, 67], "to_numpi": [16, 30, 33, 49, 61, 73, 76], "to_scal": [89, 95], "to_str": [13, 32, 58, 75], "toarrai": [17, 19, 20, 26, 31, 33, 40, 45, 50, 63, 69, 74, 76], "tobago": [25, 26, 44, 45, 68, 69], "todai": [13, 14, 30, 31, 32, 34, 50, 52, 53, 58, 59, 73, 74, 75, 76, 77, 79, 84, 88, 90, 94, 96], "todens": [26, 27, 45, 46, 69, 70], "togeth": [9, 13, 14, 16, 17, 18, 19, 28, 31, 39, 50, 51, 58, 59, 61, 62, 63, 66, 71, 74, 86, 89, 92, 95], "toi": [9, 15, 16, 27, 28, 29, 30, 33, 38, 46, 49, 60, 61, 70, 71, 72, 73, 76, 80, 84], "toilet": [32, 75], "toke": 98, "token": [6, 13, 31, 40, 41, 50, 63, 65, 74, 98], "token_pattern": [19, 40, 41, 63, 65], "tol": [27, 35, 40, 41, 42, 44, 55, 63, 65, 66, 67, 68, 75, 78, 81, 94], "told": 98, "toler": 40, "tolist": [13, 14, 15, 17, 19, 21, 24, 25, 26, 27, 28, 30, 33, 34, 37, 38, 39, 40, 43, 45, 46, 49, 52, 58, 59, 60, 63, 64, 66, 67, 68, 69, 70, 71, 73, 76, 85, 90, 91, 96], "tom": [20, 58], "tomasbeuzen": 9, "tomorrow": [14, 34, 52, 59, 76, 77, 84, 90, 96], "ton": [20, 22, 65], "tonal": 58, "tone": [48, 58], "too": [7, 8, 13, 14, 15, 16, 18, 19, 20, 22, 24, 25, 26, 32, 33, 34, 35, 38, 40, 41, 43, 44, 45, 51, 52, 54, 55, 56, 57, 58, 60, 61, 63, 65, 67, 68, 69, 75, 76, 77, 78, 79, 82, 86, 87, 90, 92, 96, 98], "took": [17, 33, 52, 76], "tool": [1, 5, 8, 9, 11, 12, 13, 15, 19, 20, 21, 23, 24, 26, 29, 30, 31, 32, 33, 34, 40, 42, 43, 45, 50, 52, 53, 56, 57, 58, 63, 64, 66, 67, 69, 72, 73, 74, 75, 76, 77, 79, 84, 98], "toolbox": [16, 25, 44, 51, 61, 68], "toolkit": [51, 82], "tootsi": 95, "top": [11, 14, 19, 20, 22, 23, 29, 32, 35, 40, 41, 42, 52, 55, 56, 57, 58, 59, 63, 65, 66, 72, 75, 76, 78, 79, 89, 95, 96, 98], "topi": [31, 50, 51, 74], "topic": [1, 2, 9, 12, 14, 24, 28, 30, 32, 49, 59, 67, 71, 73, 75, 79, 80, 84, 98], "topic2vec": [31, 50, 51, 74], "topics_per_chunk": [31, 50, 51, 74], "topn": [13, 58], "torch": [31, 32, 38, 47, 48, 50, 74, 75], "torch_util": 32, "torchvis": [13, 32, 38, 47, 48, 58, 75], "toronto": [31, 35, 50, 51, 55, 74, 78], "tort": 0, "total": [1, 9, 14, 17, 18, 19, 23, 24, 25, 26, 27, 31, 33, 34, 42, 43, 45, 46, 50, 51, 52, 53, 55, 58, 59, 62, 63, 66, 67, 68, 69, 70, 74, 76, 77, 78, 80, 92, 94, 96], "total_bedroom": [18, 27, 46, 62, 63, 70, 87, 93], "total_bilirubin": 58, "total_protien": 58, "total_room": [18, 27, 46, 62, 63, 70, 87, 93], "total_second": [52, 76, 90, 96], "totalbsmtsf": [24, 26, 35, 43, 45, 54, 55, 67, 69, 78], "totalcharg": [27, 34, 53, 77], "totem": [32, 75], "totensor": [38, 47, 48], "toti": [0, 1, 51, 82, 98], "totrmsabvgrd": [24, 26, 35, 43, 45, 54, 55, 67, 69, 78], "touch": 79, "toward": [13, 20, 21, 26, 31, 40, 45, 50, 51, 58, 64, 69, 74, 98], "towardsdatasci": [32, 34, 53, 75, 77], "town": 58, "townsvil": [52, 76, 96], "toxic": [31, 50, 74], "toy_clust": [31, 50, 51, 74], "toy_clust_df": [28, 71], "toy_df": [19, 31, 50, 51, 63, 74], "toy_lda_data": [31, 50, 51, 74], "toy_movie_feat": [30, 49, 73], "toy_rat": [30, 49, 73], "toy_spam": [19, 63], "toy_x": [31, 50, 51, 74], "tp": [23, 42, 66], "tpot": [22, 41, 65], "tpr": [23, 42, 66], "tpr_lr": [23, 42, 66], "tpr_svc": [23, 42, 66], "tr_score": [15, 37, 86, 92], "traceback": [4, 9, 18, 19, 34, 63, 77], "track": [1, 6, 19, 63, 66, 79, 98], "trade": [12, 21, 23, 27, 28, 42, 64, 66, 70, 71, 84], "tradeoff": [16, 18, 21, 24, 27, 28, 32, 37, 43, 46, 61, 62, 64, 67, 70, 71, 75], "tradit": [13, 30, 31, 34, 49, 50, 53, 58, 73, 74, 77, 98], "tradition": 98, "trail": 9, "train": [8, 16, 17, 18, 20, 22, 23, 24, 25, 26, 27, 28, 30, 34, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 51, 53, 61, 62, 65, 67, 68, 69, 70, 71, 73, 77, 83, 84, 85, 86, 87, 88, 90, 91, 92, 93, 94, 96], "train_accuraci": [23, 42, 66], "train_df": [13, 15, 18, 20, 21, 23, 24, 25, 26, 27, 33, 34, 35, 40, 42, 43, 44, 45, 46, 52, 53, 54, 55, 56, 57, 58, 62, 63, 64, 66, 67, 68, 69, 70, 76, 77, 78, 79, 80, 87, 88, 90, 93, 94, 96], "train_df_churn": [34, 77], "train_df_nan": [25, 26, 44, 45, 66, 68, 69], "train_df_ord": [52, 76, 90, 96], "train_df_sort": [33, 52, 76], "train_df_surv": [34, 53, 77], "train_df_surv_not_churn": [34, 53, 77], "train_dir": 38, "train_energy_data": [86, 92], "train_f1": [23, 42, 66], "train_for_usr": [30, 49, 73], "train_mape_scor": [24, 67], "train_mat": [30, 49, 73], "train_mat_imp": [30, 49, 73], "train_neg_mean_squared_error": [24, 67], "train_neg_root_mean_square_error": [24, 67], "train_precis": [23, 42, 66], "train_r2": [24, 67], "train_recal": [23, 42, 66], "train_scor": [15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 33, 34, 37, 38, 39, 40, 42, 43, 44, 45, 46, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 76, 77, 86, 92, 93, 94], "train_shap_valu": [26, 45, 69], "train_sklearn": [24, 67], "train_test_split": [13, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 30, 32, 33, 34, 35, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 49, 52, 53, 54, 55, 56, 57, 58, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 73, 75, 76, 77, 78, 79, 80, 81, 83, 86, 87, 88, 90, 92, 93, 94, 96], "train_x": [30, 49, 73], "training_energy_data": [86, 92], "trane": 60, "transact": [14, 23, 33, 35, 42, 52, 55, 59, 66, 76, 78], "transfer": [20, 34, 47, 53, 56, 57, 77, 79], "transform": [0, 16, 20, 22, 23, 25, 26, 29, 32, 33, 34, 38, 40, 41, 42, 44, 45, 46, 47, 48, 51, 52, 53, 61, 65, 66, 68, 69, 72, 75, 76, 77, 79, 84, 86, 87, 89, 90, 92, 93, 94, 95, 96], "transform_input": [40, 41, 42, 62, 63, 65, 67], "transformed_exampl": [25, 44, 68], "transformed_oh": [18, 62], "transformedtargetregressor": [24, 27, 35, 43, 46, 54, 55, 67, 70, 78, 84], "transformedtargetregressortransformedtargetregressor": 24, "transformer_weight": [39, 41, 44, 45, 63, 65, 67, 68, 69, 94], "translat": [1, 10, 31, 32, 50, 74, 75], "transpar": [23, 42, 66, 84], "transpos": [27, 32, 38, 46, 47, 48, 70, 75], "trasform": [18, 62], "trash": [85, 91], "traumat": 98, "treat": [9, 18, 19, 24, 30, 31, 32, 34, 43, 49, 50, 52, 55, 62, 63, 66, 67, 73, 74, 75, 76, 77, 78, 84, 90, 96, 98], "treati": 98, "treatment": [19, 63], "tree": [1, 2, 16, 18, 19, 20, 21, 22, 24, 29, 32, 33, 34, 38, 39, 40, 41, 43, 60, 61, 62, 63, 64, 65, 67, 70, 72, 75, 76, 77, 79, 83, 84, 85, 87, 88, 91, 93, 94], "tree1": [25, 68], "tree2": [25, 68], "tree3": [25, 68], "tree_method": [44, 68], "tree_numeric_transform": [26, 45, 69], "treecolumntransform": [25, 44, 68, 94], "treeexplain": [26, 45, 69], "tremend": 58, "trend": [12, 31, 34, 74, 77, 84], "tri": [14, 25, 26, 31, 35, 44, 45, 50, 55, 68, 69, 74, 78, 83, 88, 94], "trial": [22, 34, 41, 53, 65, 77], "triangl": [16, 28, 61, 71], "triangular": 40, "trick": [6, 24, 43, 67], "tricki": [19, 22, 26, 30, 41, 45, 49, 63, 65, 69, 73], "trifl": 58, "trigger": [16, 32, 61], "trigram": [50, 51, 74], "trivia": 25, "trivial": [29, 72], "troma": 20, "true": [9, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 31, 32, 33, 34, 35, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 50, 51, 52, 53, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 86, 88, 90, 92, 93, 94, 95, 96, 97], "true_": 39, "true_valu": 97, "truli": [24, 31, 43, 50, 51, 58, 67, 74, 82], "truncat": [29, 72], "truncate_mod": [29, 48, 72], "truncation_mod": [29, 72], "trust": [15, 17, 18, 19, 20, 22, 23, 24, 25, 26, 27, 30, 31, 32, 35, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 54, 55, 58, 62, 63, 65, 66, 67, 68, 69, 70, 73, 74, 75, 78, 94], "trustworthi": [29, 72, 88, 94], "truth": [1, 21, 25, 27, 28, 29, 30, 33, 44, 46, 49, 68, 70, 71, 72, 73, 76, 81], "try": [1, 4, 9, 13, 14, 15, 16, 19, 20, 21, 22, 23, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 37, 38, 40, 41, 42, 44, 45, 46, 47, 48, 49, 50, 51, 53, 54, 56, 57, 58, 59, 60, 61, 63, 64, 65, 66, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 81, 82, 84, 85, 86, 88, 89, 90, 91, 92, 94, 95, 96, 98], "tsa": [33, 52, 76], "tscv": [33, 76], "tslearn": [33, 52, 76], "tsunami": 58, "ttr": [24, 43, 67], "ttr_pipe": [24, 43, 67], "tue": [1, 33, 76, 98], "tuesdai": [1, 13, 27, 52, 76, 81, 96, 98], "tug": 58, "tuggeranong": [52, 76, 96], "tulip": [31, 50, 74], "tumor": 84, "tune": [15, 22, 25, 29, 30, 32, 35, 37, 41, 44, 49, 55, 56, 57, 60, 65, 68, 72, 73, 75, 78, 79, 88, 94], "tupl": 34, "turn": [4, 15, 31, 34, 38, 47, 48, 51, 53, 58, 60, 74, 77, 84, 87, 93, 98], "turnaround": 58, "turturro": 20, "tusker": [32, 75], "tutori": [4, 5, 6, 10, 11, 13, 30, 49, 56, 57, 73, 79, 84, 98], "tv": [20, 58], "tweak": [16, 38, 61, 86, 92], "tweet": [31, 50, 51, 74], "twelv": 58, "twice": [9, 19, 21, 60, 63, 64], "twinx": [35, 54, 55, 78], "twist": [20, 31, 50, 51, 74], "twitter": [31, 50, 51, 74], "two": [4, 5, 6, 7, 8, 9, 10, 11, 13, 14, 15, 16, 17, 18, 21, 22, 23, 25, 26, 27, 28, 29, 30, 32, 33, 34, 35, 38, 39, 41, 42, 44, 45, 46, 47, 51, 53, 55, 56, 57, 58, 59, 60, 61, 62, 64, 65, 66, 68, 69, 70, 71, 72, 73, 75, 76, 77, 78, 79, 80, 82, 83, 84, 87, 89, 93, 95, 98], "two_citi": [16, 61], "two_song": [18, 62], "two_songs_subset": [18, 62], "tx": [21, 64], "tx_i": [35, 55, 78], "txt": [13, 32, 56, 57, 58, 75, 79], "typ": [24, 26, 35, 43, 45, 54, 55, 67, 69, 78], "type": [4, 5, 9, 11, 12, 14, 17, 18, 19, 20, 22, 25, 27, 29, 30, 31, 32, 39, 44, 46, 47, 48, 49, 50, 51, 56, 57, 59, 61, 62, 63, 65, 68, 70, 72, 73, 74, 75, 79, 82, 84, 86, 87, 89, 90, 92, 93, 95, 96], "typeerror": [34, 77], "typic": [2, 13, 14, 15, 16, 18, 21, 22, 23, 24, 25, 26, 28, 30, 31, 33, 35, 42, 43, 44, 45, 50, 52, 55, 58, 59, 61, 62, 63, 64, 65, 66, 67, 68, 69, 71, 73, 74, 76, 78, 79, 84, 98], "u": [1, 4, 15, 16, 18, 19, 20, 21, 23, 25, 26, 27, 28, 29, 30, 31, 32, 34, 37, 38, 40, 41, 42, 44, 45, 46, 50, 51, 52, 53, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 79, 80, 82, 85, 86, 87, 88, 90, 91, 92, 93, 94, 96], "u6": [14, 59, 91], "u_1": [16, 61], "u_2": [16, 61], "u_i": [16, 61], "u_n": [16, 61], "ubc": [0, 4, 5, 9, 10, 11, 13, 14, 15, 16, 18, 19, 21, 22, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 44, 45, 46, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 82, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 98], "ubc_img": [32, 75], "ubc_okanagan": [31, 50, 51, 74], "ubco": [31, 50, 51, 74], "ubyssei": [31, 50, 51, 74], "ucsb": 10, "ud036": 10, "udac": 10, "ufunc": [24, 67], "ufv": [31, 50, 51, 74], "uint8": 38, "ultim": [15, 55, 58, 60, 78], "ultralyt": [32, 75], "uluru": [52, 76, 96], "umbrella": [30, 73], "un": [24, 34, 43, 67, 77], "unabl": [13, 15, 17, 18, 19, 20, 22, 23, 24, 25, 26, 27, 29, 32, 34, 35, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 54, 55, 58, 62, 63, 65, 66, 67, 68, 69, 70, 72, 75, 77, 78, 94, 98], "unambigu": [51, 82], "unassign": [28, 29, 71, 72], "unassum": [20, 40], "unbias": 66, "unbidden": 40, "uncas": [31, 50, 74], "unced": 98, "uncertain": [21, 58, 64, 88, 94], "uncertain_indic": [88, 94], "uncertainti": [21, 23, 35, 42, 55, 64, 66, 78, 79], "unchang": [26, 69], "uncia": [32, 58, 75], "uncom": 17, "uncomfort": [30, 31, 49, 50, 73, 74], "uncommit": [31, 50, 74], "uncorrel": [26, 69], "uncov": [31, 74], "under": [0, 1, 8, 15, 17, 24, 31, 32, 34, 39, 43, 50, 51, 58, 59, 60, 67, 74, 75, 77, 79, 80, 82], "under_sampl": 80, "underestim": [34, 77], "underfit": [16, 21, 22, 32, 37, 38, 61, 64, 65, 75, 86, 92], "undergradu": 5, "underground": 58, "underli": [2, 26, 27, 28, 45, 69, 70, 71], "underneath": 8, "underpredict": [24, 67], "underr": [20, 58], "undersampl": 66, "undersample_pip": 80, "understand": [0, 1, 4, 8, 12, 13, 16, 19, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 37, 38, 42, 43, 44, 45, 46, 49, 50, 51, 52, 55, 58, 59, 60, 61, 63, 64, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 82, 84, 85, 91, 98], "understood": 80, "undertaken": 58, "undoubtedli": 58, "unemploi": [34, 77], "unexpect": [19, 21, 22, 31, 50, 51, 63, 64, 65, 74], "unexplain": [24, 43, 67], "unf": [24, 26, 35, 43, 45, 54, 55, 67, 69, 78], "unfinish": [24, 43, 67], "unflatten_input": 47, "unforgett": [20, 58], "unfortun": [7, 22, 28, 29, 45, 58, 65, 69, 71, 72, 92], "unfunni": [20, 58], "unhappi": 37, "unifi": [31, 50, 74], "uniform": [22, 29, 39, 62, 63, 66, 72, 91, 94], "unimport": [22, 26, 41, 45, 65, 69], "uninform": 39, "uninterest": 58, "uninterpret": [26, 45, 69], "unintuit": 9, "union": 9, "uniqu": [15, 18, 19, 24, 25, 26, 27, 30, 31, 34, 37, 42, 43, 44, 45, 48, 49, 50, 51, 52, 62, 63, 66, 67, 68, 69, 73, 74, 76, 77, 87, 90, 96], "unit": [17, 21, 24, 25, 26, 31, 32, 34, 39, 43, 44, 45, 50, 51, 53, 64, 66, 67, 68, 69, 74, 75, 77], "unitless": [24, 67], "univers": [1, 10, 31, 50, 51, 74, 82], "university_year": [19, 63, 84], "unix": [33, 76], "unknown": [7, 13, 50, 51, 58, 74, 84], "unknown_valu": [39, 44, 45, 63, 67, 68, 69], "unlabel": [13, 15, 29, 58, 60, 72], "unless": [8, 98], "unlik": [9, 13, 15, 16, 19, 24, 26, 28, 29, 43, 45, 58, 60, 61, 63, 67, 69, 71, 72], "unlimit": [33, 76], "unlucki": [15, 60], "unmarri": [25, 26, 44, 45, 68, 69], "unnam": [13, 20, 58], "uno": [17, 39], "unoffici": 98, "unpleas": 58, "unpredict": 20, "unqualifi": 66, "unrealist": [58, 60], "unreason": [7, 13, 24, 43, 67], "unrecogniz": 13, "unrel": [50, 74], "unreli": [15, 60], "unrespond": 13, "unrev": 40, "unsatisfi": 58, "unscal": [18, 62], "unseen": [15, 17, 27, 28, 32, 59, 70, 71, 75, 79, 86, 92], "unstructur": [51, 82], "unsubtl": 58, "unsupervis": [13, 30, 31, 32, 34, 49, 50, 51, 58, 73, 74, 75, 79, 98], "unsur": [8, 35, 55, 78], "unthink": 58, "until": [4, 14, 15, 22, 27, 28, 29, 31, 34, 35, 41, 46, 50, 51, 55, 59, 60, 65, 70, 71, 72, 74, 77, 78, 79, 82, 92], "unus": [86, 92], "unusu": [17, 39], "unwieldi": [14, 17, 18, 59, 62], "unzip": [26, 45, 69], "uoft": [31, 50, 51, 74], "up": [5, 6, 8, 9, 14, 17, 18, 19, 20, 21, 22, 23, 26, 27, 28, 29, 30, 31, 32, 33, 34, 37, 39, 40, 41, 42, 45, 46, 49, 50, 51, 54, 58, 59, 62, 63, 64, 65, 66, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 80, 82, 84, 85, 91, 93, 94, 95, 96, 98], "uparrow": [29, 72], "upcom": 71, "updat": [6, 11, 16, 18, 19, 25, 28, 31, 32, 38, 44, 50, 61, 62, 63, 68, 71, 74, 75, 86, 92], "update_cent": [28, 71], "update_plot": [16, 38, 61, 86, 92], "update_z": [28, 71], "upei": [31, 50, 51, 74], "upgrad": [31, 50, 51, 74], "upload": 8, "upon": [0, 14, 19, 25, 26, 28, 29, 31, 32, 44, 50, 51, 58, 59, 60, 63, 68, 69, 70, 71, 72, 74, 75, 80], "upper": [23, 34, 42, 66, 77], "upperbound_pric": [17, 39], "upto": [33, 76], "ur": 58, "urgent": [19, 31, 51, 63, 74], "url": [4, 15, 23, 31, 34, 42, 50, 53, 56, 57, 60, 66, 74, 77, 79, 80, 98], "us": [0, 1, 2, 4, 6, 12, 17, 20, 21, 22, 23, 26, 27, 29, 30, 33, 34, 37, 39, 40, 41, 42, 45, 46, 47, 48, 49, 52, 53, 54, 56, 57, 64, 65, 66, 69, 72, 73, 76, 77, 79, 81, 84, 86, 87, 88, 89, 90, 92, 93, 94, 95, 96], "usa": [9, 16, 21, 51, 60, 61, 64, 82], "usabl": 79, "usag": [5, 17, 18, 19, 23, 24, 27, 31, 34, 42, 43, 46, 50, 51, 52, 53, 62, 63, 66, 67, 70, 74, 76, 77, 92, 94, 96], "usec_": [34, 53, 77], "useless": [22, 26, 27, 41, 45, 46, 65, 69, 70], "user": [13, 14, 16, 18, 19, 22, 25, 26, 28, 29, 31, 32, 34, 38, 41, 44, 45, 47, 50, 51, 53, 55, 56, 57, 58, 59, 60, 62, 63, 65, 68, 69, 71, 72, 74, 75, 77, 78, 79, 82, 83, 84], "user_id": [30, 49, 73], "user_inverse_mapp": [30, 49, 73], "user_kei": [30, 49, 73], "user_mapp": [30, 49, 73], "user_nam": [30, 49, 73], "usernam": 6, "userwarn": [14, 19, 25, 31, 32, 34, 44, 45, 59, 60, 63, 68, 69], "usf": [19, 63], "using_copy_on_writ": [34, 77], "using_cow": [34, 77], "usp": [16, 22], "usual": [1, 13, 14, 15, 16, 17, 18, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33, 34, 35, 39, 42, 43, 44, 45, 46, 49, 50, 51, 52, 53, 54, 55, 58, 59, 60, 61, 62, 64, 65, 66, 67, 68, 69, 71, 72, 73, 74, 75, 76, 77, 78, 79, 82, 90, 96, 98], "usvi": 44, "utc": [33, 53, 76, 77], "utcnow": [53, 77], "utf": [40, 41, 63, 65], "util": [6, 14, 15, 16, 17, 18, 19, 20, 21, 22, 24, 25, 26, 31, 32, 34, 35, 37, 38, 39, 40, 41, 43, 44, 45, 47, 48, 50, 53, 54, 55, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 74, 75, 77, 78, 84, 85, 86, 87, 88, 91, 92, 93, 94], "utilities_allpub": [24, 45, 67, 69], "utilities_nosewa": [24, 45, 67, 69], "utility_mat": [30, 49, 73], "uvic": [31, 50, 51, 74], "v": [1, 3, 5, 8, 19, 29, 33, 34, 37, 38, 51, 52, 53, 55, 63, 64, 72, 76, 77, 78, 82, 84, 97], "v1": [13, 23, 31, 42, 58, 66, 74, 80], "v10": [23, 42, 66], "v11": [23, 42, 66], "v12": [23, 42, 66], "v13": [23, 42, 66], "v14": [23, 42, 66], "v15": [23, 42, 66], "v16": [23, 42, 66], "v17": [23, 42, 66], "v18": [23, 42, 66], "v19": [23, 42, 66], "v2": [13, 23, 31, 42, 50, 58, 66, 74, 80], "v20": [23, 42, 66], "v21": [23, 42, 66, 80], "v22": [23, 42, 66, 80], "v23": [23, 42, 66, 80], "v24": [23, 42, 66, 80], "v25": [23, 42, 66, 80], "v26": [23, 42, 66, 80], "v27": [23, 42, 66, 80], "v28": [23, 42, 66, 80], "v3": [23, 42, 66, 80], "v4": [23, 42, 66, 80], "v5": [23, 42, 66, 80], "v6": [23, 42, 66, 80], "v7": [23, 42, 66, 80], "v8": [23, 42, 66, 80], "v9": [23, 42, 66, 80], "v_1": [16, 61], "v_2": [16, 61], "v_i": [16, 61], "v_n": [16, 61], "vacat": [21, 31, 50, 64, 74], "vaccin": [35, 54, 55, 78], "vada_pav": 51, "vain": [31, 50, 65, 74], "val": [30, 34, 49, 53, 73, 77], "valenc": [18, 22, 41, 61, 62, 65], "valid": [1, 14, 16, 19, 20, 24, 25, 26, 27, 28, 30, 32, 34, 35, 38, 39, 40, 41, 43, 44, 45, 46, 49, 55, 59, 61, 63, 67, 68, 69, 70, 71, 73, 75, 77, 78, 79, 80, 84, 87, 88, 90, 93, 94, 96, 98], "valid_dir": 38, "valid_mat": [30, 49, 73], "valid_sample_df": [25, 44, 68], "valid_sample_i": [25, 44, 68], "valid_sample_x": [25, 44, 68], "valid_scor": [15, 37, 86, 92], "valid_x": [30, 49, 73], "validate_data": [18, 34], "validate_paramet": [44, 68], "validate_separ": [18, 34], "valu": [8, 9, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 37, 38, 39, 41, 42, 43, 44, 45, 46, 47, 49, 50, 51, 52, 53, 54, 55, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 81, 83, 84, 85, 86, 87, 89, 90, 91, 92, 93, 94, 95, 96], "valuabl": [5, 12, 29, 70, 72, 79, 98], "value_count": [14, 15, 17, 19, 23, 25, 26, 34, 37, 39, 40, 42, 44, 45, 52, 53, 56, 57, 58, 59, 63, 66, 68, 69, 76, 77, 79, 88, 90, 94, 96], "value_throttl": [16, 61, 86, 92], "valueerror": [9, 18, 19, 34, 53, 62, 63, 76, 77, 90, 96], "values_format": [23, 42, 66], "vampir": 20, "vancouv": [17, 31, 35, 50, 51, 55, 74, 78, 82], "vancouver_canuck": [31, 50, 51, 74], "vanilla": [21, 64], "vaniti": 20, "var": [45, 62, 69], "var_": [26, 45, 69], "varada": [0, 1, 14, 98], "vari": [12, 14, 22, 29, 34, 41, 53, 59, 65, 68, 72, 77, 86, 92], "variabl": [8, 9, 14, 18, 19, 21, 22, 24, 26, 27, 31, 33, 34, 35, 37, 43, 45, 52, 55, 59, 62, 63, 64, 65, 67, 69, 70, 76, 77, 78, 89, 90, 92, 95, 96], "varianc": [24, 26, 29, 33, 37, 43, 45, 52, 67, 69, 72, 76, 86, 92], "variant": [26, 29, 45, 69, 72], "variat": [15, 21, 24, 27, 43, 60, 64, 66, 67, 80, 81], "varieti": [13, 25, 31, 51, 58, 68, 74], "variou": [12, 13, 16, 24, 26, 32, 33, 34, 35, 38, 43, 52, 53, 55, 56, 57, 58, 61, 67, 69, 75, 76, 77, 78, 79, 84, 86, 92], "vastli": 58, "vault": [15, 58, 60], "ve": [8, 9, 13, 16, 17, 23, 24, 26, 30, 31, 32, 35, 37, 38, 39, 42, 43, 45, 49, 50, 51, 52, 55, 56, 57, 58, 60, 61, 66, 67, 69, 73, 74, 75, 76, 78, 79, 80, 82, 83, 90, 96], "vec": [19, 20, 31, 32, 40, 50, 51, 63, 74, 75], "vec1": [31, 51, 74], "vec1_i": [31, 51, 74], "vec2": [31, 51, 74], "vec2_i": [31, 51, 74], "vec8": [19, 63], "vec8_binari": [19, 63], "vec_binari": [19, 63], "vecom": [22, 65], "vector": [14, 18, 21, 30, 32, 35, 38, 39, 47, 49, 50, 55, 59, 64, 73, 75, 78, 80, 82, 86, 88, 92, 94], "vener": 58, "verb": [31, 50, 51, 74, 82], "verbal": 84, "verbos": [13, 25, 26, 35, 39, 40, 41, 42, 44, 45, 55, 58, 62, 63, 65, 66, 67, 68, 69, 75, 78, 94], "verbose_feature_names_out": [39, 41, 44, 45, 53, 63, 65, 67, 68, 69, 77, 94], "veri": [2, 4, 6, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 39, 40, 41, 42, 43, 44, 45, 46, 47, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 81, 82, 86, 90, 91, 92, 96, 98], "verneuil": 40, "versa": [24, 43, 67, 86, 92], "version": [1, 4, 5, 6, 8, 9, 11, 14, 15, 17, 21, 24, 26, 29, 31, 33, 39, 43, 45, 50, 51, 52, 53, 62, 64, 65, 67, 69, 72, 74, 76, 77, 83, 90, 96], "versu": 10, "vert": [26, 45, 69], "vertic": [14, 33, 52, 59, 76, 80], "vgg": [32, 75], "vgg16": [32, 38, 75], "via": [8, 13, 27, 70, 80, 98], "vibe": [17, 39], "vice": [24, 43, 58, 67, 86, 92], "victim": 58, "victor": 58, "video": [1, 5, 8, 9, 10, 11, 30, 31, 32, 34, 35, 37, 50, 54, 55, 56, 57, 73, 74, 75, 77, 78, 79, 98], "vietnames": [17, 18, 62], "view": [7, 8, 15, 17, 26, 29, 32, 33, 34, 35, 37, 45, 54, 55, 58, 59, 69, 72, 75, 76, 77, 78], "viewer": 58, "viewform": 22, "viewpoint": [30, 73], "vif": [26, 45, 69], "vikski": 51, "villain": 58, "violat": [18, 19, 34, 39, 62, 63, 77, 79, 98], "virginia": [31, 32, 50, 74, 75], "viridi": [22, 41, 65], "virtu": 20, "virtual": [11, 13, 58], "vision": [1, 47, 58, 79, 83], "visit": [9, 23, 42, 58, 98], "visitor": 58, "visual": [1, 11, 12, 14, 15, 16, 19, 20, 21, 23, 24, 25, 26, 28, 29, 32, 33, 34, 37, 40, 42, 44, 45, 53, 58, 59, 60, 61, 63, 64, 66, 67, 68, 69, 71, 72, 75, 76, 77, 84, 87, 89, 93, 95], "visualize_coeffici": [20, 40], "vittorio": 58, "viu": [31, 50, 51, 74], "vivid": [20, 40], "viz": [35, 54, 55, 78], "voc": [25, 26, 44, 45, 66, 68, 69], "vocab": [20, 31, 40, 50, 51, 74], "vocabulari": [19, 21, 31, 41, 50, 51, 63, 64, 65, 74, 82], "vocabulary_": [19, 63], "voic": [13, 31, 58, 74], "volcano": 58, "volum": 79, "vote": [16, 18, 25, 44, 61, 62, 68, 83, 88, 94], "voting_ndt": [25, 44, 68], "votingclassifi": [25, 44, 68, 88, 94], "votingclassifierifit": 94, "votingclassifierinot": [25, 44, 68], "votingregressor": [25, 44, 68], "vulner": 20, "w": [6, 19, 21, 24, 28, 31, 35, 40, 41, 43, 49, 50, 51, 52, 55, 56, 57, 63, 64, 65, 67, 71, 74, 76, 78, 79, 96], "w_0": [21, 64], "w_1": [21, 64], "w_1x_1": [21, 64], "w_2x_2": [21, 64], "w_3x_3": [21, 64], "w_4x_4": [21, 64], "w_d": [21, 64], "w_dx_d": [21, 64], "w_i": 49, "w_j": [20, 21, 40, 64], "wa": [4, 6, 13, 14, 15, 17, 18, 20, 21, 25, 26, 30, 31, 32, 34, 35, 39, 40, 44, 45, 49, 50, 51, 53, 55, 58, 59, 60, 62, 64, 66, 68, 69, 73, 74, 75, 77, 78, 82, 83, 85, 86, 89, 90, 91, 92, 95, 96, 98], "wa_fn": [34, 53, 77], "waggawagga": 96, "wai": [0, 2, 5, 7, 9, 13, 14, 15, 16, 17, 18, 19, 20, 21, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33, 34, 39, 40, 42, 43, 44, 45, 47, 49, 50, 51, 52, 56, 57, 58, 59, 60, 61, 62, 63, 64, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 79, 80, 82, 83, 84, 86, 90, 91, 92, 93, 96, 98], "wait": [4, 5, 14, 16, 17, 19, 34, 58, 59, 61, 63, 77, 79, 98], "waitlist": 98, "walk": [16, 31, 38, 50, 56, 57, 58, 61, 74, 79, 80, 86, 92], "walker": [32, 58, 75], "wallabi": [32, 75], "walpol": 96, "walru": [31, 40, 50, 74], "want": [4, 5, 7, 8, 9, 11, 13, 14, 15, 16, 17, 18, 20, 22, 23, 24, 25, 27, 28, 29, 30, 31, 32, 33, 35, 38, 39, 41, 42, 43, 44, 46, 49, 50, 51, 52, 53, 55, 56, 57, 58, 59, 60, 61, 62, 65, 66, 67, 68, 70, 71, 72, 73, 74, 75, 76, 78, 79, 80, 82, 84, 87, 89, 90, 93, 95, 96], "war": [30, 49, 58, 73], "ward": [29, 48, 58, 72], "warlik": 58, "warm": [18, 62], "warm_start": [35, 40, 42, 44, 55, 66, 68, 75, 78, 94], "warn": [7, 13, 15, 16, 19, 23, 24, 25, 26, 28, 29, 31, 34, 42, 43, 44, 45, 53, 60, 61, 63, 67, 68, 69, 77, 83, 88, 94], "warn_on_unknown": 63, "warranti": 0, "washroom": 98, "wasn": [17, 20, 39, 51, 82], "wast": [4, 19, 20, 35, 40, 55, 63, 78, 93], "watch": [1, 5, 13, 20, 21, 30, 40, 49, 51, 58, 61, 64, 73, 84], "watchfil": 38, "water": [17, 35, 54, 55, 78], "waterfal": [26, 45, 69], "waterfront": [15, 37, 58, 59], "watsonia": 96, "wavelet": [27, 70], "wax": 58, "waxwork": 20, "wb": [56, 57, 79], "wd": [24, 26, 35, 43, 45, 54, 55, 67, 69, 78], "we": [1, 4, 6, 7, 8, 11, 13, 14, 16, 17, 20, 23, 29, 31, 32, 33, 38, 39, 40, 41, 42, 43, 47, 50, 51, 52, 54, 56, 57, 58, 59, 61, 72, 74, 75, 76, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 98], "weak": [20, 58, 84], "weapon": 58, "wear": 58, "weather": [14, 33, 59, 76, 79], "weatherau": [52, 76, 90, 96], "weav": 58, "web": [6, 13, 51, 82, 84], "web_api": [56, 57, 79], "web_appl": [56, 57, 79], "weblog": 51, "websit": [4, 5], "wed": [33, 76], "wednesdai": [1, 33, 76, 98], "week": [1, 7, 13, 16, 18, 19, 24, 25, 26, 28, 31, 33, 35, 43, 44, 45, 50, 51, 55, 60, 61, 62, 63, 66, 67, 68, 69, 73, 74, 76, 78, 86, 92], "weekdai": [33, 76, 92], "weekend": [9, 20, 33, 35, 40, 55, 76, 78, 92], "weekli": 5, "weigh": [31, 50, 74], "weight": [13, 16, 23, 25, 30, 31, 32, 34, 38, 39, 42, 44, 45, 47, 48, 49, 50, 51, 61, 62, 63, 66, 68, 70, 73, 74, 75, 94, 98], "weighted_averag": 80, "weinberg": [26, 45, 69], "weird": [24, 43, 67], "welcom": [5, 91, 98], "well": [4, 6, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 32, 33, 34, 35, 42, 44, 45, 50, 51, 52, 53, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 74, 75, 76, 77, 78, 79, 80, 82, 84, 89, 92, 95, 98], "wellyanto": [1, 98], "welsh": [32, 58, 75], "went": [24, 25, 43, 67, 88, 94], "were": [0, 7, 13, 17, 20, 21, 23, 24, 31, 32, 33, 34, 35, 39, 42, 43, 50, 51, 52, 55, 58, 63, 64, 67, 74, 75, 76, 77, 78, 82, 88, 92, 94, 98], "weren": [51, 82], "werther\u00f5": 95, "what": [6, 8, 9, 10, 11, 14, 16, 17, 20, 22, 29, 32, 33, 37, 38, 39, 40, 41, 43, 52, 56, 57, 59, 61, 65, 72, 75, 76, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96], "whatev": [27, 58, 70], "when": [1, 4, 5, 7, 8, 13, 14, 15, 16, 17, 19, 21, 23, 24, 25, 26, 27, 28, 29, 31, 32, 33, 34, 37, 38, 39, 41, 42, 43, 44, 45, 47, 49, 50, 51, 52, 53, 56, 57, 58, 59, 60, 61, 63, 64, 66, 67, 68, 69, 71, 72, 73, 74, 75, 76, 77, 79, 80, 81, 82, 83, 84, 85, 87, 88, 90, 91, 93, 94, 96, 98], "where": [0, 1, 6, 8, 13, 14, 15, 16, 17, 18, 20, 21, 22, 23, 24, 25, 26, 28, 30, 31, 32, 33, 35, 37, 38, 39, 40, 41, 42, 43, 44, 45, 49, 50, 51, 52, 54, 55, 56, 57, 58, 59, 60, 61, 64, 65, 66, 67, 68, 69, 71, 73, 74, 75, 76, 78, 79, 80, 82, 84, 86, 90, 92, 96], "wherea": [2, 14, 17, 21, 22, 24, 26, 29, 35, 39, 41, 45, 55, 59, 64, 65, 67, 69, 72, 78], "whether": [0, 4, 8, 9, 14, 15, 17, 18, 19, 21, 24, 25, 26, 27, 29, 33, 34, 39, 43, 44, 45, 46, 51, 52, 53, 59, 60, 62, 63, 64, 66, 67, 68, 69, 70, 72, 76, 77, 79, 80, 81, 82, 85, 88, 90, 91, 94, 96, 98], "which": [4, 6, 7, 9, 14, 15, 16, 17, 18, 19, 20, 21, 22, 24, 26, 27, 31, 32, 33, 34, 35, 37, 38, 39, 40, 41, 43, 45, 46, 50, 51, 53, 54, 55, 56, 57, 58, 60, 61, 62, 63, 64, 65, 67, 69, 70, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 91, 92, 93, 94, 95, 98], "whichev": [25, 44, 68], "while": [14, 15, 18, 20, 21, 22, 23, 25, 26, 28, 30, 31, 34, 42, 44, 45, 49, 50, 51, 58, 59, 60, 64, 65, 66, 68, 69, 71, 73, 74, 77, 82], "whilst": 58, "white": [25, 26, 29, 44, 45, 51, 58, 66, 68, 69, 72, 82], "whitespac": [34, 51, 53, 77, 82], "who": [4, 7, 13, 25, 26, 28, 29, 31, 33, 34, 35, 45, 50, 51, 53, 55, 58, 69, 71, 72, 74, 76, 77, 78, 79, 80, 82, 84, 98], "whole": [8, 15, 22, 24, 26, 30, 31, 41, 43, 45, 50, 58, 60, 65, 67, 69, 73, 74, 79], "whom": [0, 31, 50, 51, 74, 82], "whose": [4, 20], "why": [9, 14, 16, 17, 24, 25, 28, 29, 31, 33, 34, 37, 39, 41, 43, 44, 49, 50, 51, 60, 61, 66, 67, 68, 71, 72, 74, 76, 77, 82, 84, 85, 86, 87, 91, 92, 93], "wid": [56, 57, 79, 80], "wide": [6, 21, 22, 25, 27, 30, 31, 32, 35, 41, 44, 54, 55, 64, 65, 68, 70, 73, 74, 75, 78, 98], "wider": [16, 38, 61, 86, 92], "widescreen": 58, "widespread": [31, 50, 51, 58, 74], "widget": [16, 23, 28, 29, 38, 42, 61, 66, 71, 72, 86, 92], "width": [14, 15, 16, 31, 38, 50, 51, 59, 60, 61, 66, 74, 85, 86, 91, 92], "width_ratio": [85, 91], "wife": [20, 25, 26, 44, 45, 58, 66, 68, 69], "wiggl": 98, "wiki": [31, 35, 50, 51, 55, 74, 78], "wiki_df": [31, 50, 51, 74], "wiki_dict": [31, 50, 51, 74], "wikipedia": [31, 32, 35, 50, 51, 55, 74, 75, 78], "wikipedia2vec": [31, 50, 51, 74], "wilcox": 40, "wild": [13, 15, 38, 58, 60], "william": 58, "williamtown": 96, "willing": [23, 42, 66], "win": [16, 19, 20, 25, 26, 27, 30, 40, 45, 46, 49, 61, 63, 68, 69, 70, 73, 83, 89, 95], "wind": [14, 58, 59], "winddir3pm": [52, 76, 90, 96], "winddir3pm_miss": [52, 76, 96], "winddir3pm_ss": [52, 76, 96], "winddir3pm_ssw": [52, 76, 96], "winddir3pm_sw": [52, 76, 96], "winddir3pm_w": [52, 76, 96], "winddir3pm_wnw": [52, 76, 96], "winddir3pm_wsw": [52, 76, 96], "winddir9am": [52, 76, 90, 96], "windgustdir": [52, 76, 90, 96], "windgustspe": [52, 76, 90, 96], "window": [11, 31, 34, 74, 77], "windspeed3pm": [52, 76, 90, 96], "windspeed9am": [52, 76, 90, 96], "wine_1": 9, "wink": 58, "winperc": [89, 95], "winter": [52, 76, 96], "winter_month": [52, 76, 96], "wipeout": 58, "wire": [30, 49, 73], "wisdom": [25, 68], "wish": [4, 13, 14, 20, 28, 55, 58, 59, 71, 78, 98], "wit": 58, "witchcliff": 96, "with_mean": [39, 41, 42, 44, 45, 62, 63, 65, 67, 68, 69, 94], "with_std": [39, 41, 42, 44, 45, 62, 63, 65, 67, 68, 69, 94], "within": [14, 18, 20, 21, 27, 28, 29, 34, 38, 41, 44, 46, 53, 58, 59, 62, 64, 65, 68, 70, 71, 72, 76, 77, 79, 84, 90, 96], "without": [0, 5, 6, 8, 13, 14, 23, 25, 26, 27, 30, 32, 33, 34, 35, 39, 42, 44, 45, 46, 53, 55, 56, 57, 58, 59, 66, 68, 69, 70, 73, 75, 76, 77, 78, 79, 81, 98], "wnw": [52, 76, 96], "wolf": 20, "wollongong": 96, "wolv": [29, 72], "woman": [31, 50, 51, 58, 74], "wombat": [32, 75], "women": [31, 50, 74], "won": [13, 14, 15, 16, 19, 20, 21, 25, 27, 30, 31, 32, 33, 34, 46, 49, 50, 51, 53, 56, 57, 59, 60, 61, 63, 64, 70, 73, 74, 75, 76, 77, 79, 82], "wonder": [13, 20, 40, 58, 60], "woo": 58, "wooddecksf": [24, 26, 35, 43, 45, 54, 55, 67, 69, 78], "woomera": 96, "word": [12, 13, 15, 17, 20, 21, 22, 23, 27, 28, 29, 30, 32, 33, 34, 35, 37, 39, 40, 41, 42, 46, 55, 58, 64, 65, 66, 70, 71, 72, 73, 75, 76, 77, 78, 82, 84, 98], "word1": [31, 50, 51, 74], "word2": [31, 50, 51, 74], "word2vec": [12, 31, 32, 50, 51, 74, 75, 82], "word3": [31, 50, 51, 74], "word_coeff_df": [20, 40], "word_pair": [31, 50, 51, 74], "word_token": [31, 50, 51, 74, 82], "wordnet": [51, 82], "wordnetlemmat": [51, 82], "words_in_ex": [20, 40], "work": [0, 4, 5, 6, 8, 9, 11, 13, 16, 17, 18, 19, 20, 21, 22, 23, 24, 26, 27, 28, 30, 31, 33, 34, 39, 41, 42, 43, 45, 46, 49, 50, 51, 52, 53, 54, 56, 57, 61, 62, 63, 64, 65, 66, 67, 69, 70, 71, 73, 74, 76, 77, 79, 81, 84, 88, 89, 90, 93, 94, 95, 96, 98], "workclass": [25, 26, 44, 45, 66, 68, 69], "workclass_feder": [25, 26, 44, 45, 68, 69], "workclass_loc": [25, 26, 44, 45, 68, 69], "workclass_miss": [26, 44, 45, 69], "workclass_nev": [25, 26, 44, 45, 68, 69], "workclass_priv": [25, 26, 44, 45, 68, 69], "workclass_self": [26, 44, 69], "workclass_st": [26, 44, 69], "workclass_without": [26, 44, 69], "workflow": [14, 31, 50, 59, 74, 79, 98], "workhors": [13, 58], "world": [15, 16, 18, 19, 21, 22, 25, 26, 27, 28, 29, 30, 31, 32, 45, 46, 49, 50, 51, 58, 61, 62, 63, 64, 65, 66, 69, 70, 71, 72, 73, 74, 75, 81, 82, 84], "worm": [32, 75], "worri": [13, 29, 30, 49, 58, 71, 72, 73, 88, 94], "wors": [14, 17, 22, 24, 25, 32, 34, 43, 44, 53, 59, 65, 67, 68, 75, 77, 85, 91], "worst": [20, 23, 27, 28, 40, 42, 46, 58, 66, 70, 71], "worth": [14, 16, 24, 43, 58, 59, 61, 66, 67, 80], "worthi": [21, 64], "would": [4, 13, 14, 16, 17, 18, 19, 20, 21, 22, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 37, 38, 43, 44, 45, 46, 49, 50, 51, 52, 53, 55, 56, 57, 58, 59, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 83, 84, 86, 87, 88, 90, 92, 93, 94, 96, 98], "wouldn": [19, 22, 34, 41, 51, 58, 63, 65, 77, 82], "wow": [26, 45, 58, 69], "wrangl": [17, 39], "wrap": [19, 34, 63], "wrapper": [18, 27, 81, 95], "wrist": 58, "write": [4, 8, 12, 13, 22, 25, 28, 30, 31, 35, 41, 50, 51, 55, 56, 57, 58, 65, 70, 71, 74, 78, 79, 82, 86, 88, 89, 92, 94, 98], "writer": 58, "written": [8, 19, 26, 31, 35, 45, 50, 52, 55, 63, 69, 74, 76, 78, 90, 96], "wrong": [15, 17, 21, 24, 27, 28, 34, 35, 39, 43, 53, 55, 58, 60, 64, 67, 71, 77, 78, 81, 95], "wrote": [31, 50, 51, 52, 74, 98], "wsw": [52, 76, 96], "wtf": [56, 57, 79], "wvxp_oakj1i": [31, 50, 74], "www": [10, 13, 21, 64], "x": [4, 9, 11, 15, 16, 17, 18, 19, 21, 23, 25, 27, 28, 29, 30, 31, 32, 33, 34, 37, 38, 39, 42, 44, 46, 49, 50, 51, 52, 56, 57, 60, 61, 62, 63, 64, 66, 68, 70, 71, 72, 73, 74, 75, 76, 79, 80, 83, 84, 85, 86, 89, 91, 92, 95, 96, 97], "x0": [27, 46, 70], "x0_male": 66, "x1": [27, 30, 46, 49, 70, 73], "x150": 1, "x153": 1, "x1x2": [27, 46, 70], "x2": [27, 29, 30, 46, 49, 70, 72, 73], "x27": [17, 18, 19, 20, 22, 23, 24, 25, 27, 35, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 54, 55, 62, 63, 65, 66, 67, 68, 69, 70, 75, 78, 94], "x337": 1, "x_": [20, 21, 40, 49, 64], "x_1": [21, 27, 28, 46, 64, 70, 71], "x_1x_2": [27, 46, 70], "x_2": [21, 27, 28, 46, 64, 70, 71], "x_anim_train": 38, "x_anim_valid": 38, "x_binari": [14, 59], "x_bird": 47, "x_citi": [16, 61], "x_coord": [89, 95], "x_count": [19, 63], "x_d": [21, 64], "x_femal": 66, "x_food": [47, 48], "x_hour": [33, 76], "x_hour_week": [33, 76], "x_hour_week_onehot": [33, 76], "x_hour_week_onehot_poli": [33, 76], "x_hour_week_onehot_poly_lag": [33, 76], "x_i": [21, 30, 64, 73], "x_imp_ohe_train": [18, 62], "x_init": [28, 71], "x_int": [19, 63], "x_label": [14, 15, 16, 41, 59, 60, 61, 65, 85, 91], "x_lag_featur": [33, 76], "x_lag_features_imp": [33, 76], "x_male": 66, "x_mask": [19, 63], "x_multi": 83, "x_n": [27, 46, 70], "x_orig": [29, 72], "x_re": 80, "x_small_citi": [16, 61], "x_spotifi": [22, 41, 61, 65], "x_subset": [14, 15, 59, 60], "x_test": [13, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 32, 33, 34, 35, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 53, 54, 55, 58, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 75, 76, 77, 78, 80, 83, 86, 87, 88, 92, 93, 94], "x_test_big": [22, 65], "x_test_cat": [17, 39], "x_test_cat_oh": [17, 39], "x_test_enc": [26, 34, 35, 45, 52, 53, 54, 55, 69, 76, 77, 78, 90, 96], "x_test_happi": [56, 57, 79, 80], "x_test_imp": [18, 62], "x_test_multi": 83, "x_test_num": [17, 39], "x_test_num_imp": [17, 39], "x_test_num_imp_sc": [17, 39], "x_test_pr": [33, 76], "x_test_predict": [17, 18, 62], "x_test_scal": [18, 62], "x_test_transform": [17, 18, 62], "x_toi": [16, 18, 19, 33, 61, 62, 63, 76], "x_toy_oh": [18, 62], "x_toy_ord": [18, 19, 62, 63], "x_tr": [15, 37, 86, 92], "x_train": [13, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 30, 32, 33, 34, 35, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 49, 53, 54, 55, 58, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 73, 75, 76, 77, 78, 80, 81, 83, 86, 87, 88, 92, 93, 94], "x_train_big": [23, 42, 66, 80], "x_train_cat": [17, 39], "x_train_cat_oh": [17, 39], "x_train_enc": [24, 26, 34, 35, 43, 45, 52, 53, 54, 55, 66, 67, 69, 76, 77, 78, 90, 96], "x_train_happi": [56, 57, 79, 80], "x_train_hous": [27, 46, 70], "x_train_imp": [17, 18, 62], "x_train_imp_sc": [17, 18, 62], "x_train_multi": 83, "x_train_num": [17, 39], "x_train_num_imp": [17, 39], "x_train_num_imp_sc": [17, 39], "x_train_ord": 17, "x_train_oversampl": 80, "x_train_perm": [26, 45, 69], "x_train_pp": [63, 93], "x_train_predict": [17, 18, 62], "x_train_scal": [18, 27, 46, 62, 70], "x_train_subsampl": 80, "x_train_tini": [22, 65], "x_train_transform": [17, 18, 62], "x_train_usr": [30, 49, 73], "x_transform": [19, 39, 63], "x_valid": [15, 23, 30, 37, 38, 42, 49, 66, 73, 80, 86, 92], "x_vari": [29, 72], "x_xor": [27, 46, 70], "xanni": [22, 41, 65], "xavier": [27, 30, 46, 49, 70, 73], "xcode": 6, "xgbclassifi": [25, 26, 44, 45, 68, 69], "xgbclassifierxgbclassifi": 25, "xgboost": [26, 45, 69], "xgboostcolumntransform": [25, 44, 68], "xgbregressor": [13, 25, 44, 58, 68], "xlabel": [9, 14, 15, 16, 21, 22, 23, 24, 26, 29, 32, 33, 34, 35, 38, 41, 42, 43, 45, 48, 52, 53, 54, 55, 59, 60, 61, 64, 65, 66, 67, 69, 72, 75, 76, 77, 78, 83, 85, 89, 90, 91, 95, 96, 97], "xlim": [34, 53, 77], "xor": [21, 27, 46, 64, 70], "xp": [18, 34], "xscale": [41, 65], "xt": [19, 63], "xtick": [23, 33, 38, 42, 52, 60, 66, 76, 85, 90, 91, 96], "xtick_label": 76, "xticklabel": [22, 41, 65], "xticks_rot": 80, "xwm\u0259\u03b8kw\u0259y": 98, "xx": [27, 28, 46, 70, 71], "xxxxviii": 40, "y": [9, 15, 16, 17, 18, 19, 21, 22, 23, 25, 27, 28, 29, 30, 32, 33, 34, 37, 38, 39, 41, 42, 44, 46, 49, 51, 52, 53, 60, 61, 62, 63, 64, 65, 66, 68, 70, 71, 72, 73, 75, 76, 77, 80, 82, 83, 84, 85, 86, 89, 90, 91, 92, 94, 95, 96, 97], "y_": [30, 73], "y_citi": [16, 61], "y_coord": [89, 95], "y_femal": 66, "y_hat": [21, 44, 64, 68], "y_i": [24, 27, 30, 43, 44, 46, 67, 68, 70, 73, 81], "y_init": [28, 71], "y_label": [14, 15, 16, 41, 59, 60, 61, 65, 85, 91], "y_male": 66, "y_mat": [30, 49, 73], "y_multi": 83, "y_numer": 18, "y_pred": [23, 33, 42, 66, 76], "y_pred_lower_threshold": [23, 42, 66], "y_pred_toi": 80, "y_pred_train": [33, 76], "y_re": 80, "y_small_citi": [16, 61], "y_spotifi": [22, 41, 65], "y_test": [13, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 32, 33, 34, 35, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 52, 53, 54, 55, 58, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 75, 76, 77, 78, 80, 83, 86, 87, 88, 90, 92, 93, 94, 96], "y_test_big": [22, 65], "y_test_happi": [56, 57, 79, 80], "y_test_multi": 83, "y_test_num": [25, 26, 44, 45, 68, 69], "y_toi": [16, 33, 61, 76], "y_tr": [15, 37, 86, 92], "y_train": [13, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 30, 32, 33, 34, 35, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 49, 52, 53, 54, 55, 58, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 73, 75, 76, 77, 78, 80, 81, 83, 86, 87, 88, 90, 92, 93, 94, 96], "y_train_big": [23, 42, 66, 80], "y_train_happi": [56, 57, 79, 80], "y_train_hous": [27, 46, 70], "y_train_multi": 83, "y_train_num": [25, 26, 44, 45, 68, 69], "y_train_ord": [52, 76, 90, 96], "y_train_oversampl": 80, "y_train_subsampl": 80, "y_train_tini": [22, 65], "y_train_usr": [30, 49, 73], "y_true": [35, 55, 78], "y_true_toi": 80, "y_valid": [15, 23, 30, 32, 37, 38, 42, 49, 66, 73, 75, 80, 86, 92], "y_vari": [29, 72], "y_xor": [27, 46, 70], "yah": 58, "yale": [31, 50, 51, 74], "yann": [26, 45, 69], "yawn": 58, "ycxmx": [34, 77], "ye": [4, 13, 14, 17, 18, 19, 26, 27, 28, 29, 30, 32, 33, 35, 39, 45, 49, 52, 53, 55, 58, 59, 62, 63, 69, 71, 72, 73, 75, 76, 78, 79, 84, 89, 90, 93, 95, 96], "year": [5, 13, 14, 20, 27, 28, 30, 31, 32, 34, 49, 51, 52, 53, 58, 59, 73, 74, 75, 76, 77], "yearbuilt": [24, 26, 35, 43, 45, 54, 55, 67, 69, 78], "yearremodadd": [24, 26, 35, 43, 45, 54, 55, 67, 69, 78], "yeb4": 16, "yeild": 17, "yellow": [22, 31, 41, 50, 65, 74], "yellowbrick": [28, 29, 71, 72, 89, 95], "yesterdai": [52, 76, 90, 96], "yet": [12, 17, 18, 21, 26, 30, 33, 34, 39, 45, 49, 53, 58, 64, 69, 73, 76, 77, 86, 92], "yield": 17, "ylabel": [9, 14, 15, 16, 21, 22, 23, 24, 29, 32, 33, 34, 35, 37, 38, 41, 42, 43, 48, 52, 53, 54, 55, 59, 60, 61, 64, 65, 66, 67, 72, 75, 76, 77, 78, 83, 85, 86, 89, 90, 91, 92, 95, 96, 97], "ylim": [34, 35, 53, 54, 55, 77, 78], "yml": 11, "yolo": [32, 75], "yolo8": [32, 75], "yolo_input": [32, 75], "yolo_result": [32, 75], "yolo_test": [32, 75], "yolov8n": [32, 75], "york": [33, 76], "you": [0, 1, 4, 5, 6, 7, 8, 9, 11, 17, 23, 26, 31, 38, 41, 42, 43, 45, 46, 47, 48, 50, 51, 53, 54, 56, 57, 69, 74, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 98], "young": [20, 58], "your": [0, 1, 2, 4, 5, 7, 8, 9, 16, 17, 18, 19, 21, 22, 23, 24, 25, 26, 27, 28, 30, 31, 32, 33, 34, 37, 39, 41, 42, 43, 44, 45, 49, 50, 51, 52, 53, 56, 57, 58, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 73, 74, 75, 76, 77, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 92, 93, 94, 95, 96, 98], "yourself": [4, 12, 19, 30, 35, 49, 51, 55, 63, 66, 73, 78, 82, 84, 89, 92, 95, 98], "yourselv": [51, 82], "yourusernam": 11, "youtub": [1, 13, 30, 31, 50, 51, 55, 73, 74, 78, 98], "yr_built": [15, 37, 58, 59], "yr_renov": [15, 37, 58, 59], "yrpxn": [34, 53, 77], "yrsold": [24, 26, 35, 43, 45, 54, 55, 67, 69, 78], "ytick": [23, 38, 42, 60, 66, 85, 91], "yticklabel": [22, 41, 65], "yy": [27, 46, 52, 70, 76, 90, 96], "yyyi": [52, 76, 90, 96], "z": [9, 21, 27, 28, 29, 30, 32, 34, 38, 46, 47, 48, 64, 70, 71, 72, 73, 75, 77], "z_bird": 47, "z_food": [47, 48], "z_hrch": 48, "z_i": [32, 75], "z_j": [32, 75], "z_km": [28, 71], "z_train": [32, 38, 75], "z_valid": [32, 38, 75], "zachari": [34, 53, 77], "zero": [9, 15, 19, 22, 30, 31, 35, 49, 50, 51, 54, 55, 63, 65, 73, 74, 78], "zero_divis": [23, 42, 66], "zheng": [1, 98], "zip": [16, 21, 30, 38, 49, 61, 64, 73, 86, 92], "zipcod": [15, 37, 58, 59], "zoe": [1, 98], "zombi": [20, 40], "zone": [20, 40, 52, 76, 90, 96], "zoo": [20, 40], "zoom": [8, 98], "zorro": [20, 40], "zu": [20, 40], "zucco": [20, 40], "\u0259m": 98, "\u03bc": 83}, "titles": ["LICENSE", "UBC CPSC 330: Applied Machine Learning (2025W1)", "CPSC 330 vs. CPSC 340", "CPSC 330 Documents", "How to ask for help", "Frequently Asked Questions", "Git and GitHub: Getting Started", "CPSC 330 grading policies", "Homework info &amp; submission guidelines", "CPSC 330 Python notes", "Reference material", "Setting up your coding environment", "Course Learning Objectives", "Lecture 1: Course Introduction", "Lecture 2: Terminology, Baselines, Decision Trees", "Lecture 3: Machine Learning Fundamentals", "Lecture 4: <span class=\"math notranslate nohighlight\">\\(k\\)</span>-Nearest Neighbours and SVM RBFs", "Lecture 5 and 6: Class demo", "Lecture 5: Preprocessing and <code class=\"docutils literal notranslate\"><span class=\"pre\">sklearn</span></code> pipelines", "Lecture 6: <code class=\"docutils literal notranslate\"><span class=\"pre\">sklearn</span></code> <code class=\"docutils literal notranslate\"><span class=\"pre\">ColumnTransformer</span></code> and Text Features", "Lecture 7: Class demo", "Lecture 7: Linear Models", "Lecture 8: Hyperparameter Optimization and Optimization Bias", "Lecture 9: Class demo", "Lecture 10: Regression metrics", "Lecture 11: Ensembles", "Lecture 12: Feature importances and model transparency", "Lecture 13: Feature engineering and feature selection", "Lecture 14: K-Means Clustering", "Lecture 16: More Clustering", "Lecture 16: Recommender Systems", "Lecture 17: Introduction to natural language processing", "Lecture 18: Multi-class classification and introduction to computer vision", "Lecture 19: Time series", "Lecture 20: Survival analysis", "Lecture 21: Communication", "Section 102", "Lecture 3: ML Fundamentals Class Demo", "Lecture 4: Class demo", "Lecture 5 and 6: Class demo", "Lectures 7: Class demo", "Lectures 8: Class demo", "Lecture 9: Class demo", "Lecture 10: Class demo", "Lecture 11: Ensembles", "Lecture 12: Class demo", "Lecture 13: Class demo", "Lecture 15: Clustering class demo", "Lecture 15: Class demo", "Lecture 16: Class demo", "Lecture 17: Class demo", "Lecture 18: Class demo", "Lecture 19: Class demo", "Lecture 20: Class demo", "Lecture 21: Class demo (Based on the lecture notes)", "Lecture 22: Class demo (Based on the lecture notes)", "Lecture 23: Class demo (Based on the lecture notes)", "Lecture 24: Class demo (Based on the lecture notes)", "Lecture 1: Course Introduction", "Lecture 2: Terminology, Baselines, Decision Trees", "Lecture 3: Machine Learning Fundamentals", "Lecture 4: <span class=\"math notranslate nohighlight\">\\(k\\)</span>-Nearest Neighbours and SVM RBFs", "Lecture 5: Preprocessing and <code class=\"docutils literal notranslate\"><span class=\"pre\">sklearn</span></code> pipelines", "Lecture 6: <code class=\"docutils literal notranslate\"><span class=\"pre\">sklearn</span></code> <code class=\"docutils literal notranslate\"><span class=\"pre\">ColumnTransformer</span></code> and Text Features", "Lecture 7: Linear Models", "Lecture 8: Hyperparameter Optimization and Optimization Bias", "Lecture 9: Classification metrics", "Lecture 10: Regression metrics", "Lecture 11: Ensembles", "Lecture 12: Feature importances and model transparency", "Lecture 13: Feature engineering and feature selection", "Lecture 14: K-Means Clustering", "Lecture 15: More Clustering", "Lecture 16: Recommender Systems", "Lecture 17: Introduction to natural language processing", "Lecture 18: Multi-class classification and introduction to computer vision", "Lecture 19: Time series", "Lecture 20: Survival analysis", "Lecture 21: Communication", "Lecture 23: Deployment and conclusion", "Appendix A: Lecture 09", "Appendix A: Lecture 13", "Appendix C: Basic text preprocessing [video]", "Appendix D: Multi-class, meta-strategies", "Final exam preparation: guiding questions", "Tutorial 1", "Tutorial 2", "Tutorial 3", "Tutorial 6", "Tutorial 6", "Tutorial 8", "Tutorial 1", "Tutorial 2", "Tutorial 3", "Tutorial 6", "Tutorial 6", "Tutorial 8", "&lt;no title&gt;", "Syllabus"], "titleterms": {"": [5, 13, 16, 17, 18, 19, 23, 24, 26, 35, 39, 42, 43, 45, 47, 52, 53, 54, 55, 58, 60, 61, 62, 63, 66, 67, 69, 76, 77, 78], "0": [68, 87], "09": 80, "1": [6, 11, 13, 14, 15, 16, 18, 19, 21, 22, 24, 25, 27, 28, 29, 30, 34, 35, 41, 44, 55, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 70, 71, 72, 77, 78, 84, 85, 86, 87, 88, 90, 91, 92, 93, 94, 96], "10": [24, 43, 67, 88, 94], "102": 36, "11": [25, 44, 68], "12": [25, 26, 45, 69], "13": [27, 46, 70, 81], "14": [27, 28, 70, 71], "15": [28, 35, 47, 48, 55, 72, 78, 79], "16": [29, 30, 49, 72, 73], "17": [30, 31, 50, 74], "18": [32, 51, 75], "19": [33, 52, 76], "2": [6, 11, 13, 14, 15, 16, 18, 19, 21, 22, 24, 28, 29, 30, 34, 35, 43, 55, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 71, 72, 77, 78, 84, 85, 86, 87, 88, 90, 91, 92, 93, 94, 96], "20": [34, 35, 53, 55, 77, 78, 79], "2025w1": 1, "21": [34, 35, 54, 78], "22": 55, "23": [56, 79], "24": 57, "3": [6, 11, 13, 14, 15, 18, 21, 28, 29, 34, 35, 37, 58, 59, 60, 62, 70, 72, 77, 85, 86, 87, 88, 90, 91, 92, 93, 94, 96], "330": [1, 2, 3, 7, 9, 13, 79], "340": [2, 5, 13, 79], "4": [11, 13, 14, 15, 16, 35, 38, 45, 55, 58, 59, 60, 61, 78, 85, 86, 87, 88, 90, 91, 92, 93, 94, 96], "5": [9, 11, 13, 14, 15, 16, 17, 18, 19, 26, 28, 32, 34, 35, 39, 50, 51, 55, 59, 60, 61, 62, 63, 69, 70, 71, 74, 75, 77, 78, 86, 87, 88, 90, 92, 93, 94, 96], "6": [11, 17, 19, 39, 63, 86, 88, 89, 90, 92, 94, 95, 96], "7": [11, 20, 21, 40, 64, 88, 94], "8": [22, 41, 65, 88, 90, 94, 96], "9": [23, 42, 66, 88, 94], "A": [4, 11, 23, 29, 31, 42, 50, 52, 66, 72, 74, 76, 80, 81], "No": 9, "Not": 84, "One": [18, 52, 62, 76, 83], "The": [1, 15, 21, 22, 25, 28, 31, 41, 44, 50, 60, 64, 65, 68, 70, 71, 74, 88, 89, 94, 95], "__": [22, 41, 65], "about": [9, 13, 27, 30, 35, 46, 55, 70, 73, 78, 81], "academ": 98, "access": [8, 21, 64, 98], "accommod": 98, "acknowledg": 98, "activ": [13, 15, 26, 27, 28, 31, 35, 45, 50, 51, 55, 66, 69, 70, 71, 74, 78], "actual": 63, "ad": 9, "addit": [8, 26, 45, 69], "address": [23, 42, 66], "advantag": [22, 41, 65], "advic": [27, 70], "after": [31, 50, 74], "ai": [5, 13, 58, 98], "aka": [35, 55, 78], "algorithm": [14, 16, 27, 28, 46, 59, 61, 70, 71], "all": [13, 21, 23, 28, 29, 30, 35, 42, 49, 55, 59, 62, 64, 66, 71, 72, 73, 78], "alpha": [21, 24, 43, 64, 67], "alreadi": [56, 57, 79], "altern": [11, 14, 17, 18, 39, 59, 62], "am": 5, "an": [25, 35, 44, 55, 68, 78], "analogi": 61, "analysi": [15, 17, 31, 34, 37, 39, 50, 52, 74, 76, 77, 79, 84, 86, 90, 92, 96], "angl": [35, 55, 78], "announc": [16, 19, 21, 25, 59, 61, 63, 64, 68], "answer": [34, 77], "ap": [23, 42, 66], "api": [17, 18, 56, 57, 62, 79], "app": [56, 57, 79], "appendix": [80, 81, 82, 83], "appli": [1, 9, 18, 19, 24, 35, 43, 54, 55, 62, 63, 67, 78], "applic": [28, 71], "applymap": 9, "approach": [30, 33, 34, 35, 49, 52, 53, 55, 73, 76, 77, 78, 79, 83], "approxim": [15, 60], "ar": [5, 13, 18, 21, 28, 29, 30, 31, 49, 50, 58, 59, 62, 64, 66, 71, 72, 73, 74], "architectur": [31, 50, 74], "area": [23, 42, 66], "argument": [16, 60, 61], "around": [35, 55, 78], "arrai": 9, "articl": 10, "asap": [35, 55, 78], "ask": [4, 5], "assess": 37, "assign": [5, 8, 98], "associ": [21, 64], "assum": [34, 77], "attend": [5, 26], "attent": [14, 16, 59, 61], "attribut": [26, 35, 45, 55, 69, 78], "auc": [23, 42, 66], "audit": 5, "authent": 6, "autom": [22, 65], "averag": [25, 30, 44, 49, 68, 73, 80, 88, 94], "avoid": [15, 60], "b": [11, 28, 71], "backward": [27, 81], "bad": [22, 41, 65], "bag": [19, 63], "balanc": 66, "bank": [23, 42], "base": [25, 27, 30, 33, 46, 49, 52, 54, 55, 56, 57, 61, 68, 70, 73, 76, 90, 96], "baselin": [14, 15, 18, 23, 25, 26, 30, 37, 42, 44, 45, 49, 59, 62, 66, 68, 69, 73, 86, 92], "basic": [51, 82], "been": [53, 77], "befor": [13, 18, 31, 50, 62, 74], "best": 70, "better": [15, 22, 23, 27, 35, 41, 42, 54, 55, 60, 65, 66, 70, 78], "between": [16, 31, 59, 61, 74, 79, 85, 91], "beyond": [26, 30, 31, 45, 49, 50, 69, 73, 74], "bia": [15, 22, 60, 65], "big": [14, 15, 18, 59, 60, 62], "binari": [23, 42, 66], "book": 1, "boost": [25, 35, 44, 54, 55, 68, 78], "bootstrap": [25, 68], "bottom": [35, 55, 78], "boundari": [14, 16, 21, 38, 59, 61, 64, 85, 91], "bow": [19, 63], "box": [32, 75], "break": [9, 13, 14, 15, 16, 19, 32, 34, 35, 50, 51, 55, 59, 60, 61, 62, 63, 70, 74, 75, 77, 78, 79], "broadcast": 9, "browser": 13, "build": [13, 14, 20, 24, 30, 37, 40, 43, 49, 56, 57, 58, 59, 67, 73, 79], "c": [16, 22, 41, 61, 65, 82], "calcul": [21, 64], "california": [21, 63, 64, 87, 93], "can": [5, 9, 15, 18, 25, 26, 28, 44, 45, 60, 62, 68, 69, 70, 71], "canada": [59, 85, 91], "care": [30, 35, 55, 73, 78], "carri": [18, 27, 46, 62, 70], "case": [19, 21, 29, 63, 64, 72], "catboost": [25, 44, 68], "categor": [17, 18, 19, 26, 33, 39, 45, 62, 63, 69, 76], "categori": [19, 63], "censor": [34, 53, 77], "centr": 98, "certain": 63, "cfa": 98, "chang": [66, 80], "charact": [13, 58], "characterist": [23, 42, 66], "cheatsheet": 9, "checklist": 13, "choos": [16, 28, 61, 71], "chunk": [35, 55, 78], "churn": [34, 77], "cite": 8, "citi": [21, 64], "claim": [35, 55, 78], "class": [5, 13, 17, 20, 22, 23, 24, 25, 26, 30, 32, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 65, 66, 67, 68, 69, 73, 75, 80, 83, 98], "class_attend": [19, 63], "class_weight": 66, "classif": [14, 23, 32, 38, 42, 56, 57, 59, 66, 75, 79, 80, 84], "classifi": [14, 17, 20, 21, 25, 39, 40, 44, 59, 64, 68], "clearli": [27, 81], "cluster": [28, 29, 47, 48, 71, 72, 84, 89, 95], "cnn": [32, 75], "co": [1, 98], "code": [5, 11, 98], "coeffici": [20, 21, 26, 40, 45, 64, 69], "color": [85, 86, 87, 88, 90, 91, 92, 93, 94, 96], "column": [9, 18, 19, 33, 62, 63, 76], "columntransform": [19, 63, 87, 93], "combin": [25, 44, 68], "come": [15, 16, 60, 61], "command": 6, "comment": [14, 22, 23, 24, 28, 29, 30, 42, 49, 59, 65, 66, 67, 71, 72, 73], "common": [18, 28, 31, 50, 62, 71, 74], "commonli": [51, 82], "commun": [13, 35, 55, 78, 84], "compact": [17, 18, 62], "companion": 10, "complet": [30, 49, 73], "complex": [15, 60], "complic": [52, 76, 90, 96], "compon": [21, 64], "comprehens": [87, 93], "comput": [13, 32, 75, 84], "con": [16, 29, 61, 72, 84], "concept": [35, 37, 55, 78], "concern": 7, "concess": 98, "conclus": 79, "conda": 11, "conduct": 98, "confid": [21, 35, 55, 64, 78], "configur": 11, "confus": [23, 35, 42, 54, 55, 66, 78], "consid": [34, 77], "construct": [25, 44, 68], "content": [30, 49, 73], "context": 51, "continu": [14, 59], "conveni": [19, 63], "convolut": [32, 75], "corpu": [56, 57, 79], "correct": [11, 28, 71], "correl": [26, 45, 69], "countri": [59, 85, 91], "countvector": [19, 63], "cours": [1, 5, 10, 11, 12, 13, 58, 79, 98], "cover": [30, 34, 49, 53, 56, 57, 73, 77, 79], "cox": [34, 53, 77], "cpsc": [1, 2, 3, 5, 7, 9, 13], "creat": [8, 11, 14, 19, 30, 49, 56, 57, 59, 60, 63, 73, 79], "credit": 11, "critic": [23, 42], "cross": [15, 17, 18, 23, 27, 33, 37, 42, 46, 52, 60, 62, 66, 70, 76, 86, 92], "cross_val_scor": 60, "cross_valid": [15, 24, 43, 60, 67], "csv": 9, "curs": [16, 61], "curv": [23, 34, 42, 53, 66, 77], "custom": [28, 34, 53, 71, 77], "cv": [22, 65], "d": 83, "dai": [33, 76], "data": [13, 14, 15, 16, 17, 18, 19, 21, 22, 24, 25, 26, 28, 30, 33, 35, 37, 39, 43, 44, 45, 52, 53, 54, 55, 58, 59, 60, 61, 62, 63, 64, 65, 67, 68, 69, 70, 71, 73, 76, 78, 79, 80, 86, 90, 92, 96], "datafram": [9, 19, 63], "dataset": [8, 14, 18, 20, 21, 22, 23, 24, 32, 33, 35, 40, 42, 43, 52, 54, 55, 59, 62, 63, 64, 65, 66, 67, 75, 76, 78, 87, 88, 89, 90, 93, 94, 95, 96], "date": [1, 33, 52, 76], "datetim": [52, 76, 90, 96], "dbscan": [29, 48, 72], "deal": [19, 63, 66], "decis": [14, 15, 16, 21, 26, 37, 38, 45, 55, 59, 61, 64, 69, 78, 86, 92], "decisiontreeclassifi": [14, 25, 44, 59, 68], "decreas": [23, 42, 66], "deep": [32, 33, 52, 75, 76], "defin": [27, 81], "definit": [13, 58], "deliver": [1, 13], "demo": [15, 17, 20, 23, 27, 37, 38, 39, 40, 41, 42, 43, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 70, 76, 79], "demonstr": [23, 42, 66], "dendrogram": [29, 72], "depend": 70, "deploi": [56, 57, 79], "deploy": [15, 56, 57, 60, 79, 84], "descript": 98, "desktop": 6, "detail": [15, 24, 29, 42, 43, 66, 67, 72], "detect": [32, 75], "df": 9, "did": [15, 18, 19, 24, 30, 34, 35, 49, 53, 55, 56, 57, 60, 62, 63, 66, 67, 73, 77, 78, 79], "differ": [5, 18, 22, 23, 24, 26, 41, 42, 43, 45, 62, 65, 67, 69, 79, 84], "dimens": [16, 61], "dimension": [16, 61], "directori": [56, 57, 79], "discuss": [15, 17, 22, 30, 31, 35, 51, 55, 56, 57, 65, 66, 73, 74, 78, 79], "diseas": [13, 58], "distanc": [16, 28, 61, 71], "distribut": [22, 31, 41, 50, 65, 74], "dl": [13, 58], "do": [5, 17, 18, 22, 23, 25, 26, 27, 35, 39, 42, 44, 45, 46, 55, 62, 63, 65, 66, 68, 69, 70, 78], "document": [3, 9, 28, 71], "doe": [5, 14, 15, 21, 29, 32, 35, 55, 59, 64, 72, 75, 78], "domain": [27, 70], "dr": 11, "drop": 9, "due": 1, "dummi": [17, 38, 39], "dummyclassifi": [14, 25, 34, 44, 52, 59, 68, 76, 77], "dummyregressor": [14, 18, 24, 43, 59, 62, 67], "easiest": 6, "eda": [18, 23, 24, 42, 43, 62, 66, 67, 79, 86, 87, 89, 92, 95], "effect": [25, 35, 44, 55, 68, 78], "elbow": [28, 71], "element": 9, "elimin": [27, 46, 70], "embed": [31, 50, 51, 74], "encod": [18, 19, 27, 33, 46, 52, 62, 63, 70, 76], "engin": [27, 33, 46, 52, 70, 76, 84], "ensembl": [25, 44, 68, 84], "enter": [17, 39], "environ": [5, 11, 56, 57, 79], "equal": [35, 54, 55, 78], "error": [11, 15, 22, 23, 24, 30, 42, 43, 49, 60, 65, 66, 67, 73], "estim": [17, 18, 25, 39, 44, 62, 68], "ethic": 84, "euclidean": [16, 61], "eva": [13, 58, 60], "evalu": [23, 29, 30, 34, 42, 49, 53, 66, 72, 73, 77, 80, 84], "evalut": 42, "event": [34, 77], "everyon": [34, 77], "exactli": [21, 64], "exam": [5, 84, 98], "examin": [19, 20, 24, 35, 40, 43, 54, 55, 63, 67, 78, 84], "exampl": [13, 14, 16, 18, 19, 21, 22, 23, 25, 26, 27, 28, 31, 32, 34, 35, 42, 44, 45, 50, 51, 55, 58, 59, 60, 61, 62, 63, 64, 65, 66, 68, 69, 71, 74, 75, 77, 78, 81], "exercis": [14, 15, 16, 18, 19, 21, 22, 24, 25, 27, 30, 32, 34, 44, 49, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 70, 75, 77, 85, 91], "exhaust": [22, 41, 65], "experi": [35, 55, 78], "explain": [26, 35, 45, 55, 69, 78], "explan": [26, 35, 45, 55, 69, 78], "explor": [16, 28, 61, 71], "exploratori": [15, 17, 37, 39, 52, 76, 86, 90, 92, 96], "express": [13, 58], "extract": [19, 33, 63, 76], "extractor": [32, 75], "f1": [23, 42, 66], "failur": [29, 72], "fair": 66, "fancier": [22, 41, 65], "farewel": 79, "faster": 9, "fastest": 9, "featur": [13, 14, 16, 17, 18, 19, 21, 24, 26, 27, 30, 32, 33, 35, 39, 43, 45, 46, 49, 52, 54, 55, 58, 59, 61, 62, 63, 64, 67, 69, 70, 73, 75, 76, 78, 81, 84, 90, 96], "feature_importances_": [26, 45, 69], "few": [23, 29, 42, 55, 66, 72, 78], "fictiti": [13, 58], "figur": 8, "filter": [9, 30, 49, 73], "final": [14, 22, 28, 29, 30, 33, 49, 52, 59, 65, 71, 72, 73, 76, 84, 86, 92, 98], "find": [14, 16, 27, 61, 70], "first": [13, 18, 62], "fit": [14, 18, 44, 59, 62, 68], "follow": [13, 15, 28, 29, 30, 49, 59, 60, 71, 72, 73], "font": [85, 86, 87, 88, 90, 91, 92, 93, 94, 96], "forecast": [33, 76], "forest": [25, 26, 35, 44, 45, 54, 55, 68, 69, 78], "forg": 11, "format": [8, 9, 13], "formul": [30, 49, 73], "forward": [27, 81], "frequent": 5, "from": [5, 9, 31, 35, 50, 55, 74, 78], "full": [56, 57, 79], "function": [9, 21, 24, 43, 64, 67], "fundament": [15, 16, 25, 37, 44, 60, 61, 68, 84], "further": [33, 76], "futur": [33, 76], "gamma": [16, 61], "garbag": [27, 70], "gaussian": [41, 65], "gb": [35, 54, 55, 78], "genai": 13, "gener": [4, 5, 7, 15, 16, 21, 25, 27, 44, 60, 61, 64, 68, 70, 81, 98], "geometr": [16, 61], "get": [5, 6, 45, 69], "git": [6, 11], "github": 6, "given": [13, 14, 53, 58, 59, 77], "global": [30, 49, 73], "goal": [15, 60], "golden": [15, 18, 19, 60, 62, 63], "good": [35, 54, 55, 66, 78], "grade": [4, 7, 13, 14, 59, 98], "gradescop": 8, "gradient": [25, 35, 44, 54, 55, 68, 78], "grid": [22, 35, 41, 55, 65, 78], "gridsearchcv": [22, 24, 35, 41, 43, 55, 65, 67, 78], "group": [15, 28, 66, 71], "guid": 84, "guidelin": [4, 7, 8], "ha": [13, 53, 58, 77], "halv": [22, 41, 65], "handl": [66, 80], "have": [25, 26, 35, 44, 45, 55, 68, 69, 78], "hazard": [34, 53, 77], "heatmap": [22, 41, 65], "help": [4, 27, 70], "here": [15, 53, 60, 77], "hierarch": [29, 48, 72], "high": [32, 75], "home": [29, 72], "homework": [5, 8, 13], "hot": [18, 27, 46, 52, 62, 70, 76], "hous": [13, 15, 18, 21, 58, 59, 62, 63, 64, 87, 93], "how": [4, 5, 8, 14, 15, 16, 17, 18, 21, 25, 26, 27, 29, 32, 35, 39, 44, 45, 46, 55, 59, 60, 61, 62, 64, 68, 69, 70, 72, 75, 78], "hyper": [22, 65], "hyperparamet": [14, 15, 16, 19, 21, 22, 24, 25, 28, 37, 41, 43, 44, 59, 61, 63, 64, 65, 67, 68, 71, 84, 86, 92], "hypothesi": [31, 50, 74], "i": [5, 13, 15, 18, 19, 22, 23, 25, 26, 27, 28, 30, 31, 35, 42, 44, 45, 46, 51, 55, 56, 57, 58, 60, 62, 63, 65, 66, 68, 69, 70, 71, 73, 74, 78, 79, 81], "iclcik": 49, "iclick": [13, 14, 15, 16, 18, 19, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 32, 34, 35, 44, 49, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 70, 71, 72, 73, 75, 77, 98], "idea": [16, 25, 27, 31, 35, 44, 50, 55, 61, 66, 68, 74, 78, 80, 81], "identifi": [19, 26, 45, 63, 69], "imag": [13, 38, 47, 58], "imbal": [24, 25, 26, 44, 45, 66, 67, 68, 69, 80], "import": [1, 6, 13, 14, 15, 16, 17, 18, 19, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 84, 85, 86, 90, 91, 92, 96], "imput": [18, 30, 49, 62, 73], "incorpor": [17, 19, 39, 63], "increas": [23, 42, 66], "index": 9, "inertia": [28, 71], "info": 8, "inform": [26, 33, 45, 69, 76], "initi": [28, 71, 79], "inject": [25, 44, 68], "input": [13, 28, 58, 71], "instal": [6, 11], "instruct": [0, 8], "instructor": 1, "interact": [27, 46, 70], "intercept": [21, 64], "interest": [35, 55, 78], "interim": [23, 26, 27, 33, 42, 45, 46, 66, 69, 70, 76], "interpret": [20, 21, 26, 28, 40, 45, 64, 69, 79], "intra": [28, 71], "intro": [30, 73], "introduct": [9, 13, 26, 27, 28, 29, 31, 32, 35, 45, 46, 50, 55, 58, 69, 70, 71, 72, 74, 75, 78, 84], "intuit": [21, 37, 64], "involv": [33, 52, 55, 76, 78], "issu": [35, 55, 78], "jupyt": 13, "jupyterlab": 11, "k": [16, 18, 28, 29, 30, 49, 61, 62, 71, 72, 73, 89, 95], "kaplan": [34, 53, 77], "kei": [26, 45, 55, 69, 78, 79], "kernel": [16, 61], "kind": [25, 44, 68], "kneighborsclassifi": [16, 38, 61], "knn": [17, 38, 39], "label": [13, 28, 35, 55, 58, 71, 78], "lag": [33, 52, 76, 90, 96], "land": 98, "languag": [5, 31, 50, 51, 74], "larg": [22, 31, 50, 65, 74], "late": 8, "latitud": [59, 85, 91], "lda": [31, 50, 51, 74], "learn": [1, 6, 11, 12, 13, 14, 15, 16, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 37, 40, 42, 43, 52, 55, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79], "least": [21, 64], "lectur": [1, 5, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 98], "let": [13, 16, 17, 18, 19, 23, 24, 26, 35, 39, 42, 43, 45, 47, 54, 55, 61, 62, 63, 66, 67, 69, 78], "level": [32, 75], "licens": [0, 1], "lightgbm": [25, 44, 68], "like": 5, "limit": [7, 21, 29, 64, 72], "line": 6, "linear": [20, 21, 24, 26, 40, 43, 45, 64, 67, 69], "link": 1, "list": 10, "liver": [13, 58], "ll": [15, 60], "llm": [31, 50, 74], "lo": [15, 16, 18, 19, 21, 22, 24, 25, 26, 30, 32, 33, 45, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 73, 75, 76, 79], "load": [56, 57, 79], "local": [56, 57, 79], "localhost": [56, 57, 79], "logist": [21, 23, 42, 64, 66], "logisticregress": [34, 35, 52, 55, 66, 76, 77, 78], "longitud": [59, 85, 91], "look": [5, 23, 28, 42, 66, 71], "loop": 9, "loss": [35, 55, 78], "lower": [22, 65], "m": 5, "machin": [1, 13, 14, 15, 16, 23, 28, 37, 42, 58, 59, 60, 61, 66, 71, 79], "maco": 6, "macro": 80, "magnitud": [21, 64], "mai": 70, "main": [21, 30, 35, 55, 64, 73, 78], "make": [9, 21, 35, 55, 64, 78], "make_column_transform": [19, 63], "make_pipelin": [17, 18, 62], "mani": [22, 63, 65], "manual": [22, 65], "mape": [24, 43, 67], "markov": [31, 50, 74], "materi": [0, 1, 10], "matplotlib": 9, "matric": [19, 63], "matrix": [23, 30, 42, 49, 66, 73], "matter": 15, "max_depth": [14, 59], "mean": [24, 28, 29, 31, 35, 43, 50, 51, 55, 67, 71, 72, 74, 78, 89, 95], "measur": [31, 70, 74], "media": [31, 50, 51, 74], "meet": [13, 58, 98], "meier": [34, 53, 77], "messag": [13, 29, 58, 72], "meta": 83, "method": [9, 17, 22, 27, 28, 39, 41, 65, 71, 81], "metric": [23, 24, 42, 43, 66, 67, 80, 84], "midterm": [71, 98], "might": [34, 77], "min": [9, 13, 14, 15, 16, 19, 26, 28, 32, 34, 35, 45, 50, 51, 55, 59, 60, 61, 62, 63, 69, 70, 71, 74, 75, 77, 78, 79], "miniconda": 11, "miniforg": 11, "minor": 80, "misc": [1, 10], "miscellan": [30, 49, 73], "mislead": [35, 54, 55, 78], "ml": [13, 15, 16, 26, 35, 37, 45, 55, 58, 60, 61, 66, 69, 78, 84], "model": [13, 14, 15, 17, 18, 19, 20, 21, 23, 24, 25, 26, 27, 31, 32, 34, 37, 38, 39, 40, 42, 43, 44, 45, 46, 50, 51, 53, 56, 57, 58, 59, 60, 61, 62, 63, 64, 67, 68, 69, 70, 74, 75, 77, 79, 84, 86, 92], "model_select": [22, 41, 65], "moment": [56, 57, 79], "month": [52, 53, 76, 77], "more": [14, 15, 16, 17, 18, 19, 21, 24, 27, 29, 42, 52, 59, 61, 62, 63, 64, 66, 67, 70, 72, 76, 90, 96], "most": [20, 21, 23, 40, 42, 64], "motiv": [15, 16, 18, 21, 22, 23, 25, 26, 27, 28, 29, 30, 31, 33, 35, 42, 45, 46, 50, 51, 55, 60, 61, 62, 64, 65, 66, 68, 69, 70, 71, 72, 73, 74, 76, 78], "movi": [13, 30, 49, 58, 73], "mse": [24, 43, 67], "much": [22, 65], "multi": [32, 75, 80, 83], "multiclass": 84, "multipl": [16, 19, 24, 43, 61, 63, 67], "multipli": 9, "n": [53, 77], "n_estim": [25, 44, 68], "n_iter": [22, 41, 65], "n_job": [22, 41, 65], "n_neighbor": [16, 61], "name": [15, 24, 30, 43, 60, 67, 73], "natur": [31, 51, 74], "nearest": [16, 18, 28, 30, 49, 61, 62, 71, 73], "need": [18, 22, 62, 65], "neg": [20, 23, 40, 42, 66], "neighbour": [16, 18, 30, 49, 61, 62, 73], "nest": 9, "netflix": [25, 68], "network": [32, 75], "neural": [32, 75], "new": [35, 55, 56, 57, 78, 79], "next": [13, 79], "nlp": [31, 50, 51, 74, 82, 84], "nn": [16, 61], "node": 14, "non": [16, 19, 45, 61, 63, 69], "notat": 9, "note": [9, 33, 54, 55, 56, 57, 60, 76, 86, 92], "notebook": [11, 13], "now": [34, 77], "number": [25, 28, 44, 52, 68, 71, 76], "numer": [26, 27, 45, 46, 69, 70], "numpi": 9, "object": [12, 14, 25, 31, 32, 33, 34, 35, 59, 68, 74, 75, 76, 77, 78, 79], "observ": [23, 42, 66], "occasion": [18, 62], "off": [15, 16, 25, 44, 60, 61, 68], "oh": [18, 19, 62, 63], "ok": [18, 19, 62, 63], "onc": [23, 42, 66], "one": [19, 27, 46, 63, 70], "onehotencod": [19, 63], "onli": [11, 19, 34, 63, 77], "onlin": [1, 10], "open": 11, "oper": [23, 42, 66], "optim": [15, 22, 37, 41, 65, 84], "option": [6, 11, 16, 18, 22, 27, 32, 34, 41, 42, 44, 53, 56, 57, 61, 62, 65, 66, 68, 75, 77, 79, 81], "ordin": [1, 17, 18, 19, 26, 39, 45, 62, 63, 69, 98], "other": [9, 16, 24, 27, 28, 33, 34, 35, 43, 46, 51, 52, 53, 55, 61, 67, 71, 76, 77, 78, 81, 82], "our": [8, 17, 18, 35, 55, 56, 57, 60, 62, 78, 79], "out": [18, 27, 32, 35, 46, 54, 55, 62, 70, 75, 78, 79], "outcom": [13, 14, 15, 16, 18, 19, 21, 22, 24, 26, 27, 28, 29, 30, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 69, 70, 71, 72, 73], "outlin": [85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96], "outlook": [53, 77], "output": [28, 71], "over": [9, 16, 21, 61, 64, 80], "overfit": [15, 22, 60, 65], "overlap": 5, "oversampl": 80, "overview": [16, 42, 61], "ovo": 83, "ovr": 83, "packag": [33, 52, 76], "panda": 9, "pandas_profil": [24, 43, 67], "paper": [25, 44, 66, 68], "paradigm": [18, 62], "paramet": [14, 21, 22, 41, 59, 64, 65, 66, 84], "parametr": [16, 61], "pars": [52, 76, 90, 96], "part": 84, "pass": [22, 41, 65], "patient": [13, 58], "paus": 17, "perfect": [28, 71], "perhap": [35, 54, 55, 78], "permut": 45, "permutation_import": [26, 45, 69], "persona": [13, 58], "piazza": 4, "pick": [15, 22, 60, 65], "pictur": [14, 15, 18, 59, 60, 62], "piec": [55, 78], "pipelin": [17, 18, 31, 39, 50, 51, 62, 74], "plan": [29, 72], "playground": [16, 38, 61, 86, 92], "plot": [9, 26, 28, 34, 45, 53, 69, 71, 77], "point": [16, 23, 26, 28, 33, 42, 45, 52, 61, 66, 69, 71, 76], "polici": 7, "poll": 71, "ponder": [20, 40], "popular": [13, 58], "posit": [20, 23, 40, 42, 66], "posix": [33, 76], "possibl": [19, 24, 28, 43, 63, 67, 71], "post": 10, "pr": [23, 42, 66], "practic": [14, 59, 61], "pre": [31, 32, 50, 74, 75], "precis": [23, 42, 66], "predict": [13, 14, 21, 26, 30, 31, 32, 34, 44, 45, 49, 50, 53, 58, 59, 63, 64, 68, 69, 73, 74, 75, 77, 83, 85, 91], "predict_proba": [21, 35, 55, 64, 78], "predictor": 79, "prefer": [35, 55, 78], "prepar": [8, 84], "preprocess": [18, 19, 24, 35, 43, 51, 52, 54, 55, 62, 63, 67, 76, 78, 79, 82, 84, 89, 90, 95, 96], "prerequisit": [5, 13], "pretrain": [31, 50, 74], "preval": [13, 58], "price": [13, 58, 59], "principl": [35, 55, 78], "prize": [25, 68], "pro": [16, 29, 61, 72, 84], "probabl": [21, 22, 41, 64, 65], "problem": [14, 15, 16, 18, 22, 27, 30, 33, 41, 49, 52, 59, 60, 61, 62, 65, 73, 76, 79, 81], "procedur": 66, "process": [31, 51, 74], "product": [13, 58], "profil": [30, 49, 73], "program": [14, 59], "properli": [17, 39], "proport": [34, 53, 77], "python": [9, 10, 11, 13], "q": 4, "qualiti": 70, "queri": [9, 16, 61], "question": [4, 5, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 24, 25, 27, 28, 29, 30, 31, 32, 33, 34, 35, 37, 39, 40, 44, 49, 51, 52, 55, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 84, 85, 86, 87, 88, 90, 91, 92, 93, 94, 96], "quick": [11, 61], "quiz": [14, 59], "quiz2": [14, 59], "quot": [27, 70], "r": [24, 43, 67], "random": [22, 25, 26, 35, 41, 44, 45, 54, 55, 65, 68, 69, 78], "random_st": 60, "randomforestclassifi": [25, 34, 44, 68, 77], "randomizedsearchcv": [22, 24, 41, 43, 65, 67], "rang": [22, 41, 65], "rate": [30, 49, 73], "raw": [21, 64], "rbf": [16, 38, 61], "re": [35, 55, 78], "read": [9, 14, 22, 59, 65], "reader": [35, 55, 78], "real": [56, 57, 59, 79, 85, 91], "realist": [19, 63], "reason": 7, "recal": [23, 42, 66], "recap": [14, 16, 29, 34, 55, 59, 61, 72, 77, 78, 85, 87, 91, 93], "receiv": [23, 42, 66], "recip": 79, "recommend": [6, 11, 13, 18, 30, 49, 62, 73, 84], "record": 98, "recurs": [27, 46, 70], "red": [85, 86, 87, 88, 90, 91, 92, 93, 94, 96], "refer": [1, 10, 34, 53, 77], "reflect": [14, 15, 28, 29, 59, 60, 71, 72], "registr": [13, 98], "regress": [14, 16, 21, 23, 24, 37, 42, 43, 44, 59, 61, 64, 66, 67, 68], "regressor": [16, 61], "relat": [4, 14, 16, 35, 55, 59, 61, 66, 78], "relev": [10, 25, 27, 44, 66, 68, 70, 81], "remark": [33, 52, 76], "rememb": [28, 71], "remind": [30, 49, 59, 73], "remov": 9, "renam": 9, "render": [56, 57, 79], "repo": 11, "report": [8, 23, 42], "repositori": 8, "represent": [19, 31, 50, 63, 74], "request": [56, 57, 79], "requir": [13, 79], "rescu": [15, 60], "resourc": [10, 13, 22, 27, 28, 29, 30, 49, 65, 66, 70, 71, 72, 73], "rest": 83, "result": [22, 28, 35, 41, 54, 55, 65, 78], "retail": [33, 76], "reus": [35, 55, 78], "review": [13, 20, 40, 58, 79], "revis": 37, "rf": [35, 54, 55, 78], "rfe": [27, 46, 70], "ridg": [21, 24, 43, 64, 67], "ridgecv": [24, 43, 67], "right": [34, 77], "rmse": [24, 43, 67], "roc": [23, 42, 66], "root": [14, 24, 43, 67], "row": 9, "rule": [15, 18, 19, 60, 62, 63], "run": [11, 18, 35, 55, 62, 78], "same": 9, "sampl": [25, 28, 68, 71, 80], "sauc": [28, 71], "save": [13, 56, 57, 58, 79], "scale": [13, 17, 18, 21, 26, 39, 45, 58, 62, 64, 69], "scenario": [23, 42], "schedul": 1, "scheme": 98, "scikit": [15, 18, 19, 24, 43, 60, 62, 63, 67], "score": [14, 21, 22, 23, 24, 27, 28, 42, 43, 59, 60, 64, 65, 66, 67, 71, 81], "search": [16, 22, 27, 35, 41, 46, 55, 61, 65, 78, 81], "season": [33, 52, 76], "section": [5, 36], "segment": [28, 71], "select": [11, 13, 27, 28, 29, 30, 46, 49, 59, 70, 71, 72, 73, 81, 84], "send": [56, 57, 79], "sentenc": [31, 50, 74], "sentiment": [13, 31, 50, 58, 74], "separ": [24, 26, 35, 43, 45, 54, 55, 67, 69, 78], "seri": [9, 33, 52, 76, 84, 90, 96], "server": [56, 57, 79], "servic": [56, 57, 79], "set": [11, 13, 22, 37, 56, 57, 60, 65, 66, 79], "set_config": [19, 63], "shap": [26, 45, 69], "shape": [9, 29, 72], "shaplei": [26, 45, 69], "short": 10, "should": [25, 30, 35, 44, 55, 68, 73, 78], "show": [26, 35, 45, 55, 69, 78], "sigmoid": [21, 32, 64, 75], "sign": [21, 64], "silhouett": [28, 71], "similar": [16, 31, 61, 74], "simpl": [15, 31, 50, 60, 74], "simplefeatur": [26, 69], "simpleimput": [17, 39], "simul": [88, 94], "singl": [15, 37, 60], "size": 9, "sklearn": [14, 17, 18, 19, 22, 25, 26, 39, 41, 44, 45, 59, 62, 63, 65, 66, 68, 69], "slowest": 9, "small": [35, 55, 78], "smote": 80, "social": [31, 50, 51, 74], "softmax": [32, 75], "softwar": [0, 32, 33, 52, 75, 76], "solut": 25, "solv": [22, 65], "some": [14, 22, 25, 27, 42, 44, 59, 65, 66, 68, 70, 79], "sort": 9, "sort_valu": 9, "sourc": [8, 26], "space": [33, 52, 76], "spaci": 51, "spaghetti": [28, 71], "spam": [13, 19, 58, 63], "spars": [19, 63], "specif": [4, 27, 70], "split": [15, 17, 18, 33, 37, 39, 52, 60, 62, 66, 76, 86, 92], "spotifi": [18, 22, 62, 65], "squar": [24, 43, 67], "stack": [25, 44, 68, 88, 94], "standardscal": [18, 62], "start": [6, 11, 16], "statement": [13, 28, 29, 30, 49, 59, 71, 72, 73], "statist": 79, "step": [6, 11, 14, 37, 51, 59, 82, 87, 93], "strategi": [25, 44, 68, 83], "stratifi": 66, "strength": [21, 25, 44, 64, 68], "structur": [56, 57, 79], "studi": 84, "style": 13, "submiss": 8, "submit": [5, 8], "success": [22, 41, 65], "summari": [9, 13, 14, 15, 16, 17, 18, 21, 22, 23, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 42, 44, 45, 46, 49, 50, 51, 53, 58, 59, 60, 61, 62, 64, 65, 66, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77], "supervis": [13, 14, 15, 16, 28, 30, 37, 49, 58, 59, 60, 61, 71, 73, 79], "support": [16, 61], "surviv": [34, 53, 77, 84], "svc": [23, 42, 66], "svm": [16, 21, 38, 61, 64], "syllabu": [1, 98], "syntax": [17, 18, 19, 22, 41, 62, 63, 65], "synthet": 80, "system": [30, 49, 73, 84], "ta": [1, 98], "tabular": [14, 16, 59, 61, 79], "tackl": [24, 67], "take": [5, 29, 72], "takeawai": 79, "talk": 13, "target": [13, 14, 19, 24, 28, 43, 58, 59, 63, 67, 71], "task": [51, 82], "teach": [1, 98], "team": [1, 98], "techniqu": [18, 62, 80], "templat": 8, "tempor": [33, 76], "tent": 1, "terminologi": [14, 32, 59, 75], "test": [6, 15, 22, 33, 37, 52, 60, 65, 76], "test_df": 60, "test_siz": 60, "text": [17, 19, 31, 39, 50, 51, 63, 74, 82], "than": [19, 22, 27, 35, 54, 55, 63, 65, 70, 78], "thei": [25, 44, 68], "them": 9, "thi": [5, 9, 13, 17, 18, 19, 23, 26, 35, 37, 39, 42, 45, 55, 58, 62, 63, 69, 78, 79], "thing": [18, 35, 54, 55, 62, 78], "threshold": [23, 42, 66], "time": [7, 13, 33, 34, 52, 58, 76, 77, 84, 90, 96], "tip": 84, "tl": 11, "todai": [15, 18, 19, 24, 35, 55, 60, 62, 63, 66, 67, 78], "toi": [14, 19, 23, 31, 42, 50, 51, 59, 63, 66, 74], "token": [51, 82], "tool": [51, 82], "topic": [31, 50, 51, 74], "trade": [15, 16, 25, 44, 60, 61, 68], "tradeoff": [15, 23, 25, 42, 44, 60, 66, 68], "tradit": [14, 33, 52, 59, 76], "train": [13, 14, 15, 19, 21, 31, 32, 33, 35, 50, 52, 54, 55, 56, 57, 58, 59, 60, 63, 64, 66, 74, 75, 76, 78, 79], "train_df": 60, "train_siz": 60, "transfer": [32, 75], "transform": [17, 18, 19, 24, 27, 31, 35, 39, 43, 50, 54, 55, 62, 63, 67, 70, 74, 78], "transpar": [26, 45, 69, 79], "tree": [14, 15, 25, 26, 35, 37, 44, 45, 54, 55, 59, 68, 69, 78, 86, 92], "trend": [33, 76], "troubleshoot": 11, "true": [13, 28, 29, 30, 49, 71, 72, 73], "try": [17, 18, 24, 35, 39, 43, 55, 62, 67, 78, 79], "tune": [24, 28, 43, 67, 71, 86, 92], "tutori": [16, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96], "two": [19, 63], "type": [13, 15, 23, 24, 26, 28, 33, 34, 35, 42, 43, 45, 52, 53, 54, 55, 58, 60, 66, 67, 69, 71, 76, 77, 78], "typic": [5, 37, 51, 60, 82], "u": [35, 55, 78], "ubc": 1, "ubuntu": 6, "under": [23, 42, 66], "underfit": [15, 60], "undersampl": 80, "understand": 79, "unequ": [33, 52, 76], "uniform": [41, 65], "unknown": [19, 63], "unlabel": [28, 71], "unseen": [13, 58, 60], "unsupervis": [14, 28, 59, 71], "up": [11, 13, 15, 16, 35, 55, 56, 57, 60, 61, 78, 79], "updat": 8, "url": 9, "us": [5, 8, 9, 11, 13, 14, 15, 16, 18, 19, 24, 25, 28, 31, 32, 35, 38, 43, 44, 50, 51, 55, 58, 59, 60, 61, 62, 63, 67, 68, 70, 71, 74, 75, 78, 80, 82, 83, 85, 91, 98], "usa": [59, 85, 91], "user": [6, 30, 49, 73], "usual": [27, 70], "util": [30, 49, 73], "v": [2, 11, 13, 14, 15, 16, 23, 26, 28, 32, 39, 42, 45, 59, 60, 61, 66, 69, 71, 75, 79, 83], "valid": [15, 17, 18, 22, 23, 33, 37, 42, 52, 60, 62, 65, 66, 76, 86, 92], "varianc": [15, 60], "vector": [9, 16, 31, 51, 61, 74], "verifi": 11, "video": [13, 14, 15, 16, 18, 21, 22, 24, 25, 26, 28, 29, 43, 44, 51, 58, 59, 60, 61, 62, 64, 66, 67, 68, 71, 72, 82], "view": [16, 19, 61, 63], "violat": [15, 60], "vision": [32, 75, 84], "visual": [10, 22, 35, 41, 54, 55, 65, 78], "vocabulari": [20, 40], "wai": [22, 27, 35, 46, 55, 65, 78, 81], "waitlist": [5, 13], "want": [19, 26, 34, 45, 63, 69, 77], "warn": [14, 27, 46, 59, 70, 81], "watch": [35, 54, 55, 78], "we": [5, 9, 15, 18, 19, 21, 22, 24, 25, 26, 27, 28, 30, 34, 35, 37, 44, 45, 46, 49, 53, 55, 60, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 73, 77, 78, 79], "weak": [25, 44, 68], "web": [56, 57, 79], "websit": 13, "week": 5, "weight": [21, 64, 80], "what": [5, 13, 15, 18, 19, 21, 23, 24, 25, 26, 27, 28, 30, 31, 34, 35, 42, 44, 45, 46, 49, 50, 51, 53, 55, 58, 60, 62, 63, 64, 66, 67, 68, 69, 70, 71, 73, 74, 77, 78, 79], "when": [9, 11, 18, 22, 35, 55, 62, 65, 78], "where": [19, 34, 63, 77], "whether": [13, 58], "which": [13, 23, 25, 28, 29, 30, 42, 44, 49, 59, 66, 68, 71, 72, 73], "who": 5, "why": [13, 15, 19, 22, 26, 27, 30, 32, 35, 45, 46, 55, 58, 63, 65, 69, 70, 73, 75, 78], "window": 6, "wise": 9, "without": [28, 71], "word": [19, 31, 50, 51, 63, 74], "work": [14, 25, 29, 32, 35, 44, 55, 59, 68, 72, 75, 78], "workflow": [13, 15, 23, 42, 58, 60, 66], "workload": 5, "would": [15, 23, 39, 42, 60], "wrapper": 83, "write": [14, 59], "x": [13, 14, 24, 26, 35, 43, 45, 54, 55, 58, 59, 67, 69, 78], "xgboost": [25, 44, 68], "y": [13, 14, 24, 26, 35, 43, 45, 54, 55, 58, 59, 67, 69, 78], "ye": [34, 77], "yield": [22, 41, 65], "you": [13, 14, 15, 16, 18, 19, 20, 21, 22, 24, 25, 27, 28, 29, 30, 32, 33, 34, 35, 37, 39, 40, 44, 49, 52, 55, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 70, 71, 72, 73, 75, 76, 77, 78, 79], "your": [6, 11, 13, 14, 15, 35, 54, 55, 59, 78]}})