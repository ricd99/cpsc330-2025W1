Search.setIndex({"alltitles": {"": [[38, "id1"]], "(Optional) Evaluation": [[34, "optional-evaluation"], [54, "optional-evaluation"], [78, "optional-evaluation"]], "(Optional) Example 1: Optimization bias": [[22, "optional-example-1-optimization-bias"], [66, "optional-example-1-optimization-bias"]], "(Optional) Example 2: Optimization bias": [[22, "optional-example-2-optimization-bias"], [66, "optional-example-2-optimization-bias"]], "(Optional) Fancier methods": [[22, "optional-fancier-methods"], [42, "optional-fancier-methods"], [66, "optional-fancier-methods"]], "(Optional) Fitting in boosted regression trees.": [[45, "optional-fitting-in-boosted-regression-trees"], [69, "optional-fitting-in-boosted-regression-trees"]], "(Optional) Forward or backward selection": [[27, "optional-forward-or-backward-selection"], [82, "optional-forward-or-backward-selection"]], "(Optional) Given customer has been here n months, what\u2019s the outlook?": [[54, "optional-given-customer-has-been-here-n-months-what-s-the-outlook"], [78, "optional-given-customer-has-been-here-n-months-what-s-the-outlook"]], "(Optional) How does training work in neural networks? (High-Level)": [[32, "optional-how-does-training-work-in-neural-networks-high-level"], [76, "optional-how-does-training-work-in-neural-networks-high-level"]], "(Optional) Learn JupyterLab and Python": [[11, "optional-learn-jupyterlab-and-python"]], "(Optional) Parametric vs non parametric": [[16, "optional-parametric-vs-non-parametric"], [62, "optional-parametric-vs-non-parametric"]], "(Optional) Prediction in boosted regression trees": [[45, "optional-prediction-in-boosted-regression-trees"], [69, "optional-prediction-in-boosted-regression-trees"]], "(Optional) Problems with feature selection": [[27, "optional-problems-with-feature-selection"], [82, "optional-problems-with-feature-selection"]], "(Optional) Search and score": [[27, "optional-search-and-score"], [82, "optional-search-and-score"]], "(Optional) Searching for optimal parameters with successive halving\u00b6": [[22, "optional-searching-for-optimal-parameters-with-successive-halving"], [42, "optional-searching-for-optimal-parameters-with-successive-halving"], [66, "optional-searching-for-optimal-parameters-with-successive-halving"]], "(Optional) Setting up a directory structure and environment": [[36, "optional-setting-up-a-directory-structure-and-environment"], [57, "optional-setting-up-a-directory-structure-and-environment"], [58, "optional-setting-up-a-directory-structure-and-environment"], [80, "optional-setting-up-a-directory-structure-and-environment"]], "(Optional) Some more details": [[43, "optional-some-more-details"], [67, "optional-some-more-details"]], "(Supervised) machine learning: popular definition": [[13, "supervised-machine-learning-popular-definition"], [59, "supervised-machine-learning-popular-definition"]], "(iClicker) Exercise 14.1": [[71, "id1"]], "(iClicker) Exercise 20.1": [[78, "iclicker-exercise-20-1"]], "(iClicker) Exercise 20.2": [[78, "iclicker-exercise-20-2"]], "(iClicker) Exercise 21.1": [[34, "iclicker-exercise-21-1"]], "(iClicker) Exercise 21.2": [[34, "iclicker-exercise-21-2"]], "(iClicker) Exercise 4.1": [[16, "iclicker-exercise-4-1"], [62, "iclicker-exercise-4-1"]], "(iClicker) Exercise 4.2": [[16, "iclicker-exercise-4-2"], [62, "iclicker-exercise-4-2"]], "(iClicker) Exercise 5.1": [[18, "iclicker-exercise-5-1"], [63, "iclicker-exercise-5-1"]], "(iClicker) Exercise 5.2": [[18, "iclicker-exercise-5-2"], [63, "iclicker-exercise-5-2"]], "(iClicker) Exercise 5.3": [[18, "iclicker-exercise-5-3"], [63, "iclicker-exercise-5-3"]], "(iClicker) Exercise 6.1": [[19, "iclicker-exercise-6-1"], [64, "iclicker-exercise-6-1"]], "(iClicker) Exercise 6.2": [[19, "iclicker-exercise-6-2"], [64, "iclicker-exercise-6-2"]], "(iClicker) Exercise 7.1": [[21, "iclicker-exercise-7-1"], [65, "iclicker-exercise-7-1"]], "(iClicker) Exercise 7.2": [[21, "iclicker-exercise-7-2"], [65, "iclicker-exercise-7-2"]], "(iClicker) Exercise 7.3": [[21, "iclicker-exercise-7-3"]], "(iClicker) Exercise 8.1": [[22, "iclicker-exercise-8-1"], [66, "iclicker-exercise-8-1"]], "(iClicker) Midterm poll": [[72, "iclicker-midterm-poll"]], "15.1 Select all of the following statements which are True (iClicker)": [[28, "select-all-of-the-following-statements-which-are-true-iclicker"]], "15.2 Select all of the following statements which are True (iClicker)": [[28, "id1"]], "15.3 Select all of the following statements which are True (iClicker)": [[28, "id3"]], "16.1 Select all of the following statements which are True (iClicker)": [[29, "select-all-of-the-following-statements-which-are-true-iclicker"]], "16.2 Select all of the following statements which are True (iClicker)": [[29, "id2"]], "16.3 Select all of the following statements which are True": [[29, "select-all-of-the-following-statements-which-are-true"], [73, "select-all-of-the-following-statements-which-are-true"]], "330 vs. 340": [[36, "vs-340"], [80, "vs-340"]], "<font color='red'>Question 10</font>": [[89, "question-10"], [95, "question-10"]], "<font color='red'>Question 1</font>": [[86, "question-1"], [87, "question-1"], [89, "question-1"], [91, "question-1"], [92, "question-1"], [93, "question-1"], [95, "question-1"], [97, "question-1"]], "<font color='red'>Question 2</font>": [[86, "question-2"], [89, "question-2"], [91, "question-2"], [92, "question-2"], [95, "question-2"], [97, "question-2"]], "<font color='red'>Question 3: Baseline model</font>": [[87, "question-3-baseline-model"], [93, "question-3-baseline-model"]], "<font color='red'>Question 3</font>": [[86, "question-3"], [89, "question-3"], [91, "question-3"], [92, "question-3"], [95, "question-3"], [97, "question-3"]], "<font color='red'>Question 4: Decision tree</font>": [[87, "question-4-decision-tree"], [93, "question-4-decision-tree"]], "<font color='red'>Question 4</font>": [[86, "question-4"], [89, "question-4"], [91, "question-4"], [92, "question-4"], [95, "question-4"], [97, "question-4"]], "<font color='red'>Question 5: Cross-validation</font>": [[87, "question-5-cross-validation"]], "<font color='red'>Question 5: Hyperparameter tuning</font>": [[87, "question-5-hyperparameter-tuning"], [93, "question-5-hyperparameter-tuning"]], "<font color='red'>Question 5</font>": [[89, "question-5"], [91, "question-5"], [95, "question-5"], [97, "question-5"]], "<font color='red'>Question 6: Cross-validation</font>": [[93, "question-6-cross-validation"]], "<font color='red'>Question 6: Hyperparameters playground</font>": [[87, "question-6-hyperparameters-playground"], [93, "question-6-hyperparameters-playground"]], "<font color='red'>Question 6</font>": [[89, "question-6"], [91, "question-6"], [95, "question-6"], [97, "question-6"]], "<font color='red'>Question 7</font>": [[89, "question-7"], [95, "question-7"]], "<font color='red'>Question 8</font>": [[89, "question-8"], [95, "question-8"]], "<font color='red'>Question 9</font>": [[89, "question-9"], [95, "question-9"]], "<font color='red'>Recap Questions</font>": [[86, "recap-questions"], [92, "recap-questions"]], "<font color='red'>Recap/comprehension questions</font>": [[88, "recap-comprehension-questions"], [94, "recap-comprehension-questions"]], "A few comments on PR curve": [[23, "a-few-comments-on-pr-curve"], [43, "a-few-comments-on-pr-curve"], [67, "a-few-comments-on-pr-curve"]], "A few comments on clustering evaluation": [[29, "a-few-comments-on-clustering-evaluation"], [73, "a-few-comments-on-clustering-evaluation"]], "A simple model of language": [[31, "a-simple-model-of-language"], [51, "a-simple-model-of-language"], [75, "a-simple-model-of-language"]], "AP score": [[23, "ap-score"], [43, "ap-score"], [67, "ap-score"]], "AP vs. F1-score": [[23, "ap-vs-f1-score"], [43, "ap-vs-f1-score"], [67, "ap-vs-f1-score"]], "API on the localhost": [[36, "api-on-the-localhost"], [57, "api-on-the-localhost"], [58, "api-on-the-localhost"], [80, "api-on-the-localhost"]], "AUC or AP?": [[23, "auc-or-ap"]], "About this course": [[13, "about-this-course"]], "About this document": [[9, "about-this-document"]], "Academic concessions": [[99, "academic-concessions"]], "Accessing homework assignments": [[8, "accessing-homework-assignments"]], "Accessing learned parameters": [[21, "accessing-learned-parameters"], [65, "accessing-learned-parameters"]], "Activity": [[13, "activity"], [27, "activity"]], "Activity (~4 mins)": [[46, "activity-4-mins"]], "Activity (~5 mins)": [[26, "activity-5-mins"], [26, "id3"], [70, "activity-5-mins"], [70, "id3"]], "Activity: Context and word meaning": [[52, "activity-context-and-word-meaning"]], "Activity: Discuss the following questions in your group": [[15, "activity-discuss-the-following-questions-in-your-group"]], "Activity: How can you measure quality of the data? (~3 mins)": [[71, "activity-how-can-you-measure-quality-of-the-data-3-mins"]], "Activity: explaining GridSearchCV (15 min)": [[35, "activity-explaining-gridsearchcv-15-min"], [56, "activity-explaining-gridsearchcv-15-min"], [79, "activity-explaining-gridsearchcv-15-min"]], "Activity: interpretation of results": [[28, "activity-interpretation-of-results"]], "Adding/removing columns with [] and drop()": [[9, "adding-removing-columns-with-and-drop"]], "Adding/removing rows with [] and drop()": [[9, "adding-removing-rows-with-and-drop"]], "Additional sources": [[26, "additional-sources"]], "Additional submission instructions": [[8, "additional-submission-instructions"]], "Addressing class imbalance": [[67, "addressing-class-imbalance"]], "Advantages of RandomizedSearchCV": [[22, "advantages-of-randomizedsearchcv"], [22, "id1"], [42, "advantages-of-randomizedsearchcv"], [42, "id1"], [66, "advantages-of-randomizedsearchcv"], [66, "id1"]], "Alternative and more compact syntax: make_pipeline": [[17, "alternative-and-more-compact-syntax-make-pipeline"], [18, "alternative-and-more-compact-syntax-make-pipeline"], [63, "alternative-and-more-compact-syntax-make-pipeline"]], "Alternative methods for scaling": [[17, "alternative-methods-for-scaling"], [40, "alternative-methods-for-scaling"]], "Alternative terminology for examples, features, targets, and training": [[14, "alternative-terminology-for-examples-features-targets-and-training"], [60, "alternative-terminology-for-examples-features-targets-and-training"]], "An effective strategy": [[25, "an-effective-strategy"], [45, "an-effective-strategy"], [69, "an-effective-strategy"]], "An example of a bootstrap samples": [[25, "an-example-of-a-bootstrap-samples"], [69, "an-example-of-a-bootstrap-samples"]], "An introduction to Grid Search": [[35, "an-introduction-to-grid-search"], [56, "an-introduction-to-grid-search"], [79, "an-introduction-to-grid-search"]], "Analogy-based algorithms in practice": [[62, "analogy-based-algorithms-in-practice"]], "Analogy-based models": [[62, "analogy-based-models"]], "Appendix A: Handling class imbalance": [[81, null]], "Appendix B: Feature Selection": [[82, null]], "Appendix C: Basic text preprocessing [video]": [[83, null]], "Appendix D: Multi-class, meta-strategies": [[84, null]], "Applying feature transformations": [[24, "applying-feature-transformations"], [35, "applying-feature-transformations"], [44, "applying-feature-transformations"], [55, "applying-feature-transformations"], [56, "applying-feature-transformations"], [68, "applying-feature-transformations"], [79, "applying-feature-transformations"]], "Applying functions to a dataframe with df.apply() and df.applymap()": [[9, "applying-functions-to-a-dataframe-with-df-apply-and-df-applymap"]], "Approach 1: Only consider the examples where \u201cChurn\u201d=Yes": [[34, "approach-1-only-consider-the-examples-where-churn-yes"], [78, "approach-1-only-consider-the-examples-where-churn-yes"]], "Approach 2: Assume everyone churns right now": [[34, "approach-2-assume-everyone-churns-right-now"], [78, "approach-2-assume-everyone-churns-right-now"]], "Approach 3: Survival analysis": [[34, "approach-3-survival-analysis"], [78, "approach-3-survival-analysis"]], "Approach from all angles": [[35, "approach-from-all-angles"], [56, "approach-from-all-angles"], [79, "approach-from-all-angles"]], "Are we doing better with class_weight=\"balanced\"?": [[67, "are-we-doing-better-with-class-weight-balanced"]], "Area under the curve (AUC)": [[23, "area-under-the-curve-auc"], [43, "area-under-the-curve-auc"], [67, "area-under-the-curve-auc"]], "Assessing on the test set": [[38, "assessing-on-the-test-set"]], "Assignments": [[99, "assignments"]], "Attention": [[14, null], [14, null], [16, null], [60, null], [60, null], [60, null], [62, null]], "Attribution": [[35, "attribution"], [56, "attribution"], [79, "attribution"]], "Automated hyperparameter optimization": [[22, "automated-hyperparameter-optimization"], [22, "id3"], [66, "automated-hyperparameter-optimization"], [66, "id3"]], "Averaging": [[25, "averaging"], [45, "averaging"], [69, "averaging"]], "Averaging simulation": [[89, "averaging-simulation"], [95, "averaging-simulation"]], "Bad range for hyperparameters": [[22, "bad-range-for-hyperparameters"], [42, "bad-range-for-hyperparameters"], [66, "bad-range-for-hyperparameters"]], "Bag of words (BOW) representation": [[19, "bag-of-words-bow-representation"], [64, "bag-of-words-bow-representation"]], "Baseline": [[23, "baseline"], [26, "baseline"], [43, "baseline"], [46, "baseline"], [67, "baseline"], [70, "baseline"]], "Baseline Approaches": [[30, "baseline-approaches"], [50, "baseline-approaches"], [74, "baseline-approaches"]], "Baseline model": [[15, "baseline-model"], [38, "baseline-model"]], "Baselines": [[14, "baselines"], [25, "baselines"], [45, "baselines"], [60, "baselines"], [69, "baselines"]], "Baselines [video]": [[14, "baselines-video"], [60, "baselines-video"]], "Basic text preprocessing [video]": [[52, "basic-text-preprocessing-video"]], "Better features usually help more than a better model.": [[27, "better-features-usually-help-more-than-a-better-model"], [71, "better-features-usually-help-more-than-a-better-model"]], "Beyond error rate in recommendation systems": [[30, "beyond-error-rate-in-recommendation-systems"], [50, "beyond-error-rate-in-recommendation-systems"], [74, "beyond-error-rate-in-recommendation-systems"]], "Beyond words: sentence embeddings": [[31, "beyond-words-sentence-embeddings"], [51, "beyond-words-sentence-embeddings"], [75, "beyond-words-sentence-embeddings"]], "Bias vs variance tradeoff": [[15, "bias-vs-variance-tradeoff"], [61, "bias-vs-variance-tradeoff"]], "Big picture and datasets": [[14, "big-picture-and-datasets"], [60, "big-picture-and-datasets"]], "Big picture and motivation": [[15, "big-picture-and-motivation"], [61, "big-picture-and-motivation"]], "Books": [[1, "books"]], "Bottom-up explanations": [[35, "bottom-up-explanations"], [56, "bottom-up-explanations"], [79, "bottom-up-explanations"]], "Break (5 min)": [[9, "break-5-min"], [13, "break-5-min"], [14, "break-5-min"], [15, "break-5-min"], [16, "break-5-min"], [19, "break-5-min"], [32, "break-5-min"], [34, "break-5-min"], [35, "break-5-min"], [51, "break-5-min"], [52, "break-5-min"], [56, "break-5-min"], [60, "break-5-min"], [61, "break-5-min"], [62, "break-5-min"], [63, "break-5-min"], [64, "break-5-min"], [71, "break-5-min"], [75, "break-5-min"], [76, "break-5-min"], [78, "break-5-min"], [79, "break-5-min"]], "Break (~15 min)": [[36, "break-15-min"], [80, "break-15-min"]], "Broadcasting in numpy": [[9, "broadcasting-in-numpy"]], "Building a model": [[36, "building-a-model"], [57, "building-a-model"], [58, "building-a-model"], [80, "building-a-model"]], "Building a supervise machine learning model": [[13, "building-a-supervise-machine-learning-model"], [59, "building-a-supervise-machine-learning-model"]], "Building and deploying a web app": [[36, "building-and-deploying-a-web-app"], [57, "building-and-deploying-a-web-app"], [58, "building-and-deploying-a-web-app"], [80, "building-and-deploying-a-web-app"]], "Building decision trees with sklearn": [[14, "building-decision-trees-with-sklearn"], [60, "building-decision-trees-with-sklearn"]], "Building user profiles": [[30, "building-user-profiles"], [50, "building-user-profiles"], [74, "building-user-profiles"]], "CPSC 330 Documents": [[3, null]], "CPSC 330 Python notes": [[9, null]], "CPSC 330 grading policies": [[7, null]], "CPSC 330 vs. 340": [[13, "cpsc-330-vs-340"]], "CPSC 330 vs. CPSC 340": [[2, null]], "Can I attend lectures from a different section?": [[5, "can-i-attend-lectures-from-a-different-section"]], "Can I audit the class?": [[5, "can-i-audit-the-class"]], "Can I use generative AI in this course?": [[5, "can-i-use-generative-ai-in-this-course"]], "Can we learn without targets?": [[28, "can-we-learn-without-targets"], [72, "can-we-learn-without-targets"]], "Can we use this feature in the model?": [[18, "can-we-use-this-feature-in-the-model"], [63, "can-we-use-this-feature-in-the-model"]], "Cases where it\u2019s OK to break the golden rule": [[19, "cases-where-it-s-ok-to-break-the-golden-rule"], [64, "cases-where-it-s-ok-to-break-the-golden-rule"]], "CatBoost": [[25, "catboost"], [45, "catboost"], [69, "catboost"]], "Categorical features": [[17, "categorical-features"], [26, "categorical-features"], [40, "categorical-features"], [46, "categorical-features"], [70, "categorical-features"]], "Categorical features [video]": [[18, "categorical-features-video"], [63, "categorical-features-video"]], "Categorical features with only two possible categories": [[19, "categorical-features-with-only-two-possible-categories"], [64, "categorical-features-with-only-two-possible-categories"]], "Censoring and survival analysis": [[34, "censoring-and-survival-analysis"], [78, "censoring-and-survival-analysis"]], "Centre for Accessibility (CfA) Exam Accommodations": [[99, "centre-for-accessibility-cfa-exam-accommodations"]], "Changing the training procedure": [[67, "changing-the-training-procedure"]], "Characters in this course?": [[13, "characters-in-this-course"], [59, "characters-in-this-course"]], "Checklist for you before next class": [[13, "checklist-for-you-before-next-class"]], "Choosing K [video]": [[28, "choosing-k-video"], [72, "choosing-k-video"]], "Choosing n_neighbors": [[16, "choosing-n-neighbors"], [62, "choosing-n-neighbors"]], "Citing sources": [[8, "citing-sources"]], "Class imbalance in training sets": [[67, "class-imbalance-in-training-sets"]], "Class meetings": [[99, "class-meetings"]], "Classification report": [[23, "classification-report"], [43, "classification-report"]], "Classification vs. Regression": [[14, "classification-vs-regression"], [60, "classification-vs-regression"]], "Classification with KNeighborsClassifier": [[39, "classification-with-kneighborsclassifier"]], "Clustering": [[85, "clustering"]], "Clustering Activity (~5 mins)": [[28, "clustering-activity-5-mins"], [72, "clustering-activity-5-mins"]], "Clustering motivation [video]": [[28, "clustering-motivation-video"], [72, "clustering-motivation-video"]], "Clustering with K-Means": [[90, "clustering-with-k-means"], [96, "clustering-with-k-means"]], "Clustering: Input and (possible) output": [[28, "clustering-input-and-possible-output"], [72, "clustering-input-and-possible-output"]], "Code of conduct": [[99, "code-of-conduct"]], "Coefficients and intercept": [[21, "coefficients-and-intercept"], [65, "coefficients-and-intercept"]], "ColumnTransformer example": [[19, "columntransformer-example"], [64, "columntransformer-example"]], "ColumnTransformer on the California housing dataset": [[64, "columntransformer-on-the-california-housing-dataset"], [88, "columntransformer-on-the-california-housing-dataset"], [94, "columntransformer-on-the-california-housing-dataset"]], "ColumnTransformer: Transformed data": [[19, "columntransformer-transformed-data"], [64, "columntransformer-transformed-data"]], "Coming up \u2026": [[15, "coming-up"], [61, "coming-up"]], "Coming up:": [[16, "coming-up"], [62, "coming-up"]], "Common applications": [[28, "common-applications"], [72, "common-applications"]], "Common architectures": [[31, "common-architectures"], [51, "common-architectures"], [75, "common-architectures"]], "Common preprocessing techniques": [[18, "common-preprocessing-techniques"], [63, "common-preprocessing-techniques"]], "Communication": [[85, "communication"]], "Communications": [[13, "communications"]], "Completing the utility matrix with content-based filtering": [[30, "completing-the-utility-matrix-with-content-based-filtering"], [50, "completing-the-utility-matrix-with-content-based-filtering"], [74, "completing-the-utility-matrix-with-content-based-filtering"]], "Components of a linear classifier": [[21, "components-of-a-linear-classifier"], [65, "components-of-a-linear-classifier"]], "Concepts then labels, not the other way around": [[35, "concepts-then-labels-not-the-other-way-around"], [56, "concepts-then-labels-not-the-other-way-around"], [79, "concepts-then-labels-not-the-other-way-around"]], "Concepts we revised in this demo": [[38, "concepts-we-revised-in-this-demo"]], "Conclusion & farewell": [[36, "conclusion-farewell"], [80, "conclusion-farewell"]], "Confidence and predict_proba (20 min)": [[35, "confidence-and-predict-proba-20-min"], [56, "confidence-and-predict-proba-20-min"], [79, "confidence-and-predict-proba-20-min"]], "Confusing and perhaps misleading visualization of results": [[35, "confusing-and-perhaps-misleading-visualization-of-results"], [55, "confusing-and-perhaps-misleading-visualization-of-results"], [56, "confusing-and-perhaps-misleading-visualization-of-results"], [79, "confusing-and-perhaps-misleading-visualization-of-results"]], "Confusion matrix": [[23, "confusion-matrix"], [43, "confusion-matrix"]], "Confusion matrix and related metrics": [[67, "confusion-matrix-and-related-metrics"]], "Confusion matrix with cross-validation": [[23, "confusion-matrix-with-cross-validation"], [43, "confusion-matrix-with-cross-validation"], [67, "confusion-matrix-with-cross-validation"]], "Cons of k-NNs for supervised learning": [[16, "cons-of-k-nns-for-supervised-learning"], [62, "cons-of-k-nns-for-supervised-learning"]], "Content-based filtering": [[30, "content-based-filtering"], [50, "content-based-filtering"], [74, "content-based-filtering"]], "Convenient make_column_transformer syntax": [[19, "convenient-make-column-transformer-syntax"], [64, "convenient-make-column-transformer-syntax"]], "Convolutional Neural Networks (CNNs) (high level)": [[32, "convolutional-neural-networks-cnns-high-level"], [76, "convolutional-neural-networks-cnns-high-level"]], "Course Learning Objectives": [[12, null]], "Course co-ordinator": [[1, "course-co-ordinator"], [99, "course-co-ordinator"]], "Course description": [[99, "course-description"]], "Course format": [[13, "course-format"]], "Course review / conclusion (~20 min)": [[36, "course-review-conclusion-20-min"], [80, "course-review-conclusion-20-min"]], "Course website": [[13, "course-website"]], "Cox proportional hazards model": [[34, "cox-proportional-hazards-model"], [54, "cox-proportional-hazards-model"], [78, "cox-proportional-hazards-model"]], "Create X and y": [[14, "create-x-and-y"], [60, "create-x-and-y"]], "Create a classifier object": [[14, "create-a-classifier-object"], [60, "create-a-classifier-object"]], "Create a column transformer": [[19, "create-a-column-transformer"], [64, "create-a-column-transformer"]], "Creating train_df and test_df": [[61, "creating-train-df-and-test-df"]], "Creating utility matrix": [[30, "creating-utility-matrix"], [50, "creating-utility-matrix"], [74, "creating-utility-matrix"]], "Credit": [[11, "credit"]], "Cross validation with different metrics": [[23, "cross-validation-with-different-metrics"], [43, "cross-validation-with-different-metrics"]], "Cross-validation": [[33, "cross-validation"], [38, "cross-validation"], [53, "cross-validation"], [77, "cross-validation"], [77, "id4"]], "Cross-validation [video]": [[15, "cross-validation-video"], [61, "cross-validation-video"]], "Cross-validation to the rescue!!": [[15, "cross-validation-to-the-rescue"], [61, "cross-validation-to-the-rescue"]], "Cross-validation using scikit-learn": [[61, "cross-validation-using-scikit-learn"]], "Cross-validation using scikit-learn on housing data": [[15, "cross-validation-using-scikit-learn-on-housing-data"]], "Curse of dimensionality": [[16, "curse-of-dimensionality"], [62, "curse-of-dimensionality"]], "Customer churn": [[34, "customer-churn"], [78, "customer-churn"]], "Customer segmentation": [[28, "customer-segmentation"], [72, "customer-segmentation"]], "DBSCAN": [[49, "dbscan"]], "DBSCAN [video]": [[29, "dbscan-video"], [73, "dbscan-video"]], "DBSCAN introduction": [[29, "dbscan-introduction"], [73, "dbscan-introduction"]], "DBSCAN: failure cases": [[29, "dbscan-failure-cases"], [29, "id1"], [73, "dbscan-failure-cases"], [73, "id1"]], "Data": [[19, "data"], [21, "data"], [25, "data"], [26, "data"], [26, "id1"], [45, "data"], [46, "data"], [46, "id1"], [54, "data"], [64, "data"], [65, "data"], [69, "data"], [70, "data"], [70, "id1"], [81, "data"]], "Data Splitting [video]": [[15, "data-splitting-video"], [61, "data-splitting-video"]], "Data and main approaches": [[30, "data-and-main-approaches"], [74, "data-and-main-approaches"]], "Data and splitting": [[17, "data-and-splitting"], [40, "data-and-splitting"]], "Data exploration": [[28, "data-exploration"], [72, "data-exploration"]], "Data splitting": [[38, "data-splitting"], [87, "data-splitting"], [93, "data-splitting"]], "Dataframe summaries": [[9, "dataframe-summaries"]], "Dataset": [[32, "dataset"], [35, "dataset"], [55, "dataset"], [56, "dataset"], [76, "dataset"], [79, "dataset"]], "Dataset [video]": [[24, "dataset-video"], [44, "dataset-video"], [68, "dataset-video"]], "Dataset for demonstration": [[23, "dataset-for-demonstration"], [43, "dataset-for-demonstration"], [67, "dataset-for-demonstration"]], "Dataset, splitting, and baseline": [[18, "dataset-splitting-and-baseline"], [63, "dataset-splitting-and-baseline"]], "Datasets": [[8, "datasets"]], "Dealing with class imbalance [video]": [[67, "dealing-with-class-imbalance-video"]], "Dealing with unknown categories": [[19, "dealing-with-unknown-categories"], [64, "dealing-with-unknown-categories"]], "Decision boundaries playground": [[39, "decision-boundaries-playground"]], "Decision boundary": [[14, "decision-boundary"], [60, "decision-boundary"]], "Decision boundary for max_depth=1": [[14, "decision-boundary-for-max-depth-1"], [60, "decision-boundary-for-max-depth-1"]], "Decision boundary for max_depth=2": [[14, "decision-boundary-for-max-depth-2"], [60, "decision-boundary-for-max-depth-2"]], "Decision boundary for max_depth=5": [[14, "decision-boundary-for-max-depth-5"], [60, "decision-boundary-for-max-depth-5"]], "Decision boundary of SVMs": [[16, "decision-boundary-of-svms"], [62, "decision-boundary-of-svms"]], "Decision boundary of logistic regression": [[21, "decision-boundary-of-logistic-regression"], [65, "decision-boundary-of-logistic-regression"]], "Decision tree algorithm": [[14, "decision-tree-algorithm"], [60, "decision-tree-algorithm"]], "Decision tree feature importances": [[26, "decision-tree-feature-importances"], [46, "decision-tree-feature-importances"], [70, "decision-tree-feature-importances"]], "Decision tree for regression problems": [[14, "decision-tree-for-regression-problems"], [60, "decision-tree-for-regression-problems"]], "Decision tree model": [[15, "decision-tree-model"], [38, "decision-tree-model"]], "Decision tree with max_depth=1": [[14, "decision-tree-with-max-depth-1"], [60, "decision-tree-with-max-depth-1"]], "Decision tree with max_depth=3": [[14, "decision-tree-with-max-depth-3"], [60, "decision-tree-with-max-depth-3"]], "Decision trees [video]": [[14, "decision-trees-video"], [60, "decision-trees-video"]], "Decision trees with continuous features": [[14, "decision-trees-with-continuous-features"], [60, "decision-trees-with-continuous-features"]], "DecisionTreeClassifier baseline": [[25, "decisiontreeclassifier-baseline"], [45, "decisiontreeclassifier-baseline"], [69, "decisiontreeclassifier-baseline"]], "DecisionTreeClassifier on quiz2 grade prediction toy dataset": [[14, "decisiontreeclassifier-on-quiz2-grade-prediction-toy-dataset"], [60, "decisiontreeclassifier-on-quiz2-grade-prediction-toy-dataset"]], "Decisions involve a few key pieces": [[56, "decisions-involve-a-few-key-pieces"], [79, "decisions-involve-a-few-key-pieces"]], "Decreasing the threshold": [[23, "decreasing-the-threshold"], [43, "decreasing-the-threshold"], [67, "decreasing-the-threshold"]], "Deep learning": [[33, "deep-learning"], [53, "deep-learning"], [77, "deep-learning"]], "Deep learning software": [[32, "deep-learning-software"], [76, "deep-learning-software"]], "Deliverable due dates (tentative)": [[1, "deliverable-due-dates-tentative"]], "Demo": [[15, "demo"]], "Demo of creating a new web service": [[36, "demo-of-creating-a-new-web-service"], [57, "demo-of-creating-a-new-web-service"], [58, "demo-of-creating-a-new-web-service"], [80, "demo-of-creating-a-new-web-service"]], "Demo of feature engineering with numeric features": [[27, "demo-of-feature-engineering-with-numeric-features"], [47, "demo-of-feature-engineering-with-numeric-features"], [71, "demo-of-feature-engineering-with-numeric-features"]], "Demo: A more complicated dataset": [[53, "demo-a-more-complicated-dataset"], [77, "demo-a-more-complicated-dataset"]], "Demo: Deploying moment classification model": [[36, "demo-deploying-moment-classification-model"], [57, "demo-deploying-moment-classification-model"], [58, "demo-deploying-moment-classification-model"], [80, "demo-deploying-moment-classification-model"]], "Demo: Model interpretation of linear classifiers": [[20, "demo-model-interpretation-of-linear-classifiers"], [41, "demo-model-interpretation-of-linear-classifiers"]], "Dendrogram": [[29, "dendrogram"], [73, "dendrogram"]], "Deploying the API on a server (not covered)": [[36, "deploying-the-api-on-a-server-not-covered"], [57, "deploying-the-api-on-a-server-not-covered"], [58, "deploying-the-api-on-a-server-not-covered"], [80, "deploying-the-api-on-a-server-not-covered"]], "Deployment (Not examinable)": [[85, "deployment-not-examinable"]], "Difference between Statistics and Machine Learning": [[36, "difference-between-statistics-and-machine-learning"], [80, "difference-between-statistics-and-machine-learning"]], "Different models": [[26, "different-models"], [46, "different-models"], [70, "different-models"]], "Different range for hyperparameters yields better results!": [[22, "different-range-for-hyperparameters-yields-better-results"], [42, "different-range-for-hyperparameters-yields-better-results"], [66, "different-range-for-hyperparameters-yields-better-results"]], "Different scoring functions with cross_validate": [[24, "different-scoring-functions-with-cross-validate"], [44, "different-scoring-functions-with-cross-validate"], [68, "different-scoring-functions-with-cross-validate"]], "Dimensions in ML problems": [[16, "dimensions-in-ml-problems"], [62, "dimensions-in-ml-problems"]], "Discuss the following questions in your group": [[15, "discuss-the-following-questions-in-your-group"]], "Discussion": [[36, "discussion"], [57, "discussion"], [58, "discussion"], [80, "discussion"]], "Discussion question": [[31, "discussion-question"], [52, "discussion-question"], [75, "discussion-question"]], "Discussion questions": [[17, "discussion-questions"]], "Discussion questions:": [[35, "discussion-questions"], [56, "discussion-questions"], [79, "discussion-questions"]], "Distance between feature vectors": [[16, "distance-between-feature-vectors"], [62, "distance-between-feature-vectors"]], "Distributional hypothesis": [[31, "distributional-hypothesis"], [51, "distributional-hypothesis"], [75, "distributional-hypothesis"]], "Do we actually want to use certain features for prediction?": [[64, "do-we-actually-want-to-use-certain-features-for-prediction"]], "Do we have class imbalance?": [[25, "do-we-have-class-imbalance"], [26, "do-we-have-class-imbalance"], [45, "do-we-have-class-imbalance"], [46, "do-we-have-class-imbalance"], [69, "do-we-have-class-imbalance"], [70, "do-we-have-class-imbalance"]], "Do we have correlated features?": [[26, "do-we-have-correlated-features"], [46, "do-we-have-correlated-features"], [70, "do-we-have-correlated-features"]], "Document clustering": [[28, "document-clustering"], [72, "document-clustering"]], "Domain-specific transformations": [[27, "domain-specific-transformations"], [71, "domain-specific-transformations"]], "Dummy Classifier": [[17, "dummy-classifier"], [40, "dummy-classifier"]], "Dummy model": [[39, "dummy-model"]], "DummyClassifier": [[14, "dummyclassifier"], [34, "dummyclassifier"], [53, "dummyclassifier"], [60, "dummyclassifier"], [77, "dummyclassifier"], [78, "dummyclassifier"]], "DummyClassifier baseline": [[25, "dummyclassifier-baseline"], [45, "dummyclassifier-baseline"], [69, "dummyclassifier-baseline"]], "DummyClassifier on quiz2 grade prediction toy dataset": [[14, "dummyclassifier-on-quiz2-grade-prediction-toy-dataset"], [60, "dummyclassifier-on-quiz2-grade-prediction-toy-dataset"]], "DummyRegressor": [[14, "dummyregressor"], [24, "dummyregressor"], [44, "dummyregressor"], [60, "dummyregressor"], [68, "dummyregressor"]], "EDA": [[18, "eda"], [23, "eda"], [24, "eda"], [43, "eda"], [44, "eda"], [63, "eda"], [67, "eda"], [68, "eda"], [90, "eda"], [96, "eda"]], "EDA: Exploratory Data Analysis": [[87, "eda-exploratory-data-analysis"], [93, "eda-exploratory-data-analysis"]], "Encoding text data": [[19, "encoding-text-data"], [64, "encoding-text-data"]], "Encoding time as a number": [[53, "encoding-time-as-a-number"], [77, "encoding-time-as-a-number"]], "Encoding time of day as a categorical feature": [[33, "encoding-time-of-day-as-a-categorical-feature"], [77, "encoding-time-of-day-as-a-categorical-feature"]], "Ensemble models": [[25, "ensemble-models"]], "Ensembles": [[85, "ensembles"]], "Equally good": [[35, "equally-good"], [55, "equally-good"], [56, "equally-good"], [79, "equally-good"]], "Errors when creating course environment": [[11, "errors-when-creating-course-environment"]], "Ethics": [[85, "ethics"]], "Euclidean distance": [[16, "euclidean-distance"], [62, "euclidean-distance"]], "Evaluating DBSCAN clusters": [[29, "evaluating-dbscan-clusters"], [73, "evaluating-dbscan-clusters"]], "Evaluation": [[30, "evaluation"], [30, "id2"], [50, "evaluation"], [50, "id3"], [74, "evaluation"], [74, "id4"]], "Evaluation metrics": [[85, "evaluation-metrics"]], "Evaluation metrics for binary classification: Motivation": [[23, "evaluation-metrics-for-binary-classification-motivation"], [43, "evaluation-metrics-for-binary-classification-motivation"], [67, "evaluation-metrics-for-binary-classification-motivation"]], "Evaluation metrics for multi-class classification": [[81, "evaluation-metrics-for-multi-class-classification"]], "Evalution metrics overview": [[43, "evalution-metrics-overview"]], "Examining learned coefficients": [[20, "examining-learned-coefficients"], [41, "examining-learned-coefficients"]], "Examining the preprocessed data": [[24, "examining-the-preprocessed-data"], [35, "examining-the-preprocessed-data"], [44, "examining-the-preprocessed-data"], [55, "examining-the-preprocessed-data"], [56, "examining-the-preprocessed-data"], [68, "examining-the-preprocessed-data"], [79, "examining-the-preprocessed-data"]], "Examining the vocabulary": [[20, "examining-the-vocabulary"], [41, "examining-the-vocabulary"]], "Example": [[21, "example"], [25, "example"], [45, "example"], [65, "example"], [69, "example"]], "Example 1": [[35, "example-1"]], "Example 1: Predicting whether a patient has a liver disease or not": [[13, "example-1-predicting-whether-a-patient-has-a-liver-disease-or-not"], [59, "example-1-predicting-whether-a-patient-has-a-liver-disease-or-not"]], "Example 1: What is \u201ccorrect\u201d grouping?": [[28, "example-1-what-is-correct-grouping"], [72, "example-1-what-is-correct-grouping"]], "Example 1: quiz 2 grade prediction": [[14, "example-1-quiz-2-grade-prediction"], [60, "example-1-quiz-2-grade-prediction"]], "Example 2": [[35, "example-2"]], "Example 2: Predicting country using the longitude and latitude": [[60, "example-2-predicting-country-using-the-longitude-and-latitude"]], "Example 2: Predicting the label of a given image": [[13, "example-2-predicting-the-label-of-a-given-image"], [59, "example-2-predicting-the-label-of-a-given-image"]], "Example 3": [[35, "example-3"]], "Example 3: Predicting sentiment expressed in a movie review": [[13, "example-3-predicting-sentiment-expressed-in-a-movie-review"], [59, "example-3-predicting-sentiment-expressed-in-a-movie-review"]], "Example 4: Predicting housing prices": [[13, "example-4-predicting-housing-prices"], [59, "example-4-predicting-housing-prices"]], "Example showing how can we interpret coefficients of scaled features.": [[26, "example-showing-how-can-we-interpret-coefficients-of-scaled-features"], [46, "example-showing-how-can-we-interpret-coefficients-of-scaled-features"], [70, "example-showing-how-can-we-interpret-coefficients-of-scaled-features"]], "Example: Is \u201cRelevance\u201d clearly defined?": [[27, "example-is-relevance-clearly-defined"], [82, "example-is-relevance-clearly-defined"]], "Example: Predict whether a message is spam or not": [[13, "example-predict-whether-a-message-is-spam-or-not"], [59, "example-predict-whether-a-message-is-spam-or-not"]], "Example: Sentiment analysis using a pretrained model": [[31, "example-sentiment-analysis-using-a-pretrained-model"], [51, "example-sentiment-analysis-using-a-pretrained-model"], [75, "example-sentiment-analysis-using-a-pretrained-model"]], "Example: Supervised vs unsupervised learning": [[28, "example-supervised-vs-unsupervised-learning"], [72, "example-supervised-vs-unsupervised-learning"]], "Example: Tabular data for grade prediction": [[14, "example-tabular-data-for-grade-prediction"], [60, "example-tabular-data-for-grade-prediction"]], "Example: Tabular data for the housing price prediction": [[60, "example-tabular-data-for-the-housing-price-prediction"]], "Example: class_weight parameter of sklearn LogisticRegression": [[67, "example-class-weight-parameter-of-sklearn-logisticregression"]], "Example: k-nearest neighbours on the Spotify dataset": [[18, "example-k-nearest-neighbours-on-the-spotify-dataset"], [63, "example-k-nearest-neighbours-on-the-spotify-dataset"]], "Examples": [[13, "examples"], [59, "examples"]], "Exercise - Features and targets": [[14, "exercise-features-and-targets"]], "Exercise 17.1 Select all of the following statements which are True (iClicker)": [[30, "exercise-17-1-select-all-of-the-following-statements-which-are-true-iclicker"]], "Exercise 17.2 Select all of the following statements which are True (iClicker)": [[30, "exercise-17-2-select-all-of-the-following-statements-which-are-true-iclicker"]], "Exercise 2.1 Select all of the following statements which are examples of supervised machine learning": [[60, "exercise-2-1-select-all-of-the-following-statements-which-are-examples-of-supervised-machine-learning"]], "Exercise 2.4": [[60, "exercise-2-4"]], "Exercise 8.2": [[22, "exercise-8-2"], [66, "exercise-8-2"]], "Exercise: Predicting country using the longitude and latitude": [[86, "exercise-predicting-country-using-the-longitude-and-latitude"], [92, "exercise-predicting-country-using-the-longitude-and-latitude"]], "Exhaustive grid search: sklearn.model_selection.GridSearchCV": [[22, "exhaustive-grid-search-sklearn-model-selection-gridsearchcv"], [42, "exhaustive-grid-search-sklearn-model-selection-gridsearchcv"], [66, "exhaustive-grid-search-sklearn-model-selection-gridsearchcv"]], "Explaining a prediction": [[26, "explaining-a-prediction"], [46, "explaining-a-prediction"], [70, "explaining-a-prediction"]], "Explanation 1": [[35, "explanation-1"], [56, "explanation-1"], [79, "explanation-1"]], "Explanation 2": [[35, "explanation-2"], [56, "explanation-2"], [79, "explanation-2"]], "Exploratory Data Analysis": [[15, "exploratory-data-analysis"], [38, "exploratory-data-analysis"]], "Exploratory data analysis": [[17, "exploratory-data-analysis"], [40, "exploratory-data-analysis"], [53, "exploratory-data-analysis"], [77, "exploratory-data-analysis"], [91, "exploratory-data-analysis"], [97, "exploratory-data-analysis"]], "Extracting BOW features using scikit-learn": [[19, "extracting-bow-features-using-scikit-learn"], [64, "extracting-bow-features-using-scikit-learn"]], "Extracting date and time information": [[33, "extracting-date-and-time-information"], [77, "extracting-date-and-time-information"]], "F1-score": [[23, "f1-score"], [43, "f1-score"]], "Faster method: vectorize the loop over rows": [[9, "faster-method-vectorize-the-loop-over-rows"]], "Fastest method: broadcasting": [[9, "fastest-method-broadcasting"]], "Feature crosses for one-hot encoded features": [[27, "feature-crosses-for-one-hot-encoded-features"], [47, "feature-crosses-for-one-hot-encoded-features"], [71, "feature-crosses-for-one-hot-encoded-features"]], "Feature engineering": [[33, "feature-engineering"], [53, "feature-engineering"], [77, "feature-engineering"]], "Feature engineering and selection": [[85, "feature-engineering-and-selection"]], "Feature engineering for date/time columns": [[33, "feature-engineering-for-date-time-columns"], [77, "feature-engineering-for-date-time-columns"]], "Feature engineering: Encoding date/time as feature(s)": [[53, "feature-engineering-encoding-date-time-as-feature-s"], [77, "feature-engineering-encoding-date-time-as-feature-s"]], "Feature engineering: Motivation": [[27, "feature-engineering-motivation"], [71, "feature-engineering-motivation"]], "Feature importances": [[26, "feature-importances"], [46, "feature-importances"], [70, "feature-importances"], [85, "feature-importances"]], "Feature importances in linear models": [[26, "feature-importances-in-linear-models"], [26, "id2"], [46, "feature-importances-in-linear-models"], [46, "id2"], [70, "feature-importances-in-linear-models"], [70, "id2"]], "Feature interactions and feature crosses": [[27, "feature-interactions-and-feature-crosses"], [47, "feature-interactions-and-feature-crosses"], [71, "feature-interactions-and-feature-crosses"]], "Feature names of transformed data": [[24, "feature-names-of-transformed-data"], [44, "feature-names-of-transformed-data"], [68, "feature-names-of-transformed-data"]], "Feature selection: Introduction and motivation": [[27, "feature-selection-introduction-and-motivation"], [47, "feature-selection-introduction-and-motivation"], [71, "feature-selection-introduction-and-motivation"]], "Feature transformations and the golden rule": [[18, "feature-transformations-and-the-golden-rule"], [63, "feature-transformations-and-the-golden-rule"]], "Feature types": [[24, "feature-types"], [24, "id1"], [35, "feature-types"], [44, "feature-types"], [44, "id1"], [55, "feature-types"], [56, "feature-types"], [68, "feature-types"], [68, "id1"], [79, "feature-types"]], "Feature vectors": [[62, "feature-vectors"]], "Figures": [[8, "figures"]], "Filtering a dataframe with [] and df.query()": [[9, "filtering-a-dataframe-with-and-df-query"]], "Final comments and summary": [[22, "final-comments-and-summary"], [30, "final-comments-and-summary"], [50, "final-comments-and-summary"], [66, "final-comments-and-summary"], [74, "final-comments-and-summary"]], "Final comments, summary, and reflection": [[14, "final-comments-summary-and-reflection"], [28, "final-comments-summary-and-reflection"], [29, "final-comments-summary-and-reflection"], [60, "final-comments-summary-and-reflection"], [72, "final-comments-summary-and-reflection"], [73, "final-comments-summary-and-reflection"]], "Final exam": [[99, "final-exam"]], "Final exam preparation: guiding questions": [[85, null]], "Final note": [[87, "final-note"], [93, "final-note"]], "Final remarks": [[33, "final-remarks"], [53, "final-remarks"], [77, "final-remarks"]], "Finding the distances to a query point": [[16, "finding-the-distances-to-a-query-point"], [62, "finding-the-distances-to-a-query-point"]], "Finding the nearest neighbour": [[16, "finding-the-nearest-neighbour"], [62, "finding-the-nearest-neighbour"]], "First deliverables": [[13, "first-deliverables"]], "Forecasting further into the future": [[33, "forecasting-further-into-the-future"], [77, "forecasting-further-into-the-future"]], "Forecasting further into the future on a retail dataset": [[33, "forecasting-further-into-the-future-on-a-retail-dataset"], [77, "forecasting-further-into-the-future-on-a-retail-dataset"]], "Formulating the problem of recommender systems": [[30, "formulating-the-problem-of-recommender-systems"], [50, "formulating-the-problem-of-recommender-systems"], [74, "formulating-the-problem-of-recommender-systems"]], "Frequently Asked Questions": [[5, null]], "From Markov models to meaning": [[31, "from-markov-models-to-meaning"], [51, "from-markov-models-to-meaning"], [75, "from-markov-models-to-meaning"]], "From word prediction to transformers": [[31, "from-word-prediction-to-transformers"], [51, "from-word-prediction-to-transformers"], [75, "from-word-prediction-to-transformers"]], "GB better than RF": [[35, "gb-better-than-rf"], [55, "gb-better-than-rf"], [56, "gb-better-than-rf"], [79, "gb-better-than-rf"]], "Garbage in, garbage out.": [[27, "garbage-in-garbage-out"], [71, "garbage-in-garbage-out"]], "Gaussian distribution": [[42, "gaussian-distribution"], [66, "gaussian-distribution"]], "General advice on finding relevant features": [[27, "general-advice-on-finding-relevant-features"], [71, "general-advice-on-finding-relevant-features"]], "General guidelines": [[7, "general-guidelines"]], "General idea": [[25, "general-idea"], [45, "general-idea"], [69, "general-idea"]], "General idea of k-nearest neighbours algorithm": [[16, "general-idea-of-k-nearest-neighbours-algorithm"], [62, "general-idea-of-k-nearest-neighbours-algorithm"]], "General idea of search and score methods": [[27, "general-idea-of-search-and-score-methods"], [82, "general-idea-of-search-and-score-methods"]], "General questions": [[4, "general-questions"]], "Generalization [video]": [[15, "generalization-video"], [61, "generalization-video"]], "Generalization: Fundamental goal of ML": [[15, "generalization-fundamental-goal-of-ml"], [61, "generalization-fundamental-goal-of-ml"]], "Generalizing to more features": [[21, "generalizing-to-more-features"], [65, "generalizing-to-more-features"]], "Generalizing to unseen data": [[61, "generalizing-to-unseen-data"]], "Geometric view of tabular data and dimensions": [[16, "geometric-view-of-tabular-data-and-dimensions"], [62, "geometric-view-of-tabular-data-and-dimensions"]], "Git and GitHub: Getting Started": [[6, null]], "Global average baseline": [[30, "global-average-baseline"], [50, "global-average-baseline"], [74, "global-average-baseline"]], "Golden rule violation: Example 1": [[61, "golden-rule-violation-example-1"]], "Golden rule violation: Example 2": [[61, "golden-rule-violation-example-2"]], "Grades": [[13, "grades"]], "Gradient boosted trees [video]": [[25, "gradient-boosted-trees-video"], [45, "gradient-boosted-trees-video"], [69, "gradient-boosted-trees-video"]], "Gradient boosting in sklearn": [[25, "gradient-boosting-in-sklearn"], [45, "gradient-boosting-in-sklearn"], [69, "gradient-boosting-in-sklearn"]], "Grading concerns: time limit": [[7, "grading-concerns-time-limit"]], "Grading scheme": [[99, "grading-scheme"]], "Grading-related questions": [[4, "grading-related-questions"]], "Handling class imbalance by changing the data": [[81, "handling-class-imbalance-by-changing-the-data"]], "Handling imbalance": [[67, "handling-imbalance"]], "Here is the workflow we\u2019ll generally follow.": [[15, "here-is-the-workflow-we-ll-generally-follow"], [61, "here-is-the-workflow-we-ll-generally-follow"]], "Hierarchical clustering": [[49, "hierarchical-clustering"]], "Hierarchical clustering [video]": [[29, "hierarchical-clustering-video"], [73, "hierarchical-clustering-video"]], "Homework info & submission guidelines": [[8, null]], "How are we making predictions?": [[21, "how-are-we-making-predictions"], [65, "how-are-we-making-predictions"]], "How can we avoid violating golden rule?": [[15, "how-can-we-avoid-violating-golden-rule"], [61, "how-can-we-avoid-violating-golden-rule"]], "How can we get feature importances for non sklearn models?": [[46, "how-can-we-get-feature-importances-for-non-sklearn-models"], [70, "how-can-we-get-feature-importances-for-non-sklearn-models"]], "How do I submit homework assignments?": [[5, "how-do-i-submit-homework-assignments"]], "How do they work?": [[25, "how-do-they-work"], [45, "how-do-they-work"], [69, "how-do-they-work"]], "How do we carry out feature selection?": [[27, "how-do-we-carry-out-feature-selection"], [47, "how-do-we-carry-out-feature-selection"], [71, "how-do-we-carry-out-feature-selection"]], "How does fit work?": [[14, "how-does-fit-work"], [60, "how-does-fit-work"], [60, "id2"]], "How does it work?": [[29, "how-does-it-work"], [35, "how-does-it-work"], [56, "how-does-it-work"], [73, "how-does-it-work"], [79, "how-does-it-work"]], "How does logistic regression calculate these probabilities?": [[21, "how-does-logistic-regression-calculate-these-probabilities"], [65, "how-does-logistic-regression-calculate-these-probabilities"]], "How does predict work?": [[14, "how-does-predict-work"], [60, "how-does-predict-work"]], "How does this course overlap with CPSC 340?": [[5, "how-does-this-course-overlap-with-cpsc-340"]], "How to approximate generalization error?": [[15, "how-to-approximate-generalization-error"], [61, "how-to-approximate-generalization-error"]], "How to ask for help": [[4, null]], "How to carry out cross-validation?": [[18, "how-to-carry-out-cross-validation"], [63, "how-to-carry-out-cross-validation"]], "How to choose n_neighbors?": [[16, "how-to-choose-n-neighbors"], [62, "how-to-choose-n-neighbors"]], "How to do it properly? Enter sklearn pipelines!!": [[17, "how-to-do-it-properly-enter-sklearn-pipelines"]], "How to pick a model that would generalize better?": [[15, "how-to-pick-a-model-that-would-generalize-better"], [61, "how-to-pick-a-model-that-would-generalize-better"]], "How to submit": [[8, "how-to-submit"]], "How would you do it properly? Enter sklearn pipelines!!": [[40, "how-would-you-do-it-properly-enter-sklearn-pipelines"]], "Hyperparameter alpha of Ridge": [[21, "hyperparameter-alpha-of-ridge"], [65, "hyperparameter-alpha-of-ridge"]], "Hyperparameter optimization": [[15, "hyperparameter-optimization"], [38, "hyperparameter-optimization"], [85, "hyperparameter-optimization"]], "Hyperparameter optimization motivation": [[66, "hyperparameter-optimization-motivation"]], "Hyperparameter optimization motivation (video)": [[22, "hyperparameter-optimization-motivation-video"]], "Hyperparameter tuning for the number of clusters": [[28, "hyperparameter-tuning-for-the-number-of-clusters"], [72, "hyperparameter-tuning-for-the-number-of-clusters"]], "Hyperparameters of SVM": [[16, "hyperparameters-of-svm"], [62, "hyperparameters-of-svm"]], "Hyperparameters: the problem": [[22, "hyperparameters-the-problem"], [66, "hyperparameters-the-problem"]], "Identify the transformations we want to apply": [[19, "identify-the-transformations-we-want-to-apply"], [64, "identify-the-transformations-we-want-to-apply"]], "Image classification using KNNs and SVM RBF": [[39, "image-classification-using-knns-and-svm-rbf"]], "Importance of scaling": [[21, "importance-of-scaling"], [65, "importance-of-scaling"]], "Important hyperparameters": [[25, "important-hyperparameters"], [45, "important-hyperparameters"], [69, "important-hyperparameters"]], "Important hyperparameters of CountVectorizer": [[19, "important-hyperparameters-of-countvectorizer"], [64, "important-hyperparameters-of-countvectorizer"]], "Important links": [[1, "important-links"]], "Important points to remember": [[28, "important-points-to-remember"], [72, "important-points-to-remember"]], "Imports": [[13, "imports"], [14, "imports"], [15, "imports"], [16, "imports"], [17, "imports"], [18, "imports"], [19, "imports"], [21, "imports"], [22, "imports"], [23, "imports"], [24, "imports"], [25, "imports"], [26, "imports"], [27, "imports"], [28, "imports"], [29, "imports"], [30, "imports"], [31, "imports"], [32, "imports"], [33, "imports"], [34, "imports"], [35, "imports"], [36, "imports"], [38, "imports"], [39, "imports"], [40, "imports"], [41, "imports"], [42, "imports"], [43, "imports"], [44, "imports"], [45, "imports"], [46, "imports"], [47, "imports"], [50, "imports"], [51, "imports"], [52, "imports"], [53, "imports"], [54, "imports"], [55, "imports"], [56, "imports"], [57, "imports"], [58, "imports"], [59, "imports"], [60, "imports"], [61, "imports"], [62, "imports"], [63, "imports"], [64, "imports"], [65, "imports"], [66, "imports"], [67, "imports"], [68, "imports"], [69, "imports"], [70, "imports"], [71, "imports"], [72, "imports"], [73, "imports"], [74, "imports"], [75, "imports"], [76, "imports"], [77, "imports"], [78, "imports"], [79, "imports"], [80, "imports"], [85, "imports"], [86, "imports"], [87, "imports"], [91, "imports"], [92, "imports"], [93, "imports"], [97, "imports"]], "Imports and LO": [[22, "imports-and-lo"], [24, "imports-and-lo"], [32, "imports-and-lo"], [33, "imports-and-lo"], [66, "imports-and-lo"], [68, "imports-and-lo"], [76, "imports-and-lo"], [77, "imports-and-lo"]], "Imports and LOs": [[36, "imports-and-los"], [67, "imports-and-los"], [80, "imports-and-los"]], "Imports and learning outcomes": [[28, "imports-and-learning-outcomes"], [72, "imports-and-learning-outcomes"]], "Imports, Announcements, LOs": [[60, "imports-announcements-los"]], "Imports, Announcements, and LO": [[19, "imports-announcements-and-lo"], [21, "imports-announcements-and-lo"], [64, "imports-announcements-and-lo"], [65, "imports-announcements-and-lo"]], "Imports, LOs": [[15, "imports-los"], [18, "imports-los"], [26, "imports-los"], [46, "imports-los"], [61, "imports-los"], [63, "imports-los"], [70, "imports-los"]], "Imports, announcements, LOs": [[25, "imports-announcements-los"], [69, "imports-announcements-los"]], "Imports, announcements, and LOs": [[16, "imports-announcements-and-los"], [62, "imports-announcements-and-los"]], "Imputation": [[18, "imputation"], [63, "imputation"]], "Imputation and scaling [video]": [[18, "imputation-and-scaling-video"], [63, "imputation-and-scaling-video"]], "Incorporating ordinal feature class_attendance": [[19, "incorporating-ordinal-feature-class-attendance"], [64, "incorporating-ordinal-feature-class-attendance"]], "Incorporating text features": [[17, "incorporating-text-features"], [40, "incorporating-text-features"]], "Increasing the threshold": [[23, "increasing-the-threshold"], [43, "increasing-the-threshold"], [67, "increasing-the-threshold"]], "Indexing Dataframes": [[9, "indexing-dataframes"]], "Indexing cheatsheet": [[9, "indexing-cheatsheet"]], "Inertia": [[28, "inertia"], [72, "inertia"]], "Initial analysis, EDA, preprocessing": [[36, "initial-analysis-eda-preprocessing"], [80, "initial-analysis-eda-preprocessing"]], "Initialization of K-Means": [[28, "initialization-of-k-means"], [72, "initialization-of-k-means"]], "Inject randomness in the classifier construction": [[25, "inject-randomness-in-the-classifier-construction"], [45, "inject-randomness-in-the-classifier-construction"], [69, "inject-randomness-in-the-classifier-construction"]], "Input data": [[13, "input-data"], [59, "input-data"]], "Input features X and target y": [[59, "input-features-x-and-target-y"]], "Input: features X and target y": [[13, "input-features-x-and-target-y"]], "Install VS Code": [[11, "install-vs-code"]], "Instructional Material": [[0, "instructional-material"]], "Instructors": [[1, "instructors"]], "Interesting to you != useful to the reader (aka it\u2019s not about you)": [[35, "interesting-to-you-useful-to-the-reader-aka-it-s-not-about-you"], [56, "interesting-to-you-useful-to-the-reader-aka-it-s-not-about-you"], [79, "interesting-to-you-useful-to-the-reader-aka-it-s-not-about-you"]], "Interim summary": [[23, "interim-summary"], [26, "interim-summary"], [27, "interim-summary"], [33, "interim-summary"], [43, "interim-summary"], [46, "interim-summary"], [47, "interim-summary"], [67, "interim-summary"], [70, "interim-summary"], [71, "interim-summary"], [77, "interim-summary"]], "Interpretation of coefficients": [[21, "interpretation-of-coefficients"], [65, "interpretation-of-coefficients"]], "Interpretation of coefficients in linear models": [[21, "interpretation-of-coefficients-in-linear-models"], [65, "interpretation-of-coefficients-in-linear-models"]], "Interpreting coefficients of numeric features": [[26, "interpreting-coefficients-of-numeric-features"], [46, "interpreting-coefficients-of-numeric-features"], [70, "interpreting-coefficients-of-numeric-features"]], "Introduction": [[29, "introduction"], [73, "introduction"], [85, "introduction"]], "Introduction to NLP": [[85, "introduction-to-nlp"]], "Introduction to computer vision": [[32, "introduction-to-computer-vision"], [76, "introduction-to-computer-vision"]], "Introduction to large language models": [[31, "introduction-to-large-language-models"], [51, "introduction-to-large-language-models"], [75, "introduction-to-large-language-models"]], "Introduction to neural networks": [[32, "introduction-to-neural-networks"], [76, "introduction-to-neural-networks"]], "Introduction to pandas": [[9, "introduction-to-pandas"]], "Introduction to unsupervised learning": [[28, "introduction-to-unsupervised-learning"], [72, "introduction-to-unsupervised-learning"]], "Intuition of regression trees": [[38, "intuition-of-regression-trees"]], "Is stratifying a good idea?": [[67, "is-stratifying-a-good-idea"]], "Is this a realistic representation of text data?": [[19, "is-this-a-realistic-representation-of-text-data"], [64, "is-this-a-realistic-representation-of-text-data"]], "Is this misleading?": [[35, "is-this-misleading"], [56, "is-this-misleading"], [79, "is-this-misleading"]], "Is \u201cRelevance\u201d clearly defined?": [[27, "is-relevance-clearly-defined"], [27, "id1"], [27, "id2"], [27, "id3"], [27, "id4"], [27, "id5"], [27, "id6"], [82, "is-relevance-clearly-defined"], [82, "id1"], [82, "id2"], [82, "id3"], [82, "id4"], [82, "id5"], [82, "id6"]], "I\u2019m on the waitlist. How likely am I to get into this course?": [[5, "i-m-on-the-waitlist-how-likely-am-i-to-get-into-this-course"]], "K-Means algorithm": [[28, "k-means-algorithm"], [72, "k-means-algorithm"]], "K-Means clustering [video]": [[28, "k-means-clustering-video"], [72, "k-means-clustering-video"]], "K-Means example": [[28, "k-means-example"], [72, "k-means-example"]], "K-Means limitations": [[29, "k-means-limitations"], [73, "k-means-limitations"]], "K-Means limitations: Shape of K-Means clusters": [[29, "k-means-limitations-shape-of-k-means-clusters"], [73, "k-means-limitations-shape-of-k-means-clusters"]], "K-Means recap": [[29, "k-means-recap"], [73, "k-means-recap"]], "K-Means: failure case 1": [[29, "k-means-failure-case-1"], [73, "k-means-failure-case-1"]], "K-Means: failure case 2": [[29, "k-means-failure-case-2"], [73, "k-means-failure-case-2"]], "K-Means: failure case 3": [[29, "k-means-failure-case-3"], [73, "k-means-failure-case-3"]], "Kaplan-Meier survival curve": [[34, "kaplan-meier-survival-curve"], [54, "kaplan-meier-survival-curve"], [78, "kaplan-meier-survival-curve"]], "Key point": [[26, "key-point"], [46, "key-point"], [70, "key-point"]], "LDA topics in social media": [[31, "lda-topics-in-social-media"], [51, "lda-topics-in-social-media"], [52, "lda-topics-in-social-media"], [75, "lda-topics-in-social-media"]], "LICENSE": [[0, null]], "Labeled vs. Unlabeled data": [[28, "labeled-vs-unlabeled-data"], [72, "labeled-vs-unlabeled-data"]], "Lag-based features": [[33, "lag-based-features"], [53, "lag-based-features"], [77, "lag-based-features"], [77, "id5"], [91, "lag-based-features"], [97, "lag-based-features"]], "Land acknowledgement": [[99, "land-acknowledgement"]], "Language model": [[31, "language-model"], [51, "language-model"], [75, "language-model"]], "Language models activity": [[31, "language-models-activity"], [51, "language-models-activity"], [75, "language-models-activity"]], "Large datasets solve many of these problems": [[22, "large-datasets-solve-many-of-these-problems"], [66, "large-datasets-solve-many-of-these-problems"]], "Late submissions": [[8, "late-submissions"]], "Learned coefficients associated with all features": [[21, "learned-coefficients-associated-with-all-features"], [65, "learned-coefficients-associated-with-all-features"]], "Learned model": [[38, "learned-model"]], "Learning git": [[6, "learning-git"]], "Learning objectives": [[31, "learning-objectives"], [32, "learning-objectives"], [33, "learning-objectives"], [34, "learning-objectives"], [35, "learning-objectives"], [36, "learning-objectives"], [75, "learning-objectives"], [76, "learning-objectives"], [77, "learning-objectives"], [78, "learning-objectives"], [79, "learning-objectives"], [80, "learning-objectives"]], "Learning outcomes": [[13, "learning-outcomes"], [14, "learning-outcomes"], [15, "learning-outcomes"], [16, "learning-outcomes"], [18, "learning-outcomes"], [19, "learning-outcomes"], [21, "learning-outcomes"], [22, "learning-outcomes"], [24, "learning-outcomes"], [26, "learning-outcomes"], [27, "learning-outcomes"], [28, "learning-outcomes"], [29, "learning-outcomes"], [59, "learning-outcomes"], [60, "learning-outcomes"], [61, "learning-outcomes"], [62, "learning-outcomes"], [63, "learning-outcomes"], [64, "learning-outcomes"], [65, "learning-outcomes"], [66, "learning-outcomes"], [67, "learning-outcomes"], [68, "learning-outcomes"], [70, "learning-outcomes"], [71, "learning-outcomes"], [72, "learning-outcomes"], [73, "learning-outcomes"]], "Learning outcomes <a name=\"lo\"></a>": [[30, "learning-outcomes"], [74, "learning-outcomes"]], "Least confident cases": [[21, "least-confident-cases"], [65, "least-confident-cases"]], "Lecture 10: Class demo": [[44, null]], "Lecture 10: Regression metrics": [[24, null], [68, null]], "Lecture 11: Ensembles": [[25, null], [45, null], [69, null]], "Lecture 12: Class demo": [[46, null]], "Lecture 12: Feature importances and model transparency": [[26, null], [70, null]], "Lecture 13: Class demo": [[47, null]], "Lecture 13: Feature engineering and feature selection": [[27, null], [71, null]], "Lecture 14: K-Means Clustering": [[28, null], [72, null]], "Lecture 15: Class demo": [[49, null]], "Lecture 15: Clustering class demo": [[48, null]], "Lecture 15: More Clustering": [[73, null]], "Lecture 16: Class demo": [[50, null]], "Lecture 16: More Clustering": [[29, null]], "Lecture 16: Recommender Systems": [[30, null], [74, null]], "Lecture 17: Class demo": [[51, null]], "Lecture 17: Introduction to natural language processing": [[31, null], [75, null]], "Lecture 18: Class demo": [[52, null]], "Lecture 18: Multi-class classification and introduction to computer vision": [[32, null], [76, null]], "Lecture 19: Class demo": [[53, null]], "Lecture 19: Time series": [[33, null], [77, null]], "Lecture 1: Course Introduction": [[13, null], [59, null]], "Lecture 20: Class demo": [[54, null]], "Lecture 20: Survival analysis": [[34, null], [78, null]], "Lecture 21: Class demo (Based on the lecture notes)": [[55, null]], "Lecture 21: Communication": [[35, null], [79, null]], "Lecture 22: Class demo (Based on the lecture notes)": [[56, null]], "Lecture 23: Class demo (Based on the lecture notes)": [[57, null]], "Lecture 23: Deployment and conclusion": [[36, null], [80, null]], "Lecture 24: Class demo (Based on the lecture notes)": [[58, null]], "Lecture 2: Terminology, Baselines, Decision Trees": [[14, null], [60, null]], "Lecture 3: ML Fundamentals Class Demo": [[38, null]], "Lecture 3: Machine Learning Fundamentals": [[15, null], [61, null]], "Lecture 4: Class demo": [[39, null]], "Lecture 4: k-Nearest Neighbours and SVM RBFs": [[16, null], [62, null]], "Lecture 5 and 6: Class demo": [[17, null], [40, null]], "Lecture 5: Preprocessing and sklearn pipelines": [[18, null], [63, null]], "Lecture 6: sklearn ColumnTransformer and Text Features": [[19, null], [64, null]], "Lecture 7: Class demo": [[20, null]], "Lecture 7: Linear Models": [[21, null], [65, null]], "Lecture 8: Hyperparameter Optimization and Optimization Bias": [[22, null], [66, null]], "Lecture 9: Class demo": [[23, null], [43, null]], "Lecture 9: Classification metrics": [[67, null]], "Lecture and homework format: Jupyter notebooks": [[13, "lecture-and-homework-format-jupyter-notebooks"]], "Lecture learning objectives": [[25, "lecture-learning-objectives"], [69, "lecture-learning-objectives"]], "Lecture plan and learning outcomes": [[29, "lecture-plan-and-learning-outcomes"], [73, "lecture-plan-and-learning-outcomes"]], "Lecture recordings": [[99, "lecture-recordings"]], "Lecture schedule (tentative)": [[1, "lecture-schedule-tentative"]], "Lecture style": [[13, "lecture-style"]], "Lectures 7: Class demo": [[41, null]], "Lectures 8: Class demo": [[42, null]], "Let\u2019s cluster images!!": [[48, "let-s-cluster-images"]], "Let\u2019s do it on our housing data": [[18, "let-s-do-it-on-our-housing-data"], [63, "let-s-do-it-on-our-housing-data"]], "Let\u2019s examine the transformed data": [[19, "let-s-examine-the-transformed-data"], [64, "let-s-examine-the-transformed-data"]], "Let\u2019s explore SVM RBFs": [[16, "let-s-explore-svm-rbfs"], [62, "let-s-explore-svm-rbfs"]], "Let\u2019s first run our baseline model DummyRegressor": [[18, "let-s-first-run-our-baseline-model-dummyregressor"], [63, "let-s-first-run-our-baseline-model-dummyregressor"]], "Let\u2019s identify feature types": [[26, "let-s-identify-feature-types"], [46, "let-s-identify-feature-types"], [70, "let-s-identify-feature-types"]], "Let\u2019s look at all the scores at once": [[23, "let-s-look-at-all-the-scores-at-once"], [43, "let-s-look-at-all-the-scores-at-once"], [67, "let-s-look-at-all-the-scores-at-once"]], "Let\u2019s separate X and y": [[24, "let-s-separate-x-and-y"], [26, "let-s-separate-x-and-y"], [35, "let-s-separate-x-and-y"], [44, "let-s-separate-x-and-y"], [46, "let-s-separate-x-and-y"], [55, "let-s-separate-x-and-y"], [56, "let-s-separate-x-and-y"], [68, "let-s-separate-x-and-y"], [70, "let-s-separate-x-and-y"], [79, "let-s-separate-x-and-y"]], "Let\u2019s start with a recap": [[16, "let-s-start-with-a-recap"]], "Let\u2019s talk about GenAI": [[13, "let-s-talk-about-genai"]], "Let\u2019s try KNN on this data": [[17, "let-s-try-knn-on-this-data"], [40, "let-s-try-knn-on-this-data"]], "Let\u2019s try a linear model: Ridge": [[24, "let-s-try-a-linear-model-ridge"], [44, "let-s-try-a-linear-model-ridge"], [68, "let-s-try-a-linear-model-ridge"]], "Let\u2019s try cross-validation with our pipeline": [[17, "let-s-try-cross-validation-with-our-pipeline"], [18, "let-s-try-cross-validation-with-our-pipeline"], [63, "let-s-try-cross-validation-with-our-pipeline"]], "License": [[1, "license"]], "LightGBM": [[25, "lightgbm"], [45, "lightgbm"], [69, "lightgbm"]], "Limitations of linear models": [[21, "limitations-of-linear-models"], [65, "limitations-of-linear-models"]], "Linear SVM": [[21, "linear-svm"], [65, "linear-svm"]], "Linear models [video]": [[21, "linear-models-video"], [65, "linear-models-video"]], "Linear regression": [[21, "linear-regression"], [65, "linear-regression"]], "Lists of resources": [[10, "lists-of-resources"]], "Loading our saved model": [[36, "loading-our-saved-model"], [57, "loading-our-saved-model"], [58, "loading-our-saved-model"], [80, "loading-our-saved-model"]], "Logistic regression [video]": [[21, "logistic-regression-video"], [65, "logistic-regression-video"]], "Logistic regression intuition": [[21, "logistic-regression-intuition"], [65, "logistic-regression-intuition"]], "Logistic regression on the cities data": [[21, "logistic-regression-on-the-cities-data"], [65, "logistic-regression-on-the-cities-data"]], "LogisticRegression": [[34, "logisticregression"], [53, "logisticregression"], [77, "logisticregression"], [78, "logisticregression"]], "MAPE": [[24, "mape"], [44, "mape"], [68, "mape"]], "ML and decision-making (5 min)": [[56, "ml-and-decision-making-5-min"], [79, "ml-and-decision-making-5-min"]], "ML fairness activity": [[67, "ml-fairness-activity"]], "ML fundamentals": [[85, "ml-fundamentals"]], "Machine learning workflow": [[13, "machine-learning-workflow"], [23, "machine-learning-workflow"], [43, "machine-learning-workflow"], [67, "machine-learning-workflow"]], "Macro average and weighted average": [[81, "macro-average-and-weighted-average"]], "Magnitude of the coefficients": [[21, "magnitude-of-the-coefficients"], [65, "magnitude-of-the-coefficients"]], "Main hyperparameter of logistic regression": [[21, "main-hyperparameter-of-logistic-regression"], [65, "main-hyperparameter-of-logistic-regression"]], "Main hyperparameters": [[21, "main-hyperparameters"], [65, "main-hyperparameters"]], "Main issues in ML-related communication": [[35, "main-issues-in-ml-related-communication"], [56, "main-issues-in-ml-related-communication"], [79, "main-issues-in-ml-related-communication"]], "Manual hyperparameter optimization": [[22, "manual-hyperparameter-optimization"], [66, "manual-hyperparameter-optimization"]], "Mean intra-cluster distance (a)": [[28, "mean-intra-cluster-distance-a"], [72, "mean-intra-cluster-distance-a"]], "Mean nearest-cluster distance (b)": [[28, "mean-nearest-cluster-distance-b"], [72, "mean-nearest-cluster-distance-b"]], "Mean squared error (MSE)": [[24, "mean-squared-error-mse"], [44, "mean-squared-error-mse"], [68, "mean-squared-error-mse"]], "Measuring similarity between vectors": [[31, "measuring-similarity-between-vectors"], [75, "measuring-similarity-between-vectors"]], "Meet Eva (a fictitious persona)!": [[13, "meet-eva-a-fictitious-persona"], [59, "meet-eva-a-fictitious-persona"]], "Method 1: The Elbow method": [[28, "method-1-the-elbow-method"], [72, "method-1-the-elbow-method"]], "Method 2: The Silhouette method": [[28, "method-2-the-silhouette-method"], [72, "method-2-the-silhouette-method"]], "Midterm": [[99, "midterm"]], "Misc": [[1, "misc"], [10, "misc"]], "Miscellaneous comments on content-based filtering": [[30, "miscellaneous-comments-on-content-based-filtering"], [50, "miscellaneous-comments-on-content-based-filtering"], [74, "miscellaneous-comments-on-content-based-filtering"]], "Model building": [[24, "model-building"], [36, "model-building"], [44, "model-building"], [68, "model-building"], [80, "model-building"]], "Model building on the dataset": [[20, "model-building-on-the-dataset"], [41, "model-building-on-the-dataset"]], "Model complexity and training error": [[15, "model-complexity-and-training-error"], [61, "model-complexity-and-training-error"]], "Model deployment": [[36, "model-deployment"], [36, "id1"], [57, "model-deployment"], [58, "model-deployment"], [80, "model-deployment"], [80, "id1"]], "Model interpretability beyond linear models": [[46, "model-interpretability-beyond-linear-models"], [70, "model-interpretability-beyond-linear-models"]], "Model interpretability beyond linear models (video)": [[26, "model-interpretability-beyond-linear-models-video"]], "Model predictions on unseen data": [[13, "model-predictions-on-unseen-data"], [59, "model-predictions-on-unseen-data"]], "Model transparency and interpretation": [[36, "model-transparency-and-interpretation"], [80, "model-transparency-and-interpretation"]], "Model-based selection": [[27, "model-based-selection"], [47, "model-based-selection"], [71, "model-based-selection"]], "Modeling": [[17, "modeling"], [40, "modeling"]], "More comments on tackling class imbalance": [[24, "more-comments-on-tackling-class-imbalance"], [68, "more-comments-on-tackling-class-imbalance"]], "More details": [[15, "more-details"]], "More details on DBSCAN": [[29, "more-details-on-dbscan"], [73, "more-details-on-dbscan"]], "More on feature transformations": [[19, "more-on-feature-transformations"], [64, "more-on-feature-transformations"]], "More on k-NNs [video]": [[16, "more-on-k-nns-video"], [62, "more-on-k-nns-video"]], "More terminology [video]": [[14, "more-terminology-video"], [60, "more-terminology-video"]], "More than one ordinal columns?": [[19, "more-than-one-ordinal-columns"], [64, "more-than-one-ordinal-columns"]], "Most confident cases": [[21, "most-confident-cases"], [65, "most-confident-cases"]], "Most negative review": [[20, "most-negative-review"], [41, "most-negative-review"]], "Most positive review": [[20, "most-positive-review"], [41, "most-positive-review"]], "Motivating example": [[21, "motivating-example"], [65, "motivating-example"]], "Motivation": [[22, "motivation"], [31, "motivation"], [33, "motivation"], [35, "motivation"], [51, "motivation"], [56, "motivation"], [66, "motivation"], [75, "motivation"], [77, "motivation"], [79, "motivation"]], "Motivation [video]": [[25, "motivation-video"], [69, "motivation-video"]], "Motivation and big picture [video]": [[18, "motivation-and-big-picture-video"], [63, "motivation-and-big-picture-video"]], "Motivation and context": [[52, "motivation-and-context"]], "Motivation and distances [video]": [[16, "motivation-and-distances-video"], [62, "motivation-and-distances-video"]], "Movie features": [[30, "movie-features"], [50, "movie-features"], [74, "movie-features"]], "Multi-class classification": [[32, "multi-class-classification"], [76, "multi-class-classification"]], "Multiclass classification and computer vision": [[85, "multiclass-classification-and-computer-vision"]], "Multiple transformations in a transformer": [[19, "multiple-transformations-in-a-transformer"], [64, "multiple-transformations-in-a-transformer"]], "NLP pipelines before and after LLMs": [[31, "nlp-pipelines-before-and-after-llms"], [51, "nlp-pipelines-before-and-after-llms"], [75, "nlp-pipelines-before-and-after-llms"]], "NOTE:": [[9, "note"]], "Neural networks example and terminology": [[32, "neural-networks-example-and-terminology"], [76, "neural-networks-example-and-terminology"]], "New ideas in small chunks": [[35, "new-ideas-in-small-chunks"], [56, "new-ideas-in-small-chunks"], [79, "new-ideas-in-small-chunks"]], "No-loop method: make them the same size, and multiply element-wise": [[9, "no-loop-method-make-them-the-same-size-and-multiply-element-wise"]], "Note": [[33, null], [61, null], [61, null], [77, null]], "Number of trees and fundamental trade-off": [[25, "number-of-trees-and-fundamental-trade-off"], [45, "number-of-trees-and-fundamental-trade-off"], [69, "number-of-trees-and-fundamental-trade-off"]], "Numpy array shapes": [[9, "numpy-array-shapes"]], "Numpy arrays": [[9, "numpy-arrays"]], "OHE with many categories": [[64, "ohe-with-many-categories"]], "Object detection": [[32, "object-detection"], [76, "object-detection"]], "Observations": [[23, "observations"], [43, "observations"], [67, "observations"]], "One Vs. One approach": [[84, "one-vs-one-approach"]], "One Vs. One prediction": [[84, "one-vs-one-prediction"]], "One vs. Rest": [[84, "one-vs-rest"]], "One-hot encoding (OHE)": [[18, "one-hot-encoding-ohe"], [63, "one-hot-encoding-ohe"]], "One-hot encoding of the month": [[53, "one-hot-encoding-of-the-month"], [77, "one-hot-encoding-of-the-month"]], "One-hot encoding seasons": [[53, "one-hot-encoding-seasons"], [77, "one-hot-encoding-seasons"]], "OneHotEncoder and sparse features": [[19, "onehotencoder-and-sparse-features"], [64, "onehotencoder-and-sparse-features"]], "Online courses": [[1, "online-courses"], [10, "online-courses"]], "Open the repo in VS Code": [[11, "open-the-repo-in-vs-code"]], "Operating point": [[23, "operating-point"], [43, "operating-point"], [67, "operating-point"]], "Optimization bias of hyper-parameter learning": [[22, "optimization-bias-of-hyper-parameter-learning"], [66, "optimization-bias-of-hyper-parameter-learning"]], "Optimization bias of parameter learning": [[22, "optimization-bias-of-parameter-learning"], [66, "optimization-bias-of-parameter-learning"]], "Optimization bias on the Spotify dataset": [[22, "optimization-bias-on-the-spotify-dataset"], [66, "optimization-bias-on-the-spotify-dataset"]], "Optimization bias/Overfitting of the validation set": [[66, "optimization-bias-overfitting-of-the-validation-set"]], "Optimization bias/Overfitting of the validation set (video)": [[22, "optimization-bias-overfitting-of-the-validation-set-video"]], "Option 1: GitHub Desktop (easiest)": [[6, "option-1-github-desktop-easiest"]], "Option 2: Command-line Git (recommended)": [[6, "option-2-command-line-git-recommended"]], "Option A (recommended): Miniforge": [[11, "option-a-recommended-miniforge"]], "Option B: Miniconda": [[11, "option-b-miniconda"]], "Optional readings and resources": [[22, "optional-readings-and-resources"], [66, "optional-readings-and-resources"]], "Ordinal encoding (occasionally recommended)": [[18, "ordinal-encoding-occasionally-recommended"], [63, "ordinal-encoding-occasionally-recommended"]], "Ordinal features": [[17, "ordinal-features"], [26, "ordinal-features"], [40, "ordinal-features"], [46, "ordinal-features"], [70, "ordinal-features"]], "Other applications": [[28, "other-applications"], [72, "other-applications"]], "Other approaches / what did we not cover?": [[34, "other-approaches-what-did-we-not-cover"], [54, "other-approaches-what-did-we-not-cover"], [78, "other-approaches-what-did-we-not-cover"]], "Other commonly used preprocessing steps": [[52, "other-commonly-used-preprocessing-steps"], [83, "other-commonly-used-preprocessing-steps"]], "Other possible preprocessing?": [[24, "other-possible-preprocessing"], [44, "other-possible-preprocessing"], [68, "other-possible-preprocessing"]], "Other software package": [[33, "other-software-package"], [53, "other-software-package"], [77, "other-software-package"]], "Other tools for preprocessing": [[52, "other-tools-for-preprocessing"], [83, "other-tools-for-preprocessing"]], "Other typical NLP tasks": [[52, "other-typical-nlp-tasks"], [83, "other-typical-nlp-tasks"]], "Other useful arguments of KNeighborsClassifier": [[16, "other-useful-arguments-of-kneighborsclassifier"], [62, "other-useful-arguments-of-kneighborsclassifier"]], "Other ways to search": [[27, "other-ways-to-search"], [47, "other-ways-to-search"], [82, "other-ways-to-search"]], "Our typical supervised learning set up is as follows:": [[61, "our-typical-supervised-learning-set-up-is-as-follows"]], "Outline": [[86, "outline"], [87, "outline"], [88, "outline"], [89, "outline"], [90, "outline"], [91, "outline"], [92, "outline"], [93, "outline"], [94, "outline"], [95, "outline"], [96, "outline"], [97, "outline"]], "Over confident cases": [[21, "over-confident-cases"], [65, "over-confident-cases"]], "Overfitting": [[15, "overfitting"], [61, "overfitting"]], "Overfitting of the validation data": [[22, "overfitting-of-the-validation-data"], [66, "overfitting-of-the-validation-data"]], "Overfitting of the validation error": [[22, "overfitting-of-the-validation-error"], [66, "overfitting-of-the-validation-error"]], "Oversampling": [[81, "oversampling"]], "Overview": [[16, "overview"], [62, "overview"]], "POSIX time feature": [[33, "posix-time-feature"], [77, "posix-time-feature"]], "PR curves for logistic regression and SVC": [[23, "pr-curves-for-logistic-regression-and-svc"], [43, "pr-curves-for-logistic-regression-and-svc"], [67, "pr-curves-for-logistic-regression-and-svc"]], "Pandas DataFrames": [[9, "pandas-dataframes"]], "Pandas Series": [[9, "pandas-series"]], "Parameters": [[14, "parameters"], [60, "parameters"]], "Parameters and hyperparameters: Summary": [[14, "parameters-and-hyperparameters-summary"], [60, "parameters-and-hyperparameters-summary"]], "Parsing datetimes": [[53, "parsing-datetimes"], [77, "parsing-datetimes"], [91, "parsing-datetimes"], [97, "parsing-datetimes"]], "Part 1": [[85, "part-1"]], "Part 2": [[85, "part-2"]], "Passing probability distributions to random search": [[22, "passing-probability-distributions-to-random-search"], [42, "passing-probability-distributions-to-random-search"], [66, "passing-probability-distributions-to-random-search"]], "Pause!": [[17, "pause"]], "Permutation importances": [[46, "permutation-importances"]], "Piazza-specific Q&A guidelines": [[4, "piazza-specific-q-a-guidelines"]], "Pipelines": [[18, "pipelines"], [63, "pipelines"]], "Playground": [[62, "playground"]], "Playground (in tutorial)": [[16, "playground-in-tutorial"]], "Plotting with matplotlib": [[9, "plotting-with-matplotlib"]], "Practice exercises": [[14, "practice-exercises"], [60, "practice-exercises"]], "Precision": [[23, "precision"], [43, "precision"]], "Precision and recall: toy example": [[23, "precision-and-recall-toy-example"], [43, "precision-and-recall-toy-example"], [67, "precision-and-recall-toy-example"]], "Precision, recall, f1 score": [[23, "precision-recall-f1-score"], [43, "precision-recall-f1-score"], [67, "precision-recall-f1-score"]], "Precision-recall curve": [[23, "precision-recall-curve"], [23, "id1"], [43, "precision-recall-curve"], [43, "id1"], [67, "precision-recall-curve"], [67, "id1"]], "Precision/Recall tradeoff": [[23, "precision-recall-tradeoff"], [43, "precision-recall-tradeoff"], [67, "precision-recall-tradeoff"]], "Predicting on unseen data using the trained model": [[13, "predicting-on-unseen-data-using-the-trained-model"], [59, "predicting-on-unseen-data-using-the-trained-model"]], "Predicting probability scores [video]": [[21, "predicting-probability-scores-video"], [65, "predicting-probability-scores-video"]], "Predicting with learned weights": [[21, "predicting-with-learned-weights"], [65, "predicting-with-learned-weights"]], "Prediction": [[34, "prediction"], [54, "prediction"], [78, "prediction"]], "Prediction of linear regression": [[21, "prediction-of-linear-regression"], [65, "prediction-of-linear-regression"]], "Prediction with learned parameters": [[21, "prediction-with-learned-parameters"], [65, "prediction-with-learned-parameters"]], "Predictions": [[32, "predictions"], [76, "predictions"]], "Preferences in LogisticRegression": [[35, "preferences-in-logisticregression"], [56, "preferences-in-logisticregression"], [79, "preferences-in-logisticregression"]], "Preparation": [[8, "preparation"]], "Preprocessing": [[19, "preprocessing"], [53, "preprocessing"], [64, "preprocessing"], [77, "preprocessing"], [85, "preprocessing"], [90, "preprocessing"], [91, "preprocessing"], [96, "preprocessing"], [97, "preprocessing"]], "Preprocessing the targets?": [[19, "preprocessing-the-targets"], [64, "preprocessing-the-targets"]], "Prevalence of ML": [[13, "prevalence-of-ml"], [59, "prevalence-of-ml"]], "Principles of effective communication": [[35, "principles-of-effective-communication"], [56, "principles-of-effective-communication"], [79, "principles-of-effective-communication"]], "Principles of good explanations (~15 min)": [[35, "principles-of-good-explanations-15-min"], [56, "principles-of-good-explanations-15-min"], [79, "principles-of-good-explanations-15-min"]], "Problem formulation": [[30, "problem-formulation"], [74, "problem-formulation"]], "Problem: Different transformations on different columns": [[18, "problem-different-transformations-on-different-columns"], [63, "problem-different-transformations-on-different-columns"]], "Problems with exhaustive grid search": [[22, "problems-with-exhaustive-grid-search"], [42, "problems-with-exhaustive-grid-search"], [66, "problems-with-exhaustive-grid-search"]], "Problems with single train/validation split": [[15, "problems-with-single-train-validation-split"], [61, "problems-with-single-train-validation-split"]], "Pros of k-NNs for supervised learning": [[16, "pros-of-k-nns-for-supervised-learning"], [62, "pros-of-k-nns-for-supervised-learning"]], "Pros, cons, parameters and hyperparameters of different ML models": [[85, "pros-cons-parameters-and-hyperparameters-of-different-ml-models"]], "Python requirements/resources": [[13, "python-requirements-resources"]], "Python resources": [[10, "python-resources"]], "Question": [[16, "question"], [62, "question"]], "Question for you": [[29, "question-for-you"], [73, "question-for-you"]], "Question for you to ponder on": [[20, "question-for-you-to-ponder-on"], [41, "question-for-you-to-ponder-on"]], "Questions for class discussion": [[30, "questions-for-class-discussion"], [74, "questions-for-class-discussion"]], "Questions for class discussion (hyperparameter optimization)": [[22, "questions-for-class-discussion-hyperparameter-optimization"], [66, "questions-for-class-discussion-hyperparameter-optimization"]], "Quick recap": [[62, "quick-recap"]], "Quick start (TL;DR)": [[11, "quick-start-tl-dr"]], "RF better than GB": [[35, "rf-better-than-gb"], [55, "rf-better-than-gb"], [56, "rf-better-than-gb"], [79, "rf-better-than-gb"]], "RFE algorithm": [[27, "rfe-algorithm"], [47, "rfe-algorithm"], [71, "rfe-algorithm"]], "R^2 (not in detail)": [[24, "r-2-not-in-detail"], [44, "r-2-not-in-detail"], [68, "r-2-not-in-detail"]], "Random forest feature importances": [[26, "random-forest-feature-importances"], [46, "random-forest-feature-importances"], [70, "random-forest-feature-importances"]], "Random forests": [[25, "random-forests"], [45, "random-forests"], [69, "random-forests"]], "Random forests: number of trees (n_estimators) and the fundamental tradeoff": [[25, "random-forests-number-of-trees-n-estimators-and-the-fundamental-tradeoff"], [45, "random-forests-number-of-trees-n-estimators-and-the-fundamental-tradeoff"], [69, "random-forests-number-of-trees-n-estimators-and-the-fundamental-tradeoff"]], "RandomForestClassifier": [[25, "randomforestclassifier"], [34, "randomforestclassifier"], [45, "randomforestclassifier"], [69, "randomforestclassifier"], [78, "randomforestclassifier"]], "Randomized hyperparameter search": [[22, "randomized-hyperparameter-search"], [42, "randomized-hyperparameter-search"], [66, "randomized-hyperparameter-search"]], "Range of C": [[22, "range-of-c"], [42, "range-of-c"], [66, "range-of-c"]], "Raw scores": [[21, "raw-scores"], [65, "raw-scores"]], "Reading from .csv": [[9, "reading-from-csv"]], "Reading from other formats": [[9, "reading-from-other-formats"]], "Reading from url": [[9, "reading-from-url"]], "Reading the data": [[14, "reading-the-data"], [60, "reading-the-data"]], "Real boundary between Canada and USA": [[60, "real-boundary-between-canada-and-usa"], [86, "real-boundary-between-canada-and-usa"], [92, "real-boundary-between-canada-and-usa"]], "Reasonable grading concerns": [[7, "reasonable-grading-concerns"]], "Recall": [[23, "recall"], [43, "recall"]], "Recap": [[34, "recap"], [56, "recap"], [78, "recap"], [79, "recap"]], "Recap and motivation [video]": [[29, "recap-and-motivation-video"], [73, "recap-and-motivation-video"]], "Recap: Supervised machine learning": [[14, "recap-supervised-machine-learning"], [60, "recap-supervised-machine-learning"]], "Receiver Operating Characteristic (ROC) curve": [[23, "receiver-operating-characteristic-roc-curve"], [43, "receiver-operating-characteristic-roc-curve"], [67, "receiver-operating-characteristic-roc-curve"]], "Recipe to approach a supervised learning problem with tabular data": [[36, "recipe-to-approach-a-supervised-learning-problem-with-tabular-data"], [80, "recipe-to-approach-a-supervised-learning-problem-with-tabular-data"]], "Recommended browser": [[13, "recommended-browser"]], "Recommender systems": [[85, "recommender-systems"]], "Recommender systems intro and motivation": [[30, "recommender-systems-intro-and-motivation"], [74, "recommender-systems-intro-and-motivation"]], "Recommender systems problem": [[30, "recommender-systems-problem"], [74, "recommender-systems-problem"]], "Recursive feature elimination (RFE)": [[27, "recursive-feature-elimination-rfe"], [47, "recursive-feature-elimination-rfe"], [71, "recursive-feature-elimination-rfe"]], "Reference Material": [[1, "reference-material"]], "Reference material": [[10, null]], "References": [[34, "references"], [54, "references"], [78, "references"]], "Registration": [[99, "registration"]], "Registration, waitlist and prerequisites": [[13, "registration-waitlist-and-prerequisites"]], "Regression scoring functions": [[24, "regression-scoring-functions"], [44, "regression-scoring-functions"], [68, "regression-scoring-functions"]], "Regression with k-nearest neighbours (k-NNs)": [[16, "regression-with-k-nearest-neighbours-k-nns"], [62, "regression-with-k-nearest-neighbours-k-nns"]], "Relation of C and the fundamental trade-off": [[16, "relation-of-c-and-the-fundamental-trade-off"], [62, "relation-of-c-and-the-fundamental-trade-off"]], "Relation of gamma and the fundamental trade-off": [[16, "relation-of-gamma-and-the-fundamental-trade-off"], [62, "relation-of-gamma-and-the-fundamental-trade-off"]], "Relevant companion materials": [[10, "relevant-companion-materials"]], "Relevant papers": [[25, "relevant-papers"], [45, "relevant-papers"], [69, "relevant-papers"]], "Relevant papers and resources": [[67, "relevant-papers-and-resources"]], "Relevant resources": [[27, "relevant-resources"], [71, "relevant-resources"]], "Reminder": [[30, "reminder"], [50, "reminder"], [74, "reminder"]], "Renaming columns with df.rename()": [[9, "renaming-columns-with-df-rename"]], "Render set-up (I already did these):": [[36, "render-set-up-i-already-did-these"], [57, "render-set-up-i-already-did-these"], [58, "render-set-up-i-already-did-these"], [80, "render-set-up-i-already-did-these"]], "Report format": [[8, "report-format"]], "Requirements (I already did these)": [[36, "requirements-i-already-did-these"], [80, "requirements-i-already-did-these"]], "Resources": [[28, "resources"], [29, "resources"], [30, "resources"], [50, "resources"], [72, "resources"], [73, "resources"], [74, "resources"]], "Reuse your running examples": [[35, "reuse-your-running-examples"], [56, "reuse-your-running-examples"], [79, "reuse-your-running-examples"]], "Ridge": [[21, "ridge"], [65, "ridge"]], "Ridge on the California housing dataset": [[21, "ridge-on-the-california-housing-dataset"], [65, "ridge-on-the-california-housing-dataset"]], "RidgeCV": [[24, "ridgecv"], [44, "ridgecv"], [68, "ridgecv"]], "Root mean squared error or RMSE": [[24, "root-mean-squared-error-or-rmse"], [44, "root-mean-squared-error-or-rmse"], [68, "root-mean-squared-error-or-rmse"]], "Running notebooks": [[11, "running-notebooks"]], "SHAP  (SHapley Additive exPlanations) introduction": [[26, "shap-shapley-additive-explanations-introduction"], [46, "shap-shapley-additive-explanations-introduction"], [70, "shap-shapley-additive-explanations-introduction"]], "SHAP plots": [[26, "shap-plots"], [46, "shap-plots"], [70, "shap-plots"]], "SMOTE idea": [[81, "smote-idea"]], "SMOTE: Synthetic Minority Over-sampling Technique": [[81, "smote-synthetic-minority-over-sampling-technique"]], "SVM Regressor": [[16, "svm-regressor"], [62, "svm-regressor"]], "Saving the model": [[36, "saving-the-model"], [57, "saving-the-model"], [58, "saving-the-model"], [80, "saving-the-model"]], "Saving time and scaling products": [[13, "saving-time-and-scaling-products"], [59, "saving-time-and-scaling-products"]], "Scaling": [[18, "scaling"], [63, "scaling"]], "Scaling using scikit-learn\u2019s StandardScaler": [[18, "scaling-using-scikit-learn-s-standardscaler"], [63, "scaling-using-scikit-learn-s-standardscaler"]], "Search over multiple hyperparameters": [[16, "search-over-multiple-hyperparameters"], [62, "search-over-multiple-hyperparameters"]], "Seasonality and trends": [[33, "seasonality-and-trends"], [77, "seasonality-and-trends"]], "Section 102": [[37, null]], "Select all of the following statements which are True (iClicker)": [[13, "select-all-of-the-following-statements-which-are-true-iclicker"], [50, "select-all-of-the-following-statements-which-are-true-iclicker"], [72, "select-all-of-the-following-statements-which-are-true-iclicker"], [72, "id1"], [72, "id3"], [73, "select-all-of-the-following-statements-which-are-true-iclicker"], [73, "id2"], [74, "select-all-of-the-following-statements-which-are-true-iclicker"], [74, "id3"]], "Select the correct environment": [[11, "select-the-correct-environment"]], "Sending a request to the API": [[36, "sending-a-request-to-the-api"], [57, "sending-a-request-to-the-api"], [58, "sending-a-request-to-the-api"], [80, "sending-a-request-to-the-api"]], "Setting up your coding environment": [[11, null]], "Setting up your computer for the course": [[13, "setting-up-your-computer-for-the-course"]], "Short posts/articles": [[10, "short-posts-articles"]], "Sigmoid vs. Softmax": [[32, "sigmoid-vs-softmax"], [76, "sigmoid-vs-softmax"]], "Sign of the coefficients": [[21, "sign-of-the-coefficients"], [65, "sign-of-the-coefficients"]], "Silhouette distance for a sample": [[28, "silhouette-distance-for-a-sample"], [72, "silhouette-distance-for-a-sample"]], "Similarity between examples": [[16, "similarity-between-examples"], [62, "similarity-between-examples"]], "Simple train/test split": [[15, "simple-train-test-split"], [61, "simple-train-test-split"]], "SimpleFeature correlations": [[26, "simplefeature-correlations"], [70, "simplefeature-correlations"]], "Single validation set": [[38, "single-validation-set"]], "Slowest method: nested loop": [[9, "slowest-method-nested-loop"]], "Software": [[0, "software"]], "Solution": [[25, "solution"]], "Some important hyperparameters:": [[25, "some-important-hyperparameters"], [45, "some-important-hyperparameters"], [69, "some-important-hyperparameters"]], "Some key takeaways": [[36, "some-key-takeaways"], [80, "some-key-takeaways"]], "Some quotes on feature engineering": [[27, "some-quotes-on-feature-engineering"], [71, "some-quotes-on-feature-engineering"]], "Some terminology related to trees": [[14, "some-terminology-related-to-trees"], [60, "some-terminology-related-to-trees"]], "Some ways to pick hyperparameters:": [[22, "some-ways-to-pick-hyperparameters"], [66, "some-ways-to-pick-hyperparameters"]], "Sorting a dataframe with df.sort_values()": [[9, "sorting-a-dataframe-with-df-sort-values"]], "Spam/non spam toy example": [[19, "spam-non-spam-toy-example"], [64, "spam-non-spam-toy-example"]], "Specific questions": [[4, "specific-questions"]], "Stacking": [[25, "stacking"], [45, "stacking"], [69, "stacking"], [89, "stacking"], [95, "stacking"]], "Step 0: EDA": [[88, "step-0-eda"]], "Step 1": [[88, "step-1"], [94, "step-1"]], "Step 1: Install Git": [[6, "step-1-install-git"], [11, "step-1-install-git"]], "Step 2": [[88, "step-2"], [94, "step-2"]], "Step 2: Install Python and Conda": [[11, "step-2-install-python-and-conda"]], "Step 2: Testing your Git installation": [[6, "step-2-testing-your-git-installation"]], "Step 3": [[88, "step-3"], [94, "step-3"]], "Step 3: Authenticating with GitHub (important!)": [[6, "step-3-authenticating-with-github-important"]], "Step 3: Verify installation": [[11, "step-3-verify-installation"]], "Step 4": [[88, "step-4"], [94, "step-4"]], "Step 4: Configure conda-forge (Miniconda only)": [[11, "step-4-configure-conda-forge-miniconda-only"]], "Step 5": [[88, "step-5"], [94, "step-5"]], "Step 5: Create the course environment": [[11, "step-5-create-the-course-environment"]], "Step 6: Using VS Code (alternative to JupyterLab)": [[11, "step-6-using-vs-code-alternative-to-jupyterlab"]], "Step 7: Troubleshooting": [[11, "step-7-troubleshooting"]], "Steps to train a classifier using sklearn": [[14, "steps-to-train-a-classifier-using-sklearn"], [60, "steps-to-train-a-classifier-using-sklearn"]], "Stratified Splits": [[67, "stratified-splits"]], "Strengths and weaknesses": [[25, "strengths-and-weaknesses"], [45, "strengths-and-weaknesses"], [69, "strengths-and-weaknesses"]], "Strengths of linear models": [[21, "strengths-of-linear-models"], [65, "strengths-of-linear-models"]], "Study tips": [[85, "study-tips"]], "Submitting on Gradescope": [[8, "submitting-on-gradescope"]], "Summary": [[13, "summary"], [16, "summary"], [25, "summary"], [31, "summary"], [32, "summary"], [34, "summary"], [45, "summary"], [51, "summary"], [52, "summary"], [54, "summary"], [59, "summary"], [62, "summary"], [69, "summary"], [75, "summary"], [76, "summary"], [78, "summary"]], "Summary and reflection": [[15, "summary-and-reflection"], [61, "summary-and-reflection"]], "Summary of linear models": [[21, "summary-of-linear-models"], [65, "summary-of-linear-models"]], "Summary of train, validation, test, and deployment data": [[15, "summary-of-train-validation-test-and-deployment-data"], [61, "summary-of-train-validation-test-and-deployment-data"]], "Summary: Pros and cons": [[29, "summary-pros-and-cons"], [73, "summary-pros-and-cons"]], "Supervised approach to rating prediction": [[30, "supervised-approach-to-rating-prediction"], [50, "supervised-approach-to-rating-prediction"], [74, "supervised-approach-to-rating-prediction"]], "Supervised learning": [[28, "supervised-learning"], [72, "supervised-learning"]], "Supervised learning (Reminder)": [[60, "supervised-learning-reminder"]], "Supervised learning vs. Unsupervised learning": [[14, "supervised-learning-vs-unsupervised-learning"], [60, "supervised-learning-vs-unsupervised-learning"]], "Supervised machine learning": [[13, "supervised-machine-learning"], [59, "supervised-machine-learning"]], "Supervised machine learning workflow": [[59, "supervised-machine-learning-workflow"]], "Support Vector Machines (SVMs) with RBF kernel [video]": [[16, "support-vector-machines-svms-with-rbf-kernel-video"], [62, "support-vector-machines-svms-with-rbf-kernel-video"]], "Support vectors": [[16, "support-vectors"], [62, "support-vectors"]], "Survival analysis": [[85, "survival-analysis"]], "Survival plots": [[34, "survival-plots"], [54, "survival-plots"], [78, "survival-plots"]], "Syllabus": [[1, "syllabus"], [1, "id1"], [99, null]], "TAs": [[1, "tas"], [99, "tas"]], "Tabular data": [[14, "tabular-data"], [60, "tabular-data"]], "Take-home message": [[29, "take-home-message"], [73, "take-home-message"]], "Teaching Team": [[99, "teaching-team"]], "Terminology [video]": [[14, "terminology-video"], [60, "terminology-video"]], "Text representations and word embeddings": [[31, "text-representations-and-word-embeddings"], [51, "text-representations-and-word-embeddings"], [75, "text-representations-and-word-embeddings"]], "The Netflix prize": [[25, "the-netflix-prize"], [69, "the-netflix-prize"]], "The __ syntax": [[22, "the-syntax"], [42, "the-syntax"], [66, "the-syntax"]], "The best features may be dependent on the model you use.": [[71, "the-best-features-may-be-dependent-on-the-model-you-use"]], "The dataset": [[89, "the-dataset"], [90, "the-dataset"], [95, "the-dataset"], [96, "the-dataset"]], "The golden rule <a name=\"4\"></a>": [[15, "the-golden-rule"], [61, "the-golden-rule"]], "The random forests classifier": [[25, "the-random-forests-classifier"], [45, "the-random-forests-classifier"], [69, "the-random-forests-classifier"]], "The sigmoid function": [[21, "the-sigmoid-function"], [65, "the-sigmoid-function"]], "The teaching team": [[1, "the-teaching-team"]], "The \u201cfundamental tradeoff\u201d of supervised learning:": [[15, "the-fundamental-tradeoff-of-supervised-learning"], [61, "the-fundamental-tradeoff-of-supervised-learning"]], "The \u201cperfect\u201d spaghetti sauce": [[28, "the-perfect-spaghetti-sauce"], [72, "the-perfect-spaghetti-sauce"]], "Things to watch out for": [[35, "things-to-watch-out-for"], [55, "things-to-watch-out-for"], [56, "things-to-watch-out-for"], [79, "things-to-watch-out-for"]], "Thresholding": [[23, "thresholding"], [43, "thresholding"]], "Time series": [[85, "time-series"]], "Time series analysis on a more complicated dataset": [[91, "time-series-analysis-on-a-more-complicated-dataset"], [97, "time-series-analysis-on-a-more-complicated-dataset"]], "Time to event and censoring": [[34, "time-to-event-and-censoring"], [78, "time-to-event-and-censoring"]], "Tokenization": [[52, "tokenization"], [83, "tokenization"]], "Topic modeling": [[31, "topic-modeling"], [51, "topic-modeling"], [52, "topic-modeling"], [75, "topic-modeling"]], "Topic modeling motivation": [[31, "topic-modeling-motivation"], [51, "topic-modeling-motivation"], [52, "topic-modeling-motivation"], [75, "topic-modeling-motivation"]], "Topic modeling pipeline": [[31, "topic-modeling-pipeline"], [51, "topic-modeling-pipeline"], [52, "topic-modeling-pipeline"], [75, "topic-modeling-pipeline"]], "Topic modeling toy example": [[31, "topic-modeling-toy-example"], [51, "topic-modeling-toy-example"], [52, "topic-modeling-toy-example"], [75, "topic-modeling-toy-example"]], "Toy datasets": [[60, "toy-datasets"]], "Traditional time series approaches": [[33, "traditional-time-series-approaches"], [53, "traditional-time-series-approaches"], [77, "traditional-time-series-approaches"]], "Train/test split for temporal data": [[33, "train-test-split-for-temporal-data"], [77, "train-test-split-for-temporal-data"]], "Train/test splits": [[53, "train-test-splits"], [77, "train-test-splits"]], "Train/validation/test split": [[15, "train-validation-test-split"], [61, "train-validation-test-split"]], "Training a supervised machine learning model with X and y": [[13, "training-a-supervised-machine-learning-model-with-x-and-y"], [59, "training-a-supervised-machine-learning-model-with-x-and-y"]], "Training data for the motivating example": [[21, "training-data-for-the-motivating-example"], [65, "training-data-for-the-motivating-example"]], "Training error vs. Generalization error": [[15, "training-error-vs-generalization-error"], [61, "training-error-vs-generalization-error"]], "Training models with transformed data": [[19, "training-models-with-transformed-data"], [64, "training-models-with-transformed-data"]], "Training on the full corpus": [[36, "training-on-the-full-corpus"], [57, "training-on-the-full-corpus"], [58, "training-on-the-full-corpus"], [80, "training-on-the-full-corpus"]], "Training random forests and gradient boosted trees": [[35, "training-random-forests-and-gradient-boosted-trees"], [55, "training-random-forests-and-gradient-boosted-trees"], [56, "training-random-forests-and-gradient-boosted-trees"], [79, "training-random-forests-and-gradient-boosted-trees"]], "Transfer learning": [[32, "transfer-learning"], [76, "transfer-learning"]], "Transformations on the toy data": [[19, "transformations-on-the-toy-data"], [64, "transformations-on-the-toy-data"]], "Transforming the targets": [[24, "transforming-the-targets"], [44, "transforming-the-targets"], [68, "transforming-the-targets"]], "Transparency and explainability of ML models: Motivation": [[46, "transparency-and-explainability-of-ml-models-motivation"], [70, "transparency-and-explainability-of-ml-models-motivation"]], "Transparency and explainability of ML models: Motivation (video)": [[26, "transparency-and-explainability-of-ml-models-motivation-video"]], "Tree-based ensemble models": [[69, "tree-based-ensemble-models"]], "Tree-based models": [[25, "tree-based-models"], [69, "tree-based-models"]], "Try out this moment predictor": [[36, "try-out-this-moment-predictor"], [80, "try-out-this-moment-predictor"]], "Tuning alpha hyperparameter of Ridge": [[24, "tuning-alpha-hyperparameter-of-ridge"], [44, "tuning-alpha-hyperparameter-of-ridge"], [68, "tuning-alpha-hyperparameter-of-ridge"]], "Tutorial 1": [[86, null], [92, null]], "Tutorial 2": [[87, null], [93, null]], "Tutorial 3": [[88, null], [94, null]], "Tutorial 6": [[89, null], [90, null], [95, null], [96, null]], "Tutorial 8": [[91, null], [97, null]], "Types of censoring": [[34, "types-of-censoring"], [54, "types-of-censoring"], [78, "types-of-censoring"]], "Types of errors": [[15, "types-of-errors"], [61, "types-of-errors"]], "Types of machine learning": [[13, "types-of-machine-learning"], [28, "types-of-machine-learning"], [59, "types-of-machine-learning"], [72, "types-of-machine-learning"]], "Types of problems involving time series": [[33, "types-of-problems-involving-time-series"], [53, "types-of-problems-involving-time-series"], [77, "types-of-problems-involving-time-series"]], "Types of questions we might want to answer:": [[34, "types-of-questions-we-might-want-to-answer"], [78, "types-of-questions-we-might-want-to-answer"]], "Typical steps to build a supervised machine learning model": [[38, "typical-steps-to-build-a-supervised-machine-learning-model"]], "UBC CPSC 330: Applied Machine Learning (2025W1)": [[1, null]], "Ubuntu Users": [[6, "ubuntu-users"]], "Underfitting": [[15, "underfitting"], [61, "underfitting"]], "Underfitting, overfitting, the fundamental trade-off, the golden rule [video]": [[15, "underfitting-overfitting-the-fundamental-trade-off-the-golden-rule-video"], [61, "underfitting-overfitting-the-fundamental-trade-off-the-golden-rule-video"]], "Undersampling": [[81, "undersampling"]], "Understanding the problem": [[36, "understanding-the-problem"], [80, "understanding-the-problem"]], "Unequally spaced time points": [[33, "unequally-spaced-time-points"], [53, "unequally-spaced-time-points"], [77, "unequally-spaced-time-points"]], "Uniform distribution": [[42, "uniform-distribution"], [66, "uniform-distribution"]], "Unsupervised learning": [[28, "unsupervised-learning"], [72, "unsupervised-learning"]], "Updates to assignments": [[8, "updates-to-assignments"]], "Use of Generative AI in the course": [[99, "use-of-generative-ai-in-the-course"]], "Use our template to create a repository": [[8, "use-our-template-to-create-a-repository"]], "Using OVR and OVO as wrappers": [[84, "using-ovr-and-ovo-as-wrappers"]], "Using SMOTE": [[81, "using-smote"]], "Using Silhouette scores to select the number of clusters": [[28, "using-silhouette-scores-to-select-the-number-of-clusters"], [72, "using-silhouette-scores-to-select-the-number-of-clusters"]], "Using multiple metrics in GridSearchCV or RandomizedSearchCV": [[24, "using-multiple-metrics-in-gridsearchcv-or-randomizedsearchcv"], [44, "using-multiple-metrics-in-gridsearchcv-or-randomizedsearchcv"], [68, "using-multiple-metrics-in-gridsearchcv-or-randomizedsearchcv"]], "Using pre-trained models as feature extractor": [[32, "using-pre-trained-models-as-feature-extractor"], [76, "using-pre-trained-models-as-feature-extractor"]], "Using pre-trained models out-of-the-box": [[32, "using-pre-trained-models-out-of-the-box"], [76, "using-pre-trained-models-out-of-the-box"]], "Using pre-trained word embeddings": [[31, "using-pre-trained-word-embeddings"], [51, "using-pre-trained-word-embeddings"], [75, "using-pre-trained-word-embeddings"]], "Using regression metrics with scikit-learn": [[24, "using-regression-metrics-with-scikit-learn"], [44, "using-regression-metrics-with-scikit-learn"], [68, "using-regression-metrics-with-scikit-learn"]], "Viewing the transformed data as a dataframe": [[19, "viewing-the-transformed-data-as-a-dataframe"], [64, "viewing-the-transformed-data-as-a-dataframe"]], "Visualization": [[10, "visualization"]], "Visualizing the parameter grid as a heatmap": [[22, "visualizing-the-parameter-grid-as-a-heatmap"], [42, "visualizing-the-parameter-grid-as-a-heatmap"], [66, "visualizing-the-parameter-grid-as-a-heatmap"]], "Visualizing your results": [[35, "visualizing-your-results"], [55, "visualizing-your-results"], [56, "visualizing-your-results"], [79, "visualizing-your-results"]], "Warning": [[14, null], [60, null]], "Warnings about feature selection": [[27, "warnings-about-feature-selection"], [27, "id7"], [47, "warnings-about-feature-selection"], [71, "warnings-about-feature-selection"], [82, "warnings-about-feature-selection"]], "Weaknesses": [[25, "weaknesses"], [45, "weaknesses"], [69, "weaknesses"]], "Web app on a real server": [[36, "web-app-on-a-real-server"], [57, "web-app-on-a-real-server"], [58, "web-app-on-a-real-server"], [80, "web-app-on-a-real-server"]], "Web app on local server": [[36, "web-app-on-local-server"], [57, "web-app-on-local-server"], [58, "web-app-on-local-server"], [80, "web-app-on-local-server"]], "What all transformations we need to apply on the dataset?": [[63, "what-all-transformations-we-need-to-apply-on-the-dataset"]], "What are AI, ML, and DL?": [[13, "what-are-ai-ml-and-dl"], [59, "what-are-ai-ml-and-dl"]], "What are Large Language Models (LLMs)?": [[31, "what-are-large-language-models-llms"], [51, "what-are-large-language-models-llms"], [75, "what-are-large-language-models-llms"]], "What are the options?": [[18, "what-are-the-options"], [63, "what-are-the-options"]], "What are the prerequisites for this class?": [[5, "what-are-the-prerequisites-for-this-class"]], "What are we exactly learning?": [[21, "what-are-we-exactly-learning"], [65, "what-are-we-exactly-learning"]], "What coding language and environment will we use?": [[5, "what-coding-language-and-environment-will-we-use"]], "What did we cover?": [[30, "what-did-we-cover"], [36, "what-did-we-cover"], [50, "what-did-we-cover"], [74, "what-did-we-cover"], [80, "what-did-we-cover"]], "What did we learn today?": [[15, "what-did-we-learn-today"], [18, "what-did-we-learn-today"], [19, "what-did-we-learn-today"], [24, "what-did-we-learn-today"], [35, "what-did-we-learn-today"], [56, "what-did-we-learn-today"], [61, "what-did-we-learn-today"], [63, "what-did-we-learn-today"], [64, "what-did-we-learn-today"], [67, "what-did-we-learn-today"], [68, "what-did-we-learn-today"], [79, "what-did-we-learn-today"]], "What does a typical week look like? What\u2019s the workload?": [[5, "what-does-a-typical-week-look-like-whats-the-workload"]], "What does this have to do with applied ML?": [[35, "what-does-this-have-to-do-with-applied-ml"], [56, "what-does-this-have-to-do-with-applied-ml"], [79, "what-does-this-have-to-do-with-applied-ml"]], "What does this mean for us, when we\u2019re trying to make claims about our data?": [[35, "what-does-this-mean-for-us-when-we-re-trying-to-make-claims-about-our-data"], [56, "what-does-this-mean-for-us-when-we-re-trying-to-make-claims-about-our-data"], [79, "what-does-this-mean-for-us-when-we-re-trying-to-make-claims-about-our-data"]], "What if we apply OHE?": [[19, "what-if-we-apply-ohe"], [64, "what-if-we-apply-ohe"]], "What is Natural Language Processing (NLP)?": [[31, "what-is-natural-language-processing-nlp"], [52, "what-is-natural-language-processing-nlp"], [75, "what-is-natural-language-processing-nlp"]], "What is a recommender system?": [[30, "what-is-a-recommender-system"], [74, "what-is-a-recommender-system"]], "What is clustering?": [[28, "what-is-clustering"], [72, "what-is-clustering"]], "What is deployment?": [[36, "what-is-deployment"], [80, "what-is-deployment"]], "What is feature engineering?": [[27, "what-is-feature-engineering"], [71, "what-is-feature-engineering"]], "What is feature selection?": [[27, "what-is-feature-selection"], [47, "what-is-feature-selection"], [71, "what-is-feature-selection"]], "What is grid search?": [[35, "what-is-grid-search"], [56, "what-is-grid-search"], [79, "what-is-grid-search"]], "What is model interpretability?": [[26, "what-is-model-interpretability"], [46, "what-is-model-interpretability"], [70, "what-is-model-interpretability"]], "What is supervised machine learning (ML)?": [[13, "what-is-supervised-machine-learning-ml"], [59, "what-is-supervised-machine-learning-ml"]], "What is \u201cpositive\u201d and \u201cnegative\u201d?": [[23, "what-is-positive-and-negative"], [43, "what-is-positive-and-negative"], [67, "what-is-positive-and-negative"]], "What kind of estimators can we combine?": [[25, "what-kind-of-estimators-can-we-combine"], [45, "what-kind-of-estimators-can-we-combine"], [69, "what-kind-of-estimators-can-we-combine"]], "What next?": [[36, "what-next"], [80, "what-next"]], "What should be the loss? (Activity: 4 mins)": [[35, "what-should-be-the-loss-activity-4-mins"], [56, "what-should-be-the-loss-activity-4-mins"], [79, "what-should-be-the-loss-activity-4-mins"]], "What to look for in these plots?": [[28, "what-to-look-for-in-these-plots"], [72, "what-to-look-for-in-these-plots"]], "What transformations do we need to apply on the dataset?": [[18, "what-transformations-do-we-need-to-apply-on-the-dataset"]], "What will the exams be like?": [[5, "what-will-the-exams-be-like"]], "What\u2019s the problem?": [[18, "what-s-the-problem"], [63, "what-s-the-problem"]], "When can we use broadcasting?": [[9, "when-can-we-use-broadcasting"]], "When experimenting, show the results asap": [[35, "when-experimenting-show-the-results-asap"], [56, "when-experimenting-show-the-results-asap"], [79, "when-experimenting-show-the-results-asap"]], "When is it OK to do things before splitting?": [[18, "when-is-it-ok-to-do-things-before-splitting"], [63, "when-is-it-ok-to-do-things-before-splitting"]], "When test score is much lower than CV score": [[22, "when-test-score-is-much-lower-than-cv-score"], [66, "when-test-score-is-much-lower-than-cv-score"]], "Which model is doing better in this scenario: SVC or Logistic Regression?": [[23, "which-model-is-doing-better-in-this-scenario-svc-or-logistic-regression"], [43, "which-model-is-doing-better-in-this-scenario-svc-or-logistic-regression"]], "Which model should I use?": [[25, "which-model-should-i-use"], [45, "which-model-should-i-use"], [69, "which-model-should-i-use"]], "Which type of error is more important?": [[67, "which-type-of-error-is-more-important"]], "Which types of errors would be most critical for the bank to address?": [[23, "which-types-of-errors-would-be-most-critical-for-the-bank-to-address"], [43, "which-types-of-errors-would-be-most-critical-for-the-bank-to-address"]], "Who takes this course?": [[5, "who-takes-this-course"]], "Why do we need a test set?": [[22, "why-do-we-need-a-test-set"], [66, "why-do-we-need-a-test-set"]], "Why do we want this information?": [[26, "why-do-we-want-this-information"], [46, "why-do-we-want-this-information"], [70, "why-do-we-want-this-information"]], "Why does it matter": [[15, "why-does-it-matter"]], "Why feature selection?": [[27, "why-feature-selection"], [47, "why-feature-selection"], [71, "why-feature-selection"]], "Why machine learning (ML)? [video]": [[13, "why-machine-learning-ml-video"], [59, "why-machine-learning-ml-video"]], "Why model transparency/interpretability?": [[26, "why-model-transparency-interpretability"], [46, "why-model-transparency-interpretability"], [70, "why-model-transparency-interpretability"]], "Why neural networks?": [[32, "why-neural-networks"], [76, "why-neural-networks"]], "Why not neural networks?": [[32, "why-not-neural-networks"], [76, "why-not-neural-networks"]], "Why should I use it?": [[35, "why-should-i-use-it"], [56, "why-should-i-use-it"], [79, "why-should-i-use-it"]], "Why should we care about effective communication?": [[35, "why-should-we-care-about-effective-communication"], [56, "why-should-we-care-about-effective-communication"], [79, "why-should-we-care-about-effective-communication"]], "Why should we care about recommendation systems?": [[30, "why-should-we-care-about-recommendation-systems"], [74, "why-should-we-care-about-recommendation-systems"]], "Why sparse matrices?": [[19, "why-sparse-matrices"], [64, "why-sparse-matrices"]], "Windows Users": [[6, "windows-users"]], "Word embeddings": [[52, "word-embeddings"]], "Word embeddings: The idea": [[31, "word-embeddings-the-idea"], [51, "word-embeddings-the-idea"], [75, "word-embeddings-the-idea"]], "Word vectors with spaCy": [[52, "word-vectors-with-spacy"]], "Writing a traditional program to predict quiz2 grade": [[14, "writing-a-traditional-program-to-predict-quiz2-grade"], [60, "writing-a-traditional-program-to-predict-quiz2-grade"]], "XGBoost": [[25, "xgboost"], [45, "xgboost"], [69, "xgboost"]], "[] notation": [[9, "notation"]], "class_weight=\"balanced\"": [[67, "class-weight-balanced"]], "cross_val_score": [[61, "cross-val-score"]], "cross_validate": [[15, "cross-validate"], [61, "cross-validate"]], "fit and transform paradigm for transformers": [[18, "fit-and-transform-paradigm-for-transformers"], [63, "fit-and-transform-paradigm-for-transformers"]], "fit the classifier": [[14, "fit-the-classifier"], [60, "fit-the-classifier"]], "fit, predict , and score summary": [[14, "fit-predict-and-score-summary"], [60, "fit-predict-and-score-summary"]], "iClciker exercise": [[50, "iclciker-exercise"]], "iClicker": [[99, "iclicker"]], "iClicker (for attendance)": [[26, "iclicker-for-attendance"]], "iClicker Exercise": [[32, "iclicker-exercise"], [32, "id1"], [76, "iclicker-exercise"]], "iClicker Exercise 1.1": [[59, "iclicker-exercise-1-1"]], "iClicker Exercise 10.1": [[24, "iclicker-exercise-10-1"], [68, "iclicker-exercise-10-1"]], "iClicker Exercise 10.2": [[24, "iclicker-exercise-10-2"], [68, "iclicker-exercise-10-2"]], "iClicker Exercise 11.0": [[69, "iclicker-exercise-11-0"]], "iClicker Exercise 11.1": [[45, "iclicker-exercise-11-1"], [69, "iclicker-exercise-11-1"]], "iClicker Exercise 12.1": [[25, "iclicker-exercise-12-1"]], "iClicker Exercise 14.1": [[27, "iclicker-exercise-14-1"], [71, "iclicker-exercise-14-1"]], "iClicker Exercise 2.1 Supervised vs unsupervised": [[14, "iclicker-exercise-2-1-supervised-vs-unsupervised"]], "iClicker Exercise 2.2 Classification vs regression": [[14, "iclicker-exercise-2-2-classification-vs-regression"]], "iClicker Exercise 2.2 Supervised vs unsupervised": [[60, "iclicker-exercise-2-2-supervised-vs-unsupervised"]], "iClicker Exercise 2.3 - Find the root node": [[14, "iclicker-exercise-2-3-find-the-root-node"]], "iClicker Exercise 2.3 Classification vs regression": [[60, "iclicker-exercise-2-3-classification-vs-regression"]], "iClicker Exercise 2.4: Baselines and decision trees": [[14, "iclicker-exercise-2-4-baselines-and-decision-trees"]], "iClicker Exercise 2.5: Baselines and decision trees": [[60, "iclicker-exercise-2-5-baselines-and-decision-trees"]], "iClicker Exercise 3.1": [[15, "iclicker-exercise-3-1"], [61, "iclicker-exercise-3-1"]], "iClicker Exercise 3.2": [[15, "iclicker-exercise-3-2"], [61, "iclicker-exercise-3-2"]], "iClicker Exercise 9.1": [[67, "iclicker-exercise-9-1"]], "iClicker Exercise 9.2": [[67, "iclicker-exercise-9-2"]], "iClicker questions": [[35, "iclicker-questions"]], "iClicker: Precision score": [[23, "iclicker-precision-score"]], "iClicker: Recall score": [[23, "iclicker-recall-score"]], "k-Nearest Neighbours (k-NNs) [video]": [[16, "k-nearest-neighbours-k-nns-video"], [62, "k-nearest-neighbours-k-nns-video"]], "k-nearest neighbours imputation": [[30, "k-nearest-neighbours-imputation"], [50, "k-nearest-neighbours-imputation"], [74, "k-nearest-neighbours-imputation"]], "macOS": [[6, "macos"]], "n_iter": [[22, "n-iter"], [42, "n-iter"], [66, "n-iter"]], "n_jobs=-1": [[22, "n-jobs-1"], [42, "n-jobs-1"], [66, "n-jobs-1"]], "pandas_profiler": [[24, "pandas-profiler"], [44, "pandas-profiler"], [68, "pandas-profiler"]], "predict the target of given examples": [[14, "predict-the-target-of-given-examples"], [60, "predict-the-target-of-given-examples"]], "predict_proba": [[21, "predict-proba"], [65, "predict-proba"]], "random_state argument": [[61, "random-state-argument"]], "score your model": [[14, "score-your-model"], [60, "score-your-model"]], "sklearn API summary: estimators": [[17, "sklearn-api-summary-estimators"], [18, "sklearn-api-summary-estimators"], [63, "sklearn-api-summary-estimators"]], "sklearn API summary: transformers": [[17, "sklearn-api-summary-transformers"], [18, "sklearn-api-summary-transformers"], [63, "sklearn-api-summary-transformers"]], "sklearn Transformers vs Estimators": [[40, "sklearn-transformers-vs-estimators"]], "sklearn set_config": [[19, "sklearn-set-config"], [64, "sklearn-set-config"]], "sklearn\u2019s ColumnTransformer": [[19, "sklearn-s-columntransformer"], [64, "sklearn-s-columntransformer"]], "sklearn\u2019s SimpleImputer": [[17, "sklearn-s-simpleimputer"], [40, "sklearn-s-simpleimputer"]], "sklearn\u2019s feature_importances_ and permutation_importance": [[26, "sklearn-s-feature-importances-and-permutation-importance"], [46, "sklearn-s-feature-importances-and-permutation-importance"], [70, "sklearn-s-feature-importances-and-permutation-importance"]], "sklearn\u2019s feature_importances_ attribute vs permutation_importance": [[26, "sklearn-s-feature-importances-attribute-vs-permutation-importance"], [46, "sklearn-s-feature-importances-attribute-vs-permutation-importance"], [70, "sklearn-s-feature-importances-attribute-vs-permutation-importance"]], "test score vs. cross-validation score": [[61, "test-score-vs-cross-validation-score"]], "test_size, train_size arguments": [[61, "test-size-train-size-arguments"]], "\u201cDeployment\u201d data": [[15, "deployment-data"], [61, "deployment-data"]], "\u2753\u2753 Question for you": [[30, "question-for-you"], [30, "id1"]], "\u2753\u2753 Questions for group discussion": [[67, "questions-for-group-discussion"]], "\u2753\u2753 Questions for you": [[13, "questions-for-you"], [14, "questions-for-you"], [15, "questions-for-you"], [15, "id1"], [16, "questions-for-you"], [16, "id1"], [18, "questions-for-you"], [18, "id1"], [18, "id2"], [19, "questions-for-you"], [19, "id1"], [20, "questions-for-you"], [21, "questions-for-you"], [21, "id1"], [22, "questions-for-you"], [22, "id2"], [24, "questions-for-you"], [24, "id2"], [25, "questions-for-you"], [27, "questions-for-you"], [28, "questions-for-you"], [28, "id2"], [29, "questions-for-you"], [29, "id3"], [30, "questions-for-you"], [32, "questions-for-you"], [33, "questions-for-you"], [33, "id1"], [33, "id2"], [34, "questions-for-you"], [34, "id1"], [34, "id2"], [34, "id3"], [34, "id4"], [35, "questions-for-you"], [36, "questions-for-you"], [36, "id2"], [38, "questions-for-you"], [38, "id2"], [38, "id3"], [40, "questions-for-you"], [40, "id1"], [41, "questions-for-you"], [45, "questions-for-you"], [45, "id1"], [50, "questions-for-you"], [50, "id1"], [50, "id2"], [53, "questions-for-you"], [56, "questions-for-you"], [56, "id1"], [59, "questions-for-you"], [60, "questions-for-you"], [60, "id1"], [60, "id3"], [61, "questions-for-you"], [61, "id1"], [62, "questions-for-you"], [62, "id1"], [63, "questions-for-you"], [63, "id1"], [63, "id2"], [64, "questions-for-you"], [64, "id1"], [65, "questions-for-you"], [65, "id1"], [65, "id2"], [66, "questions-for-you"], [66, "id2"], [67, "questions-for-you"], [67, "id2"], [68, "questions-for-you"], [68, "id2"], [69, "questions-for-you"], [69, "id1"], [69, "id2"], [71, "questions-for-you"], [72, "questions-for-you"], [72, "id2"], [73, "questions-for-you"], [73, "id3"], [74, "questions-for-you"], [74, "id1"], [74, "id2"], [76, "questions-for-you"], [77, "questions-for-you"], [77, "id1"], [77, "id2"], [77, "id3"], [78, "questions-for-you"], [78, "id1"], [78, "id2"], [78, "id3"], [78, "id4"], [79, "questions-for-you"], [79, "id1"], [80, "questions-for-you"], [80, "id2"]], "\ud83e\udd14 Eva\u2019s questions": [[13, "eva-s-questions"], [59, "eva-s-questions"], [61, "eva-s-questions"]]}, "docnames": ["LICENSE", "README", "docs/330_vs_340", "docs/README", "docs/asking_for_help", "docs/faq", "docs/git_installation", "docs/grades", "docs/homework_instructions", "docs/python_notes", "docs/resources", "docs/setup", "learning-objectives", "lectures/101-103-Giulia-lectures/01_intro", "lectures/101-103-Giulia-lectures/02_terminology-decision-trees", "lectures/101-103-Giulia-lectures/03_ml-fundamentals", "lectures/101-103-Giulia-lectures/04_kNNs-SVM-RBF", "lectures/101-103-Giulia-lectures/05-06-preprocessing-demo", "lectures/101-103-Giulia-lectures/05_preprocessing-pipelines", "lectures/101-103-Giulia-lectures/06_column-transformer-text-feats", "lectures/101-103-Giulia-lectures/07_class-demo", "lectures/101-103-Giulia-lectures/07_linear-models", "lectures/101-103-Giulia-lectures/08_hyperparameter-optimization", "lectures/101-103-Giulia-lectures/09-classification-metrics-short", "lectures/101-103-Giulia-lectures/10_regression-metrics", "lectures/101-103-Giulia-lectures/11_ensembles", "lectures/101-103-Giulia-lectures/12_feat-importances", "lectures/101-103-Giulia-lectures/13_feature-engineering-selection", "lectures/101-103-Giulia-lectures/14_K-Means", "lectures/101-103-Giulia-lectures/15_DBSCAN-hierarchical", "lectures/101-103-Giulia-lectures/16_recommender-systems", "lectures/101-103-Giulia-lectures/17_natural-language-processing", "lectures/101-103-Giulia-lectures/18_intro_to_computer-vision", "lectures/101-103-Giulia-lectures/19_time-series", "lectures/101-103-Giulia-lectures/20_survival-analysis", "lectures/101-103-Giulia-lectures/21_communication", "lectures/101-103-Giulia-lectures/23_deployment-conclusion", "lectures/102-Varada-lectures/README", "lectures/102-Varada-lectures/class_demos/demo_03-ml-fundamentals", "lectures/102-Varada-lectures/class_demos/demo_04-kNNs-SVMs", "lectures/102-Varada-lectures/class_demos/demo_05-06-preprocessing", "lectures/102-Varada-lectures/class_demos/demo_07-linear-models", "lectures/102-Varada-lectures/class_demos/demo_08-hyperparameter-optimization", "lectures/102-Varada-lectures/class_demos/demo_09-classification-metrics", "lectures/102-Varada-lectures/class_demos/demo_10-regression-metrics", "lectures/102-Varada-lectures/class_demos/demo_11-ensembles", "lectures/102-Varada-lectures/class_demos/demo_12-feat-importances", "lectures/102-Varada-lectures/class_demos/demo_13-feature-engineering-selection", "lectures/102-Varada-lectures/class_demos/demo_14-k-means", "lectures/102-Varada-lectures/class_demos/demo_15-dbscan-hierarchical", "lectures/102-Varada-lectures/class_demos/demo_16-recommender-systems", "lectures/102-Varada-lectures/class_demos/demo_17-natural-language-processing", "lectures/102-Varada-lectures/class_demos/demo_18-natural-language-processing", "lectures/102-Varada-lectures/class_demos/demo_19_time-series", "lectures/102-Varada-lectures/class_demos/demo_20-survival-analysis", "lectures/102-Varada-lectures/class_demos/demo_21-communication", "lectures/102-Varada-lectures/class_demos/demo_22-communication", "lectures/102-Varada-lectures/class_demos/demo_23-deployment-conclusion", "lectures/102-Varada-lectures/class_demos/demo_24-deployment-conclusion", "lectures/notes/01_intro", "lectures/notes/02_terminology-decision-trees", "lectures/notes/03_ml-fundamentals", "lectures/notes/04_kNNs-SVM-RBF", "lectures/notes/05_preprocessing-pipelines", "lectures/notes/06_column-transformer-text-feats", "lectures/notes/07_linear-models", "lectures/notes/08_hyperparameter-optimization", "lectures/notes/09_classification-metrics", "lectures/notes/10_regression-metrics", "lectures/notes/11_ensembles", "lectures/notes/12_feat-importances", "lectures/notes/13_feature-engineering-selection", "lectures/notes/14_K-Means", "lectures/notes/15_DBSCAN-hierarchical", "lectures/notes/16_recommender-systems", "lectures/notes/17_natural-language-processing", "lectures/notes/18_intro_to_computer-vision", "lectures/notes/19_time-series", "lectures/notes/20_survival-analysis", "lectures/notes/21_communication", "lectures/notes/23_deployment-conclusion", "lectures/notes/AppendixA", "lectures/notes/AppendixB", "lectures/notes/AppendixC", "lectures/notes/AppendixD", "lectures/notes/final-exam-review-guiding-question", "lectures/tutorials/01_decision_boundaries", "lectures/tutorials/02_ML_fundamentals", "lectures/tutorials/03_Preprocessing", "lectures/tutorials/06_Ensembles", "lectures/tutorials/07_clustering", "lectures/tutorials/08_Time_series", "lectures/tutorials/solutions/01_decision_boundaries_solution", "lectures/tutorials/solutions/02_ML_fundamentals", "lectures/tutorials/solutions/03_Preprocessing", "lectures/tutorials/solutions/06_Ensembles_solution", "lectures/tutorials/solutions/07_clustering_sol", "lectures/tutorials/solutions/08_Time_series_sol", "lectures/web_api/Untitled", "syllabus"], "envversion": {"sphinx": 62, "sphinx.domains.c": 3, "sphinx.domains.changeset": 1, "sphinx.domains.citation": 1, "sphinx.domains.cpp": 9, "sphinx.domains.index": 1, "sphinx.domains.javascript": 3, "sphinx.domains.math": 2, "sphinx.domains.python": 4, "sphinx.domains.rst": 2, "sphinx.domains.std": 2, "sphinx.ext.intersphinx": 1}, "filenames": ["LICENSE.md", "README.md", "docs/330_vs_340.md", "docs/README.md", "docs/asking_for_help.md", "docs/faq.md", "docs/git_installation.md", "docs/grades.md", "docs/homework_instructions.md", "docs/python_notes.ipynb", "docs/resources.md", "docs/setup.md", "learning-objectives.md", "lectures/101-103-Giulia-lectures/01_intro.ipynb", "lectures/101-103-Giulia-lectures/02_terminology-decision-trees.ipynb", "lectures/101-103-Giulia-lectures/03_ml-fundamentals.ipynb", "lectures/101-103-Giulia-lectures/04_kNNs-SVM-RBF.ipynb", "lectures/101-103-Giulia-lectures/05-06-preprocessing-demo.ipynb", "lectures/101-103-Giulia-lectures/05_preprocessing-pipelines.ipynb", "lectures/101-103-Giulia-lectures/06_column-transformer-text-feats.ipynb", "lectures/101-103-Giulia-lectures/07_class-demo.ipynb", "lectures/101-103-Giulia-lectures/07_linear-models.ipynb", "lectures/101-103-Giulia-lectures/08_hyperparameter-optimization.ipynb", "lectures/101-103-Giulia-lectures/09-classification-metrics-short.ipynb", "lectures/101-103-Giulia-lectures/10_regression-metrics.ipynb", "lectures/101-103-Giulia-lectures/11_ensembles.ipynb", "lectures/101-103-Giulia-lectures/12_feat-importances.ipynb", "lectures/101-103-Giulia-lectures/13_feature-engineering-selection.ipynb", "lectures/101-103-Giulia-lectures/14_K-Means.ipynb", "lectures/101-103-Giulia-lectures/15_DBSCAN-hierarchical.ipynb", "lectures/101-103-Giulia-lectures/16_recommender-systems.ipynb", "lectures/101-103-Giulia-lectures/17_natural-language-processing.ipynb", "lectures/101-103-Giulia-lectures/18_intro_to_computer-vision.ipynb", "lectures/101-103-Giulia-lectures/19_time-series.ipynb", "lectures/101-103-Giulia-lectures/20_survival-analysis.ipynb", "lectures/101-103-Giulia-lectures/21_communication.ipynb", "lectures/101-103-Giulia-lectures/23_deployment-conclusion.ipynb", "lectures/102-Varada-lectures/README.md", "lectures/102-Varada-lectures/class_demos/demo_03-ml-fundamentals.ipynb", "lectures/102-Varada-lectures/class_demos/demo_04-kNNs-SVMs.ipynb", "lectures/102-Varada-lectures/class_demos/demo_05-06-preprocessing.ipynb", "lectures/102-Varada-lectures/class_demos/demo_07-linear-models.ipynb", "lectures/102-Varada-lectures/class_demos/demo_08-hyperparameter-optimization.ipynb", "lectures/102-Varada-lectures/class_demos/demo_09-classification-metrics.ipynb", "lectures/102-Varada-lectures/class_demos/demo_10-regression-metrics.ipynb", "lectures/102-Varada-lectures/class_demos/demo_11-ensembles.ipynb", "lectures/102-Varada-lectures/class_demos/demo_12-feat-importances.ipynb", "lectures/102-Varada-lectures/class_demos/demo_13-feature-engineering-selection.ipynb", "lectures/102-Varada-lectures/class_demos/demo_14-k-means.ipynb", "lectures/102-Varada-lectures/class_demos/demo_15-dbscan-hierarchical.ipynb", "lectures/102-Varada-lectures/class_demos/demo_16-recommender-systems.ipynb", "lectures/102-Varada-lectures/class_demos/demo_17-natural-language-processing.ipynb", "lectures/102-Varada-lectures/class_demos/demo_18-natural-language-processing.ipynb", "lectures/102-Varada-lectures/class_demos/demo_19_time-series.ipynb", "lectures/102-Varada-lectures/class_demos/demo_20-survival-analysis.ipynb", "lectures/102-Varada-lectures/class_demos/demo_21-communication.ipynb", "lectures/102-Varada-lectures/class_demos/demo_22-communication.ipynb", "lectures/102-Varada-lectures/class_demos/demo_23-deployment-conclusion.ipynb", "lectures/102-Varada-lectures/class_demos/demo_24-deployment-conclusion.ipynb", "lectures/notes/01_intro.ipynb", "lectures/notes/02_terminology-decision-trees.ipynb", "lectures/notes/03_ml-fundamentals.ipynb", "lectures/notes/04_kNNs-SVM-RBF.ipynb", "lectures/notes/05_preprocessing-pipelines.ipynb", "lectures/notes/06_column-transformer-text-feats.ipynb", "lectures/notes/07_linear-models.ipynb", "lectures/notes/08_hyperparameter-optimization.ipynb", "lectures/notes/09_classification-metrics.ipynb", "lectures/notes/10_regression-metrics.ipynb", "lectures/notes/11_ensembles.ipynb", "lectures/notes/12_feat-importances.ipynb", "lectures/notes/13_feature-engineering-selection.ipynb", "lectures/notes/14_K-Means.ipynb", "lectures/notes/15_DBSCAN-hierarchical.ipynb", "lectures/notes/16_recommender-systems.ipynb", "lectures/notes/17_natural-language-processing.ipynb", "lectures/notes/18_intro_to_computer-vision.ipynb", "lectures/notes/19_time-series.ipynb", "lectures/notes/20_survival-analysis.ipynb", "lectures/notes/21_communication.ipynb", "lectures/notes/23_deployment-conclusion.ipynb", "lectures/notes/AppendixA.ipynb", "lectures/notes/AppendixB.ipynb", "lectures/notes/AppendixC.ipynb", "lectures/notes/AppendixD.ipynb", "lectures/notes/final-exam-review-guiding-question.ipynb", "lectures/tutorials/01_decision_boundaries.ipynb", "lectures/tutorials/02_ML_fundamentals.ipynb", "lectures/tutorials/03_Preprocessing.ipynb", "lectures/tutorials/06_Ensembles.ipynb", "lectures/tutorials/07_clustering.ipynb", "lectures/tutorials/08_Time_series.ipynb", "lectures/tutorials/solutions/01_decision_boundaries_solution.ipynb", "lectures/tutorials/solutions/02_ML_fundamentals.ipynb", "lectures/tutorials/solutions/03_Preprocessing.ipynb", "lectures/tutorials/solutions/06_Ensembles_solution.ipynb", "lectures/tutorials/solutions/07_clustering_sol.ipynb", "lectures/tutorials/solutions/08_Time_series_sol.ipynb", "lectures/web_api/Untitled.ipynb", "syllabus.md"], "indexentries": {}, "objects": {}, "objnames": {}, "objtypes": {}, "terms": {"": [1, 4, 6, 8, 9, 10, 11, 14, 15, 20, 21, 22, 25, 27, 28, 29, 30, 31, 32, 33, 34, 36, 38, 39, 41, 42, 45, 47, 49, 50, 51, 52, 57, 58, 60, 65, 66, 69, 71, 72, 73, 74, 75, 76, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 99], "0": [0, 1, 8, 9, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99], "00": [1, 15, 17, 19, 20, 21, 22, 23, 26, 29, 30, 33, 34, 35, 38, 40, 41, 42, 43, 46, 50, 53, 56, 59, 60, 62, 64, 65, 66, 67, 70, 73, 74, 77, 78, 79, 81, 91, 96, 97, 99], "000": [15, 16, 18, 20, 21, 22, 24, 25, 26, 28, 31, 32, 34, 41, 42, 44, 45, 46, 51, 52, 59, 61, 62, 63, 64, 65, 66, 68, 69, 70, 75, 76, 78, 93], "0000": [18, 20, 21, 23, 31, 41, 43, 52, 63, 65, 67, 75], "00000": [20, 22, 41, 42, 53, 66, 77, 97], "000000": [14, 15, 16, 17, 18, 19, 22, 23, 24, 25, 26, 27, 29, 30, 32, 33, 34, 38, 39, 40, 42, 43, 44, 45, 46, 47, 50, 53, 60, 61, 62, 63, 64, 66, 67, 68, 69, 70, 71, 73, 74, 76, 77, 78, 93, 95, 96, 97], "00000000e": [26, 46, 70], "000000e": [17, 40, 66, 96], "000001": 24, "00000e": 62, "000010": 24, "000011": [23, 34, 43, 67], "000012": 42, "000013": 42, "000021": [18, 63], "000022": 42, "000036": [23, 42, 43, 67], "000038": 66, "000039": [32, 76], "000042": 42, "000044": 34, "000045": 42, "000047": 66, "000057": [18, 63], "000058": 66, "000079": 66, "000088": 42, "000090": 66, "000091": 66, "000094": 42, "000096": 65, "0001": [21, 24, 34, 35, 41, 43, 45, 56, 65, 67, 68, 69, 76, 78, 79, 95], "000100": [18, 24, 63], "000102": 65, "000102e": [15, 38], "000108": [32, 76], "000113": [23, 43, 67], "000117": [24, 39, 44, 68], "000124": 21, "000126": 66, "000128": [39, 65], "000130": 39, "000131": 66, "000134": 21, "000142": [32, 65, 76], "000146": 42, "000148": 42, "000149": [18, 63], "000150": 68, "000151": 68, "000153": [66, 68], "000155": [18, 23, 43, 63, 67], "000156": [42, 65, 68], "000157": [66, 68], "000161": [21, 32, 76], "000163": [39, 66], "000165": 21, "000166": 65, "000169": 39, "000170": 21, "000176": [42, 68], "000177": 66, "000179": 42, "000182": 42, "000184": 39, "000187": [39, 42, 68], "000189": 65, "000197": 21, "000198": [23, 43, 67, 77], "000201": 77, "000207": 21, "000208": [18, 63], "000210": 65, "000212": [39, 71], "000216": 68, "000220": 66, "000221": 77, "000224": 42, "000227": [23, 43, 67], "000228": 42, "000230": 65, "000233": 39, "000234": [22, 42, 62, 66], "000235": [23, 39, 43, 67], "000236": 39, "000241": [39, 77], "000243": 65, "000245": [22, 42, 66], "000248": 39, "000252": 68, "000260": 63, "000261": [32, 76], "000264": 63, "000267": 63, "000270": 39, "000273": 65, "000280": 40, "000281": 39, "000283": 42, "000286": 66, "000287": [42, 44], "000289": [18, 32, 63, 76], "000291": [39, 40], "000294": 63, "000296": [39, 40], "000297": [44, 68], "000301": 65, "000303": 77, "000304": 39, "000305": 44, "000310": 39, "000312": [23, 43, 67], "000313": 39, "000316": 39, "000318": 65, "000320": 65, "000328": 39, "000329": 39, "000331": 63, "000335": 44, "000336": 21, "000337": 39, "000342": [32, 76], "000343": 65, "000346": 65, "000348": 63, "000350": [32, 39, 40, 76], "000353": 66, "000356": 66, "000361": 42, "000365": 44, "000366": [23, 43, 67], "000374": 39, "000379": 40, "00038": [22, 42, 66], "000380": 39, "000381": 42, "000384": 21, "000385": 65, "000386": [21, 39], "000387": 39, "000389": 40, "000390": 44, "000392": 40, "000396": [32, 40, 76], "000397": [24, 44, 68], "000401": 61, "000404": 61, "000407": 61, "000408": 61, "000409": 61, "000410": [61, 63], "000415": 21, "000416": 61, "000417": 61, "000419": 21, "000420": 39, "000422": 47, "000423": [32, 39, 61, 76], "000426": 42, "000428": 39, "000432": 39, "000434": [21, 61], "000438": 68, "000440": 61, "000441": 39, "000443": 61, "000446": 68, "000447": 68, "000448": 68, "000451": 61, "000452": 61, "000457": 63, "000459": [32, 76], "000460": 39, "000471": 40, "000475": 39, "000480": 39, "000486": [32, 76], "000488": 61, "000492": [23, 43, 65, 67], "000497": [32, 76], "000498": 66, "0005": [35, 56, 79], "000503": 66, "000504": 68, "000508": 66, "000514": 62, "000517": [61, 62], "000520": [39, 62], "000522": 68, "000536": 61, "000538": [61, 62], "000540": 39, "000544": [39, 61], "000546": [42, 62], "000557": [39, 62], "000559": 61, "000562": 61, "000565": [61, 62], "000568": 62, "00057": 42, "000570": 61, "000574": 61, "000575": 44, "000577": 61, "000578": 61, "00058": [22, 42, 66], "000584": 61, "000585": 61, "000586": 61, "000588": 62, "000589": 62, "000590": 21, "000592": 61, "000593": 61, "000599": 62, "000601": 66, "000608": 62, "000610": [21, 61], "000611": 44, "000622": 66, "000628": [32, 76], "000629": 63, "000630": [23, 24, 43, 62, 65, 67], "000636": [32, 76], "000643": [32, 76], "000646": 38, "00064647": 38, "000651": 62, "000653": [61, 62], "000654": 68, "000668": 66, "000681": 61, "000685": 39, "000693": 41, "000706": 41, "000724": 68, "000725": 61, "000726": [23, 43, 67], "000728": 24, "000740": 61, "000743": 40, "000747": 66, "000772": 61, "000773": [32, 76], "000781": [32, 76], "000786": [23, 43, 67], "00079": [22, 42, 66], "000791": 42, "000796": 38, "00079645": 38, "000801": 27, "000803": 62, "000804": 63, "000807": 38, "00080741": 38, "000812": 39, "000820": 62, "000826": 62, "000827": 62, "000828": 77, "000830": 44, "000838": 62, "000839": [39, 62], "000853": 62, "000855": 66, "000856": 63, "000858": 63, "000859": 62, "000877": 62, "000890": 39, "000891": 67, "000893": 63, "000895": 62, "000896": 62, "000900": 62, "000909": 39, "000916": 44, "000917": 66, "000927": [20, 23, 41, 43, 67], "000934": 39, "000939": 43, "000945": 71, "000947": 62, "000948": 61, "000954": 44, "000963": 68, "000964": 71, "000976": 66, "000977": 44, "000978": 42, "000982": [22, 42, 66], "000984": 44, "000986": 66, "000987": [32, 76], "000995": 33, "000997": 24, "001": [16, 18, 20, 21, 22, 24, 25, 26, 32, 34, 35, 41, 42, 43, 45, 46, 56, 59, 61, 62, 63, 64, 65, 66, 69, 70, 76, 78, 79, 95], "0010": [21, 65], "00100": [22, 42, 66], "001000": [22, 24, 42, 66], "001001": 24, "001002": 24, "001003": 33, "001004": 24, "001011": [16, 33], "001019": 18, "001060": [18, 63], "001061": 41, "001063": 38, "00106308": 38, "001068": [26, 46, 70], "001070": 44, "001077": 44, "001084": 21, "001087": 71, "001109": 39, "001124": 66, "001132": [23, 43], "001155": 71, "001162": [22, 42, 66, 71], "001170": 44, "001176": 41, "001180": [32, 76], "001184": 62, "001205": [23, 43, 67], "001220": 62, "001226": 63, "001228": 63, "001230": 39, "001239": [23, 43, 67], "001248": 62, "001249": [54, 78], "001252": 42, "001264": 62, "001265": 63, "001266": [24, 44, 68], "001268": 62, "001275": 63, "001279": 71, "001283": 21, "001286": [23, 43, 67], "001291": 42, "001302": 63, "001326": [32, 76], "001354": 19, "001363": 47, "001370": [32, 76], "001375": 39, "001379": 42, "001419": [32, 39, 76], "001428": 62, "001487": 62, "001506": 33, "001507": 42, "001509": 47, "00151": 66, "001510": 33, "001519": 33, "001522": [32, 39, 76], "001529": 64, "001535": 66, "001548": 44, "001549": 39, "001553": [63, 64], "001566": 39, "001573": 39, "001590": 64, "001593": 47, "001594": [22, 42, 64, 66], "001596": [42, 64], "001615": 64, "001622": 47, "001636": [42, 66], "001652": 62, "001662": 44, "001675": 47, "00168": 66, "001687": 39, "001693": 71, "001695": 42, "001699": 42, "0017": [23, 43, 67], "001700": [23, 43, 67], "001706": 66, "001712": 42, "001713": 66, "001714": 42, "001715": 42, "001726": 42, "001729": 66, "001740": [24, 44, 68], "001745": 41, "001758": 42, "001778": 64, "001781": 64, "001792": [22, 42, 66], "001799": 47, "001806": 44, "001818": 65, "001833": 64, "001834": 66, "001835": 66, "001842": 66, "001843": 64, "001847": 71, "001850": 65, "001851": 66, "001864": 62, "001867": [32, 76], "001871": [42, 65], "001877": 47, "001882": 39, "001883": 64, "001886": 95, "001907": 39, "001919": 95, "001934": 47, "001936": 95, "001948": 64, "001949": 71, "001962": 42, "0019627847": 31, "0019627889": [51, 52, 75], "001965": 42, "001967": 95, "001972": 95, "001976": 95, "001977": 95, "001982": 65, "001987": 67, "001988": 66, "001990": 18, "001991": 95, "001994": 71, "001995": [23, 43], "002": [18, 21, 25, 26, 31, 34, 45, 46, 51, 52, 64, 65, 69, 70, 75, 78], "002002": 24, "002004": 24, "002007": 18, "002008": 95, "002012": 18, "002014": 18, "002034": 95, "002038": 42, "002043": 95, "002048": 47, "002055": 95, "002057": [18, 63, 64, 94], "002062": 95, "002064": 47, "002080": 95, "002082": 47, "002089": 42, "002102": 42, "002105": [22, 42, 66], "002108": 65, "002126": 42, "002128": 42, "002137": 21, "002141": 47, "002153": 66, "002157": 18, "002158": 71, "002191": 66, "002196": 65, "002202": 18, "002241": 66, "002250": 95, "002272": 42, "002274": 21, "002284": 42, "002292": 21, "002293": [32, 76], "002301": 18, "002321": 39, "002326": 66, "002334": 47, "002339": 95, "002354": 65, "002355": [42, 71], "002357": 95, "002369": 66, "002393": 95, "002402": 64, "002416": 39, "002418": 39, "002440": 39, "002441": 71, "002473": 95, "002477": [21, 39], "002505": 18, "002531": [66, 95], "002533": 66, "002554": 42, "002561": [22, 42, 66], "002570": 95, "002576": 64, "002618": 21, "002628": 42, "002640": 95, "002643": 39, "002646": 71, "002664": 71, "002670": 65, "002675": 47, "00269": 42, "002690": [18, 63], "002705": 66, "002709": 95, "002775": 95, "002802": 39, "002805": 64, "002813": 77, "002824": 95, "002827": 64, "002845": 42, "002848": 39, "002854": 42, "002866": 66, "002867": 71, "002886": 66, "002889": 67, "002893": 64, "0029": [34, 78], "002906": 47, "002908": [63, 65], "002921": 39, "002926": 66, "002951": 64, "002952": 38, "00295235": 38, "002957": 42, "002965": 39, "002974": 21, "002987": 39, "002995": 63, "002999": [16, 66], "003": [18, 25, 26, 45, 46, 66, 69, 70], "003000": 24, "003002": 33, "003011": 64, "003018": 95, "003024": [32, 76], "003037": [39, 63], "003039": 42, "00304": 66, "003043": 42, "003044": [39, 42], "003047": 42, "003051": 66, "003057": [17, 42], "003059": 63, "003070": 18, "003071": 43, "003082": 64, "003087": 42, "003088": 39, "003092": 66, "003102": 95, "003114": 66, "003132": 47, "003133": [24, 42, 44, 68], "003165": 21, "003166": 71, "003169": 63, "003176": 66, "003182": 66, "003183": 71, "003185": [34, 54, 78], "003194": [21, 65], "003210": 39, "003258": 66, "003272": 39, "00327551": 38, "003276": 38, "003287": 64, "003293": 66, "003295": 47, "003300": [18, 63], "003310": 64, "003311": 95, "003312": [42, 47], "003313": 95, "003319": 95, "003320": [32, 76], "003365": 47, "003368": 64, "003389": 66, "003401": 71, "003414": 33, "003415": 95, "003423": 71, "003427": 71, "003433": 24, "003439": 64, "003440": 47, "003442": 77, "003463": 39, "003479": 21, "003481": 64, "003483": 42, "003485": 95, "003493": 71, "003514": [17, 42], "003522": 42, "003534": 16, "003535": 42, "003540": 39, "003543": 42, "003544": 42, "003547": [24, 44, 68], "003552": 42, "003560": 42, "003561": 61, "003588": 66, "003593": 39, "003607": 66, "00361": 66, "003626": 95, "003650": 95, "003652": 21, "003663": 39, "003681": [46, 70, 95], "003723": 42, "003732": 64, "003740": [44, 95], "003742": 66, "003767": 42, "003772": 42, "003779": 95, "003785": [24, 39, 44, 68], "003786": 44, "003788": 44, "003795": 42, "003804": 44, "003819": 44, "003823": 44, "003825": 42, "003833": 42, "003848": 44, "003877": 39, "003878": 42, "003885": 42, "003886": 44, "003892": 95, "003910": 39, "003919": [39, 42, 66], "003919287722401839": [42, 66], "003924": 71, "003950": 24, "003987": 93, "003995": 33, "003999": [16, 24], "004": [22, 25, 26, 32, 34, 42, 45, 46, 62, 66, 69, 70, 76], "004000": [15, 16, 24, 44], "004001": [24, 27], "004003": 16, "004004": [24, 27], "004011": 16, "004024": [16, 95], "004026": 93, "004027": 42, "004032": 41, "004035": 16, "004044": [32, 76], "004046": 44, "004048": 24, "004059": 66, "00406": 66, "004065": [33, 77], "004072": 42, "004076": 95, "004082": [33, 77, 95], "004087": 95, "004094": 27, "004114": 68, "004125": [23, 43], "004128": 95, "004174": 66, "004179": [24, 68], "004186": 68, "004205": 42, "004216": 68, "004221": 95, "004225": 47, "004229": 68, "004240": 95, "004249": 68, "004258": 95, "004264": [61, 68], "004265": 68, "004274": 47, "004337": [22, 42, 66], "004339": 95, "004340": 95, "00435173": [28, 72], "004352": [28, 72], "004360": [32, 76, 95], "004362": [54, 78], "004376": 27, "004379": 95, "004408": 41, "004415": 66, "004451": [32, 76], "004458": 95, "004461": 39, "004469": 39, "004472": 16, "004474": 95, "004481": 66, "004539": 95, "004553": 64, "004571": 95, "004574": 42, "004575": 95, "004594": 39, "004617": [32, 76], "004627": 68, "004631": 41, "004665": 21, "00468": 66, "004688": 66, "004691": 68, "004712": 42, "004733": 42, "004769": 61, "004770": [18, 63], "004772": 95, "00478": 66, "004793": 95, "004801": [18, 63, 64], "004807": 66, "004846": 66, "004852": [39, 66], "004877": 95, "004886": 95, "004924": 47, "004948": 95, "004954": 15, "004963": 70, "004975": 95, "005": [25, 26, 34, 35, 45, 46, 56, 59, 69, 70, 78, 79], "005000": 15, "005002": [15, 16], "005003": [15, 42], "005004": 15, "005012": [66, 70], "005013": 15, "005022": 95, "005039": 70, "005042": 95, "005049": 93, "005061": 42, "005071": 16, "005075": 93, "005081": 42, "005090": 64, "005104": [42, 68], "005116": 66, "005136": [15, 38], "005149": 66, "005150": 68, "005151": [22, 42, 66], "005157": 66, "005163": 42, "005169": 95, "005174": 16, "005180": 70, "005186": 66, "005207": 64, "005243": 18, "00525962": [18, 63], "005261": 23, "005263": [32, 76], "005264": 95, "005270": 39, "005298": 95, "00533": 66, "00535": 66, "005351": [20, 41], "005359": 70, "005387": [23, 43, 67, 81], "005399": 95, "005404": 68, "005426": [22, 42, 66], "00543825": [18, 63], "005449": 68, "005459": [32, 76], "005502": 46, "005511": 95, "005540": 95, "005562": 66, "005563": 42, "005587": 95, "005595": 68, "005603": 95, "005622": 46, "005659": 33, "005699": 61, "005725": 46, "00573": [22, 42, 66], "005756": 93, "005802": 66, "005809": [33, 77], "005810": 42, "005845": 66, "005879": 68, "005888": [18, 63], "005935": 46, "005957": 42, "005976": 95, "006": [25, 26, 45, 46, 63, 69, 70], "006000": 16, "006015": 66, "006033": 66, "006048": 16, "006070": 39, "006090": 65, "006110": [22, 42, 62, 66], "006156": 93, "006166": 15, "006187": 95, "006208": 39, "006219": 66, "006236": 39, "006250": 39, "006252": 68, "006283": 95, "006284": 66, "006302": 46, "00630932": [20, 41], "006326": 66, "006330": 95, "006333": 68, "006334": 66, "006378": 27, "006393": 19, "006429": 42, "006438": 21, "006441": 66, "006447": 42, "006452": [21, 65], "006475": 19, "006478": 95, "006531": 61, "006545": [22, 42, 66], "006546893270012566": [21, 65], "006557": [21, 65], "006578": [18, 63, 64, 94], "006582": 66, "006595": 66, "006597": 95, "006622": 16, "006626": 41, "006653": 68, "006667": 39, "006677": 42, "006702": 24, "006724": [32, 76], "006738": 42, "006744": [24, 44, 66, 68], "006752": 42, "006774": [32, 76], "006793": 95, "006805": 61, "00683": 66, "006845": 66, "00689": 66, "007": [20, 25, 41, 45, 69, 70], "007068": 71, "007074": 21, "007088": 27, "007194": 44, "007196": 95, "00720988e": [26, 46, 70], "007222": 93, "007308": 66, "007316": 61, "007321": 95, "007361": 93, "007366": 42, "007434": [26, 46, 70], "007441": 95, "007458": [18, 63, 64, 94], "007542": [15, 38], "007545": 66, "007564": 42, "00757": 66, "007577": 42, "007588": [28, 72], "00758803": [28, 72], "00759438": [26, 46, 70], "007666": [23, 43, 67], "007754": 66, "007781": 42, "007794": [17, 40], "007848": 42, "0079": 41, "007933": 42, "007938": 61, "008": [25, 45, 69, 78], "0080": 41, "008017": [18, 66], "008040": [53, 77, 97], "008073": 42, "008096": 66, "008101": 42, "008151": 18, "008167": [18, 63, 64, 94], "008241": 42, "008274": 42, "008286": 39, "0083": 41, "00830586": [19, 64], "008306": [19, 64], "008322e": 78, "008333": 64, "008399": 27, "008406": 64, "008431": 42, "008434": 66, "008484": 16, "008498": 39, "008541": 24, "008569": 93, "008584": 67, "008593": 16, "008608": 66, "008646": 27, "008667": [22, 42, 66], "008735": [16, 62], "008754": 42, "008783": 66, "008799": 43, "008803": 27, "008830": [34, 54, 78], "008854": 18, "008856": 47, "008919": 22, "009": [25, 26, 31, 34, 45, 46, 51, 69, 75], "00905": 66, "009059": 61, "009063": [22, 42, 66], "009064": 16, "009077": 16, "009086": 43, "009097": 66, "009143": 47, "009173": 47, "009298": 42, "009304": 43, "009325": 66, "009414": 66, "009418": 22, "009422": 61, "009429": [23, 43], "009457": 66, "009476": 97, "009514e": 24, "009522": 47, "009559": 68, "009627": 22, "009635": [23, 43], "009678": 66, "009724": 71, "009751": 16, "009797": 27, "009805": 66, "009833": 66, "00pm": [13, 41], "01": [16, 17, 18, 21, 22, 24, 26, 32, 33, 34, 35, 40, 41, 42, 44, 46, 53, 55, 56, 62, 63, 65, 66, 67, 68, 70, 76, 77, 78, 79, 84, 96, 97], "010": [20, 21, 22, 26, 34, 41, 46, 59, 64, 65, 66, 69, 70, 78], "0100": [21, 65], "01000": [42, 66], "010000": [18, 22, 24, 42, 63, 66], "010027": [21, 65], "010112": 42, "010125": 47, "010183": [18, 63, 64, 94], "0102": [22, 42, 62, 66], "010208": 71, "010238": 43, "010294": 61, "010336": 77, "010347": 43, "010506": 47, "010521": 16, "010650": 61, "010679": 61, "010688": 71, "010715": 66, "010721": [42, 54, 78], "010729": 42, "010750": 71, "010797": 27, "010832": 95, "010861": 22, "010915": 27, "011": [25, 32, 46, 51, 59, 64, 76, 96], "011000": 96, "011003": 66, "011039": 47, "011064": 42, "011096": 66, "011210": 71, "011234": [23, 43, 67], "011248": 77, "011252": 71, "011258": 42, "011269e": 24, "011287": 71, "011332": [34, 54, 78], "011336": [16, 62], "011389": 42, "011395": 22, "011402": 93, "011450": 27, "011476": 66, "011519": 42, "011555": 93, "011633": 18, "011678": [23, 43, 67], "011751": 43, "011767": [24, 44, 68], "01186": 42, "011906": 38, "01190633": 38, "011908": 66, "011992": 42, "012": [18, 25, 32, 45, 63, 64, 76], "012002": 66, "012003": 27, "012019": 61, "012030": 71, "012095": 38, "01209545": 38, "012121": 66, "012149": 81, "012152": 42, "012165": 22, "012240": 71, "012247": 39, "012505": 19, "012507": 66, "012534340843558311": [51, 75], "012534401379525661": 31, "0126": 41, "012616": [22, 42, 66], "012651": 16, "012690": 24, "012777": 67, "012808": 22, "012923": 41, "012940": 95, "012971": 42, "012978": 95, "013": [46, 69], "013041": 95, "013115": 42, "0131199607": 44, "01311996073": 24, "01311996076": 68, "013120": [46, 70], "013158": 47, "013161": [22, 42, 66], "013173": 38, "01317334": 38, "013178": 95, "013190": 24, "013248": 95, "013315": 95, "013328": 95, "013335": 95, "013433": [16, 62], "013445": 66, "01346": 22, "013499": 95, "013504": 42, "01352": 66, "013562": 95, "013613": 27, "013622": 66, "013628": 93, "013658": 95, "013662": 66, "013706928443177698": [42, 66], "013707": [42, 66], "013741": 42, "013755": 22, "013782": 93, "013799": 95, "014": [18, 34, 61, 63, 78], "014001": 27, "014078": 95, "014081e": 24, "01409912": [31, 51, 52, 75], "014107": 66, "014167": 95, "014176": 95, "014192": 66, "01432486e": [26, 46, 70], "014337": 39, "014381": 42, "014390": 95, "014478": 93, "014485": 42, "014494": 66, "014559": 19, "014607": [32, 76], "014650": [54, 78], "014662": 93, "014669": 66, "014706": 95, "014708": 42, "014730": 64, "01473536": [16, 62], "014758": [24, 78], "014839": 42, "014989": 39, "015": [18, 59, 63, 64, 69], "015039": [23, 43, 67, 81], "015161": 95, "015249": 95, "015263": 66, "015352": 42, "015361": 95, "015429": 66, "015433": 27, "015518": 47, "015522": 66, "015580": [46, 70], "015633": 81, "015635": 66, "015639": 39, "015665": 42, "015692": 16, "015724": 71, "015789": 27, "015831": 19, "015832": 27, "015851": 19, "015902": 42, "015927": 42, "015932": 16, "015957": 42, "015981": 93, "016047": 66, "016059": 16, "016064": 42, "01614": 66, "016143": 95, "016155": 47, "016163": 66, "016281": 42, "016297": 22, "016309": 24, "016330": 39, "016381": 19, "016451": 42, "01647": [22, 42, 66], "016525": [24, 26, 35, 44, 46, 55, 56, 68, 70, 79], "016555": [21, 65], "016577": 42, "016578": 42, "016587": [23, 43, 67], "016634": 66, "016660": [17, 40], "016676": [28, 72], "016688": [18, 27, 47, 63, 71], "016697": 42, "016731": 22, "016807": [21, 65], "016838": 42, "016853": 42, "016881": 42, "016911": 66, "016918": [67, 81], "016928": 66, "016944": [16, 62], "016963": 66, "016992": 19, "016993": 19, "017": [32, 34, 45, 46, 64, 70, 76], "017003": 19, "017182": 26, "017251": 19, "017297": 19, "017339": 19, "017344": 66, "017355": 42, "017370": 19, "017442": 42, "017468": 19, "017508": 19, "017594": 42, "017659": 19, "017795": 39, "017829": [53, 77, 97], "017864": 70, "017876": 22, "017951": 39, "017959e": [24, 68], "017972": [18, 63], "018011": 70, "018024": 66, "018035": 70, "018088": 38, "01808825": 38, "018119": 44, "018131": 42, "018169": 26, "018178": [16, 62], "018201": 42, "018217": [54, 78], "018224": 42, "018229": 24, "018245": 66, "018252": 44, "018266": 44, "018310": [16, 62], "018384": 78, "018402": 66, "018434": [53, 77, 97], "018436": [54, 78], "018459e": 24, "018487": [21, 65], "018494": 70, "0185": [21, 65], "018507e": 24, "018535": 66, "018551": 42, "018576": 22, "018622": [17, 40], "018687": 42, "018706": 42, "018712": 44, "018727": 78, "018745": 59, "018831": 44, "018844": 44, "018854": [23, 43, 67], "018886": 22, "018941": 68, "018975": 68, "018984": 44, "019001": 68, "019020": 44, "019021": [22, 68], "019111": 68, "019128": 68, "019146": 49, "019164": 68, "019178": 26, "01926": 22, "019293": 39, "019324": 78, "019342": 42, "019381838999846482": [42, 66], "019382": [42, 66], "019419": 68, "019444": 64, "019451": 42, "019485": 42, "019509": 24, "019531": [23, 43, 67], "019556": [34, 54, 78], "019558": 66, "0195598": [21, 65], "019614": 68, "019630": 68, "019656": 68, "019660": 68, "019718": 66, "019762": 42, "019839": [22, 42, 66], "019844": 68, "019856": 68, "019951": 42, "019969e": 78, "02": [1, 15, 17, 18, 21, 22, 24, 26, 27, 33, 34, 38, 40, 42, 46, 47, 53, 62, 63, 64, 65, 66, 68, 70, 71, 77, 78, 90, 94, 96, 97], "020": 64, "020000": 39, "02000e": 62, "020092": 42, "020121": 46, "020138": 43, "020161": 42, "020166": 22, "020326": 68, "020395": 42, "020414": [22, 42, 66], "020474": 66, "020495": 22, "02052": 42, "020621": 42, "020629": 66, "020649": 66, "020653": 61, "020742": 22, "020825": 66, "020833": [30, 50, 74], "020858": 66, "020873": [18, 63], "021": 78, "021082": 39, "021100": [18, 63], "021134": 22, "021146": 42, "021178": 24, "021305": [16, 62], "021329": 66, "021345": [22, 42, 66], "02148": 66, "021508": 42, "021613": 66, "0217": 66, "021729": 19, "021764": 66, "021819": 66, "021900": [22, 42, 62, 66], "021944": 23, "021970": 44, "022": 45, "022039": 67, "022064": 68, "022127": 68, "022162": 42, "022168": 22, "022331": [26, 46, 70], "022375": 78, "022629": [22, 42, 66], "022678": 81, "022730": 39, "022848": 61, "022852": 66, "022866": [23, 43, 67], "022976": 22, "023": [31, 32, 45, 69, 75, 76], "023021": 42, "023031": 42, "023086": [34, 54, 78], "023105": [53, 77, 97], "023127": 42, "02313684": 38, "023137": 38, "02325": 66, "023279": [17, 40], "023324": 19, "023366": [27, 47, 71], "023414": 22, "023636": [23, 43, 67, 81], "023985": 66, "023997": 22, "024028": [22, 42, 66], "024122": 66, "024160": 38, "02416048": 38, "02418337": 20, "02423": 22, "024286": 19, "024291": [33, 77], "024317": 22, "024323": 22, "024351e": [24, 68], "024390": [27, 47, 71], "024404": 70, "024459": 68, "02446630e": [26, 46, 70], "024534": 19, "024540": [18, 63], "024643": 42, "024746": 66, "024944": 39, "025": [23, 25, 43, 45, 67], "025115": 42, "025159": [54, 78], "025381": [26, 35, 46, 55, 56, 70, 79], "025391": [18, 63, 64, 94], "025396": [22, 42, 66], "025460": 39, "025482e": 66, "025489": [46, 70], "025661": 26, "025689": [22, 42, 66], "025910": [16, 62], "025941": 19, "025992": 32, "025997": 76, "025998": [18, 63, 64, 94], "026032": 42, "0261": [22, 42, 62, 66], "026145": 66, "026169": 19, "026378": 66, "026408": 22, "026616": 39, "026620": 66, "026631": 24, "026667": 39, "02677": 66, "026777": [42, 66], "02677733855112973": [42, 66], "026793": [24, 26, 35, 44, 46, 55, 56, 68, 70, 79], "026816": 19, "026896": 19, "026898": 27, "027": 70, "027075": 39, "027102": 19, "027112": [53, 77, 97], "027304": 96, "027321": [27, 47, 71], "027465": 19, "027521": 22, "027541": 24, "027725": 47, "027834": 24, "027949": 22, "027952": 66, "027965": 66, "028": 45, "028023": [23, 43, 67], "02807617": [31, 51, 52, 75], "028127": 24, "028177": 24, "028186": 39, "028236": 42, "028245": 27, "028337": [22, 42, 66], "028351": [22, 42, 66], "028353": 46, "02844": 22, "028647e": 78, "028651": 76, "028654": 32, "028672": [27, 47, 71], "028939": 22, "028971": 22, "029": [26, 31, 45, 51, 52, 69, 75], "029146": [23, 43, 67], "029164": [53, 77, 97], "029198": [22, 42, 66], "0292019089612867": 25, "029395": 39, "029418": 27, "029516": 22, "02952458891450549": 93, "029633": 49, "029909": 61, "029950e": 24, "02d": [33, 77], "03": [1, 15, 21, 22, 26, 31, 32, 33, 34, 38, 42, 46, 53, 65, 66, 68, 70, 76, 77, 78, 97], "030": [34, 51], "03017665e": [26, 46, 70], "030200": [18, 63], "030221": 62, "030408": [16, 62], "030466": 24, "03049217": [16, 62], "0305": [16, 62], "030566": 24, "030739733331869412": [21, 65], "030878": 24, "030952": 26, "030992": 24, "031": [26, 46, 51, 69, 75], "031011": 22, "031079": 24, "031103": 24, "031295": 24, "031326": 19, "031338": 32, "031339": 76, "031370": 26, "031385": [16, 62], "031564": [18, 63], "031605": 32, "031607": 76, "031791": 16, "031794": [24, 44, 68], "031835829826598": 42, "031836": 42, "0319": 52, "031963": 49, "031994": 46, "031997": 78, "032": 70, "032001": 39, "032139": 38, "03213916": 38, "032161": 78, "032314": 24, "032324": [42, 66], "032330": 24, "032404": [22, 42, 66], "032514": 78, "032516": 46, "032566": [19, 64], "03256625": [19, 64], "032624": 24, "032656": [16, 62], "032660": 39, "032874": [16, 62], "033": [45, 78], "033112": [32, 76], "033222": 78, "033267": [33, 77], "033279": [26, 46, 70], "033341": 22, "033348": [20, 41], "033459": [16, 62], "033477": 16, "0335": 66, "033625": 22, "033706": [22, 81], "033722": 24, "033780": 78, "033833": [67, 81], "033893": 24, "0339": [18, 63], "033993": 39, "034": [25, 26, 69], "034071": [23, 43, 67, 81], "03411038e": [26, 46, 70], "0344": [22, 42, 62, 66], "034462": 16, "034483": 96, "034543": 27, "034544": 19, "034979e": 24, "035": [32, 76], "0351": [18, 63], "035132": 22, "03516073": [26, 46, 70], "035161": [26, 46, 70], "035230": [53, 77, 97], "035300": 24, "035331": 67, "035363": 24, "035461": 49, "035583": 67, "035616": 27, "036": [18, 32, 45, 63, 76], "036136": [27, 47, 71], "0362": [18, 63], "036232": [32, 76], "036262": 67, "036351": 67, "036646": [24, 44, 68], "036656": 16, "036764": [23, 43, 67, 81], "036821": 22, "036869": 42, "036973": 24, "037": 25, "0370": [18, 63], "037012": 18, "037037": 96, "037161": 42, "037211": 24, "0373": [18, 63], "037333": 27, "037414": [53, 77, 97], "037544": 18, "037578": 42, "037627": 18, "037785": [23, 43, 67, 81], "0378": [18, 34, 63, 78], "037820": 18, "037835": 22, "038102": [21, 65], "038283": 18, "038287": 26, "038324": 24, "038395": 22, "038495": 32, "038498": 76, "038707": [46, 70], "038838": 24, "038873": 39, "038920": 24, "039": [26, 32, 45, 69, 76], "0392": 22, "039284": 66, "039344": [54, 78], "039498": [21, 65], "039739": 39, "03976": 22, "0399": [18, 63], "04": [1, 15, 17, 18, 24, 26, 33, 34, 38, 40, 46, 53, 63, 64, 66, 68, 70, 77, 78, 94, 97], "040": 18, "040000": 39, "040000e": [15, 38], "040129": [34, 78], "040142": 18, "040180": 68, "040448": [23, 43], "040497": [23, 43, 67], "040561": 39, "040698e": [24, 68], "040954": 78, "040984": [33, 77], "040992": 24, "041": [32, 76], "041031": [23, 43, 67], "041043": 96, "04108378": [21, 65], "041084": [21, 65], "041129": [16, 62], "041201": [23, 43, 67], "041212": 24, "041501": 18, "041578": 67, "041658": 18, "041704": [46, 70], "041716": [20, 41], "041737": 46, "041858": 26, "042081": [26, 46, 70], "042230": 18, "042236": 22, "042291": 22, "042382": [27, 47, 71], "042726": 24, "042740": 44, "042797": 18, "042957": [18, 63, 64, 94], "043": 66, "043196": 25, "043257": 64, "043305": 24, "043319": [26, 46, 70], "043377": 24, "043509": 66, "0437": [16, 60, 61, 62, 92], "043812": 27, "043890": [16, 62], "044": [22, 25, 42, 45, 62, 66], "044029": [18, 63, 64, 94], "044166": [21, 65], "044242": 26, "044253": [46, 70], "044313": [18, 63], "044383": 27, "044873": 61, "045": [15, 25, 32, 38, 60, 69, 76], "045199e": 24, "045267": [33, 77], "045277": 63, "045304": [16, 62], "045461": 42, "045481": [53, 77, 97], "045556": 23, "046": [32, 76], "04600e": 62, "046020": [16, 62], "046115": 39, "046116": 66, "046192": 66, "046193e": 24, "046626": 27, "046638": 64, "046702": 78, "0468": [34, 54, 78], "046882": 66, "0469": [18, 63], "047": 25, "04709519e": [26, 46, 70], "047174": 78, "047328": 27, "0474": [21, 65], "047464": 24, "04774884": [28, 72], "047749": [28, 72], "047810": 78, "047869": 24, "047958": 22, "047982": 27, "048": [15, 61, 64], "048022": 78, "048084": 22, "048304": 78, "048378": 61, "048418": 27, "04861878": [28, 72], "048630": [33, 77], "04881": 22, "048860": [18, 63], "048889": [24, 44, 68], "048949": 24, "049": [32, 64, 69, 76], "049083": [34, 54, 78], "049096": 39, "05": [1, 15, 17, 18, 23, 24, 29, 33, 34, 35, 38, 40, 43, 51, 53, 56, 62, 63, 66, 67, 73, 75, 77, 78, 79, 97], "050": [32, 59, 61, 76], "050000": 93, "050132": [18, 63, 64, 94], "050272": 42, "050306": 22, "050307": [34, 78], "050402": 22, "051": [32, 76], "051269": [18, 63, 64, 94], "05137470e": [26, 46, 70], "051472": [16, 62], "051577": 95, "051620": [18, 63], "05177790160774991": 42, "051778": 42, "051925": 66, "052": [18, 25, 63], "052349": [18, 63], "052607": 67, "052790": [23, 43, 67], "052819": [23, 43, 67], "05290827e": [26, 46, 70], "053144": 22, "053156": [28, 72], "05350962": 84, "0537": 66, "053763": 61, "053839": 22, "053862": 22, "053918": 66, "054054": 67, "054189": 96, "05422496": 17, "054225": [17, 40], "054461": [23, 43, 67], "054653": [19, 64], "05465323": [19, 64], "054669": [24, 26, 35, 44, 46, 55, 56, 68, 70, 79], "054757": 95, "054784": [19, 64], "05478443": [19, 64], "054973": 42, "054988": 22, "055": [18, 63], "055100": 66, "055197": 22, "055261": 39, "055302": 49, "055345": [45, 69], "055508": [20, 41], "055915e": [24, 68], "05598498": [19, 64], "055985": [19, 64], "056": [32, 76], "056478": [18, 63, 64], "05656664": 52, "056599": 39, "056703": [23, 43, 67], "056777": 41, "056955": 61, "057": [18, 32, 63, 76], "057003": [16, 62], "057028": 42, "057254": [34, 78], "057267": [34, 54, 78], "057296": [23, 43, 67, 81], "057333": 24, "057569": 41, "057598": 41, "057646": [16, 62], "057729": [23, 43, 67], "057732e": 78, "057793": [18, 63, 64, 94], "057910": [18, 63, 64], "058": 31, "0580": [21, 61, 65], "058176": [35, 55, 56, 79], "058259": 41, "058320": 42, "058437": 22, "058621": [20, 41], "058770e": 78, "059": [18, 31, 59, 63, 69, 75], "059077": [23, 43, 67, 81], "0591": [18, 63], "059183": 47, "059242": [18, 63, 64, 94], "059261": 41, "059406": 66, "059411": 24, "059816": 78, "059863": [16, 62], "059919": 26, "06": [1, 15, 18, 24, 29, 31, 32, 33, 34, 38, 51, 52, 53, 63, 66, 73, 75, 76, 77, 78, 84, 97], "060": [32, 70, 76], "060012": 66, "060019": 97, "060034": 22, "060543": 71, "061091": 42, "061100": [18, 63], "061164": 66, "061206": [23, 43, 67, 81], "061241": [16, 62], "061449": 22, "061641": 78, "061937": [16, 62], "061972": 93, "062": [22, 42, 59, 62, 66], "062060": 67, "062293": 78, "062449": [34, 78], "062566": 66, "062658e": [24, 68], "062702": [23, 43], "062723": 61, "062792": [16, 62], "062793": [52, 83], "062809": 67, "062822": 42, "062990": 42, "063": 25, "063004": 71, "063110": [18, 63, 64, 94], "063119": 22, "063173": [26, 46, 70], "063730": 78, "063772": [34, 54, 78], "064": 66, "064067": 67, "064200": [16, 62], "064205": 61, "064307": [27, 47, 71], "064452": [16, 62], "064604": 42, "065": [32, 76], "065183": 66, "065449": [24, 44, 68], "065463": [23, 43, 67], "065646": 42, "065805": 78, "065841": 23, "065849": [34, 78], "06597868": 20, "066166": 78, "066191": 22, "066251": 61, "066333": 78, "066341": 66, "066445": 63, "066512": 39, "066551": 66, "066614": 42, "066667": [18, 63], "066706": 47, "0667579112160865": [21, 65], "066810": 78, "066854": [20, 41], "066915": 42, "066944": 66, "067": [26, 45, 69], "067100": 39, "06717": 49, "067387": 22, "067499": 78, "067604": [20, 41], "067781": [34, 78], "067879": 78, "067925": 22, "067929": 66, "06797961": [24, 44, 68], "067990": [34, 78], "067991": [18, 63], "067994": [54, 78], "068": 59, "068042": 78, "068214": [21, 65], "06835056": 38, "068351": 38, "068427": 39, "068468": 42, "068648": 66, "068689": 78, "068706": [34, 78], "068709": 42, "068800e": [15, 38], "068817": 78, "068871": 42, "068939": 66, "069": [15, 25, 38], "069128": 42, "069145": 78, "069150": [26, 46, 70], "06915047": [26, 46, 70], "069188": 78, "069192": [34, 78], "069200": 42, "069302": 78, "0694": [22, 42, 62, 66], "069530": [16, 62], "069602": 42, "069644": 78, "069653": 78, "069800": 24, "069839": 66, "069953": [20, 41], "07": [1, 17, 24, 27, 31, 33, 34, 40, 47, 51, 53, 59, 66, 71, 75, 77, 78, 97], "07014": 42, "070142": 42, "070749": 66, "070841": 78, "070850": [23, 43, 67], "070898": [54, 78], "070911": 22, "070929": [23, 43, 67], "070954": 42, "071": [32, 63, 76], "071257": 42, "071301": 66, "071330": [53, 77, 97], "071515": 78, "071541": [18, 63, 64, 94], "071652": 22, "071654": [27, 47, 71], "071742": 42, "07174468998": 24, "07174469237": 44, "07174469245": 68, "071745": [46, 70], "071787": 78, "071838": 42, "071841": 66, "071932": 42, "071975": [27, 47, 71], "071987": 42, "072167": [20, 41], "072176": 78, "072243": [26, 46, 70], "072286": 78, "0723": [18, 63], "072306": 42, "072416": 42, "07245741": [24, 44, 68], "07262": 42, "072725": 23, "072881": 78, "072907": 42, "072935": 42, "072954": 78, "073016": [35, 55, 56, 79], "073195": 42, "073233": [21, 65], "073812": 42, "073849": 42, "073977": 66, "074": [18, 45, 63], "074074": 96, "0741": [16, 62], "074141": [16, 62], "074203": 63, "074216": 22, "074533": 42, "074701": 42, "074719": [19, 64], "07471942": [19, 64], "074765": 42, "074773": 61, "074853": [35, 55, 56, 79], "075": 25, "075000": [30, 50, 74], "075006": 22, "075009": [20, 41], "075042": [34, 78], "075063": [54, 78], "075077": 42, "075117": 63, "075170": [53, 77], "075453": [34, 78], "075467": [34, 78], "075517": 42, "075644": 66, "075668": 39, "075786": 78, "076018": 39, "076104": [24, 44, 68], "0762": [18, 63], "076284": [28, 72], "076464": 66, "076469": 42, "076476": 66, "076533": [24, 44, 68], "076798": [16, 62], "076862": 66, "076987": 42, "077": [25, 32, 76], "077039": 42, "077149": 42, "077204": [46, 70], "077717": 95, "077749": [52, 83], "077761": 78, "077887": 26, "077911e": 66, "077951": 42, "077953": 78, "078": [21, 26, 65], "0780": [60, 61, 92], "07804": 22, "078052": [23, 43, 67], "07808506982896264": 68, "07808506982896268": 24, "078268": 95, "078283": 66, "078318": 95, "078321": 42, "078387": [34, 78], "078622": 66, "078701": 23, "078732": 78, "07877994e": 84, "078851": 23, "078855": 95, "078880": 64, "078903": 42, "078995": 42, "079": 66, "079164": 63, "079238": 66, "079377": [34, 78], "0794": [22, 42, 62, 66], "079471e": [24, 68], "079477": 42, "079489": 95, "079852e": [24, 68], "079957": 66, "08": [18, 24, 27, 29, 31, 32, 33, 34, 47, 53, 63, 66, 68, 71, 73, 76, 77, 78, 91, 97], "080": [32, 76], "08002986030": [19, 64], "080112": 66, "080190": 97, "080238": 95, "080319": [19, 64], "08031924": [19, 64], "080355": 22, "080674": 42, "080694": [26, 46, 70], "080723": 95, "0808": 66, "081": [18, 59], "081040": 42, "081167": 78, "081292": [53, 77, 97], "081354": 95, "081458": 42, "08151507e": [26, 46, 70], "081548": 66, "08162": 42, "081658": 66, "08183": 66, "081837": [34, 78], "081981": 66, "082": 46, "082100": 66, "082251": [21, 65], "082265e": 78, "082353": 96, "082726": 24, "082749": [16, 62], "082835": [26, 46, 70], "082841": 95, "082949": [16, 62], "083": [22, 42, 62, 66], "083123": [18, 63, 64, 94], "083308": [34, 78], "083338": 61, "08338644": [31, 51, 52, 75], "083458": 24, "083545": [23, 43, 67], "083701": 42, "083813": [18, 63, 64, 94], "083836": 61, "083845": 42, "083943": 42, "084176": [34, 78], "084264": 24, "084286": 22, "084314": [34, 78], "084347": 23, "084489": 42, "084490": [35, 55, 56, 79], "084686": 39, "084746": [18, 63, 64], "085": 25, "085150": [33, 77], "085192": 61, "085292": 22, "085415": [26, 35, 46, 55, 56, 70, 79], "085477": [23, 43, 67, 81], "085508": 24, "085546": 24, "085550": 24, "085551": 24, "085698": 24, "085772": 42, "086": [51, 75], "086078": 39, "086085": 25, "086266": 42, "0864": 22, "08642578": [31, 51, 52, 75], "086461": [27, 47, 71], "086517": [15, 38], "086573": 66, "086830": 42, "086877": [34, 78], "086932": 61, "086985": 49, "087046": 66, "087194": 66, "087397": [20, 41], "08740234": [31, 51, 52, 75], "08791477": [31, 51, 52, 75], "088": [32, 76], "0880": [18, 63], "088193": [34, 78], "088353": 61, "088373": 61, "088616": 66, "088699": 66, "088710": 42, "088740": 66, "088772": 42, "088811": 42, "088948": [16, 62], "089156": 76, "089163": 32, "089571": 42, "089756": 22, "09": [1, 15, 24, 31, 33, 34, 38, 51, 53, 61, 64, 66, 67, 68, 75, 77, 78, 97, 99], "090000": [23, 43, 67], "090025": 24, "09009799": [24, 44, 68], "090165": 66, "090177": 66, "090231": [26, 46, 70], "090376e": 24, "090453": [23, 43, 67], "090580": 39, "09058097218": 59, "090765": 78, "090785": 24, "090950": 95, "090978": [15, 38], "091": [32, 76], "091030": 66, "091177": 66, "091410": 42, "091468": 22, "091491": [32, 76], "091579": 66, "091582": 42, "091625": [27, 47, 71], "091632": 39, "091793": 49, "091819": 61, "091988": 49, "092117": 42, "0922": [22, 42, 62, 66], "092396": 76, "092399": 32, "09245358900622544": 66, "092454": 66, "092462": 24, "092515": 66, "092604": 61, "092606": 66, "092660": [34, 78], "092728": 42, "092930": [19, 64], "09293048": 19, "0931": 66, "093228": [27, 47, 71], "093255": 22, "093350": [35, 55, 56, 79], "093390": [16, 62], "09345386": [19, 64], "093454": [19, 64], "093482": 22, "093868": 22, "094": [31, 51, 52, 59, 75], "094077": 66, "09425": 42, "094267": 61, "094290": [34, 78], "09430199": [19, 64], "094302": [19, 64], "094568": 42, "09458052": 19, "094581": [19, 64], "094586": [23, 43, 67, 81], "095": 45, "09503409246217502": 24, "095043": 66, "095101": 22, "095304": 66, "09573445": [22, 42, 66], "095812": 66, "095852": 49, "095912": 22, "095969": 42, "096": 45, "09619141": [31, 51, 52, 75], "096448": 24, "096462": 24, "096476": 97, "096482": 22, "096692": [18, 63], "096824": 22, "096825": 26, "096833": 61, "096927": 67, "096960": [24, 68], "097": [32, 45, 76], "09706504": [32, 76], "097088": [34, 78], "097123": 22, "097293": [18, 63, 64, 94], "097516": [18, 63], "097681": 42, "098": [21, 32, 65, 76], "098031": 42, "098070": [54, 78], "098082": 22, "098189": 22, "098295": 66, "098307": [24, 68], "098326": [16, 62], "098335": 22, "098674": 66, "098676": 42, "098787": 39, "098803": 22, "098888": 22, "09891476780532049": [21, 65], "098915": [21, 65], "098966": [18, 63], "098995": 22, "099": 69, "099230": [26, 46, 70], "099240": [18, 63, 64, 94], "099558": [18, 63, 64, 94], "099685": [24, 68], "099704": 22, "099723": [18, 63], "099749": [53, 77, 97], "0x00000174e2149b20": 17, "0x1227a36e0": 9, "0x12e647cb0": 66, "0x12e647e00": 66, "0x12f15ce10": 66, "0x15173cad0": 42, "0x15173cc20": 42, "0x151976490": 42, "0x15a765d10": 39, "1": [1, 5, 8, 9, 10, 17, 20, 23, 26, 31, 32, 33, 36, 38, 39, 40, 41, 43, 44, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 57, 58, 70, 74, 75, 76, 77, 80, 81, 82, 83, 84, 90, 96, 99], "10": [1, 4, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 38, 39, 40, 41, 42, 43, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 59, 60, 61, 62, 63, 64, 65, 66, 67, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 81, 83, 84, 85, 86, 87, 91, 92, 93, 94, 96, 97, 99], "100": [13, 15, 16, 17, 18, 19, 20, 21, 22, 24, 25, 27, 28, 29, 31, 32, 33, 34, 35, 36, 39, 40, 41, 42, 44, 45, 46, 47, 48, 51, 52, 53, 54, 55, 56, 60, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 75, 76, 77, 78, 79, 81, 82, 95, 96, 97, 98], "1000": [13, 15, 16, 20, 21, 22, 23, 24, 27, 32, 34, 35, 41, 42, 43, 44, 46, 47, 53, 54, 56, 61, 62, 65, 66, 67, 68, 70, 71, 76, 77, 78, 79, 81, 82, 84, 93, 97], "10000": [13, 15, 20, 21, 22, 24, 38, 41, 42, 53, 60, 64, 65, 66, 77, 97], "100000": [13, 16, 19, 21, 22, 24, 42, 53, 62, 64, 65, 66, 77, 97], "1000000": [17, 40, 66], "1001": 34, "100103": [53, 77], "100139": [19, 64], "10013934": 19, "100146": [53, 77], "1002": 34, "100248": [16, 62], "100253": 42, "100275": [27, 47, 71], "1003": [34, 99], "1004": [16, 34, 62], "10041668266057968": [51, 75], "10041749477386475": 31, "1005": [53, 77, 97], "100592": [32, 76], "1006": [53, 77, 97], "1007": [53, 77, 97], "1008": [53, 77, 97], "10083": [15, 38], "100833": 95, "100882": [23, 43, 67, 81], "1009": [53, 77, 97], "10092665203438746": 68, "10092665203438769": 24, "100970": [34, 78], "101": [1, 10, 13, 20, 28, 32, 34, 48, 49, 64, 69, 72, 76, 78, 99], "1010": [53, 77, 97], "1012": [53, 77, 97], "101259": 24, "101297": 22, "1014": [32, 39, 66, 76], "101406": 49, "101439": 49, "101444": 42, "1015": [32, 39, 53, 76, 77, 97], "1016": [32, 39, 53, 76, 77, 97], "101688": 66, "101699": 78, "1017": [32, 39, 53, 76, 77, 97], "101796": [24, 68], "1018": [32, 39, 53, 76, 77, 97], "101894": 67, "1019": [32, 39, 53, 76, 77, 97], "102": [1, 17, 23, 24, 34, 40, 43, 44, 67, 68, 69, 89, 95, 97, 99], "1020": [15, 27, 32, 38, 39, 47, 53, 66, 71, 76, 77, 97], "102044": [27, 47, 71], "102050": 66, "1021": [32, 39, 53, 76, 77, 97], "102135": [23, 43, 67, 81], "1022": [32, 39, 53, 76, 77, 97], "1023": [32, 39, 53, 76, 77, 97], "1024": [32, 39, 48, 49, 53, 76, 77, 97], "102435": [16, 24, 62, 68], "102463": 66, "102474": [19, 64], "10247431": [19, 64], "102485": 24, "102498": 95, "1025": [53, 77, 97], "10254": [33, 77], "1026": [16, 21, 25, 26, 28, 53, 65, 77], "102629": 66, "102694": [45, 69], "1027": [53, 77, 97], "10273": [24, 44, 68], "10274": 67, "102773": 42, "1028": [53, 77, 97], "1029": [53, 77, 97], "102918": 22, "103": [1, 5, 13, 45, 48, 69, 78, 99], "1031": [53, 77], "103122": 66, "103137": 42, "103147": 22, "103219": [27, 47, 71], "103244": 66, "1034": [27, 47, 71], "103439": [19, 64], "10343943": 19, "103448": 96, "103464": 22, "103520": [32, 76], "103846274635209263023": 22, "103886": 22, "1039": [53, 77, 97], "103917": 42, "104": [16, 18, 28, 32, 34, 62, 63, 72, 76], "1040": [18, 63], "104060": 66, "104070": [24, 68], "1041": [24, 26, 44, 46, 53, 68, 70, 77, 97], "10416666666666667": [30, 50, 74], "1042": [42, 66], "104235": [54, 78], "104294": 32, "1043": [19, 64], "1044": 59, "104643": [24, 44, 68], "105": [15, 45], "1050": [15, 38, 60], "105080": [27, 47, 71], "105089": [19, 64], "10508947": 19, "10513": [33, 77], "105166": 93, "1052": 34, "1053": 34, "105314": [53, 77], "1054": 34, "105427": 78, "105498": 22, "1055": 34, "10556679": [28, 72], "1056": 34, "105656": [46, 70], "105661": 24, "1057": 34, "1058": 34, "10584062": 76, "10584063": 32, "1059": 34, "106": [17, 40, 45], "106000": [18, 63], "106023": [24, 68], "106112": [53, 77], "106180": [53, 77], "106234": 97, "106319": [53, 77], "106322": [53, 77], "106377": 77, "106424": [53, 77], "10644531": [31, 51, 52, 75], "106452": [16, 62], "10645223": [16, 62], "106453": 66, "10653": [53, 77, 97], "106705": [53, 77], "106724": 66, "106816": [53, 77], "10693359": [31, 51, 52, 75], "1070": [27, 47, 71], "107050": [53, 77], "107292": [53, 77], "107458": 49, "107502": [53, 77, 97], "1076": [15, 38], "107726": 22, "10781": [25, 26, 45, 46, 69, 70], "107838": 42, "107917": [53, 77, 97], "10793260e": [32, 76], "107947": [24, 68], "107985": [24, 68], "107991": 67, "108": [48, 59, 95], "1080": 59, "10800": 59, "108138": 22, "1084": 42, "108461": 66, "1085": [21, 65], "108521": 22, "10868": [33, 77], "108681": [16, 62], "10884": 42, "108840": 42, "1089": [24, 44, 68], "108918": 66, "10910": [33, 77], "109135": 22, "10931": 64, "109334": 66, "109526": 67, "109532": 66, "109577": 39, "1096": 64, "109699": 66, "1099": [24, 44, 68], "10_000": [20, 34, 41, 54, 78], "10th": [22, 25, 26, 45, 46, 66, 67, 69, 70], "10x": 67, "11": [1, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 33, 34, 38, 39, 40, 42, 43, 44, 46, 47, 48, 50, 51, 52, 53, 54, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 70, 71, 72, 73, 74, 75, 77, 78, 85, 93, 94, 95, 97, 99], "110": [21, 32, 42, 65, 76, 95], "1101": [18, 19], "110133": 66, "1102": 18, "110223e": 96, "1103": 18, "110316": [53, 77, 97], "110319": [53, 77, 97], "1104": [16, 18, 62], "110429": 66, "11043": 36, "11057": [33, 77], "1106": [18, 27, 47, 71], "110645": 24, "1107": 18, "1108": 18, "1109": 18, "110915e": [24, 68], "110985": [54, 78], "111": [18, 23, 24, 34, 43, 54, 63, 66, 67, 78, 81], "1110": 18, "1111": 18, "1112": 18, "11121453": [28, 72], "111215": [28, 72], "111220": [33, 77], "111271": 22, "11129": 22, "1114": 18, "111438": [27, 47, 71], "1115": 18, "111543": 24, "1116": 18, "111668": 66, "111692": 22, "111770": 32, "111771": 76, "111793": 78, "111841": 42, "112": [16, 34, 62, 95], "1122": [24, 26, 44, 46, 68, 70], "1123": 66, "112442": 22, "112519": 78, "112821": 26, "112848": [24, 44, 68], "112977": 22, "113": [69, 95], "113033": 66, "113097": 66, "1131": [15, 38], "11336331e": [26, 46, 70], "113452": 76, "113458": 32, "113600": [18, 63, 64, 94], "1138": [27, 47, 71], "113815": 26, "113837": 24, "1139": [24, 26, 35, 44, 46, 55, 56, 68, 70, 79], "113949e": 78, "114": [18, 25, 63, 64], "1140": [24, 26, 35, 44, 46, 55, 56, 59, 68, 70, 79], "114000": [18, 27, 47, 63, 71], "114521": 26, "11457": [24, 26, 35, 44, 46, 55, 56, 68, 70, 79], "114757": [15, 38], "114766": [46, 70], "114836": [27, 47, 71], "114966": [46, 70], "114976": 66, "1150": 59, "115081": 66, "115083": [18, 63], "115089": [53, 77], "11509": [24, 44, 68], "115090": [53, 77], "115091": [53, 77], "115092": [53, 77], "115139": 26, "115230": 43, "115276": 78, "115289": 26, "115401": 24, "115406": [16, 62], "115428": [53, 77, 97], "11562": 66, "115782": 22, "115956": [21, 65], "116": [18, 48, 49, 63, 96], "116086": 66, "116145": [27, 47, 71], "116167": [21, 65], "116192": 42, "116395": 24, "116443": [27, 47, 71], "116497": 24, "116505": 96, "116587": 42, "116733": 22, "11693": [24, 44, 68], "117": [18, 21, 27, 40, 47, 63, 64, 65, 71, 94], "117058": [21, 65], "117378": 78, "117380": [18, 63], "117412": [24, 68], "117528": [27, 47, 71], "11758": [53, 77, 97], "117712": [53, 77], "117816": [18, 63], "117899e": 24, "1179": [18, 63], "118": [18, 21, 24, 26, 27, 35, 44, 46, 47, 55, 56, 63, 64, 65, 68, 70, 71, 79, 95], "1180": [15, 38, 60], "118142": 66, "118182": [18, 63, 64, 94], "118230": 25, "118281": 78, "118347": [24, 68], "118438": 42, "118450": [67, 81], "1185": 64, "118563": [27, 47, 71], "11860274523496628": 31, "11860340088605881": [51, 75], "11872": 59, "118835": 49, "11886432": [22, 42, 66], "118874": 24, "118934": [23, 43, 67, 81], "11898": [23, 43, 67], "119": [18, 21, 27, 47, 53, 63, 64, 65, 71, 77, 94, 97], "1190": [15, 18, 38, 63], "119049": [53, 77, 97], "119094": 78, "11909976": [28, 72], "119100": [28, 72], "119123": 39, "11914062": [31, 51, 52, 75], "119161": 39, "119269": 22, "119400": [18, 63], "119499": 22, "1195": 19, "119570": [27, 47, 71], "119834": 76, "119847": 32, "119911": [53, 77, 97], "11th": [25, 26, 45, 46, 67, 69, 70], "12": [1, 11, 14, 16, 17, 18, 19, 20, 21, 23, 24, 27, 28, 29, 30, 31, 33, 34, 35, 38, 39, 40, 42, 43, 44, 45, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 71, 72, 73, 74, 75, 77, 78, 79, 84, 85, 86, 87, 89, 90, 91, 92, 93, 95, 96, 97, 99], "120": [16, 17, 18, 21, 24, 32, 33, 40, 44, 48, 53, 62, 63, 65, 68, 76, 77, 84, 98], "1204": [16, 62], "120445": 42, "120769e": 24, "120929": 76, "120932": 32, "121": [15, 18, 21, 22, 25, 27, 33, 38, 42, 45, 47, 59, 63, 64, 65, 66, 69, 71, 77], "1210": 66, "121056e": 24, "121084e": 24, "1212": 42, "12138": [18, 63], "1214": [24, 44, 68], "121403": [54, 78], "121438": [34, 54, 78], "1215": 99, "121504": 22, "12150684": [21, 65], "121531": [23, 43, 67, 81], "121590": 49, "121598": 26, "121599": [26, 46, 70], "121628": [16, 62], "1217": [54, 78], "12178": [27, 47, 71], "121846": [46, 70], "12194": 93, "121985": [24, 68], "122": [15, 18, 27, 32, 38, 47, 48, 59, 60, 61, 63, 64, 71, 76, 89, 92, 95], "1220": [18, 59, 63, 66], "1222": [42, 66], "122210": 26, "122307": [18, 63, 64, 94], "122331": 24, "1225": 34, "122968": 24, "123": [4, 13, 15, 16, 17, 18, 20, 21, 22, 23, 24, 25, 26, 27, 32, 33, 34, 35, 36, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 76, 77, 78, 79, 80, 81, 84, 87, 88, 92, 93, 94, 95, 96, 98], "123049e": [15, 38], "123215": 49, "123312": 22, "123367": 24, "123432": 24, "1235387316046016": [42, 66], "123539": [42, 66], "123826": 97, "123971": 22, "124": [18, 31, 49, 51, 52, 63, 75, 95], "1240": 59, "1241": [24, 27, 44, 47, 68, 71], "1242": 34, "1243": [18, 63], "12436984": [19, 64], "124370": [19, 64], "1247": [42, 66], "12483182": 20, "12498": [26, 46, 70], "124982": [27, 47, 71], "125": [9, 18, 24, 44, 48, 68, 95], "1250": [18, 63, 64, 94], "125000": [15, 38], "125036": 24, "12508": [24, 26, 35, 44, 46, 55, 56, 68, 70, 79], "125440e": [24, 68], "125476": [16, 62], "125523": [53, 77, 97], "125617": [53, 77, 97], "125644": 24, "1258": [34, 78], "125831": [34, 78], "126": [18, 25, 27, 42, 47, 71], "126011": [54, 78], "126231": 22, "126238": [27, 47, 71], "126278": 24, "126325": 24, "126398": [18, 63, 64, 94], "126488": [28, 72], "12649": [18, 63], "126500": [18, 63], "126563": 66, "126707": 49, "126808": [18, 63, 64, 94], "127": [18, 21, 36, 57, 58, 61, 63, 65, 66, 80, 95], "127086": [18, 63], "127087": 78, "1271": [25, 45, 69], "127107": [26, 46, 70], "127203": 26, "127226": 64, "127242": 24, "1273": [26, 46, 70], "127326": [24, 68], "1274": [27, 47, 71], "127418": 24, "127439": 24, "127441": 24, "127614": [24, 44, 68], "12761659": [24, 68], "127652": 24, "12768": [15, 38], "127774": 24, "127878": [16, 62], "1279": [24, 44, 68], "1280": [18, 24, 42, 44, 63, 66, 68], "1281": [24, 44, 68, 84], "128188": [18, 63, 64, 94], "128384": [24, 68], "128522": [34, 78], "128528": [24, 44, 68], "128692": [46, 70], "1287": [15, 38], "128820": [53, 77], "128828": [53, 77], "128829": [53, 77], "128830": [53, 77], "12890625": [31, 51, 52, 75], "128984": [24, 44, 68], "129": [16, 21, 27, 34, 47, 62, 65, 69, 71, 78, 89, 95], "1290": [18, 63], "12906": 59, "129216": 66, "129257": [24, 44, 68], "12927": 59, "129300": [18, 63, 64, 94], "129459": [27, 47, 71], "129600": [24, 44, 68], "129900": [23, 43, 67], "129904": [24, 44, 68], "129985": [18, 63], "12th": [25, 26, 45, 46, 67, 69, 70], "13": [1, 9, 15, 16, 17, 18, 19, 20, 23, 24, 25, 26, 29, 30, 31, 33, 34, 38, 39, 40, 43, 44, 45, 46, 49, 50, 51, 52, 53, 54, 59, 60, 61, 62, 63, 64, 66, 67, 68, 69, 70, 73, 74, 75, 77, 78, 84, 85, 93, 94, 97, 99], "130": [16, 18, 24, 26, 27, 35, 44, 46, 47, 55, 56, 59, 60, 61, 62, 63, 64, 66, 68, 70, 71, 79, 92, 94, 95], "1300": [24, 26, 35, 44, 46, 55, 56, 68, 70, 79], "1302": 81, "130339": 24, "130395": [53, 77, 97], "1304": [16, 34, 35, 54, 55, 56, 62, 78, 79], "130432": [53, 77, 97], "1306": [36, 57, 58, 80], "130666": 24, "130690e": [24, 68], "1307": [24, 44, 68], "130855": [46, 70], "130979": 66, "131": [17, 18, 34, 40, 53, 63, 77, 78], "131000": [24, 44, 68], "13107": [33, 77], "13119": 22, "131274": 22, "131275": 67, "131287": 49, "1313": [24, 44, 68], "1314": [24, 26, 35, 44, 46, 55, 56, 68, 70, 79], "131607": [24, 26, 35, 44, 46, 55, 56, 68, 70, 79], "131639": 32, "131640": 76, "13169": 93, "131773": [34, 78], "1319796954314723": [25, 45, 69], "132": [34, 78], "1320": [27, 47, 71], "1321": 59, "132158": [24, 68], "132292": [27, 47, 71], "13229595e": [26, 46, 70], "13255": [33, 77], "13265": 93, "132667": [23, 43], "132856": 24, "132875": [18, 63, 64, 94], "132886": [53, 77], "133": [34, 48, 66, 78], "133000": [24, 44, 68], "133270": [24, 68], "133337": [24, 44, 68], "133562": [34, 54, 78], "13375": 93, "133894": [23, 43], "13392236": [32, 76], "134": [21, 60, 61, 65, 92], "1340": [15, 38, 60], "134061": [27, 47, 71], "13407": [26, 46, 70], "134090": [34, 78], "134270": [20, 41], "13428": 36, "134287": 67, "13452": 20, "1346": [18, 24, 26, 27, 34, 44, 46, 47, 63, 68, 70, 71, 78], "134615": [21, 65], "134658": [18, 63], "134728": 24, "13476562": [31, 51, 52, 75], "134894": [53, 77, 97], "135": [25, 34, 53, 77, 78, 97], "1350": [15, 38], "135032": 22, "135134": [53, 77, 97], "135197": [53, 77, 97], "13521135": [26, 46, 70], "135299": [27, 47, 71], "135305": [18, 63, 64, 94], "135384": 24, "13540": [15, 38], "135422": [24, 44, 68], "1357": [15, 38, 59], "135706": 24, "136": [18, 34, 63, 97], "1360": [15, 38, 60], "1364": 18, "1365": 18, "1366": 18, "136646": 68, "13665": [18, 63, 64, 94], "136714": [23, 43, 67, 81], "1368": 18, "137": 34, "1370": [18, 22, 34, 42, 54, 59, 62, 66, 78], "13704": [24, 26, 35, 44, 46, 55, 56, 68, 70, 79], "1371": 18, "1372": [18, 35, 55, 56, 79], "137239": 24, "137269": 24, "1373": 18, "1374": 18, "137410": [28, 72], "1375": 18, "137500": [18, 63, 64, 94], "1376": 18, "1377": 18, "13775911927223206": [51, 75], "1377594769001007": 31, "137796": 96, "1378": [18, 24, 44, 68], "1379": 18, "138": [34, 48, 49, 95], "1380": [18, 59], "1381": 18, "1382": 18, "1383": [18, 66], "1384": 18, "138417": 96, "1384684145450592": [51, 75], "13846909999847412": 31, "1385": [18, 34], "138503": [27, 47, 71], "138528": [21, 65], "138564": [15, 38], "138571": [20, 41], "1386": [18, 34], "138603": 96, "1387": [18, 34], "1388": [18, 34], "138876": 78, "1389": [18, 24, 26, 34, 44, 46, 63, 68, 70], "139": [18, 19, 34, 63], "1390": 59, "139297": [23, 43, 67], "139317": 81, "139322": [23, 43, 67, 81], "139349": [23, 43, 67], "13941": 67, "139412": [54, 78], "139554": 81, "1396": 66, "1397": [42, 66], "139863": 66, "139912": 66, "139943": 93, "14": [1, 15, 16, 17, 18, 19, 22, 23, 24, 26, 29, 30, 31, 32, 33, 34, 36, 38, 39, 40, 43, 44, 46, 47, 48, 49, 50, 51, 52, 53, 54, 59, 60, 61, 62, 63, 64, 66, 67, 68, 70, 73, 74, 75, 76, 77, 78, 85, 90, 93, 96, 97, 99], "140": [18, 63, 95], "140185": [27, 47, 71], "140210": [32, 76], "140371": 39, "1404": [16, 34, 54, 62, 78], "1405": [27, 47, 71], "1406": [18, 24, 26, 44, 46, 63, 68, 70], "140631": [34, 78], "140641": [53, 77, 97], "140828": [15, 38], "140953": [53, 77, 97], "140986": 97, "141": [18, 21, 63, 65], "1410": [15, 38], "141056": 96, "141232": [53, 77, 97], "14159265358979323": 9, "14160": 67, "14176653": 38, "141851": [53, 77, 97], "142": 31, "142051e": [15, 38], "142193": [53, 77, 97], "142199": [53, 77, 97], "1423": 81, "142348": 24, "142375": 24, "142398": [53, 77, 97], "142424e": 66, "142467": 61, "142653": 76, "142654": 32, "1427": [15, 35, 38, 55, 56, 79], "142806": [53, 77, 97], "142857": 64, "14289": [18, 63, 64, 94], "14294": 93, "143": [23, 43, 48, 66, 67], "143491": [34, 78], "143693": [53, 77, 97], "143803": [27, 47, 71], "1438387200": [33, 77], "1438398000": [33, 77], "1438408800": [33, 77], "1438419600": [33, 77], "1438430400": [33, 77], "1438441200": [33, 77], "1438452000": [33, 77], "1438462800": [33, 77], "1438473600": [33, 77], "1438484400": [33, 77], "143975": [53, 77, 97], "144": [59, 66], "144000": [24, 26, 35, 44, 46, 55, 56, 68, 70, 79], "14419": 93, "144199": [53, 77, 97], "144246": 24, "144450": 24, "144686": [26, 46, 70], "14471": [18, 63, 64, 94], "144728": 77, "144729": [53, 77, 97], "144730": [53, 77, 97], "144731": [53, 77, 97], "144732": [53, 77, 97], "144733": [53, 77, 97], "144750": [16, 62], "14485": [24, 44, 68], "144851": 23, "145": [39, 49, 53, 77, 95, 97], "145185": 39, "1452": [27, 47, 71], "145425": [24, 44, 68], "145454": [53, 77, 97], "145455": [53, 77, 97], "145456": [53, 77, 97], "145457": [53, 77, 97], "145458": [53, 77, 97], "145459": [53, 77, 97], "145460": [53, 77, 97], "1457": [18, 34, 63, 64, 78, 94], "14579": [27, 47, 71], "1458": [18, 63, 64, 94], "145833": [30, 50, 74], "146": [35, 39, 55, 56, 59, 79], "1460": [24, 34, 44, 68, 78], "14648438": [31, 51, 52, 75], "1465": [18, 63, 64, 94], "146621": 43, "146656": [53, 77, 97], "146673": 42, "146681": [54, 78], "1467": [27, 47, 71], "146767": [26, 46, 67, 70], "146809": [23, 43, 67], "146830": [23, 43, 67, 81], "14690": 64, "146987": [34, 78], "147": [26, 35, 39, 46, 55, 56, 64, 70, 79], "147166": [25, 26, 45, 46, 69, 70], "14716638": [26, 46, 70], "1472": [17, 40], "147401": [54, 78], "14751": 66, "147641": [24, 44, 68], "147893": [18, 63], "147898": [23, 43, 67], "147932": [54, 78], "147944": 66, "148": [22, 25, 26, 39, 40, 42, 46, 62, 66, 70], "14813": [33, 77], "148148e": 96, "148227": 78, "148273": 96, "148343": [24, 44, 68], "148349": [34, 54, 78], "14841": 67, "148437": 67, "148684": 42, "1486840817915398": 42, "149": [34, 39, 54, 78], "1490": [15, 38], "149122": 80, "14970": [18, 63], "149788": [26, 46, 70], "149822": [18, 63, 64, 94], "14999": [18, 63], "15": [1, 9, 14, 15, 16, 17, 18, 19, 22, 23, 24, 25, 26, 27, 29, 30, 31, 32, 33, 34, 38, 39, 40, 42, 43, 44, 45, 47, 50, 51, 52, 53, 54, 60, 61, 62, 63, 64, 66, 67, 68, 69, 70, 71, 72, 74, 75, 77, 78, 82, 85, 86, 92, 93, 97, 98, 99], "150": [22, 24, 32, 35, 39, 42, 44, 48, 56, 62, 66, 68, 79, 95], "1500": [17, 40], "150000": [23, 30, 43, 50, 67, 74], "1501": 97, "150115": 66, "15026771": [24, 68], "150395": [16, 62], "1504": [16, 62], "1505": [18, 63], "150528": 48, "1509": [15, 38], "150999": [34, 78], "150mb": [23, 43, 67], "150p": 59, "151": 25, "151357": [27, 47, 71], "1514": [36, 57, 58, 80], "151508": 24, "152": [18, 33, 48, 77], "1520": [64, 66], "152148": 94, "1523300141": [15, 38], "1523300157": [15, 38], "152401": [23, 43, 67], "152455": [45, 69], "152475": 24, "152691": 39, "152859": [23, 43, 67, 81], "152934": 66, "153": 18, "1530": [15, 38, 59], "1531": 19, "153164": 76, "153165": 32, "153376": 49, "1534": [18, 63], "15377": [18, 20, 27, 47, 63, 71], "153792": [54, 78], "1538": [16, 25, 26, 28], "154": 18, "1540": 59, "154076": [26, 46, 67, 70], "154105": [27, 47, 71], "15429": [33, 77], "154386": [18, 63, 64], "1544": 97, "1545": [27, 47, 71], "154556": [54, 78], "1547": 34, "154795": [24, 26, 35, 44, 46, 55, 56, 68, 70, 79], "1548": 34, "154842": [34, 78], "154883": 39, "154883837629511": [45, 69], "1549": 34, "155": [18, 42, 59, 66], "1550": 34, "15500": [24, 44, 68], "1551": 34, "155178e": 24, "1552": 34, "1553": 34, "1554": 34, "15559528e": [26, 46, 70], "155624": [24, 44, 68], "155625": 97, "155637": [34, 78], "155900": [15, 38], "156": [18, 23, 42, 43, 48, 63, 66, 67, 81, 95], "1560": [15, 38], "1562": 66, "156245": 24, "156311e": 24, "1564": [66, 97], "15661": [33, 77], "156906": 66, "157": [18, 32, 42, 59, 66, 76, 95], "157008": [24, 44, 68], "157115": 66, "157234": [27, 47, 71], "15725": [18, 20, 27, 47, 63, 71], "157571": 39, "15775": [33, 77], "1578": [26, 46, 70], "157877": 49, "15795": [26, 46, 67, 70], "157993": [23, 43], "158": [42, 48, 66], "1580": 59, "15813": 93, "158170": 24, "1582": [26, 46, 70], "158709": 78, "158792": 49, "158867": [53, 77, 97], "158982": [24, 44, 68], "159": [42, 66, 70], "1590": [22, 42, 62, 66], "15915": [33, 77], "159347": [54, 78], "159750": 49, "159751": 39, "159776": 78, "15992": [26, 46, 70], "16": [1, 13, 14, 15, 16, 18, 19, 21, 22, 23, 24, 27, 31, 33, 34, 36, 38, 42, 43, 44, 47, 49, 51, 52, 53, 54, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 71, 75, 77, 78, 80, 85, 86, 90, 92, 93, 96, 97, 99], "160": [21, 22, 24, 42, 44, 49, 61, 62, 65, 66, 68, 87, 93, 95], "1600": [15, 38], "160000": [24, 26, 35, 44, 46, 55, 56, 68, 70, 79], "160213e": 24, "160258": 61, "160282": [27, 47, 71], "1604": [16, 62], "160506": [23, 43, 67], "1606": 42, "16063983": [19, 64], "160640": [19, 64], "160727": [26, 46, 70], "160729": [53, 77, 97], "161": [17, 18, 40, 46, 63], "161001": [54, 78], "1610243052583633": [21, 65], "1611": 99, "16111330565237114": [21, 65], "1613": [18, 63], "161300e": [15, 38], "161339": 78, "161429": 39, "16153": [33, 77], "16157": [33, 77], "16160": [33, 77], "161606": [18, 63, 64, 94], "161782": [23, 43, 67, 81], "1619": [42, 66], "161931": [24, 26, 35, 44, 46, 55, 56, 68, 70, 79], "161932": 24, "162": [48, 59], "162000": [24, 44, 68], "162214": [35, 55, 56, 79], "162330": [23, 43, 67], "162458": 43, "162667": [26, 46, 67, 70], "1627": [27, 47, 71], "162747": [32, 76], "162904": [54, 78], "163": [15, 38], "1631": 66, "163195": [18, 63, 64, 94], "163397": [18, 63, 64, 94], "1634": [18, 42, 63, 64, 66, 94], "163466": 24, "163541": 78, "16358": [33, 77], "164": [27, 32, 47, 71, 76], "164358": 43, "1645": [21, 65], "16460": [27, 47, 71], "164679": [23, 43, 67], "164706": 96, "164960": [54, 78], "165": [21, 24, 44, 48, 65, 68, 84], "1650": [22, 42, 62, 66], "16507": [21, 27, 47, 65, 71], "16508": [21, 27, 47, 65, 71], "16509": [21, 27, 47, 65, 71], "16510": [21, 27, 47, 65, 71], "16511": [21, 27, 47, 65, 71], "16512": [21, 27, 47, 65, 71], "1652": [21, 61, 65], "16533": [33, 77], "165485": [26, 46, 70], "165617": [33, 77], "165713": [34, 78], "165811": 66, "16630": [27, 47, 71], "166631": [18, 63, 64, 94], "166636": 49, "167": [18, 61], "167214": [16, 62], "167600": [27, 47, 71], "168": [18, 24, 44, 48, 68], "1680": [15, 38, 60], "168196": [18, 63, 64, 94], "168244": [26, 46, 70], "1683": 93, "1687": 66, "169": [18, 21, 27, 47, 48, 61, 65, 71], "1690": [15, 38, 59, 60], "1691": 42, "169269e": 78, "169570": 43, "169693": [16, 62], "169748": [21, 65], "16991815": 9, "1699181533555938": 9, "17": [1, 4, 9, 15, 16, 17, 18, 19, 21, 22, 23, 24, 25, 27, 33, 34, 38, 40, 43, 44, 47, 49, 50, 52, 53, 54, 60, 62, 63, 64, 65, 66, 67, 68, 71, 74, 77, 78, 85, 93, 94, 96, 97, 99], "170": [18, 29, 63, 73], "17000249028205872": 31, "1700027883052826": [51, 75], "170071": 49, "170100": [18, 63, 64, 94], "170277": [25, 26, 45, 46, 69, 70], "1704": [16, 62], "170492": 49, "170505": 32, "170512": 76, "17054987": [32, 76], "170662": 36, "170670": [24, 68], "171": [32, 49, 59, 76], "17144": [33, 77], "171468": [24, 26, 35, 44, 46, 55, 56, 68, 70, 79], "1715": 66, "171657": 61, "171779": 24, "171800": 24, "171894": 66, "171899": [54, 78], "171997": 78, "172": 95, "1720": [18, 63], "17205": [33, 77], "172096": 49, "172161": 38, "17216105": 38, "172414": 96, "1724668": 52, "172697": [54, 78], "172792": [23, 43, 67], "172985": [20, 41], "173": [22, 42, 62, 66], "173025": 66, "173086": 24, "17333954": [20, 41], "173370": 49, "173478": [54, 78], "1738": 42, "17393037": 9, "1739787032867638": 66, "173979": 66, "174": [22, 26, 42, 45, 59, 62, 66], "174590": [23, 43, 67, 81], "174652": 78, "174766": [27, 47, 71], "175": 69, "1750": [18, 36, 57, 58, 63, 80], "175000": [24, 26, 35, 44, 46, 55, 56, 68, 70, 79], "17518": [33, 77], "175459": [15, 38], "176": [18, 48, 63], "176028": 39, "1762": [51, 75], "176468": 42, "1764683596365657": 42, "176471": 96, "1766": [24, 44, 68], "176924": 78, "177": [27, 47, 48, 71], "17730": [18, 20, 27, 47, 63, 71], "177709": 78, "178": [24, 44, 59, 68], "178494": [24, 44, 68], "178529": 96, "178657": 43, "178761": [23, 43], "1788": [15, 38], "17896": [33, 77], "179": [25, 34, 45, 69, 78], "179061": 76, "179064": 32, "179080": [23, 43, 67], "179123": [16, 62], "179152": [17, 40], "179300": [18, 63], "179631": [15, 38], "179726": 49, "179730": [42, 66], "17973005068132514": [42, 66], "179802": [24, 44, 68], "18": [1, 15, 16, 17, 18, 19, 21, 22, 23, 24, 27, 28, 30, 31, 33, 34, 35, 40, 42, 43, 44, 47, 49, 50, 51, 53, 54, 56, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 71, 72, 74, 75, 77, 78, 79, 81, 85, 90, 93, 94, 96, 97, 99], "180": [22, 24, 32, 44, 66, 68, 76, 95], "1800": [15, 22, 38, 42, 59, 60, 62, 66], "18000": [33, 77], "180000": [15, 38, 60], "180214": [54, 78], "180234": [34, 78], "180279e": 24, "180290": 96, "180388": [16, 62], "1804": [16, 62], "18066406": [31, 51, 52, 75], "180900": [27, 47, 71], "180926": 39, "18096": [33, 77], "181": [34, 78], "18113": [33, 77], "18116": [33, 77], "181262": 24, "1813": 66, "181755": 96, "182": [33, 34, 77, 78], "18201414": [26, 46, 70], "182342": [34, 78], "182384": 39, "18245": [33, 77], "182639": [24, 68], "182648": [24, 44, 68], "1830": [15, 38], "18311": [33, 77], "18313": [33, 77], "18317085": 9, "183179": [34, 54, 78], "183423": [16, 62], "183471e": [24, 68], "18365": 64, "183716": 49, "18391": [18, 63, 64], "184": [33, 34, 69, 77, 78], "1840": [15, 38, 59], "184220": [20, 41], "184405": [26, 46, 70], "1847": 19, "185": [34, 61, 78], "185000": 61, "185155": [26, 46, 70], "185175": [34, 54, 78], "185270": 22, "18533": [33, 77], "1854": 66, "1857": 34, "185707": [22, 42, 62, 66], "18571": [18, 63, 64, 94], "18572": [18, 63, 64, 94], "18573": [18, 63, 64, 94], "18574": [18, 63, 64, 94], "18575": [18, 63, 64, 94], "18576": [18, 63, 64, 94], "1858": [27, 34, 47, 71], "185868": [27, 47, 71], "1859": 34, "185975": [26, 46, 70], "18597545": [26, 46, 70], "186": [17, 40], "1860": 34, "186024": 59, "1861": 34, "186561": 97, "186814": [23, 43, 67, 81], "186869": [54, 78], "186899": [23, 43, 67], "187": [21, 61, 65, 95], "1870": 66, "187000": [18, 63], "1872": [24, 44, 68], "1875": [21, 31, 51, 52, 65, 75], "187502": 78, "187503": [53, 77], "187663": [16, 62], "187700": [18, 63], "188": [21, 48, 59, 61, 65, 95], "1880": 66, "188506": 78, "1886": [21, 65], "1887": [26, 46, 67, 70], "188885": 49, "189": [17, 40], "18955": [33, 77], "189862": 96, "189981": [24, 44, 68], "18_natur": 52, "19": [1, 9, 15, 16, 19, 23, 24, 27, 30, 31, 34, 38, 43, 44, 47, 49, 50, 51, 52, 54, 59, 60, 61, 62, 64, 66, 67, 68, 71, 74, 75, 78, 85, 93, 97], "190": [15, 24, 27, 44, 45, 47, 49, 61, 68, 71], "1900": [15, 38], "19000e": 62, "1901": 59, "190319": [27, 47, 71], "19032": [33, 77], "1904": [16, 62], "190617": [18, 63, 64, 94], "1907": 42, "190832": 78, "191": [18, 49, 63], "1910": [15, 38], "1911": [27, 47, 71], "191169": [24, 44, 46, 68, 70], "191204": [27, 47, 71], "191254e": 68, "191396": [16, 62], "1914": [34, 64], "1915": 34, "1916": 34, "1917": 34, "191700": [27, 47, 71], "1918": [19, 34], "1919": 34, "191k": [46, 70], "192": 64, "1920": [34, 59], "192001": 24, "1921": 34, "19213263": [19, 64], "192133": [19, 64], "192158": 24, "19255": 93, "19266": [33, 77], "192932": [23, 43], "193": [32, 76], "1930": 59, "193021": [23, 43, 67, 81], "193122": 67, "1932": 36, "193247": [27, 47, 71], "1933": [15, 38, 60], "193346": [46, 70], "193427": 66, "1936": 59, "19365": [33, 77], "193704": [53, 77, 97], "19380": [33, 77], "1940": [19, 59, 64], "194002": [16, 62], "194008": 49, "194034": [53, 77, 97], "194040": [18, 63], "1942": 20, "19422": [46, 70], "19433594": [31, 51, 52, 75], "1944": [15, 38], "1945": [24, 44, 68], "1946": [24, 44, 59, 68], "194710": [24, 44, 68], "1948": [15, 38], "19485": [18, 63], "194883": [20, 41], "194914": 39, "194985": [24, 68], "195": [17, 18, 63, 95], "1950": [24, 44, 68], "1951": [15, 38, 60], "195228": 64, "1953": [24, 44, 66, 68], "195334": 78, "19536": 67, "1954": [15, 38, 52], "1954400510": [15, 38], "1955": [15, 38, 60], "195564": [27, 47, 71], "1957": [31, 51, 52, 75], "195753": 67, "1959": [13, 15, 38, 59], "19591": [27, 47, 71], "1960": [15, 38, 60], "1962": [31, 52, 75], "1963": 66, "196385": [26, 46, 70], "1965": [15, 38, 60], "196599": [24, 44, 68], "1966": [24, 44, 68], "19664": 20, "196739": [33, 77], "1968": 59, "196958": 24, "196963": 39, "1970": [21, 24, 33, 44, 59, 65, 68, 77], "197007": 24, "197064": 26, "1971": [15, 38], "1972": [24, 44, 68], "197432": 76, "197436": 32, "197473": 78, "1975": [15, 38], "197500": 61, "197649": [27, 47, 71], "1977": [34, 59, 78], "19777": [25, 26, 45, 46, 69, 70], "19781": [33, 77], "197917": 61, "197951": 97, "198": 34, "198127": [24, 44, 68], "1984": [24, 44, 68], "1985": [24, 44, 68], "1986": [15, 38, 64], "198645": [34, 78], "1987": [15, 38, 59, 60], "1989": 59, "198924": [18, 63, 64, 94], "199": [16, 23, 43, 59, 62, 67], "1990": [21, 22, 42, 62, 65, 66], "1991": [15, 25, 38, 45, 60, 69], "1992": [33, 77], "1993": [24, 44, 68], "199364": [23, 43, 67], "1994": [25, 59], "199412": [39, 78], "199413": [22, 42, 62, 66], "19966": [18, 27, 47, 63, 64, 71], "1997": [15, 21, 38, 42, 65, 66], "199771": [26, 46, 70], "19th": 13, "1_000_000_000": 66, "1__1stflrsf": [24, 44], "1__2ndflrsf": [24, 44], "1__3ssnporch": [24, 44], "1__bedroomabvgr": [24, 44], "1__bsmtfinsf1": [24, 44], "1__bsmtfinsf2": [24, 44], "1__bsmtfullbath": [24, 44], "1__bsmthalfbath": [24, 44], "1__bsmtunfsf": [24, 44], "1__enclosedporch": [24, 44], "1__fireplac": [24, 44], "1__fullbath": [24, 44], "1__garagearea": [24, 44], "1__garagecar": [24, 44], "1__garageyrblt": [24, 44], "1__grlivarea": [24, 44], "1__halfbath": [24, 44], "1__kitchenabvgr": [24, 44], "1__lotarea": [24, 44], "1__lotfrontag": [24, 44], "1__lowqualfinsf": [24, 44], "1__masvnrarea": [24, 44], "1__miscval": [24, 44], "1__openporchsf": [24, 44], "1__overallcond": [24, 44], "1__overallqu": [24, 44], "1__poolarea": [24, 44], "1__screenporch": [24, 44], "1__totalbsmtsf": [24, 44], "1__totrmsabvgrd": [24, 44], "1__wooddecksf": [24, 44], "1__yearbuilt": [24, 44], "1__yearremodadd": [24, 44], "1__yrsold": [24, 44], "1d": [17, 32, 34, 40, 76], "1e": [22, 24, 42, 66], "1e1": 22, "1e3": [22, 42, 66], "1e4": [22, 66], "1faipqlsdr_pmcm": 22, "1h": [18, 27, 47, 63, 64, 71, 94], "1m": 76, "1mb": 31, "1r7enrhgx5af97genxm0ix3z_j25lecfocq4kzb": 16, "1st": [9, 20, 25, 26, 33, 45, 46, 67, 69, 70, 77], "1stflrsf": [24, 26, 35, 44, 46, 55, 56, 68, 70, 79], "1v": 84, "1v2": 84, "1v3": 84, "1x10000": 20, "2": [1, 4, 5, 8, 9, 10, 17, 20, 23, 25, 26, 27, 31, 32, 33, 36, 38, 39, 40, 41, 42, 43, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 57, 58, 69, 70, 71, 74, 75, 76, 77, 80, 81, 83, 84, 96, 99], "20": [1, 4, 9, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 30, 31, 33, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 55, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 74, 75, 77, 81, 84, 85, 87, 91, 93, 94, 95, 97, 99], "200": [13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 25, 27, 29, 31, 35, 38, 39, 40, 41, 42, 43, 45, 47, 48, 51, 52, 56, 59, 60, 61, 62, 63, 64, 65, 66, 67, 69, 71, 73, 75, 79, 81, 82, 86, 87, 88, 92, 93, 94], "2000": [16, 17, 20, 22, 24, 25, 26, 27, 32, 36, 40, 41, 42, 44, 45, 46, 47, 57, 58, 62, 66, 68, 69, 70, 71, 76, 80, 81, 84], "200000": [42, 45, 46, 53, 66, 69, 70, 77, 95, 97], "200000e": [15, 38], "200024": [34, 78], "2003": [15, 38], "200326e": [24, 68], "2004": [15, 24, 38, 44, 68], "200458": 39, "200475": [23, 43, 67, 81], "2005": [15, 38], "2006": [24, 26, 35, 44, 46, 55, 56, 68, 70, 79], "2007": [15, 24, 26, 35, 38, 44, 46, 53, 55, 56, 68, 70, 77, 79, 97], "2008": [15, 24, 26, 35, 38, 44, 46, 53, 55, 56, 68, 70, 77, 79, 97], "200849": 24, "200876": [19, 64], "20087625": [19, 64], "2009": [15, 24, 26, 35, 38, 44, 46, 53, 55, 56, 68, 70, 79], "200978": [16, 62], "201": [16, 18, 34, 62, 69], "2010": [20, 24, 26, 41, 44, 46, 53, 68, 70, 77], "20113": [18, 63, 64, 94], "2012": [9, 18, 22, 42, 63, 66], "2013": [15, 31, 38, 51, 52, 53, 75, 77, 97], "201332": [29, 73], "2014": [15, 25, 38, 45, 53, 59, 69, 77], "20140521t000000": [15, 38], "20140623t000000": [15, 38], "20141013t000000": [15, 38], "20141015t000000": [15, 38], "20141209t000000": [15, 38], "201434": 67, "201488": 24, "2015": [15, 32, 33, 38, 53, 76, 77, 97], "20150116t000000": [15, 38], "20150218t000000": [15, 38], "20150223t000000": [15, 38], "20150225t000000": [15, 38], "20150630": [53, 77, 91, 97], "201534": [54, 78], "2016": [9, 32, 33, 76, 77], "20160101": [33, 77], "2017": [26, 46, 53, 70, 77, 97], "201810": [23, 43, 67, 81], "201862": [27, 47, 71], "202": [16, 18, 62], "202060": 81, "2022": [33, 77], "202247": 39, "202259": 49, "2023": [1, 31, 33, 51, 75, 77], "2024": [0, 16, 19, 21, 29, 46, 52, 56, 58, 86, 91, 94, 95, 97], "20248": [18, 63], "2024w1": [0, 13], "2024w2": 13, "2025": [1, 13, 14, 15, 18, 22, 24, 25, 26, 27, 28, 30, 31, 33, 34, 35, 36, 45, 53, 54, 55, 57, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 87, 88, 89, 90, 92, 93, 96], "2025w": 99, "2025w1": [11, 13, 32, 60, 76], "202679": 67, "202736": 76, "20274": [33, 77], "202743": 32, "20277493": 17, "202775": [17, 40], "202839": [23, 43, 67], "203": [16, 18, 49, 62], "20310": [33, 77], "20311": [27, 47, 71], "20319": [33, 77], "203265": [26, 46, 70], "20334": [33, 77], "203397": 32, "203399": 76, "203421": 24, "203500": [18, 63], "20357847293371834": [21, 65], "2036": 59, "204": [16, 18, 52, 60, 61, 62, 66, 92], "2043": [34, 78], "204302": [53, 77, 97], "20433": [27, 47, 71], "204583": 61, "2046": 64, "204600": [22, 42, 62, 66], "204692": 24, "204734": 67, "20485": [33, 77], "205": [16, 18, 49, 60, 61, 62, 92], "205000": [18, 24, 26, 35, 44, 46, 55, 56, 63, 64, 68, 70, 79, 94], "205059": [27, 47, 71], "20509": [33, 77], "20514": [33, 77], "205144": [27, 47, 71], "205323": [53, 77, 97], "205470": 78, "205479": [21, 65], "205527": 78, "205597": [24, 44, 68], "20564": [33, 77], "205795": 49, "206": [16, 18, 22, 36, 42, 57, 58, 60, 61, 62, 66, 80, 81, 92], "206024": 39, "206073": [23, 43, 67, 81], "206099": 66, "20620": [33, 77], "206292": [18, 63], "20639": [27, 47, 71], "2064": [18, 63], "20640": [21, 27, 47, 65, 71], "206724": [34, 54, 78], "20683258": [21, 65], "206897": 96, "20694": [33, 77], "20699": [15, 38], "207": [16, 18, 22, 32, 42, 52, 60, 61, 62, 63, 66, 76, 83, 92], "207039e": 24, "2071": [27, 47, 71], "207814e": 24, "2079": [15, 38], "20794": [33, 77], "208": [16, 21, 22, 42, 60, 61, 62, 65, 66, 92], "209": [16, 22, 42, 49, 59, 60, 61, 62, 66, 92], "209080": 49, "209221": [35, 55, 56, 79], "209583": 61, "209746": 67, "209903": [27, 47, 71], "209935": 24, "209943": 78, "20analysi": [34, 54, 78], "20assumpt": [34, 78], "20hazard": [34, 78], "20intro": [34, 54, 78], "20lifelin": [34, 54, 78], "20with": [34, 54, 78], "21": [1, 14, 15, 16, 17, 18, 19, 20, 23, 24, 27, 28, 30, 31, 33, 38, 40, 43, 44, 47, 49, 50, 51, 52, 53, 54, 59, 60, 62, 63, 64, 67, 68, 71, 72, 74, 75, 77, 78, 93, 97, 99], "210": [22, 42, 66], "210001": [23, 43, 67], "210240": 66, "210272": [27, 47, 71], "210289": 39, "210300": 24, "210591": [18, 63, 64, 94], "210779": [53, 77], "210833": 61, "210852": [34, 78], "21086181023099465": [21, 65], "211": [22, 42, 66], "2110": [18, 63], "211250": 61, "211343": [27, 47, 71], "211378": 26, "211544": [23, 43, 67, 81], "211731": 39, "211892": [18, 63, 64, 94], "211980": 67, "212": [22, 42, 61, 66], "212133": [54, 78], "212303": [54, 78], "212385": [26, 46, 70], "212581": [27, 47, 71], "212688": [23, 43], "21274": [33, 77], "212870": [24, 44, 68], "212975": [24, 44, 68], "213": [22, 32, 33, 42, 66, 76, 77, 95], "2130": 59, "21353": [33, 77], "213571": [54, 78], "21389": [33, 77], "213896": [15, 38], "2139": [18, 63, 64, 94], "214": [22, 42, 49, 59, 66, 95], "21405": [33, 77], "214148": 24, "21436": [15, 38], "2144": 66, "21450": [15, 38], "214677": 43, "214740": [18, 63], "214821": [33, 77], "214852": 67, "2149": 34, "215": [22, 42, 66], "2150": 34, "2151": 34, "215166": 39, "2152": 34, "215245": [24, 44, 68], "2153": 34, "21530": [33, 77], "2154": 34, "215412": [24, 44, 68], "21549": [33, 77], "2155": 34, "2156": 34, "21571": [33, 77], "215744": [54, 78], "21581": [33, 77], "215812": 24, "21582031": [31, 51, 52, 75], "215865": [26, 46, 70], "21596": [33, 77], "216": [22, 42, 66], "21603": [33, 77], "21605": [33, 77], "21608": [15, 38], "21609": [15, 38], "21610": [15, 38], "21611": [15, 38], "21612": [15, 38], "216123": [34, 54, 78], "21613": [15, 38, 60], "21616484": 84, "21617": [33, 77], "216237": 24, "216250": 61, "216346": [26, 46, 70], "21634631": [26, 46, 70], "216585": [18, 63], "216596": [53, 77, 97], "21668": [33, 77], "21670": [33, 77], "216718": 67, "216728": [18, 63], "21694": [33, 77], "21697": [33, 77], "217": [36, 51, 57, 58, 75, 80], "2170": [15, 38, 60], "217334": [19, 64], "21733442": [19, 64], "2173627": [31, 51, 52, 75], "21767954": [26, 46, 70], "21768": [26, 33, 46, 70, 77], "217680": [25, 26, 45, 46, 69, 70], "21774": [33, 77], "218": [19, 64], "21813167": [45, 69], "218207": [18, 63, 64, 94], "21847": [33, 77], "21872": [24, 26, 35, 44, 46, 55, 56, 68, 70, 79], "218760": [26, 46, 70], "218830": [18, 63], "218869": 39, "219": [27, 47, 71], "2190": [18, 63], "2192": 66, "219500e": [15, 38], "219512": [27, 47, 71], "219686": 78, "219700": [27, 47, 71], "219718": 39, "21972656": [31, 51, 52, 75], "219845e": [24, 68], "22": [16, 17, 18, 22, 23, 24, 25, 26, 27, 31, 33, 34, 40, 42, 43, 44, 45, 46, 47, 48, 49, 51, 52, 53, 62, 63, 64, 66, 67, 68, 69, 70, 71, 75, 77, 78, 93, 94, 96, 97, 99], "220": [18, 61], "2200": [17, 40], "220000": 96, "22001": [46, 70], "220392": [34, 78], "220427": 95, "220441": 24, "22057": [33, 77], "2206": [34, 78], "22078": [33, 77], "221": 18, "2210": [15, 38, 59], "22114": [33, 77], "221329": [24, 68], "221348": [53, 77, 97], "221381": 97, "221531": 49, "22154": [33, 77], "221622": [18, 63, 64, 94], "22168237": 84, "221761": 39, "221900": [15, 38, 60], "222": 18, "22219": [33, 77], "22221842": 25, "22221894": [24, 44, 68], "222222": [18, 63], "22225": [33, 77], "222307": [18, 63], "222500": 61, "22260": [33, 77], "222647": [24, 26, 35, 44, 46, 55, 56, 68, 70, 79], "222765": 95, "2229": [21, 65], "222917": 61, "222943": 67, "223": 49, "22320": [33, 77], "223460": [34, 54, 78], "223750": 61, "223804": [46, 70], "223894": 49, "224": [48, 49, 66], "224389": 24, "22452": [33, 77], "224662": [24, 44, 68], "22471154513694652": [21, 65], "224865": [24, 26, 44, 46, 68, 70], "22490352392196655": 31, "22490517795085907": [51, 75], "225": 26, "225301e": 24, "2254": [18, 63], "22550": [33, 77], "226": [48, 66], "226374": 49, "226415": [18, 63], "22648": 20, "226748": 76, "226750": 32, "226789": [34, 54, 78], "2268": [25, 45, 69], "22697768": [19, 64], "226978": [19, 64], "227": 32, "2270": 66, "227090": [20, 41], "227143": [18, 63], "2272": [36, 57, 58, 80, 81], "227289": 78, "227304": [53, 77, 97], "22741": [27, 47, 71], "227559": [24, 26, 35, 44, 46, 55, 56, 68, 70, 79], "227836": [23, 43, 67], "22788": [33, 77], "228": 32, "22811601": [21, 65], "22826": [33, 77], "228329": [23, 43, 67, 81], "2285": 53, "22851562": [31, 51, 52, 75], "228603": [24, 44, 68], "228675": 24, "228716": 24, "229000": [18, 63], "22910": [33, 77], "229102": [26, 46, 70], "2294": 97, "2295": 53, "229718": [46, 70], "229930": 95, "23": [1, 15, 16, 17, 18, 21, 22, 23, 24, 27, 31, 33, 34, 38, 40, 42, 43, 44, 47, 48, 49, 51, 52, 53, 62, 63, 64, 65, 66, 67, 68, 71, 75, 77, 78, 81, 84, 93, 94, 97], "230": [22, 42, 62, 66], "2300": 59, "230000": [15, 38], "23011": [26, 46, 70], "230194": 78, "230412": 26, "2305": [26, 46, 70], "2307": [21, 61, 65], "2309": 53, "231": 99, "2310": [15, 38, 53], "2311": 53, "2312": 53, "2313": 53, "23175": [33, 77], "231815": [26, 46, 70], "232": [17, 40], "232074": 39, "232143": 64, "23223111033439636": [51, 75], "23223206400871277": 31, "232703": 67, "232751": [34, 54, 78], "23290": [33, 77], "233": [15, 38, 60], "233608": 78, "234": [25, 34, 49, 78], "234040": [67, 81], "234303": [15, 38], "234361": 96, "234436": 78, "234616": 24, "234730": [34, 78], "234952": 95, "235": [27, 47, 71], "235096": [18, 63, 64, 94], "235152": [16, 62], "235706": [27, 47, 71], "235833": 61, "236": [22, 34, 42, 62, 66, 78], "2360": [15, 38], "236174": [27, 47, 71], "236210": [28, 72], "23621041": [28, 72], "236217": 26, "23640124": [21, 65], "236456": [18, 63], "236522": 78, "23654": [26, 46, 67, 70], "236960": 66, "237": [34, 78, 81, 99], "2373": 97, "237935": [26, 46, 70], "238": [23, 34, 43, 48, 67, 78], "238192": [26, 46, 67, 70], "2388": [15, 38], "2389": 64, "239": [34, 78], "23900927": 25, "23902": [33, 77], "239083": 39, "23941": [33, 77], "239944e": [24, 68], "239949": 67, "24": [1, 11, 16, 17, 18, 23, 24, 25, 26, 27, 31, 33, 34, 39, 40, 43, 44, 45, 46, 47, 48, 49, 51, 52, 53, 59, 62, 63, 67, 68, 69, 70, 71, 75, 77, 78, 84, 93, 97], "240": [34, 78], "2401": [27, 47, 71], "240483": 96, "24051381": [45, 69], "240893": [27, 47, 71], "241": [34, 78], "24113328": [45, 69], "241379": 96, "241489": [34, 54, 78], "241620": [23, 43, 67], "24182": [53, 77], "242015": [25, 26, 45, 46, 69, 70], "24202916": 25, "242083": 61, "242169": [23, 43, 67], "242308": 96, "242381": [53, 77], "242742": 39, "24295676": [19, 64], "242957": [19, 64], "242996": [18, 63, 64, 94], "243": [33, 77], "243223": 15, "243243": [24, 44, 68], "243447": [46, 70], "2435": [27, 47, 71], "2436": [27, 47, 71], "24395": [25, 26, 45, 46, 69, 70], "24397122221206388": [53, 77], "244": [33, 49, 77], "244020": 15, "244273": [54, 78], "244344": 78, "244556": 49, "244592": [16, 62], "2447": [25, 45, 69], "244814": [34, 54, 78], "245": [33, 77], "2451": 66, "245329": [24, 44, 68], "245521": 67, "245635": 39, "245686": [23, 43, 67, 81], "246": [33, 70, 77], "246332": [24, 44, 68], "246486": [17, 40], "246646": 66, "246646103936": 66, "246653": 66, "24670054": 20, "246950": 15, "247": [33, 77], "247059": 96, "247075": 25, "247119": [53, 77, 97], "247439": [28, 72], "24743939": [28, 72], "247596": [45, 69], "247690828913": 66, "247691": 66, "248": [33, 49, 77], "2483": 41, "2484": 59, "248457": [24, 26, 35, 44, 46, 55, 56, 68, 70, 79], "248609": [24, 68], "248664": [27, 47, 71], "2487200875": [15, 38], "2488": [16, 62], "248843": 15, "248999": [34, 54, 78], "249": 49, "2496": [21, 61, 65], "249601e": 24, "249618e": 24, "249720": [16, 62], "249804": 49, "24h": [36, 57, 58, 80, 81], "25": [1, 9, 15, 16, 17, 18, 19, 21, 22, 23, 24, 25, 26, 27, 28, 29, 31, 33, 34, 35, 38, 40, 42, 43, 44, 45, 46, 47, 48, 49, 51, 52, 53, 55, 56, 58, 59, 60, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 73, 75, 77, 78, 79, 85, 86, 93, 94, 95, 96, 97], "250": [93, 95], "2500": [9, 17, 40], "25000": 59, "250000": [15, 18, 23, 24, 38, 43, 44, 63, 67, 68, 93], "250218": 24, "25031": [33, 77], "25037": [33, 77], "250588": [17, 40], "25058829": 17, "2506": [60, 61, 92], "250696": 15, "250900": [24, 44, 68], "250944": 15, "251": 95, "251093": 66, "251158e": 24, "251239": 38, "25123925": 38, "2516": [25, 45, 69], "2517": 41, "25176": [33, 77], "252": [36, 57, 58, 80], "252042": [27, 47, 71], "25214": [33, 77], "252160": [16, 62], "252163": 15, "252468": 15, "252570": 93, "252846": 15, "253": 49, "2530": 59, "2533": [21, 61, 65], "253312": [18, 63, 64, 94], "253432": [26, 46, 70], "253724": [16, 62], "253914": [24, 44, 68], "254380": 78, "254443": [23, 43, 67, 81], "25462": 93, "25477": 93, "255": [18, 39, 63], "2550": [15, 38], "255000": 96, "255165": [34, 78], "2556": [25, 45, 69], "255751": [27, 47, 71], "255889": [53, 77, 97], "256": [59, 95], "25622": [33, 77], "256263": [25, 26, 45, 46, 69, 70], "256333": [18, 63], "256437": [27, 47, 71], "25658": [27, 47, 71], "256813": [16, 62], "257": [15, 16, 25, 26, 28, 38, 48, 60], "2570": [15, 38, 59, 60], "257024": 66, "257103": [23, 43, 67, 81], "257187": 15, "2574": [27, 47, 71], "257633": 49, "257724": 32, "257725": 76, "257787": [17, 40], "258": 42, "2580": 59, "258225": [33, 77], "25823": 67, "258311": 15, "258387": [26, 46, 70], "2584": [52, 83], "258427": [16, 62], "258495": 49, "258815": [23, 43], "259": [24, 27, 44, 47, 68, 71, 95], "259027": 39, "25904": [33, 77], "2590575478171857": 21, "2590575478171884": 65, "259087": 39, "259286": [16, 62], "259500": [18, 63], "259521": 39, "26": [9, 13, 14, 15, 16, 17, 18, 22, 23, 24, 25, 26, 27, 28, 30, 31, 33, 34, 35, 36, 40, 42, 43, 44, 45, 46, 47, 49, 51, 52, 53, 54, 55, 57, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 87, 88, 89, 90, 91, 92, 93, 96, 97], "2600": [18, 63, 64, 94], "260258": [27, 47, 71], "26048": [26, 45, 46, 69, 70], "260572": [24, 44, 68], "26063": [33, 77], "260890": [24, 26, 35, 44, 46, 55, 56, 68, 70, 79], "261": 95, "261035": [24, 44, 68], "261086": 96, "261953": [53, 77, 97], "262": [24, 26, 35, 44, 46, 55, 56, 68, 70, 79], "262079e": 24, "262096": 95, "262156e": [24, 68], "262269e": 24, "2623": [24, 44, 68], "262361": [27, 47, 71], "262500": [24, 44, 68], "263": [24, 26, 44, 48, 68], "2630": [18, 63], "263000018": [15, 38], "263541": [34, 78], "263600": [18, 63], "26370005": [21, 65], "263736": 78, "263742e": 24, "26376": [33, 77], "264195": 78, "2642": 97, "264283e": [24, 68], "26447953": [19, 64], "264480": [19, 64], "265": [49, 95], "265273": [21, 65], "265483": 39, "266": 95, "266120": [53, 77, 97], "266135": [18, 63, 64, 94], "267": 95, "2670": 66, "267612e": [24, 68], "268": [42, 66], "2683": 67, "26831": [33, 77], "268339": 97, "269": [25, 46], "2691": [60, 61, 92], "26919": [27, 47, 71], "269347": 78, "269880": [16, 62], "269972": [24, 26, 35, 44, 46, 55, 56, 68, 70, 79], "27": [1, 9, 15, 16, 17, 19, 22, 23, 24, 31, 33, 34, 38, 40, 43, 44, 49, 51, 52, 53, 54, 62, 64, 66, 67, 68, 75, 77, 78, 93, 96, 97], "270093": 66, "270093376167": 66, "27021": [33, 77], "270270": [30, 50, 74], "27048": 67, "2705": 66, "271": 45, "271037": [27, 47, 71], "271287": [53, 77], "2713": 93, "271500": [27, 47, 71], "271738e": 24, "2720": [15, 38, 60], "27206": [33, 77], "272297": [54, 78], "27263": [46, 70], "272667": [18, 63, 64, 94], "273": [48, 49, 69], "2730": [18, 63], "27304": [15, 38], "273382": [18, 63, 64, 94], "273606": [18, 63, 64, 94], "2739": 14, "273962": [27, 47, 71], "274": [18, 33, 49, 63, 64, 77, 94], "2742": [46, 70], "274404": [18, 63], "274631": 78, "2749": [46, 60, 61, 70], "275": [25, 32], "275008": [53, 77, 97], "27502378984": 24, "27502379083": 68, "275023791124": 44, "275290": [23, 43, 67], "275352": [16, 62], "275410": [21, 65], "27576982": [20, 41], "2759": [26, 46, 70], "276": [18, 63], "27610135": [31, 51, 52, 75], "27638": [33, 77], "27652": 67, "276533": 96, "276687": [24, 44, 68], "2767": 97, "27676": [36, 57, 58, 80, 81], "27678": [36, 57, 58, 80, 81], "276784": 78, "276943e": 24, "27697": [36, 57, 58, 80, 81], "2770": 66, "27705": [36, 57, 58, 80, 81], "27715": [36, 57, 58, 80, 81], "277381": [16, 62], "277384": 78, "2777": [34, 78], "278441": [53, 77, 97], "278634": 81, "2787": 97, "27874871715903127": [21, 65], "278755": [19, 64], "27875502": [19, 64], "2788": [21, 61, 65], "279371": 95, "2794": [21, 65], "28": [1, 16, 18, 21, 22, 23, 24, 27, 28, 31, 33, 34, 42, 43, 44, 47, 49, 51, 52, 53, 62, 63, 64, 65, 66, 67, 68, 71, 72, 75, 77, 78, 93, 95, 97], "280": [18, 27, 42, 47, 49, 63, 71], "2800": 9, "280028": [27, 47, 71], "280148": 78, "28030": 20, "280310": [18, 63, 64, 94], "2806": 66, "280618": 67, "2807": [34, 54, 78], "280801": [34, 54, 78], "281": [18, 63], "281180": 78, "2812": 97, "28122025534": 24, "281220255387": 68, "281220255463": 44, "281583": [24, 44, 68], "281677": 95, "2817": [26, 46, 70], "281962": 18, "282": 48, "282021e": 24, "2822": [26, 46, 70], "282600": [34, 54, 78], "282778": 96, "283": [32, 76, 95], "283119e": 24, "28327": [33, 77], "283421": [24, 44, 68], "2836": [26, 46, 70], "28362": [33, 77], "283857": [16, 62], "283921": [18, 63], "283948": 20, "284": [27, 33, 46, 47, 71, 77], "284137": 97, "2845": [34, 78], "285": [18, 33, 63, 64, 77, 94], "285263": [26, 46, 70], "28526302": [26, 46, 70], "285467": [24, 26, 35, 44, 46, 55, 56, 68, 70, 79], "28571429": [14, 60], "285740": 96, "286": [15, 22, 33, 42, 61, 62, 66, 77], "286000": 66, "286200": [27, 47, 71], "286327": 39, "286416": 64, "286442": 20, "286482": [54, 78], "2865025": 84, "286545": 76, "286546": 32, "286821": [16, 62], "286870": 20, "287": [33, 77], "287001": 66, "287031": [53, 77, 97], "287147": 96, "2873": 97, "287344": [18, 63, 64, 94], "2874": 34, "287500": [27, 47, 71], "28753559": [31, 51, 52, 75], "288": [33, 77], "288002": [53, 77, 97], "2884": 97, "288462": [21, 65], "28854": [33, 77], "28868": 67, "289": [33, 77, 95], "2890": [22, 42, 62, 66], "289269": [46, 70], "28953": [33, 77], "289541": [24, 26, 35, 44, 46, 55, 56, 68, 70, 79], "289799": [16, 62], "29": [1, 9, 15, 16, 17, 18, 23, 24, 31, 33, 34, 38, 40, 43, 44, 49, 51, 52, 53, 54, 59, 62, 63, 67, 68, 75, 77, 78, 81, 93, 97], "290": [15, 33, 38, 77], "290002": [23, 43, 67, 81], "2902": 97, "290215": [32, 76], "290385": 78, "290424": [24, 68], "29045704": [24, 44, 68], "2907": 97, "290961e": 24, "291": [15, 21, 33, 38, 65, 77], "291134": 49, "291310100": [15, 38], "291667": [30, 50, 74], "291829": 95, "292": [33, 77], "2920": 97, "2925": 97, "292587": 78, "293": [33, 77], "29324459": [32, 76], "293304": 49, "2936": 97, "293631": [54, 78], "293663": [23, 43, 67, 81], "2937": 97, "294": [18, 31, 51, 52, 63, 75, 95], "2940": [34, 97], "2941": 34, "2942": 34, "29425051": 19, "294251": [19, 64], "2943": 34, "2944": 34, "2945": 34, "2946": 34, "2947": 34, "2948": [18, 63, 64, 94], "294855": [26, 46, 70], "295": 70, "295192": 39, "2953863599856858": [21, 65], "295397": [23, 43, 67], "2954": 97, "29545": [24, 44, 68], "2955": 97, "29572402": [31, 51, 52, 75], "295741": 20, "2959": 18, "296": [18, 63], "2960": [18, 97], "2961": 18, "2961559258": 34, "2962": 18, "296236": 49, "2964": 18, "296601": [27, 47, 71], "29691": [33, 77], "297": [21, 65], "2976": 97, "297949": 49, "2980": 97, "29802": [26, 46, 67, 70], "298043": 39, "298434": 39, "298561": [34, 54, 78], "2986": 97, "298612": [53, 77, 97], "2987": 97, "2988": 97, "29881": [33, 77], "299": [15, 38, 49], "299164": [27, 47, 71], "2992": 97, "2993": 97, "2997": 97, "2__bsmtcond": [24, 44], "2__bsmtqual": [24, 44], "2__extercond": [24, 44], "2__exterqu": [24, 44], "2__fireplacequ": [24, 44], "2__garagecond": [24, 44], "2__garagequ": [24, 44], "2__heatingqc": [24, 44], "2__kitchenqu": [24, 44], "2__poolqc": [24, 44], "2d": [14, 17, 32, 34, 40, 76], "2d454e5fd9a5": [34, 54, 78], "2e": 1, "2f": [15, 20, 22, 30, 33, 41, 50, 53, 61, 66, 74, 77, 97], "2m": [32, 76], "2nd": 20, "2ndflrsf": [24, 26, 35, 44, 46, 55, 56, 68, 70, 79], "2qps0o7vbmhf8wkupvnrapiaclcbga": [31, 51, 75], "2v": 84, "2v3": 84, "2x1": [90, 96], "3": [1, 8, 9, 16, 17, 19, 20, 22, 23, 24, 25, 26, 27, 30, 31, 32, 33, 36, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 62, 64, 65, 66, 67, 68, 69, 70, 72, 74, 75, 76, 77, 79, 80, 81, 83, 84, 85, 90, 96, 98], "30": [1, 4, 15, 16, 17, 21, 23, 24, 25, 26, 27, 31, 33, 34, 35, 39, 40, 43, 44, 45, 46, 47, 51, 52, 53, 54, 55, 56, 59, 61, 62, 63, 64, 65, 67, 68, 69, 70, 71, 75, 77, 78, 79, 93, 95, 97, 99], "300": [16, 29, 31, 35, 51, 52, 55, 56, 59, 62, 73, 75, 79, 84], "3000": [17, 40], "300000": [18, 53, 63, 64, 77, 97], "3000000": [31, 51, 52, 75], "3001": 97, "300464": [27, 47, 71], "3005": 97, "3008": 99, "300837": [23, 43, 67, 81], "3009": 93, "301": [34, 48, 78], "3010": [27, 47, 71], "301200": 66, "3013": 97, "3014": [27, 47, 71], "30146": [33, 77], "301563": [24, 44, 68], "3016": 97, "30167": [33, 77], "301784": 78, "3018": 97, "301838": [35, 55, 56, 79], "3019": [21, 60, 61, 65, 92], "301952": [27, 47, 71], "302": [24, 25, 26, 35, 44, 46, 55, 56, 68, 70, 79], "302037": 39, "3021": 97, "302131": [24, 44, 68], "3023": 97, "3026": 97, "302679": 78, "30279": [33, 77], "302801": [34, 54, 78], "302844": 78, "303": [24, 26, 35, 44, 46, 55, 56, 68, 70, 79, 95], "303000": [18, 63], "303004": [27, 47, 71], "303030": [21, 65], "303109": [19, 64], "30310942": 19, "303533e": 78, "303694": 39, "3038344082": [46, 70], "303916": [16, 62], "304": [16, 62], "3040": 53, "3041": 53, "3042": 53, "304211": 49, "3043": 53, "3044": 53, "304494": 20, "304784": [24, 44, 68], "305": 59, "30504657": [28, 72], "305047": [28, 72], "305236": 95, "30530902": [16, 62], "305346": [16, 62], "305674": [27, 47, 71], "3057": [21, 61, 65], "30573": [27, 47, 71], "306500": [16, 62], "307": [18, 63], "307279": [54, 78], "307419": 95, "307521": [21, 65], "30792853": [31, 51, 52, 75], "30798381": [31, 51, 52, 75], "308": 69, "308120": [18, 63], "30815": [24, 44, 68], "308236": 39, "308240": 97, "308448": [16, 62], "3089": 66, "308900e": [15, 38], "309": [27, 47, 71], "3092": [60, 61, 92], "309394": 96, "309859": [21, 65], "30pm": 13, "30th": 59, "31": [15, 16, 18, 21, 23, 24, 25, 26, 28, 31, 33, 34, 38, 43, 44, 45, 46, 48, 51, 52, 53, 59, 62, 63, 64, 65, 67, 68, 69, 70, 72, 75, 77, 78, 81, 93, 94, 95, 97], "310": [1, 95, 99], "310000": [18, 63], "31000e": 62, "310284": [26, 46, 70], "31029469": 17, "310295": [17, 40], "310345": 96, "31038074": [31, 51, 52, 75], "310405": [23, 43, 67, 81], "311": [18, 63], "3110": [18, 63], "311151": [34, 54, 78], "31127015": [26, 46, 70], "311310": 59, "311769": [27, 47, 71], "31177786": 41, "3119640638146517": [21, 65], "3120": [18, 63], "31230": 20, "3125": [18, 63], "312500": [30, 50, 74], "312501": [24, 26, 35, 44, 46, 55, 56, 68, 70, 79], "3128": 97, "31297381": [19, 64], "312974": [19, 64], "31298589e": 76, "31298590e": 32, "313": [24, 25, 44, 49, 68], "313064": 93, "313254": 78, "313397": 78, "31384": 67, "314": [18, 63], "3140": [18, 63], "314000": 66, "31449687e": [26, 46, 70], "31454": [27, 47, 71], "314582": [26, 46, 70], "314840": [27, 47, 71], "314929": [53, 77, 97], "315000": [15, 38], "315134": [53, 77, 97], "3153625428676605": [51, 75], "3153638541698456": 31, "315630": [23, 43, 67], "316": 64, "316164": [27, 47, 71], "316230": [27, 47, 71], "31634363": [31, 51, 52, 75], "316363": [16, 62], "316395e": 24, "316426": [27, 47, 71], "316552": [19, 64], "31655231": [19, 64], "316764": 96, "316798": [27, 47, 71], "317": [18, 26, 34, 46, 63, 70, 99], "317277": [27, 47, 71], "31767136668453344": [15, 38], "317761": [23, 43, 67], "317887": 22, "3179": 97, "318": [18, 34, 63], "3180": 66, "3180174485124284": [18, 63], "3188": 97, "3189": 97, "318937": [18, 63, 64], "319": [15, 18, 19, 34, 38, 60, 63, 69], "31908384": [32, 76], "319483": 39, "319513": 27, "319559": [15, 38], "319630": [34, 54, 78], "31973465": 25, "31984311": [24, 68], "31st": [33, 77], "32": [9, 16, 17, 18, 21, 22, 24, 28, 31, 33, 34, 39, 40, 42, 44, 51, 52, 53, 54, 62, 63, 64, 65, 66, 68, 72, 75, 77, 78, 93, 94, 95, 96, 97], "320": [18, 34, 63], "320155": 67, "320430": [24, 44, 68], "3209427041566191": [15, 38], "321": 34, "321050": [15, 38], "321111e": 24, "3211822": [45, 69], "32127053": [24, 44, 68], "322": [27, 34, 42, 47, 48, 71], "32240": [25, 26, 45, 46, 69, 70], "322465": [15, 38], "32247597e": [26, 46, 70], "322755": [16, 62], "323045": [18, 63, 64], "32323": 59, "32397724e": [26, 46, 70], "324179": 24, "324190": 78, "3244": 93, "324400": 95, "3245": 59, "324762": 39, "325000": [15, 38], "325103": 22, "3252": [27, 47, 71], "325319": [27, 47, 71], "32561": 67, "326": [18, 27, 47, 48, 63, 71], "326368": 97, "326616": [15, 38], "326730": [23, 43, 67], "326741e": 78, "326933": [22, 42, 62, 66], "327": [49, 95], "327037": 78, "327188": [23, 43, 67], "3272": [34, 78], "327283": [24, 44, 68], "32734": [27, 47, 71], "3274": [34, 54, 78], "327408": 67, "327412": [20, 41], "327667e": 24, "3279": 93, "32791718": [31, 51, 52, 75], "328": [27, 47, 48, 71], "328000": [15, 38], "328077e": 24, "328111": [20, 41], "328953": [16, 62], "3298721": [32, 76], "3299": [52, 83], "329911": 95, "33": [9, 15, 16, 18, 21, 22, 23, 24, 27, 31, 34, 38, 42, 43, 44, 47, 51, 52, 53, 59, 62, 63, 64, 65, 66, 67, 68, 71, 75, 77, 78, 93, 97], "330": [5, 10, 14, 17, 33, 35, 37, 40, 49, 56, 59, 60, 76, 77, 79, 99], "33000e": 62, "330207": 97, "330346": [34, 54, 78], "3310": [18, 63], "331585": 66, "331587": 39, "331599": 96, "33191802": [31, 51, 52, 75], "332": 48, "332130": 24, "33223002": [31, 51, 52, 75], "3322447": [31, 51, 52, 75], "33224516": [31, 51, 52, 75], "33224759": [31, 51, 52, 75], "332290": 47, "332671": [26, 46, 70], "3327": [53, 77, 97], "332710": 24, "332746": [34, 78], "332791": 78, "332824": [24, 44, 68], "333": [17, 40, 95], "3330": [18, 63], "33308783": [19, 64], "333088": [19, 64], "333139": [23, 43, 67], "333333": [14, 18, 30, 39, 42, 50, 60, 63, 66, 74], "3333333333333333": [30, 50, 74], "333340": [16, 62], "3336693048477173": [51, 75], "3336699604988098": 31, "33380649": [31, 51, 52, 75], "33380754": [31, 51, 52, 75], "33380761": [31, 51, 52, 75], "33381373": [31, 51, 52, 75], "33394593": [31, 51, 52, 75], "3339473": [31, 51, 52, 75], "33394769": [31, 51, 52, 75], "33395626": [31, 51, 52, 75], "33397112": [31, 51, 52, 75], "334": [27, 47, 49, 71], "33400489": [31, 51, 52, 75], "33411086": [31, 51, 52, 75], "334241": 22, "33425967": [31, 51, 52, 75], "33435326": [31, 51, 52, 75], "33439238": [31, 51, 52, 75], "33440682": [31, 51, 52, 75], "334411": [16, 62], "334576": [24, 44, 68], "33462759": [31, 51, 52, 75], "334668": 96, "33476534": [31, 51, 52, 75], "334768": 39, "335309": [24, 68], "335379": 26, "3355": [18, 63, 64, 94], "3356700488_183566145b": [32, 76], "335746": 95, "33590": [33, 77], "33641142": [26, 46, 70], "3364114233677307": [26, 46, 70], "336411423367732": [26, 46, 70], "33643394": 17, "336434": [17, 40], "33662": 20, "336735": [42, 66], "336826": [19, 64], "33682642": [19, 64], "33683087": [21, 65], "336831": [21, 65], "337034": 71, "33726089": [24, 44, 68], "33732465": [31, 51, 52, 75], "337626": 39, "33782315": [31, 51, 52, 75], "33797555": [31, 51, 52, 75], "338": [22, 42, 62, 66, 95], "338508": [34, 78], "33888659": 9, "339": [23, 43, 48, 67], "339368": [34, 54, 78], "3398": 97, "339889": 78, "34": [16, 17, 18, 21, 23, 24, 27, 31, 33, 34, 40, 43, 44, 47, 51, 52, 59, 62, 63, 64, 65, 67, 68, 71, 75, 77, 78, 93, 94], "340": [1, 3, 14, 25, 27, 32, 33, 34, 45, 49, 53, 54, 60, 69, 76, 77, 78, 82], "34000e": 62, "340162": 32, "340169": 76, "340435": 22, "340986": 22, "340988": [23, 43, 67, 81], "341": 49, "341109": [24, 44, 68], "341300": [27, 47, 71], "341465": 96, "341571": [34, 78], "34161762": [24, 26, 44, 46, 68, 70], "341712": [53, 77, 97], "34182": [46, 70], "342": 49, "3420": [18, 63], "342200": [27, 47, 71], "3423": 93, "342605e": 24, "342902": 22, "343": 49, "343542": 49, "3436": [53, 77, 97], "344": [18, 45, 49, 63], "3442": [34, 54, 78], "34426571": [24, 44, 68], "34441": [24, 68], "344770": 49, "344799": 95, "345": [26, 46, 49, 70], "345136": [16, 62], "345236": 49, "345324": 22, "345386e": 24, "3454": [34, 54, 78], "345651": 22, "345831": 59, "345842": 49, "345904": [23, 43], "346": [15, 18, 38, 49, 63, 64, 94], "346850": [23, 43, 67, 81], "34691": [53, 77], "347": [49, 95], "347047": 22, "347523": 66, "347917": [34, 78], "348": [18, 27, 47, 49, 63, 71], "34806": [24, 68], "34836": 22, "348569": [35, 55, 56, 79], "348755": 22, "348820": 78, "349": 49, "34900": [24, 44, 68], "34924955": [31, 51, 52, 75], "35": [15, 16, 18, 21, 24, 25, 26, 28, 31, 34, 38, 44, 45, 46, 51, 52, 53, 54, 62, 63, 65, 67, 68, 69, 70, 75, 77, 78, 87, 89, 93, 95, 97], "350": [48, 49, 59], "3500": [17, 40], "350000": [18, 63], "350061e": 68, "3509": 93, "351351": [30, 50, 74], "351366": [23, 43, 67], "3515": [34, 78], "351538": 95, "351718": 22, "351812": 78, "351821": [34, 54, 78], "351883": [35, 55, 56, 79], "3521": 59, "352100": [27, 47, 71], "352114": [46, 70], "352309": 22, "3524": 34, "352556": 49, "352868": 22, "352930": [18, 63, 64, 94], "353": [32, 76], "3534": 78, "35375221": 84, "353961": 66, "354045": 22, "354114": [24, 26, 35, 44, 46, 55, 56, 68, 70, 79], "3546": 93, "354604": [23, 43, 67], "3547": [27, 47, 71], "354759e": [24, 68], "355": 69, "355053": 94, "355121": 78, "3552": 34, "35561437": [31, 51, 52, 75], "356689": [25, 26, 45, 46, 69, 70], "35671794": [26, 46, 70], "356908": 95, "357": [18, 63], "3573886": [31, 51, 52, 75], "357441": 95, "357500": [18, 63, 64, 94], "3576": 59, "35771821": [31, 51, 52, 75], "357823": 59, "358": [59, 66], "3582": [34, 54, 78], "358264": [24, 26, 35, 44, 46, 55, 56, 68, 70, 79], "358333": [16, 62], "358500": [27, 47, 71], "358614": 81, "358913": [19, 64], "3589134": [19, 64], "359": [22, 42, 62, 66], "3590": 66, "359618": 95, "359784": 66, "359887": [28, 72], "359992": [16, 62], "35p": 59, "36": [15, 16, 17, 18, 21, 22, 24, 25, 26, 27, 31, 33, 34, 38, 40, 44, 45, 46, 47, 49, 51, 52, 53, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 75, 77, 78, 97], "360": 64, "360000": [15, 38], "360918": [53, 77, 97], "361": [34, 78], "361718": [23, 43, 67], "362": [15, 34, 38, 78], "362009": [33, 77], "362185e": 24, "362250": 67, "362553": [27, 47, 71], "36269995": [19, 64], "362700": [19, 64], "363": [34, 78], "363192": [16, 62], "363340": 18, "363913": [23, 43, 67, 81], "364": [33, 34, 77, 78], "36400": 59, "364008": 38, "36400802": 38, "364352": [21, 65], "364995": 78, "364998": [46, 70], "365": [33, 77], "36525": [46, 70], "365461": 95, "36559349298477173": 31, "3655935227870941": [51, 75], "365603": [21, 65], "365623": [16, 62], "365787": 95, "365897": 26, "365898": 39, "365922": 39, "366": [19, 33, 34, 64, 77, 78], "366005": [23, 43, 67, 81], "3661": 93, "3663": [34, 78], "366626": [16, 62], "36695134": [31, 51, 52, 75], "367": [33, 77], "367329e": 78, "367423": [42, 66], "367547": [31, 51, 75], "367700": [31, 51, 75], "367868": 78, "368": [33, 42, 77], "368064": 78, "368080": 42, "3681": [26, 46, 70], "368304": [21, 65], "3684": [34, 54, 78], "368406": [17, 40], "36840629": 17, "368922": [29, 73], "369": [24, 44, 68], "369142": 97, "369875": [16, 62], "37": [15, 17, 18, 21, 24, 27, 31, 33, 34, 38, 40, 44, 47, 51, 52, 53, 54, 63, 64, 65, 68, 71, 75, 77, 78, 93, 94, 95, 97], "37033313512802124": [51, 75], "37033477425575256": 31, "370370": 96, "37050406": 9, "370643": [23, 43, 67, 81], "370842": [15, 38], "371": [25, 27, 47, 53, 71, 77, 97], "3717": [26, 46, 70], "371722": [46, 70], "371875": 96, "372": [18, 63], "372000": 93, "372706": [53, 77, 97], "372763": [24, 26, 35, 44, 46, 55, 56, 68, 70, 79], "373": 78, "373031": [16, 62], "373116": 96, "373275": [53, 77, 97], "373309": 39, "373411": [15, 38], "373656": [33, 77], "374": [17, 18, 63], "37446": 93, "374678": 22, "374914": [31, 51, 75], "375108": [31, 51, 75], "37546": [46, 70], "376": [17, 18, 24, 31, 40, 44, 63, 68], "376089": [24, 44, 68], "376914": 96, "377032": [24, 44, 68], "377109": 78, "377191": 22, "377619": 66, "377619120792": 66, "37797291": [19, 64], "377973": [19, 64], "378": 78, "37807203": [31, 51, 52, 75], "378108": 22, "378159": [24, 44, 68], "37849843": 25, "378764": [16, 62], "378839": 49, "378971e": 24, "379": 17, "37903": [17, 40], "37906": [23, 43, 67, 81], "379320": 24, "379416e": 24, "379875e": [24, 68], "38": [9, 15, 16, 18, 21, 24, 27, 31, 32, 33, 34, 38, 44, 47, 51, 52, 53, 62, 63, 65, 67, 68, 71, 75, 76, 77, 78, 93, 97], "3803": [34, 78], "380436": [19, 64], "38043616": [19, 64], "380495": [16, 62], "380504": [18, 63, 64, 94], "380643": [16, 62], "381099": 95, "381190": [27, 47, 71], "3814": 64, "381416e": 78, "381428": [24, 26, 35, 44, 46, 55, 56, 68, 70, 79], "381676": [16, 62], "38192364": [28, 72], "381924": [28, 72], "38214537": [45, 69], "382558": [23, 43, 67], "3828125": [31, 51, 52, 75], "383": [18, 27, 47, 63, 71], "383119": 78, "383232": 97, "383482": 96, "383826": 22, "384": 95, "384127": [16, 62], "384532": 39, "3851": 67, "3856": [16, 62], "385639": [28, 72], "385843": [31, 51, 75], "386": 66, "386071e": 24, "386306e": 24, "386530": [26, 35, 46, 55, 56, 70, 79], "386853": 78, "387": 66, "387392": 95, "387779e": 96, "387967": 20, "388": [34, 93], "388023": [23, 43, 67, 81], "388169": [27, 47, 71], "38853": [24, 44, 68], "38867": 41, "3889": 64, "389": [25, 27, 47, 66, 71], "389065": [26, 46, 70], "389349": [27, 47, 71], "389455": 22, "389655": 78, "389736": [18, 63, 64, 94], "39": [16, 22, 23, 24, 28, 31, 33, 42, 43, 44, 48, 51, 52, 53, 62, 66, 67, 68, 72, 75, 77, 89, 95, 96, 97], "390": 26, "390103": 76, "390105": 32, "390428669205": 66, "390429": 66, "390691": [15, 38], "390725": [24, 44, 68], "39095422e": [26, 46, 70], "391": [18, 63], "3912": [34, 54, 78], "391304": [15, 38], "39163": [23, 43, 67, 81], "392": [59, 95], "392082": [26, 46, 70], "392221": [21, 65], "392385": 78, "392572": 49, "392612": [24, 44, 68], "392893": [22, 42, 62, 66], "392894": [31, 51, 75], "392910": [31, 51, 75], "393": [15, 17, 38, 40, 60, 64], "3932": [34, 54, 78], "39375": [33, 77], "393893": 22, "394113e": 24, "394351": 22, "394920": [18, 63], "394943": 22, "395282e": [24, 68], "395429": 34, "39562": 93, "395686e": 24, "395688": [34, 54, 78], "395697e": 24, "396": [18, 34, 40, 63, 78], "396752e": 24, "396991": [18, 63, 64, 94], "397": [34, 78, 95], "398": [27, 47, 71], "398068": 42, "398495": [53, 77, 97], "398916": 39, "39896994": [19, 64], "398970": [19, 64], "399": [15, 18, 38, 63], "3990": [60, 61, 92], "3991": [24, 44, 68], "399287": 96, "39931": [46, 70], "399827": [23, 43, 67], "39x15": [31, 52], "3__bsmtexposur": [24, 44], "3__bsmtfintype1": [24, 44], "3__bsmtfintype2": [24, 44], "3__fenc": [24, 44], "3__function": [24, 44], "3blue1brown": [32, 76], "3d": [27, 32, 47, 71, 76], "3f": [14, 15, 16, 18, 20, 23, 24, 30, 31, 41, 43, 44, 50, 51, 52, 60, 61, 62, 63, 67, 68, 74, 75], "3h": [33, 77], "3m": 32, "3rd": [20, 31, 51, 52, 75], "3ssnporch": [24, 26, 35, 44, 46, 55, 56, 68, 70, 79], "3v": 84, "3x3": [90, 96], "4": [0, 1, 9, 10, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 38, 40, 41, 42, 43, 44, 45, 47, 49, 50, 51, 52, 53, 54, 55, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 83, 84, 85, 96, 98, 99], "40": [9, 16, 17, 21, 22, 24, 25, 26, 27, 29, 32, 33, 34, 35, 39, 40, 44, 45, 46, 47, 53, 54, 56, 59, 62, 65, 66, 67, 68, 69, 70, 71, 73, 76, 77, 78, 79, 87, 93, 95, 97, 99], "400": [15, 18, 22, 35, 38, 42, 56, 60, 63, 66, 79], "40000": [53, 77, 97], "400000": [15, 31, 38, 42, 51, 53, 66, 75, 77, 97], "400047": [34, 78], "400157": [27, 47, 71], "400309": 49, "400649628005": 66, "400650": 66, "400881e": [15, 38], "401": [15, 22, 38, 42, 62, 66], "4011": 52, "401102": [53, 77], "401168": 22, "401541": [23, 43, 67], "401623": [24, 44, 68], "401729": 39, "401830": [26, 46, 70], "401895": 66, "402": 59, "402101": [15, 38], "402209": 22, "402258": [15, 38], "402541": 41, "402655": 18, "402808": [26, 46, 70], "402892": 78, "403169": [31, 51, 75], "403875": 41, "404": [16, 27, 31, 47, 51, 62, 71, 75], "404403": 22, "404809": [34, 78], "405": 95, "405227e": 24, "405415": [16, 62], "405650": [24, 44, 68], "405681": 78, "40584038": 25, "40584038179225734": 25, "406168": 96, "406202": 66, "406212e": 66, "40689": [27, 47, 71], "407": 81, "40725012": [32, 76], "407510": [23, 43, 67], "407862": [34, 78], "408053": 41, "40828": 59, "4084": [34, 78], "409430": [15, 38], "4095": [31, 51, 75], "409524": 32, "409525": 76, "40b5a809b05a": [34, 54, 78], "41": [16, 18, 24, 25, 26, 27, 28, 30, 32, 33, 34, 44, 46, 47, 50, 53, 62, 63, 67, 68, 70, 71, 72, 74, 76, 77, 78, 93, 97], "410": [18, 63], "4101": 93, "410240": [26, 46, 67, 70], "410599": [27, 47, 71], "410687": 95, "411": 95, "411240": 49, "411412": [24, 44, 68], "41150573": [24, 44, 68], "412": [22, 42, 59, 62, 66], "41210938": [31, 51, 52, 75], "412500": [27, 47, 71], "413017": 22, "413718": [34, 54, 78], "413793e": 96, "413796": [24, 44, 68], "413958": [23, 43, 67], "4143": [34, 78], "414404": 39, "415": [17, 40], "4151": [25, 45, 69], "415285": 22, "4153": [27, 47, 71], "4158382658": 63, "416438": 22, "416470": [20, 41], "4165": [25, 45, 69], "4166": 93, "4169": [34, 78], "416992e": 68, "417009": 49, "417259": [31, 51, 75], "417289": [20, 41], "417394": 78, "4175": 93, "418": [31, 51, 52, 75], "418031": [16, 62], "418069": 66, "418213": [34, 78], "41901484361": 66, "419015": 66, "419355": [21, 65], "4195": [46, 70], "4197": [21, 60, 61, 65, 92], "419892": 97, "42": [13, 16, 18, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 32, 33, 34, 39, 43, 44, 45, 46, 47, 48, 49, 50, 51, 59, 60, 61, 62, 63, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 81, 82, 84, 86, 87, 89, 92, 93, 95, 96, 97], "420": 66, "420000": 59, "420347": 23, "42060": [27, 47, 71], "420730e": 78, "420849": 22, "421": [32, 76], "42104086": [26, 46, 70], "421215": [28, 72], "42121526": [28, 72], "42182019352912903": 31, "4218207597732544": [51, 75], "421875": [21, 65], "422": [24, 44, 68], "422024": 49, "422930": 41, "423162": 49, "4234": [26, 46, 70], "423446": 22, "4236": [26, 46, 70], "4237": 26, "4238": 81, "423852": [23, 43, 67, 81], "424221": 24, "424222": 68, "424337e": 24, "424703": 93, "425": 95, "425112": 49, "425365": [34, 78], "42541681": 84, "425419": [24, 44, 68], "425467": 22, "426067": [18, 63], "426410": [16, 62], "427": [34, 78], "427512": 39, "427558": 22, "4276": [36, 57, 58, 80], "428": [34, 78], "428277": 39, "429": [18, 24, 26, 35, 44, 46, 55, 56, 68, 70, 79], "429217": [23, 43, 67, 81], "429634": [34, 78], "4296875": [31, 51, 52, 75], "429741": 96, "429887": 22, "43": [16, 21, 22, 23, 24, 32, 33, 34, 42, 43, 44, 53, 62, 65, 66, 67, 68, 76, 77, 78, 95, 96], "430": [24, 26, 34, 35, 44, 46, 55, 56, 66, 68, 70, 78, 79], "430295": [23, 43], "430323": [18, 63], "430571": [23, 43, 67, 81], "430704": [28, 72], "4307043": [28, 72], "430868": [21, 65], "4309767675259022": [45, 69], "43097677": [45, 69], "431": [34, 78], "4310": [18, 22, 42, 62, 63, 66], "431104": 39, "431137": [21, 65], "4314": 67, "431408": [34, 78], "432": [34, 78], "433": [25, 34, 78], "433514": [53, 77, 97], "433713": 22, "433814": [34, 54, 78], "433861": 96, "434": [21, 22, 34, 42, 46, 62, 65, 66, 78], "43445": [27, 47, 71], "435": [34, 78], "435186": [16, 62], "435294": 96, "435489": [23, 43, 67], "435792": 66, "436": [34, 78], "436492": [24, 44, 68], "43697758253484525": [21, 65], "437": 70, "4372": [28, 72], "437367": [18, 63, 64, 94], "4375": [27, 30, 47, 50, 71, 74], "437500": [30, 50, 74], "437684": [33, 77], "438": [30, 50, 74], "43820175528526306": [51, 75], "4382021725177765": 31, "438275": [19, 64], "43827545": [19, 64], "43833466": [24, 68], "438592": [26, 35, 46, 55, 56, 70, 79], "438906": [26, 46, 70], "439": [18, 63], "4390": [22, 42, 62, 66], "439209": [23, 43, 67], "439254e": [17, 40], "439360": [18, 63], "439384": 41, "439497e": 24, "439779": 67, "44": [16, 18, 21, 23, 24, 27, 28, 33, 34, 43, 44, 47, 48, 52, 53, 61, 62, 63, 65, 67, 68, 71, 77, 78, 83, 93, 97], "440": [33, 42, 53, 66, 77], "440373": 22, "440415": 76, "440418": 32, "440570": 18, "440601": 32, "440602": 76, "440897": [15, 38], "441": [24, 44, 68, 69], "441036": 93, "441136": 41, "441445": [27, 47, 71], "442": [15, 38], "44228": 22, "442377e": 24, "442806": [16, 62], "442918": 39, "4430": [54, 78], "44311": [27, 47, 71], "4432": [27, 47, 71], "44322699": [45, 69], "443317": [16, 62], "443419": [24, 26, 35, 44, 46, 55, 56, 68, 70, 79], "44372": 93, "443993": 49, "444263": 78, "444297": [27, 47, 71], "444444": [18, 63], "444523": 49, "4448": [27, 47, 71], "445": [25, 66], "445111e": 24, "445124e": 24, "445341": 96, "445922": 96, "446216": [27, 47, 71], "446284e": 24, "446617": 22, "446869": [27, 47, 71], "447": [18, 26, 45, 46, 61, 63, 70], "447059": 96, "447461": [53, 77, 97], "447517": [26, 46, 70], "447650": 78, "44787197": [31, 51, 52, 75], "448": 95, "448184": 78, "4482": 59, "448276": 96, "448276e": 96, "448313": 49, "4484": [16, 62], "448757": [34, 78], "44878422": 25, "449061": 22, "449263": 39, "449666": [16, 62], "44966612": [16, 62], "45": [9, 16, 21, 24, 33, 34, 36, 44, 52, 53, 54, 57, 58, 60, 61, 62, 65, 67, 68, 77, 78, 80, 81, 83, 91, 92, 93, 97], "450000": [30, 50, 74], "450000e": [15, 38], "450132": [53, 77, 97], "450739": [24, 44, 68], "450822": [27, 47, 71], "451888": [23, 43, 67], "452600": [27, 47, 71], "453367": [27, 47, 71], "453678": 95, "4537": [34, 54, 78], "454427": [18, 63, 64, 94], "454677": [28, 72], "45467725": [28, 72], "454788": [26, 35, 46, 55, 56, 70, 79], "454966": [23, 43, 67, 81], "4552": [26, 46, 70], "45555535": [26, 46, 70], "455652": [15, 38], "455837": 42, "45587": [53, 77, 97], "45588": [53, 77, 97], "45589": [53, 77, 97], "45590": [53, 77, 97], "45591": [53, 77, 97], "456395": 22, "456419": [27, 47, 71], "45653693": [19, 64], "456537": [19, 64], "456984": [23, 43], "457170": [23, 43], "457211": 18, "457435": [53, 77, 97], "458": [18, 63], "458063": 78, "458084": 49, "458333": [30, 50, 74], "458524": [34, 54, 78], "458879": 49, "459": [17, 24, 40, 44, 68], "4591": [18, 63], "459214e": 24, "459873": 78, "459937": 52, "45a": [53, 77, 91, 97], "45am": [53, 77, 91, 97], "46": [9, 16, 17, 18, 21, 24, 33, 34, 40, 42, 44, 53, 60, 61, 62, 63, 64, 65, 68, 77, 78, 81, 92, 94, 95, 96, 97], "460047": 78, "46019608e": [26, 46, 70], "460294": 42, "460316": 49, "4608": [60, 61, 92], "460950": [28, 72], "461": [17, 18, 63, 66], "462": [45, 51], "462060": 78, "462545": [26, 46, 70], "462963": [21, 65], "463": 67, "463582": [25, 45, 69], "464485": 49, "464815": 49, "465000": 96, "465279e": 24, "46530779": [19, 64], "465308": [19, 64], "465356": [34, 78], "4664": 59, "467": 25, "46729488": [24, 44, 68], "467379": [26, 46, 70], "467628": [27, 47, 71], "467657": 22, "467755": 78, "468": [22, 26, 42, 46, 62, 66, 70], "468232": [53, 77, 97], "468672": 93, "4687": [27, 47, 71], "468882": 96, "468996": 39, "469": [18, 63, 81], "469383": [67, 81], "4695": 67, "469571": [27, 47, 71], "469953": 93, "47": [1, 15, 16, 18, 21, 22, 24, 27, 38, 42, 44, 47, 59, 60, 61, 62, 63, 65, 66, 68, 71, 93, 96], "470": [18, 63], "4700": 66, "470060": [24, 68], "470350": 34, "470666": [24, 44, 68], "471000": [15, 38], "471032": [26, 46, 70], "471357": 49, "472": 19, "47242662": 84, "4726": [34, 54, 78], "472603": [24, 44, 68], "47278": 20, "472790": [23, 43, 67, 81], "473": [31, 51, 52, 75], "473189": 78, "473691": [16, 62], "474": 81, "474552": [16, 62], "47491": [23, 43, 67], "475000": 93, "475099": [26, 46, 70], "475188": 76, "475197": 32, "475540": [31, 51, 52, 75], "476": [14, 18, 60], "4760": 66, "47606": [27, 47, 71], "476092": [24, 26, 35, 44, 46, 55, 56, 68, 70, 79], "476406": [26, 46, 70], "476412": [28, 72], "47641249": [28, 72], "477": [18, 66], "477091": 22, "477291": [27, 47, 71], "477964": 49, "478": 18, "478060": [53, 77, 97], "478508": 39, "478647": 96, "479": [18, 25], "479109": [16, 62], "479132": [27, 47, 71], "479773": [31, 51, 52, 75], "48": [16, 21, 23, 24, 30, 33, 34, 43, 44, 48, 49, 50, 53, 60, 61, 62, 65, 67, 68, 74, 77, 78, 92, 93, 95, 97, 99], "480": [18, 24, 44, 68], "4800": 59, "480219": 49, "480249": [16, 62], "4806334": 52, "48073598": [28, 72], "4809": 66, "481": [18, 63, 97], "4810": [36, 57, 58, 80], "4813": [21, 61, 65], "481514": [24, 68], "481693": 32, "481698": 76, "481793": [18, 63], "481807": 22, "481893": [23, 43, 67, 81], "481960": [23, 43, 67], "482": 18, "4820": [15, 38], "4822": [34, 78], "482233": 49, "482500": 93, "482759e": 96, "482910": 49, "483": [18, 25], "483751": [16, 62], "484": 18, "484937": [21, 65], "485": 18, "485192": 39, "4854": [26, 46, 70], "485722": [31, 51, 52, 75], "486": 18, "4861": [18, 63, 64, 94], "486266": [18, 63], "4863": 93, "486664": [31, 51, 52, 75], "48666667": 40, "487": [18, 63, 64], "487740": [31, 51, 52, 75], "488": [18, 63], "488000": 96, "488163": [31, 51, 52, 75], "488753": [53, 77, 97], "489": 18, "489130": [21, 65], "489238": 16, "489511": 22, "489593": [31, 51, 52, 75], "49": [16, 21, 23, 24, 27, 33, 34, 43, 44, 47, 53, 62, 65, 67, 68, 71, 77, 78, 81, 89, 93, 95, 97], "490": [18, 27, 47, 71], "490000": [18, 63], "490033": [24, 44, 68], "49006623": 40, "490568": 66, "490797": [31, 51, 52, 75], "490930": [31, 51, 52, 75], "491217": [23, 43, 67], "491366": [26, 35, 46, 55, 56, 70, 79], "491379": [18, 27, 47, 63, 71], "491632": 22, "491880": 49, "491968": [31, 51, 52, 75], "492": [18, 63, 64, 81], "49206349206349204": [17, 40], "492270": [19, 64], "49227046": 19, "492307": [31, 51, 52, 75], "492551": [31, 51, 52, 75], "492994": 49, "493": [18, 63], "493489": [31, 51, 52, 75], "493544": [18, 63], "49392051": 19, "493921": [19, 64], "494": [18, 22, 34, 42, 62, 63, 66], "4943": 66, "494309": [15, 38], "495524": 39, "49575": [23, 43, 67, 81], "496": [27, 47, 71], "496146": 78, "496213": [24, 44, 68], "496757": [26, 46, 70], "497143": [31, 51, 52, 75], "497386": [16, 62], "497601": [31, 51, 75], "497787": [24, 68], "497949": [31, 51, 52, 75], "498": [36, 57, 58, 80, 81], "498133e": 24, "498157": 39, "498325": 97, "498381": 49, "498562": [16, 62], "498738": 96, "499375": 16, "499900": [18, 63], "49997": 93, "4__alley_grvl": [24, 44], "4__alley_miss": [24, 44], "4__alley_pav": [24, 44], "4__bldgtype_1fam": [24, 44], "4__bldgtype_2fmcon": [24, 44], "4__bldgtype_duplex": [24, 44], "4__bldgtype_twnh": [24, 44], "4__bldgtype_twnhs": [24, 44], "4__centralair_i": [24, 44], "4__centralair_n": [24, 44], "4__condition1_arteri": [24, 44], "4__condition1_feedr": [24, 44], "4__condition1_norm": [24, 44], "4__condition1_posa": [24, 44], "4__condition1_posn": [24, 44], "4__condition1_rra": [24, 44], "4__condition1_rran": [24, 44], "4__condition1_rrn": [24, 44], "4__condition1_rrnn": [24, 44], "4__condition2_arteri": [24, 44], "4__condition2_feedr": [24, 44], "4__condition2_norm": [24, 44], "4__condition2_posa": [24, 44], "4__condition2_posn": [24, 44], "4__condition2_rra": [24, 44], "4__condition2_rran": [24, 44], "4__condition2_rrnn": [24, 44], "4__electrical_fusea": [24, 44], "4__electrical_fusef": [24, 44], "4__electrical_fusep": [24, 44], "4__electrical_miss": [24, 44], "4__electrical_mix": [24, 44], "4__electrical_sbrkr": [24, 44], "4__exterior1st_asbshng": [24, 44], "4__exterior1st_asphshn": [24, 44], "4__exterior1st_brkcomm": [24, 44], "4__exterior1st_brkfac": [24, 44], "4__exterior1st_cblock": [24, 44], "4__exterior1st_cemntbd": [24, 44], "4__exterior1st_hdboard": [24, 44], "4__exterior1st_imstucc": [24, 44], "4__exterior1st_metalsd": [24, 44], "4__exterior1st_plywood": [24, 44], "4__exterior1st_ston": [24, 44], "4__exterior1st_stucco": [24, 44], "4__exterior1st_vinylsd": [24, 44], "4__exterior1st_wd": [24, 44], "4__exterior1st_wdsh": [24, 44], "4__exterior2nd_asbshng": [24, 44], "4__exterior2nd_asphshn": [24, 44], "4__exterior2nd_brk": [24, 44], "4__exterior2nd_brkfac": [24, 44], "4__exterior2nd_cblock": [24, 44], "4__exterior2nd_cmentbd": [24, 44], "4__exterior2nd_hdboard": [24, 44], "4__exterior2nd_imstucc": [24, 44], "4__exterior2nd_metalsd": [24, 44], "4__exterior2nd_oth": [24, 44], "4__exterior2nd_plywood": [24, 44], "4__exterior2nd_ston": [24, 44], "4__exterior2nd_stucco": [24, 44], "4__exterior2nd_vinylsd": [24, 44], "4__exterior2nd_wd": [24, 44], "4__foundation_brktil": [24, 44], "4__foundation_cblock": [24, 44], "4__foundation_pconc": [24, 44], "4__foundation_slab": [24, 44], "4__foundation_ston": [24, 44], "4__foundation_wood": [24, 44], "4__garagefinish_fin": [24, 44], "4__garagefinish_miss": [24, 44], "4__garagefinish_rfn": [24, 44], "4__garagefinish_unf": [24, 44], "4__garagetype_2typ": [24, 44], "4__garagetype_attchd": [24, 44], "4__garagetype_bas": [24, 44], "4__garagetype_builtin": [24, 44], "4__garagetype_carport": [24, 44], "4__garagetype_detchd": [24, 44], "4__garagetype_miss": [24, 44], "4__heating_floor": [24, 44], "4__heating_gasa": [24, 44], "4__heating_gasw": [24, 44], "4__heating_grav": [24, 44], "4__heating_othw": [24, 44], "4__heating_wal": [24, 44], "4__housestyle_1": [24, 44], "4__housestyle_1stori": [24, 44], "4__housestyle_2": [24, 44], "4__housestyle_2stori": [24, 44], "4__housestyle_sfoy": [24, 44], "4__housestyle_slvl": [24, 44], "4__landcontour_bnk": [24, 44], "4__landcontour_hl": [24, 44], "4__landcontour_low": [24, 44], "4__landcontour_lvl": [24, 44], "4__landslope_gtl": [24, 44], "4__landslope_mod": [24, 44], "4__landslope_sev": [24, 44], "4__lotconfig_corn": [24, 44], "4__lotconfig_culdsac": [24, 44], "4__lotconfig_fr2": [24, 44], "4__lotconfig_fr3": [24, 44], "4__lotconfig_insid": [24, 44], "4__lotshape_ir1": [24, 44], "4__lotshape_ir2": [24, 44], "4__lotshape_ir3": [24, 44], "4__lotshape_reg": [24, 44], "4__masvnrtype_brkcmn": [24, 44], "4__masvnrtype_brkfac": [24, 44], "4__masvnrtype_miss": [24, 44], "4__masvnrtype_ston": [24, 44], "4__miscfeature_gar2": [24, 44], "4__miscfeature_miss": [24, 44], "4__miscfeature_othr": [24, 44], "4__miscfeature_sh": [24, 44], "4__miscfeature_tenc": [24, 44], "4__mosold_1": [24, 44], "4__mosold_10": [24, 44], "4__mosold_11": [24, 44], "4__mosold_12": [24, 44], "4__mosold_2": [24, 44], "4__mosold_3": [24, 44], "4__mosold_4": [24, 44], "4__mosold_5": [24, 44], "4__mosold_6": [24, 44], "4__mosold_7": [24, 44], "4__mosold_8": [24, 44], "4__mosold_9": [24, 44], "4__mssubclass_120": [24, 44], "4__mssubclass_160": [24, 44], "4__mssubclass_180": [24, 44], "4__mssubclass_190": [24, 44], "4__mssubclass_20": [24, 44], "4__mssubclass_30": [24, 44], "4__mssubclass_40": [24, 44], "4__mssubclass_45": [24, 44], "4__mssubclass_50": [24, 44], "4__mssubclass_60": [24, 44], "4__mssubclass_70": [24, 44], "4__mssubclass_75": [24, 44], "4__mssubclass_80": [24, 44], "4__mssubclass_85": [24, 44], "4__mssubclass_90": [24, 44], "4__mszoning_c": [24, 44], "4__mszoning_fv": [24, 44], "4__mszoning_rh": [24, 44], "4__mszoning_rl": [24, 44], "4__mszoning_rm": [24, 44], "4__neighborhood_blmngtn": [24, 44], "4__neighborhood_bluest": [24, 44], "4__neighborhood_brdal": [24, 44], "4__neighborhood_brksid": [24, 44], "4__neighborhood_clearcr": [24, 44], "4__neighborhood_collgcr": [24, 44], "4__neighborhood_crawfor": [24, 44], "4__neighborhood_edward": [24, 44], "4__neighborhood_gilbert": [24, 44], "4__neighborhood_idotrr": [24, 44], "4__neighborhood_meadowv": [24, 44], "4__neighborhood_mitchel": [24, 44], "4__neighborhood_nam": [24, 44], "4__neighborhood_noridg": [24, 44], "4__neighborhood_npkvil": [24, 44], "4__neighborhood_nridght": [24, 44], "4__neighborhood_nwam": [24, 44], "4__neighborhood_oldtown": [24, 44], "4__neighborhood_sawy": [24, 44], "4__neighborhood_sawyerw": [24, 44], "4__neighborhood_somerst": [24, 44], "4__neighborhood_stonebr": [24, 44], "4__neighborhood_swisu": [24, 44], "4__neighborhood_timb": [24, 44], "4__neighborhood_veenk": [24, 44], "4__paveddrive_i": [24, 44], "4__paveddrive_n": [24, 44], "4__paveddrive_p": [24, 44], "4__roofmatl_clytil": [24, 44], "4__roofmatl_compshg": [24, 44], "4__roofmatl_membran": [24, 44], "4__roofmatl_met": [24, 44], "4__roofmatl_rol": [24, 44], "4__roofmatl_tar": [24, 44], "4__roofmatl_wdshak": [24, 44], "4__roofmatl_wdshngl": [24, 44], "4__roofstyle_flat": [24, 44], "4__roofstyle_g": [24, 44], "4__roofstyle_gambrel": [24, 44], "4__roofstyle_hip": [24, 44], "4__roofstyle_mansard": [24, 44], "4__roofstyle_sh": [24, 44], "4__salecondition_abnorml": [24, 44], "4__salecondition_adjland": [24, 44], "4__salecondition_alloca": [24, 44], "4__salecondition_famili": [24, 44], "4__salecondition_norm": [24, 44], "4__salecondition_parti": [24, 44], "4__saletype_cod": [24, 44], "4__saletype_con": [24, 44], "4__saletype_conld": [24, 44], "4__saletype_conli": [24, 44], "4__saletype_conlw": [24, 44], "4__saletype_cwd": [24, 44], "4__saletype_new": [24, 44], "4__saletype_oth": [24, 44], "4__saletype_wd": [24, 44], "4__street_grvl": [24, 44], "4__street_pav": [24, 44], "4__utilities_allpub": [24, 44], "4__utilities_nosewa": [24, 44], "4f": [16, 19, 20, 23, 31, 41, 43, 52, 62, 64, 67, 75], "4th": [20, 25, 26, 45, 46, 67, 69, 70], "4x": 99, "5": [1, 4, 20, 21, 22, 23, 24, 25, 27, 29, 30, 31, 33, 38, 39, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 53, 54, 55, 59, 65, 66, 67, 68, 69, 73, 74, 77, 81, 84, 85, 86, 92, 96, 98, 99], "50": [1, 15, 16, 17, 18, 19, 23, 24, 25, 26, 27, 29, 30, 31, 33, 34, 35, 38, 40, 42, 43, 44, 45, 46, 47, 51, 52, 53, 54, 55, 56, 59, 62, 63, 64, 66, 67, 68, 69, 70, 71, 73, 74, 75, 77, 78, 79, 81, 93, 96, 97, 99], "500": [18, 20, 25, 26, 27, 31, 41, 45, 46, 47, 51, 59, 63, 67, 69, 70, 71, 75], "5000": [13, 15, 20, 36, 38, 41, 57, 58, 59, 60, 80], "50000": [53, 77, 97], "500000": [15, 16, 18, 23, 24, 29, 38, 43, 44, 53, 63, 64, 67, 68, 73, 77, 97], "500000e": [15, 38, 66], "500001": [18, 63], "5000x10000": 20, "500140": 96, "5002": [24, 44, 68], "500625": 62, "50062e": 62, "500924": [18, 63, 64, 94], "501": [18, 63], "501191": [31, 51, 52, 75], "501250": [16, 62], "501304e": 24, "501875": [16, 62], "5024752475247525": 66, "502500": [16, 62], "502654": 96, "502985": [23, 43, 67, 81], "503": 41, "503000": [18, 63], "503090": [23, 43, 67], "503125": [16, 62], "50325": 41, "5034000000000001": 20, "50350": 41, "503709": 95, "503750": [16, 62], "503807": [31, 51, 52, 75], "504": [16, 27, 41, 47, 62, 71], "504231": 78, "504375": [16, 62], "504429": [19, 64], "50442945": 19, "504644": [22, 42, 66], "50475372e": [26, 46, 70], "50483": 22, "504fde4fcf8": [34, 54, 78], "505000": [16, 62], "505026": [15, 38], "505180": [31, 51, 52, 75], "505335": [23, 43, 67], "505592e": 24, "505625": 16, "5057": [24, 44, 68], "50596432e": 84, "506035e": 24, "506079e": 24, "506084e": 24, "506211": [18, 22, 42, 63, 66], "506250": 16, "506410": [21, 65], "506637": 22, "506875": [16, 62], "507130": [42, 66], "507225": 49, "507359": [18, 22, 42, 63, 66], "507500": 62, "50774": [22, 42, 66], "507740": [18, 63], "50775": [22, 42, 66], "507750": [22, 42, 66], "507752": [18, 22, 42, 63, 66], "507754": 78, "507995": [21, 65], "508": [18, 24, 44, 63, 68], "508125": 62, "508133": [18, 22, 42, 63, 66], "508371": [22, 42, 66], "508534": 52, "508741": [31, 51, 52, 75], "50884": [27, 47, 71], "50899": [22, 42, 66], "509000": 59, "509001": [24, 44, 68], "509043": 22, "509045": [15, 38], "509317": [18, 22, 42, 63, 66], "509375": 16, "5098": [31, 52, 75], "509859": [31, 51, 52, 75], "509930": [53, 77, 97], "509991": [23, 43], "50k": [13, 25, 26, 45, 46, 67, 69, 70], "51": [16, 18, 22, 24, 26, 28, 33, 34, 35, 42, 44, 46, 53, 56, 62, 63, 64, 66, 67, 68, 70, 72, 77, 78, 79, 94, 95, 97], "5100": [15, 38], "510000": [15, 16, 22, 38, 42, 60, 62, 66], "510421": [31, 51, 52, 75], "510505": [31, 51, 52, 75], "510625": 62, "510697e": [15, 38], "5107": [15, 38], "510836": [22, 42, 66], "5109": [26, 46, 70], "511": [10, 96], "5112": [15, 38, 60], "51137414e": [26, 46, 70], "51143": [27, 47, 71], "51150": [23, 43, 67, 81], "511620e": 24, "5118": [26, 46, 70], "511862": 49, "512": [32, 76], "5120": 59, "512000": [22, 42, 62, 66], "51226051": [28, 72], "5123": 52, "512319": [18, 63], "512408": [24, 26, 35, 44, 46, 55, 56, 68, 70, 79], "512897": [16, 62], "512x640": [32, 76], "513": [18, 63], "513063": 97, "5131": [52, 83], "513124": 49, "513239": 49, "513333": [17, 40], "513678": [34, 54, 78], "514150": [31, 51, 52, 75], "514155": [18, 24, 44, 63, 64, 68, 94], "514347": 52, "514598e": [24, 68], "5146": [21, 65], "5147": 93, "514950": [17, 40], "51503393": [19, 64], "515034": [19, 64], "515351e": 24, "515443": [46, 70], "5156": [18, 27, 47, 63, 71], "515677": 76, "515678": 32, "515755": [17, 40], "515848": [27, 47, 71], "516199": 52, "516394": [27, 47, 71], "516556": [17, 40], "5166": 59, "516774": 39, "516858": 52, "517241e": 96, "517273": [31, 51, 52, 75], "517346": [23, 43, 67], "517647": 96, "518113": [31, 51, 52, 75], "519000": [15, 38], "519029": [23, 43, 67, 81], "519133": 39, "51923": 22, "52": [16, 18, 21, 23, 24, 27, 33, 34, 43, 44, 47, 53, 62, 63, 65, 67, 68, 71, 77, 78, 81, 96, 97], "520076": 96, "520236": 96, "520495": [31, 51, 52, 75], "520519": 49, "52061": [53, 77], "520700": 52, "520782": [31, 51, 52, 75], "5208": [15, 38, 60], "520835": 95, "520855": 49, "520857": [23, 43, 67], "520864": 93, "5209": [24, 44, 68], "520926": 23, "5212": [24, 44, 68], "521284e": [24, 68], "521567e": 24, "521578e": 24, "521743e": 24, "521772": 52, "521797": 22, "522": [24, 44, 68], "522563e": 24, "5227966": 52, "523595": [31, 51, 52, 75], "523659": 49, "523684": [31, 51, 52, 75], "5238095238095238": [14, 60], "52398": [27, 47, 71], "524": [14, 30, 50, 60, 74], "524364": 78, "5245916114790287": 40, "525": [17, 40], "5253": [26, 46, 70], "525554": [27, 47, 71], "525757": [16, 62], "526046": 52, "526078": [18, 63, 64, 94], "526435": 39, "526501": 22, "526596": [27, 47, 71], "526602": [24, 44, 68], "526780": 39, "527251": [34, 78], "5274": [34, 54, 78], "527500": [18, 63], "528": [24, 44, 68], "5282": [34, 54, 78], "528403": [16, 62], "52881619": [16, 62], "529": 95, "529210": [23, 43, 67], "529212": 32, "529213": 76, "529388e": 24, "5294": [25, 45, 69], "529412": [18, 63], "52980132": 40, "53": [15, 21, 24, 33, 38, 42, 44, 48, 53, 65, 68, 77], "530052": 66, "530468": 32, "530470": 76, "530978": [23, 43, 67, 81], "531": [35, 56, 79], "531116e": 24, "5315": 66, "53187": [36, 80], "532034": [24, 44, 68], "5324": 34, "5325916114790287": 17, "532694": 78, "533035": 39, "53333333": 40, "533498": [16, 62], "533875": 49, "534114": 66, "534342": [27, 47, 71], "5345": [15, 38], "534753": 97, "535": [18, 27, 47, 63, 71], "535014": [18, 63], "53520104": [16, 62], "535604": [18, 63], "535622": [27, 47, 71], "535896": [20, 41], "536": 25, "536362": [28, 72], "53636249": [28, 72], "53642384": 17, "536751": 93, "537": 64, "537267": [18, 63], "537584": 93, "537732": [31, 51, 52, 75], "537778": 96, "538000": [15, 38, 60], "538565": 49, "538702": [16, 62], "538816": [23, 43, 67, 81], "539": [24, 95], "5390": [26, 46, 67, 70], "5391": [18, 27, 47, 63, 71], "539116": [53, 77, 97], "539254": 39, "539376": 78, "539424": [34, 78], "539989": [15, 38], "54": [24, 33, 34, 40, 44, 51, 53, 68, 75, 77, 78, 89, 93, 95, 97], "540": [33, 53, 77], "540000": [18, 63], "540039": 52, "540088": 38, "540359": [27, 47, 71], "541117": [24, 44, 68], "541347": [31, 51, 52, 75], "541408": 22, "541488": [27, 47, 71], "54152": 67, "541667": 64, "541795": [23, 43, 67], "542": [35, 56, 79], "542049": [46, 70], "54240": [23, 43, 67], "542624": [26, 46, 70], "542873": [18, 63, 64, 94], "54304636": [17, 40], "5431876379690949": 17, "543297": 66, "543351": [26, 46, 70], "543464": [31, 51, 52, 75], "543673": 39, "544": 66, "544084": 39, "544122": 32, "544123": 76, "544821": 49, "546": [18, 63], "5461": [24, 44, 68], "546137": 39, "546322": 95, "5463515822289584": 42, "546352": 42, "546473": [21, 65], "546610": [16, 62], "54666667": [17, 40], "54676006e": [26, 46, 70], "547": [24, 44, 66, 68], "547090": 52, "547804": 49, "547993": [23, 43, 67, 81], "548": [16, 25, 26, 28, 95], "548750": 16, "548778": 96, "5488206169941388": 93, "548831": [26, 46, 70], "54966887": [17, 40], "549682": [23, 43, 67, 81], "5498": [16, 62], "549946": [31, 51, 52, 75], "55": [16, 21, 24, 25, 26, 33, 34, 35, 44, 45, 46, 48, 51, 54, 56, 60, 61, 62, 65, 67, 68, 69, 70, 75, 77, 78, 79, 81, 92], "55000": 66, "550000": [18, 63, 64, 66], "550004": [25, 45, 69], "55015": 39, "550616": [67, 81], "551": 64, "55101": [53, 77], "55121578": 25, "5513": 66, "5514": [25, 26, 45, 46, 69, 70], "5515": [34, 54, 78], "551686": 22, "551724": 96, "551759e": 78, "551862e": [24, 68], "551975": 24, "552": [18, 24, 44, 63, 68], "552364": 49, "552492": [15, 38], "552721": [45, 69], "553": 15, "55333333": [17, 40], "553965": [26, 46, 70], "553979": [23, 43, 67], "554": 93, "5540": [34, 78], "554180": [53, 77, 97], "554463": 52, "554621": [27, 47, 71], "5551": [21, 65], "555180": [15, 38], "555625": 16, "555740": [16, 62], "556": [31, 51, 75], "55629139": 40, "5566": [18, 63, 64, 94], "556716": [17, 40], "55677301": [45, 69], "557": 69, "557242": [23, 43, 67], "557739": 24, "558": [24, 26, 27, 35, 44, 46, 47, 55, 56, 68, 70, 71, 79], "558564": [23, 43, 67, 81], "55862988e": [26, 46, 70], "55873323": 76, "55873324": 32, "5588": 59, "558824": [23, 43, 67], "558889": [24, 44, 68], "559": [24, 26, 35, 44, 45, 46, 55, 56, 66, 68, 70, 79], "559284": [15, 38], "559905": 32, "559906": 76, "56": [16, 23, 24, 28, 34, 43, 44, 53, 62, 64, 67, 68, 77, 78, 89, 95, 97], "560": [15, 38, 93], "560053": [15, 38], "560225": [18, 63], "560439": 97, "560768": [24, 44, 68], "561": [1, 22, 26, 27, 42, 47, 62, 66, 71], "561017": 23, "561074": 23, "561467": [18, 63, 64, 94], "561602": [26, 46, 70], "561645e": [24, 68], "562112": [18, 63], "5623061656951904": [31, 51, 75], "5623062252998352": 52, "562680": 93, "562712": [31, 51, 52, 75], "56291391": 17, "563": 1, "5630224174651548": [21, 65], "5630921721458435": [31, 51, 52, 75], "5631500400": [15, 38], "563314": [24, 26, 35, 44, 46, 55, 56, 68, 70, 79], "563467": [18, 63], "5639418363571167": [51, 75], "5639421939849854": 31, "564264": 22, "5644": [24, 44, 68], "564483": [27, 47, 71], "564548e": 24, "564631": 78, "565": [27, 47, 71], "5650": [15, 38, 60], "565062": [34, 54, 78], "56521734": 9, "565344": 49, "565621": 96, "565679": [23, 43, 67], "565746": 78, "565888": [18, 63], "566": [18, 63], "566092": [18, 63], "566144": 26, "56666667": 40, "5667": 67, "567169": [34, 78], "567183": 23, "567856e": 24, "568": [32, 76], "568009": [16, 62], "56804591": [24, 44, 68], "568474": 93, "568549": 93, "568663": 24, "568750": 62, "5690201394302518": [26, 46, 70], "56902014": [26, 46, 70], "56902323": [45, 69], "5690232324740979": [45, 69], "569375": 16, "5694": [27, 47, 71], "56953642": [17, 40], "57": [15, 16, 18, 22, 23, 24, 26, 33, 34, 35, 43, 44, 46, 53, 54, 55, 56, 62, 63, 64, 67, 68, 70, 77, 78, 79, 81, 93, 94, 95, 97], "570015": [24, 44, 68], "570449": [23, 43, 67], "570473": [27, 47, 71], "570599": 34, "5707": [34, 54, 78], "570739": [27, 47, 71], "571": [17, 28, 40, 72], "571431": [31, 51, 52, 75], "571500": [27, 47, 71], "571676": [20, 41], "571800": [15, 38], "571875": 16, "571901e": 24, "571969": [27, 47, 71], "572": 1, "572105": [16, 62], "572549": [18, 63], "572962": 78, "573": 84, "573050": [23, 43, 67, 81], "573129": [24, 26, 35, 44, 46, 55, 56, 68, 70, 79], "5732": [36, 57, 58, 80, 81], "573275": 93, "57333333": 17, "573457e": 78, "573542": [27, 47, 71], "573818": [23, 43, 67, 81], "573941": 93, "574": 15, "57415": [53, 77, 97], "574260": [27, 47, 71], "5744": 93, "575": 25, "575000": [30, 50, 74], "575043": [15, 38], "57510": [27, 47, 71], "575111": 96, "575190": 93, "5755444169044495": [51, 52, 75], "5755444765090942": 31, "575625": 62, "575636": [17, 40], "575756": 32, "575759": 76, "575907": [27, 47, 71], "576": [18, 63], "57615894": [17, 40], "57640869": [19, 64], "576409": [19, 64], "576434": 76, "576441": 32, "576565": 93, "576921": [31, 51, 52, 75], "578459": 39, "578523": [21, 65], "578567": 39, "578654": [67, 81], "5789": [24, 44, 68], "579": [42, 92], "579091": [27, 47, 71], "579245": [31, 51, 52, 75], "579432": [21, 65], "579559e": 24, "579660": [25, 45, 69], "5798": [25, 45, 69], "57994": [23, 43, 67, 81], "58": [16, 21, 24, 28, 33, 34, 44, 60, 61, 62, 65, 68, 77, 78, 92, 93], "580": [32, 76], "580000": 16, "580302e": [15, 38], "5804311633110046": [31, 51, 52, 75], "580539e": [24, 68], "580963": 22, "581": [26, 46, 70], "581217": [25, 45, 69], "581275": 23, "5813": [15, 38], "58137177": [19, 64], "581372": [19, 64], "5814": 59, "581687": [27, 47, 71], "581787": 78, "582": [25, 45, 59, 69], "582090": [23, 43, 67], "5824530124664307": [31, 51, 75], "5824530720710754": 52, "582469": [24, 68], "582570": [17, 40], "583": 15, "583125": 16, "58387198": [28, 72], "583872": [28, 72], "583972": 39, "584": [18, 63], "584101": 49, "584375": 62, "584615": [18, 27, 47, 63, 71], "585": [18, 63], "585187": [17, 40], "585513": [21, 65], "585609": 93, "5857": [34, 78], "586095": [18, 63, 64, 94], "586207": 96, "586875": 16, "587773": 67, "588": [22, 42, 62, 66], "588235": [21, 65], "588307": [18, 63], "589262": 96, "59": [1, 13, 16, 24, 34, 42, 44, 53, 54, 62, 68, 77, 78, 95, 96, 99], "590": [15, 26], "590243": [31, 51, 52, 75], "59049": [43, 67], "59050": [43, 67], "590618": [27, 47, 71], "59082668": [19, 64], "590827": [19, 64], "5915": 64, "591875": 62, "591971": [23, 43], "592401": 59, "592500": [16, 62], "592508": 39, "5925410985946655": [31, 51, 52, 75], "592797e": 78, "59300": [27, 47, 71], "5931": [24, 44, 68], "593125": 62, "593370": 24, "593508": [28, 72], "593750": 62, "5938": [18, 63], "593860": 26, "594": [18, 63], "5941": [15, 38], "5941596182077427": 25, "59415962": 25, "5944": [15, 38], "594595": [16, 62], "594982": [23, 43, 67, 81], "594995": 67, "5950": [18, 63], "595569e": 24, "596151": [27, 47, 71], "596810": [16, 62], "596864": [24, 44, 68], "5970": [25, 45, 69], "59700": [23, 43, 67], "597015": [21, 65], "59708": [23, 43, 67], "597326": 67, "597500": 62, "597555": 59, "597924": [24, 26, 35, 44, 46, 55, 56, 68, 70, 79], "598": [18, 63], "598057": [17, 40], "59810": [23, 43, 67], "598100": [21, 65], "598149": [24, 26, 35, 44, 46, 55, 56, 68, 70, 79], "598723": 22, "598821": 93, "5993570685386658": 52, "5993571281433105": [31, 51, 75], "599492": [21, 65], "599860": [16, 62], "599894": [53, 77, 97], "59pm": 13, "5fin": [24, 44, 68, 70], "5m": 32, "5th": [25, 26, 45, 46, 67, 69, 70], "5unf": [24, 44, 68, 70], "6": [1, 9, 15, 16, 18, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 38, 39, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 59, 60, 61, 62, 63, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 84, 85, 86, 92, 98], "60": [9, 18, 24, 26, 27, 28, 30, 33, 34, 35, 44, 46, 47, 52, 54, 55, 56, 59, 63, 68, 70, 71, 72, 74, 77, 78, 79, 81, 83, 95], "600": [18, 21, 51, 52, 63, 65, 75], "60000": [53, 77, 97], "600000": [16, 42, 53, 61, 62, 66, 77, 93, 97], "600193": [23, 43, 67], "60023631": [24, 68], "600299": 39, "600k": [24, 44, 68], "600x400": 98, "601": 66, "601042": 59, "601198": 49, "601504": [21, 65], "601712": [23, 43, 67], "601790": [21, 65], "602": [15, 18, 63, 64, 94, 95], "602000": [18, 63], "602649": [16, 62], "6028": 67, "602936": 96, "602941": [23, 43, 67], "602954": [45, 69], "6031432151794434": [51, 52, 75], "6031432747840881": 31, "60319915": 84, "603243": [15, 38], "603739": [15, 38], "603750": 62, "603970": 78, "604": [16, 62, 96], "6040": [22, 42, 62, 66], "604000": [15, 38, 60], "604032": [23, 43, 67, 81], "60429913": [24, 44, 68], "604320": [21, 65], "60455": [53, 77, 97], "604619": [21, 65], "604797": [21, 65], "6048": [53, 77], "604807": 78, "60495488": [16, 62], "605060": [23, 43, 67], "6051": [18, 63, 64, 94], "605100": [21, 65], "605101": [21, 65], "605102": [21, 65], "605263": [16, 62], "605665": 49, "605696": [21, 65], "606": [18, 63], "606000": 93, "606061": [21, 65], "6063088774681091": [31, 51, 52, 75], "606557": [21, 65], "606567": [21, 65], "606754": 20, "606811": [22, 42, 66], "606902": [21, 65], "607062": [53, 77, 97], "608050": [21, 65], "608125": 16, "6082": [18, 63], "608468": [21, 65], "608565": [34, 54, 78], "60860": [18, 63], "608633": [20, 41], "6086404323577881": [31, 51, 75], "6086405515670776": 52, "608943": 97, "609": [18, 63], "609039": 49, "6092": 59, "6093292236328125": [31, 52], "6093292832374573": [51, 75], "60943": [23, 43, 67, 81], "60k": [24, 44, 68], "61": [16, 19, 21, 24, 28, 34, 44, 49, 53, 62, 64, 65, 67, 68, 72, 77, 78], "610143": 39, "61029914": [24, 44, 68], "610407": [23, 43, 67], "610931": [29, 73], "611": 64, "6111123561859131": [51, 52, 75], "6111124157905579": 31, "611178": [53, 77, 97], "611390": 93, "611445e": 24, "611742": 49, "611875": 16, "612349": [19, 64], "61234944": [19, 64], "6124": [34, 54, 78], "6124401913875598": 92, "612500": 62, "612546": [23, 43, 67], "612621": [21, 65], "612755": [16, 62], "612998": 78, "613231": [17, 40], "613507": [21, 65], "613738": 66, "613738418384": 66, "614": [18, 63], "61420598": [19, 64], "614206": [19, 64], "614236e": 78, "614567": [27, 47, 71], "614629": 25, "614761": 23, "614861": 39, "615": [18, 63], "615124": [45, 69], "6154": [27, 47, 71], "616": 66, "616099": [22, 42, 66], "6168": [15, 38, 60], "617342": 78, "617431": [29, 73], "6176": [23, 43, 67], "617647": [23, 43, 67], "61785463": [45, 69], "618": [18, 63], "618000e": [15, 38], "618012": [22, 42, 66], "618125": 16, "6186580061912537": 52, "6186580657958984": [31, 51, 75], "618967": [31, 51, 52, 75], "61912405": [26, 46, 70], "62": [16, 17, 22, 23, 24, 33, 34, 40, 43, 44, 53, 62, 66, 67, 68, 77, 78, 95, 97], "620": 46, "620729": 39, "6210": [15, 38], "62150157": 25, "621537": 25, "622091": [20, 41], "622255": [18, 63], "622454": [22, 42, 66], "6226": [27, 47, 71], "622612": [23, 43, 67, 81], "622709": [21, 65], "623000": [18, 63], "623012": 78, "623034": 49, "62320": [53, 77], "624049": [24, 44, 68], "6241": 59, "624382": 93, "624450e": 24, "624615": [24, 44, 68], "624897": 49, "6250": [18, 63], "625000": 62, "625387": [22, 42, 66], "625682": 93, "6257": [34, 78], "626206": [24, 68], "62657": [53, 77], "62688064": [26, 46, 70], "626946": 78, "627153": 49, "627256": 49, "6273": 66, "6275": [60, 61, 92], "627722": [26, 46, 70], "627741": 49, "627966": [18, 63], "628032": [27, 47, 71], "628139": [23, 43, 67], "62873917": [26, 46, 70], "629792e": 24, "63": [16, 22, 23, 24, 33, 34, 42, 43, 44, 53, 62, 66, 67, 68, 77, 78, 81, 93, 97], "6303": [18, 63, 64, 94], "6306": [18, 27, 47, 63, 71], "630625": 62, "631104": 22, "631122": 78, "631899": 78, "632": 42, "6320": [21, 65], "6320978999137878": [51, 75], "6320979595184326": [31, 52], "6322": [27, 47, 71], "632294": 39, "632353": [23, 43, 67], "632786": [53, 77, 97], "63316788": 84, "63362": [24, 68], "633750": 16, "633933424949646": [31, 51, 52, 75], "634397": [21, 65], "634490": 64, "634686": [23, 43, 67], "634832": 49, "635": [18, 63], "635200": [27, 47, 71], "635239": [18, 63, 64, 94], "635466": 25, "635648": [21, 65], "635815": [45, 69], "636": [18, 34, 59, 63, 64, 78, 94], "636688": 49, "636849e": [24, 68], "637": [32, 76], "637982": [16, 62], "638169": [26, 46, 70], "6386": [17, 40], "638822": 93, "6389": [18, 27, 47, 63, 71], "6391518364256": [34, 54, 78], "6392": [27, 47, 71], "639754": [24, 44, 68], "64": [16, 21, 24, 33, 34, 44, 53, 62, 65, 68, 76, 77, 78, 95, 96], "640": [32, 42, 66, 76], "6400": [18, 63], "640000": [23, 43, 67], "640266": [18, 63, 64, 94], "640370e": 78, "640x480": [16, 62], "641216": [53, 77], "641297": 78, "6414100192": [15, 38], "641538": [34, 54, 78], "641873": [24, 44, 68], "642": 34, "642059": 39, "642676": [33, 77], "642965": 67, "643": [66, 78], "6431": [27, 47, 71], "643125": 62, "643311e": 24, "64331495": 17, "643315": [17, 40], "643700e": 78, "644106": [23, 43, 67, 81], "64417243": [32, 76], "64454": [23, 43, 67, 81], "644770": [29, 73], "645000": 62, "645190": 97, "645519": [23, 43, 67], "6458": [60, 61, 92], "645963": [22, 42, 66], "646050": [26, 46, 70], "6464": [34, 54, 78], "646617": [35, 55, 56, 79], "6467019867549668": [17, 40], "647": 95, "647796": [27, 47, 71], "648": [18, 22, 42, 62, 63, 66], "6480": [25, 45, 69], "648195": [23, 43, 67, 81], "648527": 49, "649513": 49, "649658": [26, 46, 70], "64994": [53, 77, 97], "65": [19, 22, 24, 34, 44, 48, 60, 64, 68, 78], "650": [67, 95], "65000": 66, "650000": 66, "65000e": 62, "65013704": [28, 72], "650743": [15, 38], "651": [15, 38], "651000": 96, "65125032": 84, "6513": [26, 46, 70], "651359e": [15, 38], "651446": [53, 77, 97], "652": 95, "65243": [24, 44, 68], "652487": [27, 47, 71], "652500": 16, "652683": 49, "6526853": [24, 44, 68], "652828": [22, 66], "652986": [27, 47, 71], "653": [18, 63], "6530": 93, "653205": 66, "653205232272": 66, "653371": 93, "653475": 49, "654": [18, 63], "65424895": [24, 44, 68], "65486": [52, 83], "654935": 78, "655050e": 68, "655172": 96, "656297e": [24, 68], "656349": [16, 62], "656827": [23, 43, 67], "656873": [15, 38], "657675": [27, 47, 71], "657786e": 24, "658047": [21, 65], "658222": [34, 78], "658645": [21, 65], "659056": [24, 44, 68], "66": [18, 21, 24, 44, 53, 60, 61, 63, 65, 68, 77, 92, 93, 95, 96, 97], "6600060120": [15, 38], "6601256728172302": 52, "660125732421875": [31, 51, 75], "660171": [16, 62], "6604": [18, 63, 64, 94], "660714": 64, "660834": 32, "660837": 76, "661023": [31, 51, 52, 75], "66214339": [16, 62], "662205": 49, "66221": [53, 77], "6622507572174072": [31, 51, 52, 75], "662450": [23, 43, 67, 81], "662500": 16, "662541e": 24, "662745": [18, 63], "662777": 25, "662853": [45, 69], "663576": 96, "66368": [26, 46, 70], "663680": [24, 26, 35, 44, 46, 55, 56, 68, 70, 79], "6637": [34, 78], "6638": [34, 78], "663822": [26, 46, 70], "6639": [34, 78], "6639008522033691": [51, 75], "6639009118080139": [31, 52], "6641": [34, 78], "6642": [34, 78], "664207": [23, 43, 67], "6643": [34, 78], "6644": [34, 78], "6645": [34, 78], "664625": [31, 51, 52, 75], "664707": [21, 65], "66473": [53, 77, 97], "665": [18, 63], "665307": [31, 51, 52, 75], "665351e": 24, "665882": [25, 45, 69], "666": [18, 63], "666166": [53, 77, 97], "666667": [18, 30, 42, 50, 61, 63, 74], "666875": 62, "667450": [53, 77], "6679946879150066": 17, "668": [31, 51, 52, 75], "668787": [16, 62], "6688": 59, "669": 17, "669376": [25, 45, 69], "66941678": 17, "669417": [17, 40], "669614": [23, 43, 67, 81], "669805e": [24, 68], "669897": 49, "67": [19, 21, 24, 33, 34, 44, 53, 54, 60, 61, 64, 65, 67, 68, 77, 78, 81, 93, 96], "670003": 22, "670344": [16, 62], "670625": 62, "6706507304116865": 40, "670854": 25, "6709133386611938": [51, 75], "6709133982658386": 52, "6709135174751282": 31, "671219": 20, "671250": 62, "671272e": [15, 38], "671772": 20, "6718650306": 24, "6718650315": 44, "67186503176": 68, "6731126308441162": [31, 52], "673112690448761": [51, 75], "673277": [22, 66], "6733849048614502": 52, "673384964466095": [31, 51, 75], "6734487414360046": [31, 51, 52, 75], "673951": 76, "673952": 32, "673983": [45, 69], "674": [17, 40], "6744": [26, 46, 70], "674490": 66, "675": 95, "675000": 59, "67501": [53, 77], "67512181": [24, 44, 68], "675570": 42, "67562658": [19, 64], "675627": [19, 64], "675676": [30, 50, 74], "675814": [16, 62], "676": [35, 55, 56, 79], "67672595": [24, 44, 68], "677": [17, 18, 40, 63], "6771429181098938": [31, 51, 52, 75], "6772": [34, 78], "677268": 78, "677567": [15, 38], "677579": [16, 62], "677601": [22, 66], "677629": [16, 62], "6778583526611328": [31, 51, 52, 75], "678": [22, 42, 62, 66], "678000": [15, 38], "678347": 42, "678689": [21, 65], "678924": 25, "679": 95, "679240": [15, 38], "679356": [25, 45, 69], "679478": [18, 63], "679516": 49, "679877": [24, 26, 35, 44, 46, 55, 56, 68, 70, 79], "68": [15, 16, 19, 24, 26, 28, 29, 33, 34, 44, 46, 53, 54, 60, 61, 62, 64, 67, 68, 70, 72, 73, 77, 78, 93, 97], "68000": [34, 54, 78], "680000": 59, "680029571056366": [31, 51, 75], "6800296306610107": 52, "680437": 93, "680657": [18, 63], "680838": 93, "681223": [16, 62], "681427": 39, "681716": [31, 51, 52, 75], "681732": 78, "682500": 16, "683015": [25, 45, 69], "683061": 93, "683171": [23, 43, 67], "68323": [22, 42, 66], "68339": [53, 77, 97], "683588": [20, 41], "683955": 97, "684211": [16, 62], "684447": [18, 63], "684532": 49, "684623": [25, 45, 69], "684960": [18, 63, 64, 94], "685": [15, 38], "685006": [17, 40], "685103e": 24, "685175": 15, "68517546": 15, "68523": [53, 77], "685625": 16, "685786": [25, 45, 69], "6858": [21, 65], "685841": 78, "686": [18, 63], "686348e": 24, "686569536423841": [17, 40], "687": [24, 44, 68], "687055": [23, 43, 67, 81], "687307": [22, 42, 66], "687500": 61, "687504": [31, 51, 52, 75], "687613": 42, "688": [42, 66], "6880359361853483": [21, 65], "688043475151062": [51, 52, 75], "6880435943603516": 31, "688135": 66, "68822214": 41, "688484": [15, 38], "689338": [24, 26, 35, 44, 46, 55, 56, 68, 70, 79], "689356": 93, "69": [15, 16, 17, 19, 24, 28, 34, 44, 48, 53, 54, 60, 61, 62, 64, 68, 72, 77, 78, 95, 96, 97], "690115": 93, "69027185e": [26, 46, 70], "690402": [22, 42, 66], "690599e": 66, "690778": [26, 46, 70], "691241": [23, 43, 67], "691617": [31, 51, 52, 75], "691640": [16, 62], "691877": [22, 66], "691924": [28, 72], "69192445": [28, 72], "692126": 39, "692308": [18, 63], "693": [18, 63], "693498": [22, 42, 66], "693590": [19, 64], "6935905": 19, "6938": [33, 59, 77], "693890": [53, 77], "693898": [33, 77], "693936": [19, 64], "69393613": [19, 64], "694": [17, 40, 42], "69411": [27, 47, 71], "694155": [16, 62], "6950": [26, 46, 70], "695156": 49, "695322": 49, "695407": 96, "695449": 76, "695457": 32, "695532": [18, 63], "695783": [31, 51, 52, 75], "696": [17, 40], "696034e": [24, 68], "696107": 93, "6962": [18, 63], "6963": [26, 46, 70], "696373": [18, 63], "696429": [23, 43, 67], "696508": 93, "696712": [33, 77], "696859": 66, "696970": [21, 65], "69698010e": [26, 46, 70], "697": [18, 27, 47, 63, 71], "697248": [23, 43, 67], "6973": [18, 63], "698": [18, 63], "698167": [53, 77, 97], "698206": [24, 44, 68], "698384608345687": [42, 66], "698385": [42, 66], "6984": [27, 47, 71], "698857": 66, "699224": [16, 62], "6993": [15, 38], "6999": 34, "699901396097971": [29, 73], "6th": [25, 26, 45, 46, 67, 69, 70], "6x61": 19, "7": [1, 14, 15, 16, 17, 18, 19, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 38, 39, 42, 43, 44, 46, 47, 49, 50, 51, 52, 53, 54, 55, 56, 59, 60, 61, 62, 63, 64, 66, 67, 68, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 84, 85, 91, 93, 97], "70": [15, 19, 24, 28, 29, 33, 34, 35, 38, 39, 44, 48, 49, 53, 54, 55, 56, 60, 61, 64, 68, 72, 73, 77, 78, 79, 81, 93, 95, 97], "70000": [53, 77, 97], "700000": [53, 77, 97], "700000e": [15, 38], "700108": 94, "700855": [23, 43, 67], "701089": 78, "701128": [53, 77, 97], "701173": [22, 66], "701186e": 24, "70162085e": [26, 46, 70], "7017": [34, 54, 78], "701863": [22, 42, 66], "702703": [16, 62], "703289": 49, "703406": 78, "703500e": 78, "703704e": 96, "704": [16, 18, 24, 44, 62, 63, 68], "704040": 93, "704099": [19, 64], "70409944": 19, "7041": [52, 83], "7042": [34, 54, 78], "704240": 97, "7043": [34, 54, 78], "7046136400143141": [21, 65], "70472": [27, 47, 71], "704969": [22, 42, 66], "705": 45, "705000": [18, 63], "705286": 42, "705470": [31, 52], "705471": [51, 75], "705511": [22, 66], "70560276": [19, 64], "705603": [19, 64], "70568": [24, 68], "705696": [16, 62], "705882": [22, 42, 61, 66], "70588235": 61, "705898": [27, 47, 71], "705952": 97, "705995e": 78, "706": 64, "706128": [16, 62], "7063": 93, "706444": [23, 43, 67, 81], "706489": [15, 38], "706533": 97, "7065342163355408": [17, 40], "706783": [19, 64], "70678332": [19, 64], "706966": [53, 77], "707681": [16, 62], "707712": [34, 54, 78], "707899": [28, 72], "70789903": [28, 72], "70799": [22, 42, 66], "708": [18, 63, 64, 66, 94], "708075": [22, 42, 66], "708527": [18, 63], "708978": [22, 42, 66], "709145": 49, "709185": [16, 62], "709334": 96, "709526": 97, "7097425133911417": 93, "70978": [27, 47, 71], "709784": 93, "709874": 66, "709880": 66, "709893": [53, 77, 97], "7099": [27, 47, 71], "71": [15, 19, 21, 24, 28, 33, 34, 44, 53, 59, 60, 61, 64, 65, 68, 72, 77, 78, 81, 97], "710000": [18, 63], "710031": [26, 46, 70], "710526": [16, 62], "710719": 96, "710896": [23, 43, 67], "71096": [27, 47, 71], "711": 66, "711077": [18, 63], "711086": 66, "711356": [15, 38], "711717": 66, "711754": [18, 63, 64, 94], "711819": [31, 51, 52, 75], "711852": [27, 47, 71], "71199006": [24, 44, 68], "712": [18, 63], "712074": [22, 42, 66], "71219761": [19, 64], "712198": [19, 64], "712324": 66, "712500": [42, 62], "7129": 66, "7129300520": [15, 38], "713": [25, 64], "713195": 93, "71327467": [24, 44, 68], "713677": 81, "714": [32, 61, 76], "714077": [18, 63, 64, 94], "714286": [22, 42, 66], "714357": 96, "7149": 34, "71517": [22, 42, 66], "7153": [34, 54, 78], "715424": 66, "715728": [23, 43, 67], "715845": [17, 40], "716": 84, "716157": [23, 43, 67], "716599": 49, "716655": [22, 66], "716657": [22, 66], "716792": [23, 43, 67], "716985": [16, 62], "717289": [22, 42, 66], "717391": [22, 42, 66], "717829": [18, 63], "718242": 66, "718266": [22, 42, 66], "718524": [53, 77, 97], "71866979": [24, 68], "718675": 78, "7188": 64, "719": [18, 27, 47, 59, 63, 71], "719141": 22, "719427e": [24, 68], "719500": [16, 62], "719606": [20, 41], "719747": [23, 43, 67, 81], "719915905190645": [15, 38], "72": [16, 23, 24, 33, 34, 43, 44, 60, 61, 62, 67, 68, 77, 78, 81, 92, 93], "7200": [15, 38], "720357": [53, 77, 97], "72036": [53, 77], "720383": 42, "720393": [22, 42], "720497": [22, 42, 66], "720859": [18, 63], "720893": [34, 78], "720904": [53, 77], "7210": [15, 38, 60], "721006": 66, "721008": [22, 42, 66], "721031": 42, "7212512828409687": [21, 65], "721616": [42, 66], "721622": 22, "721705": [18, 63], "7218": [60, 61, 92], "721818": [27, 47, 71], "721910": [34, 78], "721917": [15, 38], "721921": [18, 63], "722": [18, 63], "722241": 66, "722249": [22, 66], "722803": [15, 38], "722856": 42, "722873": [15, 38], "722887": 42, "723": [18, 63], "723220": 15, "72322046": 15, "72345029": [44, 68], "7234503": 24, "723481": 22, "723602": [22, 42, 66], "723613": [16, 62], "723951": [15, 38], "724011": 93, "724068": [15, 38], "724138e": 96, "7242": [15, 38, 60], "72423018": 20, "724410": [15, 38], "724458": [22, 42, 66], "724539": [53, 77, 97], "724703e": 78, "724722": 42, "724891": [23, 43, 67], "725": [21, 65, 66], "7250894": 84, "7255": 34, "725668": [20, 41], "725960": 42, "726": [18, 23, 27, 43, 47, 63, 67, 71], "726277": 39, "726412": [18, 63, 64, 94], "726441": 39, "726573": [22, 42, 66], "726583": [22, 42, 66], "726634": [23, 43, 67], "726659": [15, 38], "726788": [24, 44, 68], "727": 78, "727014": [53, 77], "727197": 42, "727198": [22, 42, 66], "727273": [16, 62], "727394": 78, "727554": [22, 42, 66], "7277854625841886": [34, 78], "727821": [42, 66], "7278214718381631": [42, 66], "727829": [22, 42, 66], "727994": 39, "728": [18, 23, 34, 43, 63, 67], "728235": [18, 63, 64, 94], "7283": [23, 43, 67], "728324": [23, 43, 67], "728584": 76, "728587": 32, "728777": [16, 62], "728836": 49, "729": 66, "729143": [23, 43, 67, 81], "7292": [27, 47, 71], "729374": [15, 38], "729814": [22, 42, 66], "73": [15, 19, 21, 22, 23, 24, 29, 33, 34, 43, 44, 60, 61, 64, 65, 66, 67, 68, 73, 77, 78, 81, 93], "730000": 93, "730025": [15, 38], "730383": 67, "730512": 97, "730704": [15, 38], "7309385996961713": 66, "731349": 32, "731354": 76, "731498": [34, 78], "7315": [21, 65], "7315558717766282": 22, "731572": [21, 65], "731583": [16, 62], "731733": 93, "73183": 52, "732": [31, 75, 96], "732000": 96, "732674": 34, "7328": [18, 63], "732919": [22, 42, 66], "733102": [18, 63, 64, 94], "733333": [18, 42, 61, 63, 64], "733724": 96, "733746": [22, 42, 66], "734": [24, 34, 44, 66, 68, 78], "734011": [22, 66], "7340179085731506": [51, 75], "7340192198753357": 31, "734048": [15, 38], "734385": [23, 43, 67, 81], "734816": [53, 77], "734986": [15, 38], "735": [24, 44, 68], "735043": [23, 43, 67], "735261": [22, 42, 66], "7352614272253524": [22, 66], "735637": [15, 38], "7356574535369873": [51, 75], "7356575131416321": [31, 52], "735879": [22, 42, 66], "736": 84, "7363681793212891": [31, 51, 52, 75], "736498": [22, 42, 66], "736545": 81, "7367969155311584": 31, "7367984056472778": [51, 75], "736900": [18, 63], "737285": [15, 38], "7378551974307357": 38, "7379": [15, 38, 60], "738": [18, 24, 44, 63, 68], "738564": [53, 77, 97], "738701": [18, 63, 64], "738715": 78, "738746": 78, "738836": 78, "738839": [21, 65], "738977": [22, 42, 66], "738980": 66, "739264": [18, 27, 47, 63, 71], "7395977155164125": [22, 42, 66], "739598": [22, 42, 66], "739726": 95, "739938": [22, 42, 66], "74": [15, 18, 19, 21, 22, 23, 24, 29, 34, 42, 43, 44, 60, 61, 63, 64, 65, 66, 67, 68, 73, 81, 94, 96], "740": 95, "740000": 16, "740319": [15, 38], "740542": 59, "740741": 96, "740842": 66, "740844": 42, "741": [34, 69, 78], "741037": [53, 77, 97], "741060": [15, 38], "741461": 42, "741463": 66, "741465": [42, 66], "7418": [26, 46, 70], "742078": 66, "742084": [42, 66], "742086": 42, "742088": [42, 66], "742703": 66, "7429753541946411": 31, "7429758906364441": [51, 75], "742981": [23, 43, 67], "743": [18, 22, 42, 62, 63, 66], "743132": 49, "743133": [16, 62], "743135": [23, 43, 67], "743243": 95, "743323": 66, "743324": [42, 66], "743391": [16, 62], "743555": [26, 46, 70], "7436": [60, 61, 92], "743820": 93, "743917": [18, 63, 64, 94], "743949": 42, "7440": 59, "744201": [23, 43, 67], "744673": 49, "745801": 42, "745925": [15, 38], "746": 23, "746114": [45, 69], "746328": [16, 62], "747": 59, "7472092075": 24, "7472092076": 68, "7472092077": 44, "747975": 78, "74798624e": [26, 46, 70], "748": [17, 40], "748510": [23, 43, 67], "748725": 78, "748797": [21, 65], "748977": 42, "749": [17, 40], "749118": [26, 46, 70], "75": [9, 15, 17, 18, 19, 21, 22, 23, 24, 26, 28, 34, 35, 38, 40, 42, 43, 44, 46, 53, 55, 56, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 70, 72, 77, 78, 79, 81, 93, 94, 96, 97], "750": [17, 40, 59, 93, 95], "7500": [24, 44, 68], "750000": [15, 24, 38, 42, 44, 68], "7503": [15, 38, 60], "750401": [31, 51, 52, 75], "750483": 49, "751": [17, 40], "752": [17, 40], "752169": [15, 38], "7524": [33, 77], "752728": [15, 38], "753": [17, 40], "753286": [18, 63, 64, 94], "75329946": [20, 41], "753764e": 78, "753821": [34, 78], "753x117": 17, "754": [18, 63], "754386": [23, 43, 67], "754620": [15, 38], "754874": [27, 47, 71], "75490599": 15, "754906": 15, "754938": [15, 38], "755": [34, 78], "755000": [24, 44, 68], "7551": 66, "755364": [16, 62], "755418": [22, 42, 66], "755477": [16, 62], "756": [34, 78], "7562": 59, "75625": [53, 77, 97], "757": [23, 43, 67], "757412": 49, "7574257425742574": [22, 42, 66], "75745416": [28, 72], "757545": [24, 44, 68], "757591": [33, 77], "757932": [34, 78], "75797084": 25, "757985": [25, 26, 45, 46, 69, 70], "758": [25, 26, 34, 45, 46, 69, 70, 78, 95], "758035": 39, "758062e": [24, 68], "758259": [15, 38], "75826": [25, 26, 45, 46, 69, 70], "758514": [22, 42, 66], "7588186": [32, 76], "7588527798652649": 52, "7588528394699097": [31, 51, 75], "75886672": [45, 69], "75948619": [45, 69], "759561": [28, 72], "75956122": [28, 72], "7599": [21, 65], "76": [18, 21, 23, 24, 26, 27, 34, 43, 44, 46, 47, 49, 61, 63, 65, 66, 67, 68, 70, 71, 78, 81, 93, 95], "760": [25, 34, 78], "760000": 25, "760262": [42, 66], "760678": [53, 77], "760966": [15, 38], "76099073": 25, "76161": [22, 42, 66], "761936": 78, "761945e": [24, 68], "762": [34, 78], "7620": [15, 38, 59], "762093e": 24, "76270194": [26, 46, 70], "762965": 97, "763": [18, 63], "763480": [15, 38], "763525": 49, "7639": [15, 38, 60], "764": 95, "764052": [27, 47, 71], "764124": 49, "76470588": 61, "764706": [16, 22, 42, 61, 62, 66], "765": 81, "765000": 42, "765591": [23, 43, 67], "765601": [24, 44, 68], "766317e": 24, "766318": [15, 38], "766423": [24, 44, 68], "766430": [16, 62], "766957": [23, 43], "767": [24, 26, 35, 44, 46, 55, 56, 68, 70, 79], "7675780653953552": 31, "7675789594650269": [51, 75], "767704": 78, "767742": [21, 65], "767802": [22, 42, 66], "767819": [53, 77, 97], "767852": [16, 62], "768": [18, 24, 26, 35, 44, 46, 55, 56, 63, 64, 68, 70, 79, 94, 95], "768176": 78, "768184": [15, 38], "768279": [35, 55, 56, 79], "768407": 42, "7684071705306555": 42, "768512": [23, 43, 67], "769": 61, "769030": [15, 38], "769231": [18, 63], "769349": 15, "76934947": 15, "77": [14, 15, 19, 21, 23, 24, 29, 33, 34, 43, 44, 48, 60, 61, 64, 65, 67, 68, 73, 77, 78, 85, 89, 93, 95], "770": [15, 38, 60], "770000": 25, "770163": [15, 38], "770833": [30, 50, 74], "770898": [22, 42, 66], "771": [18, 42, 63], "771089": 96, "771511": 49, "771969": [16, 62], "772000": 15, "772185": [15, 38], "772245": 93, "772532": [23, 43, 67], "7728396574320712": 15, "772848": 96, "773017": [24, 26, 35, 44, 46, 55, 56, 68, 70, 79], "7736": 66, "773851": [33, 77], "773902e": 68, "774261": [53, 77], "774789": [34, 78], "774844": [19, 64], "77484447": [19, 64], "7750553478074826": [53, 77, 97], "775270": [24, 44, 68], "7752884548630534": [21, 65], "775311": [46, 70], "77536150e": [26, 46, 70], "775558e": 96, "7758": 66, "776": [42, 66], "7763": [18, 20, 27, 47, 63, 71], "776427": [34, 54, 78], "776883e": 24, "77709": [22, 42, 66], "777600": [15, 38], "77778158": 25, "777934": [16, 62], "778078": 27, "7781845435415525": [53, 77, 97], "7784948928666875": [15, 38], "779": [18, 27, 47, 63, 71], "779271": [27, 47, 71], "779838": 20, "78": [14, 15, 18, 19, 24, 27, 28, 33, 34, 44, 47, 54, 59, 60, 61, 63, 64, 67, 68, 71, 72, 77, 78, 81, 84, 85, 95], "780": 42, "7800": 66, "780000": [45, 69], "780296": 24, "780298": 24, "780316": 24, "780497": 24, "78058051e": [26, 46, 70], "780822": 95, "780864": [23, 43, 67, 81], "781": [18, 63], "781004": [16, 62], "781531": [67, 81], "7816": [24, 44, 68], "781769": 15, "78176915": 15, "78186833": [45, 69], "781977": 39, "782183": 24, "782219": [16, 62], "7827": 67, "782850": 78, "783266": 49, "783274": 78, "783282": [22, 42, 66], "783582": [16, 62], "783784": [30, 50, 74, 95], "783789": [16, 62], "784424": [21, 65], "784573": [27, 47, 71], "785105": 24, "785108": 24, "785134": 24, "78521263": [31, 51, 52, 75], "785399": 24, "785483": [53, 77, 97], "785714": [18, 63], "786": 25, "786024": 49, "786115": [27, 47, 71], "7864": [20, 41], "786506": [32, 76], "786555": 24, "786682": 49, "787": [18, 63], "787574": [24, 68], "787879": [16, 21, 62, 65], "78792657": 15, "787927": 15, "787933": 24, "788": [34, 48, 78], "788647472858429": [31, 52], "7886475920677185": [51, 75], "7887": [26, 46, 70], "789": 95, "7891381897690053": [21, 65], "789436": [18, 63], "789657": [53, 77, 97], "79": [15, 18, 19, 21, 24, 33, 34, 44, 60, 61, 63, 64, 65, 68, 77, 78, 81, 92], "790": [23, 43, 67], "790000": [18, 63], "7901": 34, "79041": [24, 44, 68], "790481e": [17, 40], "790521": [15, 38], "790721": [35, 55, 56, 79], "790731": [21, 65], "791017": 78, "791071": 78, "791467": [18, 63], "792": 84, "792023": [26, 35, 46, 55, 56, 70, 79], "79250": [18, 63], "792577": [24, 44, 68], "792603": [16, 62], "792828": 24, "792894": 49, "793": [27, 47, 71], "793243": [18, 63], "79378": [23, 43, 67, 81], "7938": 64, "794118": [16, 62], "794236": [18, 63], "794521": 95, "794820": [18, 63], "794894": [20, 41], "795": [22, 42, 62, 66], "79500e": 62, "7951": 66, "7951559890417756": 24, "7951559890417759": [44, 68], "795902": [53, 77, 97], "795985": 15, "79598528": 15, "796": [18, 63], "7964215270662817": [21, 65], "797": [18, 63], "797355": [18, 63, 64, 94], "7978563117812038": [18, 63], "798": [18, 63], "7982": [16, 62], "798427": 95, "7986538": 24, "7986544": 68, "7986546": 44, "799476": 76, "799486": 32, "799845": 78, "799983": [16, 62], "79998417": 84, "7f688092391a": [32, 76], "7pm": [27, 47, 71], "7th": [25, 26, 45, 46, 67, 69, 70], "8": [1, 10, 14, 15, 16, 17, 18, 19, 21, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 38, 39, 40, 41, 43, 44, 45, 46, 47, 49, 50, 51, 52, 53, 54, 55, 56, 59, 60, 61, 62, 63, 64, 65, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 84, 85, 87, 93, 96, 98], "80": [5, 14, 15, 16, 17, 18, 19, 21, 24, 26, 27, 28, 29, 33, 34, 35, 36, 39, 40, 44, 46, 47, 48, 53, 54, 55, 56, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 70, 71, 73, 77, 78, 79, 81, 85, 90, 95, 96, 97, 98, 99], "800": [15, 17, 22, 40, 42, 51, 52, 59, 61, 66, 75], "800000": [42, 53, 66, 77, 97], "8001": [21, 65], "800190": [16, 62], "800391": 42, "80062924": [16, 62], "800k": [35, 56, 79], "801219e": [24, 68], "801666": [23, 43, 67], "801863": [16, 62], "802502": [27, 47, 71], "802902": 24, "802960": 97, "802987": [16, 62], "803": [16, 18, 62, 63], "803373": 97, "803617": [23, 43, 67], "804": [16, 34, 62, 78], "804072": 96, "8041": 34, "804337": 93, "8044116": 15, "804412": 15, "804580": 20, "804818": [18, 63, 64, 94], "80482065": [19, 64], "804821": [19, 64], "804845": 94, "804955": 15, "80495534": 15, "805": 45, "805198": 24, "805342": [53, 77], "805415": 39, "805970": [16, 21, 62, 65], "806": [64, 95], "8062": [15, 38, 60], "806334557802439": 42, "806335": 42, "8076": [24, 44, 68], "807684": [16, 62], "807735": [23, 43, 67], "8078": 59, "808": [34, 78], "8080": [15, 38, 60], "808208": [23, 43, 67, 81], "808219": 95, "808857": 78, "808958": [16, 62], "809": [18, 63], "809450": [34, 78], "8098": [34, 78], "809894": [34, 78], "81": [15, 16, 19, 21, 22, 23, 24, 26, 28, 33, 34, 35, 42, 43, 44, 46, 53, 55, 56, 60, 61, 62, 64, 65, 66, 67, 68, 70, 72, 77, 78, 79, 81, 96, 97], "810": 84, "810073": [24, 26, 46, 70], "810098": [27, 47, 71], "810267": [23, 43], "810368": [16, 62], "810625": 62, "810631": 78, "81071706": [22, 42, 66], "810811": [30, 50, 74, 95], "8112": 59, "811297": 93, "811877": 76, "811878": 32, "812133": 42, "812272": 24, "812298": 15, "81229831": 15, "812363": [24, 44, 68], "812500": [42, 61], "812875": [34, 54, 78], "813": [18, 63], "813586": [23, 43, 67], "813842": 42, "814218": 78, "814356": [23, 43], "814815": 96, "815000": 93, "815669": [23, 43, 67], "815732": 42, "815890": 93, "816201": 39, "8162831858407079": [36, 57, 58, 80], "816717791411044": [34, 54, 78], "817": [25, 45, 69], "817159": 93, "817244": 95, "817558": [18, 63, 64], "817640": 49, "817920": 93, "8180": [18, 63], "818041": [34, 78], "818591": 93, "818868": [18, 63], "818936": 93, "818982": 93, "819152": [16, 62], "819213": 78, "8195": [21, 65], "819549": [16, 62], "819584": [16, 62], "81970188": [19, 64], "819702": [19, 64], "82": [14, 19, 20, 22, 28, 29, 34, 53, 60, 64, 66, 73, 77, 78, 81, 93, 96, 97], "820": [16, 62], "820033": 24, "820143": [21, 65], "82025568e": [26, 46, 70], "820287": 93, "820312": 42, "820324": 32, "820326": 76, "820564": 24, "8208955223880597": 32, "821040": [26, 46, 70], "821327": [31, 51, 52, 75], "821807": 24, "8219": [18, 63], "821918": 95, "8221": 64, "82273995": [19, 64], "822740": [19, 64], "822822": 95, "823364": [17, 40], "82336432": 17, "823511": [23, 43, 67, 81], "823529": [16, 21, 61, 62, 65], "82352941": 61, "823543": [27, 47, 71], "823610e": 78, "823875": 42, "824": 95, "824324": 95, "824735": 93, "824849": [23, 43, 67], "824884": 24, "825": [18, 20, 63], "825123": [27, 47, 71], "8253": [16, 62], "825306": 66, "825460": 93, "825470": [34, 78], "8256": [20, 41], "825697": [24, 44, 68], "826142": [24, 44, 68], "82615": [20, 41], "826203": [21, 65], "826216": 24, "826513": [53, 77, 97], "826553": 24, "82666046": [20, 41], "82670": [53, 77, 97], "826739": 24, "826758": 24, "826760": 24, "827039": [21, 65], "827068": [21, 65], "827130": [23, 43, 67, 81], "827261": 24, "8277511961722488": 92, "827842": [21, 65], "827907": [22, 42, 66], "828": [15, 20, 38, 41], "8280229354283182": 68, "8280229354283185": 24, "82804": [22, 42, 66], "828332": [24, 26, 35, 44, 46, 55, 56, 68, 70, 79], "828358": [16, 62], "828405": [33, 77], "828682": [22, 42, 66], "82869879": [31, 51, 52, 75], "828891": [22, 66], "828976": 66, "829": 95, "829027": 78, "829754": 96, "829887": 93, "829932": 95, "83": [14, 15, 19, 23, 29, 30, 31, 33, 34, 42, 43, 50, 51, 52, 53, 60, 61, 64, 66, 67, 73, 74, 75, 77, 78, 81, 85, 96, 97], "830": [41, 42], "830382": [23, 43, 67], "830712e": [24, 68], "831135": [16, 62], "8312": [20, 41], "831314": 49, "831611": [24, 26, 46, 70], "831989": [22, 42, 66], "832": [18, 20, 63], "8322": [20, 41], "832221": [32, 76], "832320": [21, 65], "832370": [23, 43, 67, 81], "832866": 24, "833": [22, 41, 42, 62, 66], "83320": [53, 77], "8334": [26, 46, 70], "833913": [15, 38], "8340": [16, 20, 41, 62], "834109": [22, 42, 66], "834180": 76, "834183": 32, "834356e": [24, 68], "83437": [24, 68], "834455": [16, 62], "8347": 34, "8348": 93, "835": 34, "835531": 95, "835571": 97, "8356": [26, 46, 70], "835616": 95, "835651": 66, "835749": [24, 26, 46, 70], "835876": [15, 38], "835995e": 78, "836": 34, "83603": [24, 44, 46, 68, 70], "8361313": [24, 44, 68], "836189": [16, 62], "836735": [23, 43, 67, 95], "836817": 93, "836878e": 24, "836880e": 24, "837": 34, "837022e": 24, "837838": [16, 62], "837848": [16, 62], "838": [22, 34, 42, 62, 66], "83848726e": 76, "83848731e": 32, "83876": [22, 42, 66], "8388866943476289": [21, 65], "838951": [24, 68], "8389756947416367": [21, 65], "839": 34, "839225": [24, 44, 68], "84": [14, 15, 19, 33, 34, 38, 48, 53, 54, 60, 61, 64, 66, 77, 78, 85, 93, 96, 97], "840": [18, 34, 41, 63], "84002795": [19, 64], "840028": [19, 64], "840074": 61, "840183": [24, 44, 68], "840492": [24, 26, 35, 44, 46, 55, 56, 68, 70, 79], "84062193": [26, 46, 70], "841": [20, 24, 34, 44, 68], "841208": [22, 42, 66], "841886": 66, "841983": [22, 42, 66], "842": [18, 20, 34, 41, 63], "842028": [23, 43, 67, 81], "842064": 78, "842105": [16, 62], "8422": [20, 41], "843": [45, 69], "843281": [26, 46, 70], "843284": [16, 21, 62, 65], "843537": 95, "843842": [18, 63, 64, 94], "843992": [24, 26, 46, 70], "844": [20, 25], "844409": [19, 64], "84440919": [19, 64], "844921": [28, 72], "845": 66, "8451161623704895": [45, 69], "846154": [18, 63], "8462": [27, 47, 71], "846260e": 24, "846650": 24, "84679073": [16, 62], "84698489": [32, 76], "847": [25, 26], "847178": [23, 43, 67], "847287": [22, 42, 66], "8475": [33, 77], "84772": [23, 43, 67], "847799": [22, 42, 66], "847808": [23, 43, 67], "8478316682480326": [53, 77, 97], "848": [41, 45, 46, 69, 70], "84893192": [22, 42, 66], "849": [25, 26, 45, 46, 69, 70], "849172": 95, "849315": 95, "849438e": [24, 68], "849612": [22, 42, 66], "849812": [34, 78], "85": [14, 15, 19, 24, 25, 26, 27, 33, 34, 44, 45, 46, 47, 53, 60, 61, 64, 67, 68, 69, 70, 71, 77, 78, 81, 85, 96, 97], "850": [25, 26, 45, 46, 59, 69, 70], "850000": 93, "8502": 66, "850283": [53, 77, 97], "850340": 95, "850503": [22, 42, 66], "850746": [16, 62], "8507462686567164": 76, "851003": 78, "851291": 78, "851351": 95, "851460": 24, "851852": [21, 65], "852": [54, 78], "852053": [22, 42, 66], "852104": [24, 44, 68], "852941": [21, 65], "8532608695652174": 95, "853399": [23, 43, 67, 81], "854129": [24, 44, 68], "854167": [30, 50, 74], "854500": [34, 78], "854560": 95, "8546143543902771": [34, 78], "854744525547446": [34, 54, 78], "854749": [53, 77], "855306": 97, "85545875": [16, 62], "855461": 95, "85597188": [19, 64], "855972": [19, 64], "856": 66, "856164": 95, "856175": [18, 63], "856589": [22, 42, 66], "856721": 39, "856795": 78, "856868": 95, "857": [24, 44, 68], "857456": 39, "857874": [22, 42, 66], "858": [21, 45, 65, 69], "8580": [18, 63, 64, 94], "858209": [16, 21, 62, 65], "858475": 42, "858915": [22, 42, 66], "859": 25, "859318": 24, "859439": [28, 72], "85943906": [28, 72], "859455": [34, 78], "859659": 95, "859668": 95, "85969": [22, 42, 66], "859799": [22, 42, 66], "86": [14, 19, 21, 22, 23, 27, 33, 34, 42, 43, 47, 48, 49, 53, 60, 62, 64, 65, 66, 67, 71, 77, 78, 81, 95], "860": [25, 26, 46, 67, 70, 96], "86000e": 62, "8601643854446082": 68, "8601643854446083": 24, "860329": 49, "860523": 78, "860677": [23, 43, 67, 81], "861": [18, 63], "86102": [53, 77, 97], "861157": [35, 55, 56, 79], "861348": [22, 42, 66], "862236": 78, "862236e": 68, "862432": [24, 44, 68], "862552": [18, 63], "8625888648969532": [34, 78], "862644": 49, "86267067": [19, 64], "862671": [19, 64], "862997": [27, 47, 71], "863014": [21, 65, 95], "863305": [34, 78], "863699": 95, "863889": [33, 77], "863941": 24, "863998": 96, "864": [25, 45, 69], "86400": [53, 77, 97], "864172": 49, "8641864337292489": [34, 78], "864205": [46, 70], "864294": 39, "864865": 95, "865152": 95, "865562": [34, 78], "866110": [21, 65], "866328": [34, 78], "866364": 95, "866667": [23, 43, 61, 67], "866980": 24, "867558": [27, 47, 71], "867841": 95, "867927e": 78, "868003": 24, "868182": 95, "868281": 24, "868305": 24, "868308": 24, "868381": 95, "868397": 49, "869077": [19, 64], "86907725": [19, 64], "869094": [22, 42, 66], "8691": 64, "869531": [16, 62], "869713": 76, "869717": 32, "869964": [22, 42, 66], "87": [18, 19, 33, 34, 60, 63, 64, 77, 78, 81], "870": [25, 45, 69], "870748": 95, "871": [25, 26, 45, 46, 66, 69, 70], "871094": [53, 77, 97], "8711": 67, "871200": [15, 38], "871212": 95, "871782": 95, "872": [25, 26, 45, 46, 69, 70], "872093": [22, 42, 66], "872302": [20, 41], "872722908439952": [26, 46, 70], "8727229084399575": [26, 46, 70], "872961060": [24, 44, 68], "8729610607986": 24, "873": [25, 45, 69], "8731": [24, 26, 35, 44, 46, 55, 56, 68, 70, 79], "873103": [16, 62], "873131": 49, "873182": [33, 77], "873356": [16, 62], "873486": 95, "873529": 49, "873643": [22, 42, 66], "873704": [24, 44, 68], "874062": [19, 64], "87406235": [19, 64], "874305": [33, 77], "874433": 95, "874516": [22, 42, 66], "874532": [24, 44, 68], "874767e": [24, 68], "874966": 39, "875": [81, 95], "8750": [18, 27, 47, 63, 71], "875000": [42, 61], "87516818": [20, 41], "875946": 95, "876065": [22, 42, 66], "876540": [34, 78], "876566e": [15, 38], "876574": [18, 63, 64, 94], "876712": 95, "87681182": [31, 51, 52, 75], "877046": [27, 47, 71], "877390": [46, 70], "877458": 95, "877519": [22, 42, 66], "877551": [23, 43, 67, 95], "878183": [16, 62], "878378": 95, "87844893": [24, 44, 68], "87849316": [21, 65], "878971": 95, "879": [18, 63], "87907": [22, 42, 66], "879938": [22, 42, 66], "88": [15, 17, 18, 19, 21, 23, 27, 34, 43, 47, 48, 60, 61, 63, 64, 65, 67, 71, 78, 81, 93, 94], "880": [27, 47, 71], "8801": [52, 83], "880303": 95, "880348": [22, 42, 66], "880831": [53, 77, 97], "881351": 49, "881370": 42, "881370370570494": 42, "881395": [22, 42, 66], "881720": [23, 43, 67], "881807": 49, "881818": 95, "883138": [22, 42, 66], "884354": 95, "884586": [22, 42, 66], "885": 59, "885044": [24, 26, 35, 44, 46, 55, 56, 68, 70, 79], "8859": [13, 20, 41, 59], "885968": [34, 78], "886047": [22, 42, 66], "886759": [21, 65], "887": [25, 45, 69], "887017": [23, 43, 67], "887159": [53, 77, 97], "8873": [23, 43, 67], "887324": [23, 43, 67], "887343": [16, 62], "887597": [22, 42, 66], "887701": [23, 43, 67], "887772": 15, "8878117": [19, 64], "887812": [19, 64], "887979": 95, "888": [25, 26, 45, 46, 66, 69, 70], "888066": [26, 46, 70], "888372": [22, 42, 66], "888513": [23, 43, 67], "888645": 15, "888811": 66, "888889": [18, 21, 63, 65], "888961": [26, 46, 70], "889": [25, 45, 69], "889086": [24, 44, 68], "889147": [22, 42, 66], "889394": 95, "889429": [33, 77], "889921": [53, 77], "89": [14, 15, 19, 23, 29, 33, 34, 43, 48, 49, 53, 60, 61, 64, 67, 73, 77, 78, 85, 97], "890": [17, 34, 40], "890001": 49, "890107": 15, "890201": 15, "890411": 95, "890456": [15, 38], "890457": [24, 44, 68], "890933": [34, 54, 78], "891": [25, 34], "891001": 67, "891156": 95, "891174": 15, "891223": 15, "891224": 15, "891384": 15, "891557": [22, 42, 66], "891892": 95, "892": 34, "892476": [23, 43, 67], "892477": [16, 62], "892491": [18, 63], "892587": 95, "89270": [27, 47, 71], "892733": [33, 77], "892961": [27, 47, 71], "892983": 15, "893": 34, "893000": [18, 63], "893260": [19, 64], "89326049": 19, "893580": 78, "8937442459553657": [26, 46, 70], "893915": 15, "894": [18, 34, 63], "894230": 78, "894587": [35, 55, 56, 79], "894828": 15, "894960": [15, 38], "895": [25, 45, 69], "89515383": 17, "895154": [17, 40], "895349": [22, 42, 66], "895405": 49, "895541": [24, 44, 68], "895613": 95, "89572": [53, 77, 97], "895833": [23, 43, 67], "895963": [21, 65], "897": [25, 45, 64, 69], "897010": [18, 63, 64], "89706451e": [26, 46, 70], "897126": 95, "897674": [22, 42, 66], "897736": 34, "898": [26, 46, 70], "898016": [22, 42, 66], "898237": 39, "898703e": 24, "899": [18, 63, 64, 66, 94], "8994": [26, 46, 70], "8997": [24, 44, 68], "899736": [15, 38], "899940": 78, "899969": [53, 77, 97], "8th": [25, 26, 45, 46, 67, 69, 70], "8xnvb3wojvta7atnvk1s_obfsvwldyzibljoboxw": 22, "9": [1, 4, 15, 16, 17, 18, 19, 20, 21, 22, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 38, 39, 41, 42, 44, 45, 46, 47, 49, 50, 51, 52, 53, 54, 56, 59, 60, 61, 62, 63, 64, 65, 66, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 81, 85, 86, 92, 93, 97], "90": [9, 14, 15, 16, 19, 23, 24, 29, 30, 33, 34, 43, 44, 59, 60, 61, 62, 64, 67, 68, 73, 74, 77, 78, 81, 85], "900": [19, 22, 64, 66, 81], "90000": [53, 77, 97], "900000": [53, 61, 77, 97], "900000e": [15, 38], "900662": 61, "901": 64, "901085": [21, 65], "9010852321946795": [21, 65], "901261": 96, "901262": [33, 77], "90159483": [28, 72], "901595": [28, 72], "901802": 49, "902": 69, "902122": 97, "902232": 42, "902337": 39, "902401": [22, 42, 66], "903080": 49, "903101": [22, 42, 66], "903125": 62, "903434": 39, "904": [16, 22, 42, 62, 66], "90403853": [19, 64], "904039": [19, 64], "904110": 95, "904226": [16, 62], "904462e": 78, "904565": 39, "9047619047619048": [14, 60], "904930e": [15, 38], "905": [16, 18, 62, 63], "905249": 49, "905327": [53, 77], "905405": 95, "906": 96, "906510": 93, "906667": [39, 61], "90669": [27, 47, 71], "906865": 61, "907": [34, 54, 78], "907595": [33, 77], "907752": 78, "907874": 97, "908": [18, 63], "908140": [18, 63, 64, 94], "908215": [24, 44, 68], "909091": [18, 63], "909471e": 68, "90982": [27, 47, 71], "91": [14, 15, 18, 19, 22, 27, 28, 33, 38, 42, 47, 53, 60, 61, 63, 64, 66, 67, 71, 72, 77, 81, 85, 97], "910": [15, 19, 38, 60], "9100": [33, 77], "910018": [24, 44, 68], "910174": [24, 44, 68], "9103": [33, 77], "910456e": 24, "91063776": [26, 46, 70], "9108334653214172": 15, "910843": [24, 44, 68], "911": [17, 40], "911024": 49, "911615": [24, 44, 68], "911846": [24, 44, 68], "912": [18, 34, 63], "912395": [26, 46, 70], "912847": 93, "913": 34, "913333": [39, 61], "913767": [24, 44, 68], "913849": [24, 44, 68], "914": 34, "914003": [26, 46, 70], "914451894256": 24, "914451894267": [44, 68], "914520": 49, "914585": [26, 46, 70], "915": 34, "91515735": [24, 44, 68], "915701": 95, "915714e": 24, "915952": [24, 44, 68], "916": 34, "916254": [16, 62], "916347": 39, "916722": [26, 46, 70], "917": [34, 95], "917526": [23, 43, 67], "917808": 95, "917837": [23, 43, 67], "91795": [20, 41], "918": [15, 25, 34, 38, 45, 69, 95], "918124": [23, 43, 67], "9182": [33, 77], "918224": [17, 40], "918919": 95, "919": 34, "919198": [26, 46, 70], "919270": [34, 78], "9196": 59, "92": [14, 15, 19, 29, 33, 34, 53, 60, 61, 64, 67, 73, 77, 78, 85, 93, 97], "920": 34, "920000": [39, 61], "920067": [34, 78], "920093": 96, "9203": 66, "920305": [27, 47, 71], "920462": [26, 46, 70], "921": 34, "92120500e": 84, "921422": [34, 78], "921438": [24, 39, 44, 68], "921850": [24, 44, 68], "92195464": [26, 46, 70], "921955": [26, 46, 70], "922": 64, "923077": [23, 43, 67], "923283": [18, 63, 64, 94], "923432": [26, 46, 70], "924485": [27, 47, 71], "9245": [21, 61, 65], "925272e": 24, "925288e": 24, "925593": [16, 62], "925768": [23, 43, 67], "926": [34, 95], "926657": [24, 44, 68], "926667": 39, "926733e": 24, "926829": [23, 43, 67], "927": 34, "927685": 78, "927710": 49, "927814": 32, "927826": 76, "928": [34, 66], "92809": [27, 47, 71], "92852376": [16, 62], "929": [34, 66], "9295": 66, "93": [14, 15, 19, 21, 28, 33, 34, 60, 61, 64, 65, 66, 72, 77, 78, 85], "930": 34, "930000": [18, 63], "930062": [15, 38], "930123": [16, 62], "930561": [16, 62], "9308647034083802": 38, "931": 34, "931439e": 24, "931556": 78, "931786": [21, 65], "931896": [15, 38], "932": [18, 34, 63], "932070": [34, 78], "932124": [16, 62], "932365": 96, "932375": 81, "932379e": 78, "932733": [23, 43], "93279": [53, 77], "933": [34, 93], "933191": 78, "933333": 39, "9336": [18, 63], "934": [17, 40], "93402132": [20, 41], "934205": [16, 62], "934269": [18, 63, 64, 94], "934783": [23, 43, 67], "9351": [27, 47, 71], "935512": 78, "935802": [16, 62], "93665": [53, 77, 97], "936733": 34, "937429": [35, 55, 56, 79], "9375": 61, "937500": [19, 61, 64], "938": [23, 43, 67], "938201": [15, 38], "938219": [34, 78], "9383": [16, 21, 62, 65], "93869659": [19, 64], "938697": [19, 64], "939006": [67, 81], "9391": [24, 44, 68], "939394": [16, 21, 62, 65], "939805": [15, 38], "94": [14, 15, 18, 19, 21, 23, 24, 33, 36, 43, 44, 48, 53, 60, 61, 63, 64, 65, 66, 67, 68, 77, 85, 94], "940": 95, "940000": 39, "9401": [33, 77], "940434": 49, "9406": [60, 61, 92], "941": [34, 54, 78], "9410": [15, 38], "941176": [19, 61, 64], "94117647": 61, "941938": 78, "942": [17, 40, 64], "943": 34, "943609": [27, 47, 71], "944": [34, 59], "944092": [23, 43, 67, 81], "944342": [34, 78], "944354": 64, "944733": 97, "944745": [32, 76], "944878": 42, "94487839624894": 42, "945": 34, "945000": 39, "945749": 49, "945980": 39, "946": 34, "946402e": 68, "946667": 39, "946783": [16, 62], "946875e": 68, "947": [18, 34, 63, 66], "9471": 66, "947500": 16, "948": 34, "948482": 78, "94888": [23, 43, 67], "948893": 95, "948901": 78, "949": [18, 19, 63], "9490": [18, 63], "9492": [24, 44, 68], "94933723": [24, 44, 68], "94959681": [19, 64], "949597": [19, 64], "949734": 76, "949736": 32, "95": [14, 15, 19, 29, 33, 34, 35, 48, 56, 60, 61, 64, 67, 73, 77, 78, 79, 90, 93, 95, 96], "950000": [18, 63, 93], "950088": [27, 47, 71], "9505": [26, 46, 70], "950564": [27, 47, 71], "9506": [26, 46, 70], "950696": [34, 54, 78], "950733": [16, 62], "951294": [24, 44, 68], "951574": [27, 47, 71], "951644": [27, 47, 71], "951667": 39, "951669": [27, 47, 71], "951696": [16, 62], "952456e": 66, "953": [25, 45, 64, 69], "953005": 78, "9530973451327434": [36, 57, 58, 80], "953333": 39, "954003": 95, "954082": 95, "954294e": 78, "954798": 49, "955034": 42, "955078": 42, "95511263": [16, 62], "955113": [16, 62], "955355": 42, "95535503227586": 42, "955723": 95, "9558": [33, 77], "956": [18, 63], "956966": [27, 47, 71], "957075": [27, 47, 71], "9573": [33, 77], "957411": 95, "9576": 59, "957919": [16, 62], "957987": [16, 62], "958": 42, "9583333333333334": [32, 76], "958393": [18, 27, 47, 63, 71], "95886206e": [32, 76], "959": [17, 18, 40, 63], "959139": [26, 46, 70], "959402e": [24, 68], "959870": [23, 43, 67], "959873": 78, "959922": 42, "96": [19, 21, 22, 27, 33, 47, 53, 60, 64, 65, 66, 67, 71, 77], "960": [17, 19, 21, 40, 65], "960000e": [17, 40], "9601165335428803": 42, "960117": 42, "960914": 42, "961": [17, 40], "961109802000133": [29, 73], "961404": [18, 63, 64], "961498": [24, 26, 35, 44, 46, 55, 56, 68, 70, 79], "961583": 81, "961771": [21, 65], "961898": [21, 65], "962": [17, 40], "963": [17, 40], "963024": [15, 38], "963030": 81, "96319": [53, 77], "96320": [53, 77], "96321": [53, 77], "96322": [53, 77], "96323": [53, 77], "96325": [53, 77], "963333": 39, "963641": 93, "963689": [27, 47, 71], "964": [17, 40], "964225": 95, "965517": 96, "96554": [27, 47, 71], "965787": 42, "9661": [24, 44, 68], "966131": [18, 63, 64, 94], "966393": 81, "9664": [60, 61, 92], "966667": 39, "966681": 25, "966812": [15, 38], "967907": [23, 43, 67], "968": [18, 63], "968233": [27, 47, 71], "96833": [52, 83], "968333": 39, "96834506": [16, 62], "968493": 78, "968514e": [24, 68], "96875": [32, 76], "968750": 42, "968857": 93, "9691": [24, 44, 68], "9692602666681306": [21, 65], "96965253": [26, 46, 70], "969653": [26, 46, 70], "97": [15, 19, 21, 22, 26, 29, 33, 34, 42, 60, 61, 64, 65, 66, 70, 73, 77, 78], "970518": 67, "970646": 42, "970683": [27, 47, 71], "9707980910387133": 25, "971725": 96, "972003": [45, 69], "97203586": [19, 64], "972036": [19, 64], "97217": [53, 77], "972198": 66, "972208": 96, "97223953": [19, 64], "972240": [19, 64], "972379": [17, 40], "97237936": 17, "972440": [67, 81], "97253": [53, 77], "9730": 64, "973225": 67, "973280": [19, 64], "97328024": [19, 64], "973294": [17, 40], "973333": 39, "974": [18, 63, 95], "974181": 39, "974480": [27, 47, 71], "974534": 39, "9748": [21, 65], "974801e": [24, 68], "975104": [17, 40], "975172e": 78, "97581663": [20, 41], "975895": [53, 77, 97], "976": [18, 23, 25, 43, 45, 63, 67, 69], "976000": 96, "9760519862174988": 31, "9760521650314331": [51, 75], "9760765550239234": 92, "976517": 42, "976562": 42, "976667": 39, "977": [18, 53, 63, 77, 97], "977278": [27, 47, 71], "9773": [16, 60, 61, 62, 92], "977359e": 78, "977873": 78, "978": [21, 65], "978031": 78, "9781449369880": [33, 77], "9781789957211": [32, 76], "97823755": [21, 65], "978487": 42, "9785299": 52, "978738": [27, 47, 71], "979": [25, 26, 45, 46, 69, 70], "979353": 49, "979562": [34, 54, 78], "98": [18, 19, 21, 24, 26, 28, 33, 34, 35, 44, 46, 52, 54, 55, 56, 60, 63, 64, 65, 68, 70, 72, 77, 78, 79, 83, 93, 95], "980": [53, 77, 97], "980000": 39, "98001": [15, 38], "98007": 59, "98010": 15, "98024": 15, "98027": [15, 38], "98028": [15, 38, 60], "98033": [15, 38], "98038": 15, "98039": 15, "980431": 42, "98045": 59, "98052": [15, 59], "98055": 59, "980634": [34, 78], "98065": [15, 38], "98072": 59, "98074": [15, 38, 60], "98075": 59, "98077": [15, 38], "9808": [21, 65], "980862": 78, "980894": 49, "980958": 39, "981": 26, "98102": 15, "98103": [15, 38], "98107": 59, "98112": 59, "98115": 15, "98116": 59, "98117": 15, "98118": [15, 38], "981195": [53, 77], "98125": [15, 38, 60], "98136": [15, 38, 60], "98144": [15, 38], "981447": 78, "98146": [15, 38], "98148": 15, "981643": [15, 38], "981735": [21, 65], "98178": [15, 38, 60], "981948": 78, "98199": [15, 38], "982184": [22, 42, 66], "982570": [34, 78], "983": [32, 76], "983333": 39, "983340": [15, 38], "9837": [21, 61, 65], "984": 66, "984653": [21, 65], "984664": [24, 44, 68], "985000": 39, "985283": [22, 42, 66], "9854": [21, 60, 61, 65, 92], "985457": 78, "98570": [20, 41], "985816": 61, "986047": [22, 42, 66], "986207": [22, 42, 66], "987": [32, 45, 66, 76], "987062": [24, 44, 68], "987597": [22, 42, 66], "9876": [25, 26, 45, 46, 69, 70], "987681": [27, 47, 71], "988": [27, 47, 71], "988000": 96, "9881": [60, 61, 92], "988281": 42, "988333": 39, "988381": [22, 42, 66], "988841": [22, 42, 66], "988901": [24, 44, 68], "989": [14, 60], "989147": [22, 42, 66], "989156": [22, 42, 66], "989443": [34, 78], "989922": [22, 42, 66], "989973": [21, 65], "99": [15, 18, 19, 22, 23, 33, 42, 43, 53, 60, 61, 63, 64, 66, 67, 77, 93, 97], "990000": 93, "990631": [53, 77, 97], "990754": [53, 77], "991052": 93, "9912": [16, 21, 62, 65], "991209": [34, 78], "9915": [53, 77, 97], "991667": 39, "991810": [15, 38], "991966": [34, 78], "992": [61, 66], "992148": 93, "992188": 42, "992220": [15, 38], "992254": [22, 42, 66], "99240562": [26, 46, 70], "992406": [22, 42, 66], "992569": [17, 40], "9926": 64, "992857": 61, "992908": 61, "993023": [22, 42, 66], "993029": [22, 42, 66], "993065": [34, 54, 78], "9931": [60, 61, 92], "993164": 42, "993333": 39, "9934531067299874": [21, 65], "993666": [26, 46, 70], "99369068": 20, "993692": 32, "993694": 76, "993969": [24, 26, 35, 44, 46, 55, 56, 68, 70, 79], "994": 59, "994135": 42, "994138": 42, "994266": [22, 42, 66], "994574": [22, 42, 66], "994764": [53, 77, 97], "995": [27, 32, 47, 71, 76, 93], "9950": [27, 47, 71], "9951": [60, 61, 92], "995112": 42, "99515": [53, 77], "995434": [24, 44, 68], "995707631111145": [31, 51, 75], "996": 93, "996090": 42, "996424": [15, 38], "996487": [15, 38], "996765": [46, 70], "996788": [34, 78], "996820": [34, 78], "9968347348881582": 38, "996899": [22, 42, 66], "997": [23, 34, 93], "99744241e": [26, 46, 70], "9977957422135844": [46, 70], "9977957422135846": 26, "998": [23, 34, 43, 67, 78, 93], "998019e": 68, "9983": [23, 43, 67], "998302": [23, 43, 67], "998370": [15, 38], "998440": [15, 38], "99845": [22, 42, 66], "998451": [22, 42, 66], "998569": 93, "998848": 93, "999": [21, 34, 65, 93], "99907": [22, 42, 66], "999122": [23, 43, 67], "9991338290544213": [15, 38], "999147": [23, 43, 67], "999172": [23, 43, 67], "999178": [15, 38], "999183": [23, 43, 67], "999185": [23, 43, 67], "999192": [23, 43, 67], "999210": [23, 43, 67], "999213": [15, 38], "999214": [23, 43, 67], "999221": [23, 43, 67], "999223": [23, 43, 67], "999225": [22, 42, 66], "999254": [23, 43, 67], "999298": [23, 43, 67], "999317": [23, 43, 67], "99931882": [44, 68], "99931883": 24, "999335": [23, 43, 67], "999438": [15, 38], "9994394006711425": [15, 38], "9994770884513855": [31, 51, 75], "999480": [15, 38], "999518": [15, 38], "999535": [22, 42, 66], "999539": [15, 38], "999544": [15, 38], "999545": [15, 38], "999546": [15, 38], "999558": [15, 38], "999562": [15, 38], "999567": [15, 38], "999577": [53, 77], "999622": [18, 63], "99975": [20, 41], "99980": [20, 41], "999885": 93, "9999": 13, "999916": 93, "999999": 93, "9999999999999998": 26, "9am": [27, 47, 71], "9m": 76, "9th": [13, 25, 26, 45, 46, 67, 69, 70], "A": [0, 1, 5, 9, 10, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 24, 25, 26, 27, 28, 30, 32, 33, 34, 35, 36, 39, 40, 41, 42, 44, 45, 46, 47, 48, 49, 50, 52, 54, 55, 56, 59, 60, 61, 62, 63, 64, 65, 66, 68, 69, 70, 71, 72, 74, 76, 78, 79, 80, 82, 83, 84, 85, 91, 97, 99], "AND": [0, 24, 44, 68], "AS": 0, "And": [13, 20, 22, 24, 28, 31, 33, 34, 35, 44, 51, 52, 54, 56, 59, 60, 66, 68, 75, 77, 78, 79, 85, 86, 87, 92, 93], "As": [4, 15, 16, 19, 22, 24, 25, 26, 30, 34, 35, 36, 44, 45, 46, 50, 53, 54, 55, 56, 57, 58, 59, 61, 64, 66, 68, 69, 70, 74, 77, 78, 79, 80, 84, 87, 89, 92, 93, 95, 99], "At": [4, 11, 13, 15, 21, 23, 25, 27, 28, 32, 33, 34, 38, 43, 45, 47, 59, 61, 65, 67, 69, 71, 72, 76, 87, 93], "BE": [0, 31, 52, 75], "BUT": [0, 9], "BY": [0, 1], "Be": [5, 8, 13, 16, 26, 35, 36, 46, 55, 56, 62, 70, 79, 80, 85, 87, 93], "Being": [32, 76], "But": [9, 13, 14, 15, 16, 17, 18, 19, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 40, 43, 44, 45, 46, 47, 50, 51, 53, 54, 56, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 84, 87, 89, 91, 93, 95, 97, 99], "By": [8, 12, 13, 15, 16, 19, 23, 25, 28, 31, 34, 35, 39, 43, 45, 51, 52, 54, 56, 59, 60, 61, 62, 63, 64, 67, 69, 72, 75, 78, 79, 87, 93, 94], "FOR": 0, "For": [0, 1, 4, 6, 8, 9, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 83, 85, 87, 89, 91, 93, 95, 97, 99], "IN": [0, 15, 21, 40, 61, 65], "IT": [21, 40, 65], "If": [1, 4, 5, 6, 7, 8, 9, 11, 13, 14, 15, 16, 17, 18, 19, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 38, 40, 43, 44, 45, 46, 47, 50, 51, 52, 53, 54, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 91, 92, 93, 94, 95, 97, 99], "In": [1, 5, 7, 8, 9, 10, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 83, 85, 86, 87, 88, 89, 91, 92, 93, 94, 95, 97, 99], "It": [2, 4, 6, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 87, 89, 90, 93, 95, 96, 99], "Its": [34, 54, 59, 78], "NEAR": [18, 27, 47, 63, 64, 71, 94], "NO": 0, "NOT": [0, 9, 19, 21, 40, 64, 65], "No": [0, 13, 14, 17, 24, 25, 26, 27, 29, 32, 34, 35, 40, 44, 45, 46, 47, 53, 54, 55, 56, 59, 60, 68, 69, 70, 71, 73, 76, 77, 78, 79, 85, 91, 93, 94, 97, 99], "Not": [24, 25, 26, 27, 28, 30, 34, 44, 45, 46, 47, 50, 53, 54, 59, 67, 68, 69, 70, 71, 72, 74, 77, 78, 94], "OF": 0, "OR": [0, 9, 24, 44, 68], "Of": [10, 19, 22, 42, 64, 66, 67], "On": [4, 8, 15, 17, 18, 19, 20, 22, 23, 24, 25, 26, 27, 29, 32, 34, 35, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 55, 56, 59, 63, 64, 66, 67, 68, 69, 70, 71, 73, 76, 78, 79, 95], "One": [6, 9, 14, 15, 17, 19, 20, 21, 22, 23, 26, 27, 28, 29, 31, 34, 40, 41, 43, 46, 51, 54, 60, 61, 64, 65, 66, 67, 70, 72, 73, 75, 78, 85, 91, 96, 97], "Or": [11, 16, 22, 35, 39, 42, 56, 62, 64, 66, 79, 87, 93], "Such": [7, 30, 33, 59, 74, 77], "THE": [0, 15, 61], "TO": [0, 31, 52, 75], "That": [6, 14, 18, 21, 22, 24, 25, 26, 28, 29, 30, 31, 33, 34, 35, 36, 42, 44, 45, 46, 51, 52, 54, 56, 59, 60, 61, 63, 65, 66, 68, 69, 70, 72, 73, 74, 75, 77, 78, 79, 80], "The": [0, 2, 5, 8, 9, 11, 12, 13, 14, 16, 17, 18, 19, 20, 23, 24, 26, 27, 29, 30, 32, 33, 34, 35, 36, 38, 39, 40, 41, 43, 44, 46, 47, 50, 52, 53, 54, 55, 56, 57, 58, 59, 60, 62, 63, 64, 67, 68, 70, 73, 74, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 87, 88, 91, 92, 93, 94, 97, 99], "Then": [14, 21, 25, 28, 33, 36, 45, 57, 58, 60, 65, 69, 72, 77, 80], "There": [1, 2, 5, 6, 9, 10, 13, 14, 15, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 40, 42, 43, 44, 45, 46, 47, 48, 50, 51, 52, 53, 54, 56, 57, 58, 59, 60, 61, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 97, 99], "These": [4, 11, 14, 16, 21, 24, 25, 26, 27, 28, 30, 33, 35, 44, 46, 47, 51, 53, 56, 60, 61, 62, 65, 68, 69, 70, 71, 72, 74, 75, 77, 79, 81, 89, 95, 96, 99], "To": [9, 11, 13, 14, 15, 16, 17, 18, 19, 20, 21, 24, 25, 27, 31, 32, 33, 36, 39, 40, 44, 45, 47, 48, 49, 51, 52, 56, 59, 60, 61, 62, 63, 64, 65, 68, 69, 71, 73, 75, 76, 77, 79, 80, 87, 89, 91, 93, 95, 97, 99], "WITH": 0, "Will": [67, 78, 85], "With": [0, 6, 13, 14, 16, 17, 18, 19, 21, 22, 24, 26, 27, 28, 29, 30, 31, 32, 34, 39, 44, 46, 47, 51, 54, 59, 60, 62, 63, 64, 65, 66, 68, 70, 71, 72, 73, 74, 75, 76, 78, 84, 87, 93], "_": [34, 45, 50, 52, 69, 78, 83], "___": [31, 51, 75], "__array__": 34, "__call__": [19, 34, 64], "__class__": [21, 33, 65, 77], "__finalize__": [34, 78], "__getitem__": 63, "__init__": [16, 25, 26, 28], "__name__": [21, 33, 65, 77], "__sklearn_tags__": 18, "__testing_word2vec": [31, 51, 52, 75], "_ahead": [77, 91, 97], "_array_api": 34, "_asarray_with_ord": 34, "_assert_all_finit": 18, "_assert_all_finite_element_wis": 18, "_astype_nansaf": [34, 78], "_base": 18, "_blank": [23, 43], "_california_housing_dataset": [21, 65], "_call_func_on_transform": [19, 34, 64], "_check_i": [18, 34], "_column_transform": [19, 34, 64], "_constructor_from_mgr": [34, 78], "_count_physical_cor": [16, 25, 26, 28], "_data": 34, "_deprecate_force_all_finit": 18, "_distn_infrastructur": [42, 66], "_encod": [19, 64], "_err_msg_1dcolumn": 34, "_estim": [18, 34], "_execute_child": [16, 25, 26, 28], "_fit": 18, "_fit_context": 18, "_fit_transform_on": 34, "_get_empty_rout": 34, "_get_sequential_output": [19, 34, 64], "_i": [24, 32, 76], "_is_numpy_namespac": 18, "_iter": 34, "_lag": [77, 91, 97], "_logist": 84, "_mgr": [34, 78], "_original_iter": 34, "_print_elapsed_tim": 34, "_proba": [45, 69], "_raise_for_param": 34, "_regress": 18, "_reset": 34, "_run": 34, "_score": [19, 64], "_scorer": [19, 64], "_set_output": [19, 34, 64], "_time_fit_was_cal": [54, 78], "_transform": [19, 64], "_transform_on": [19, 64], "_valid": [19, 64], "_validate_param": 18, "_valu": 34, "_winapi": [16, 25, 26, 28], "_with_config": 34, "aaaaaaaacu0": [31, 51, 75], "aaja": 41, "ab": [21, 23, 24, 26, 43, 44, 46, 65, 67, 68, 70, 77, 91, 97], "abbrevi": [52, 83], "abil": [13, 19, 20, 22, 26, 31, 33, 41, 46, 52, 59, 64, 66, 70, 75, 77, 87, 93], "abl": [5, 9, 12, 13, 14, 15, 16, 18, 19, 21, 22, 24, 25, 26, 27, 28, 29, 30, 31, 33, 35, 36, 45, 50, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 77, 79, 80, 87, 92, 93], "about": [1, 2, 4, 7, 8, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 31, 32, 33, 34, 36, 38, 40, 41, 42, 43, 44, 45, 46, 48, 50, 51, 52, 53, 54, 55, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 72, 73, 75, 76, 77, 78, 80, 83, 84, 85, 86, 87, 88, 89, 90, 92, 93, 95, 96, 99], "abov": [0, 6, 9, 13, 14, 15, 16, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33, 35, 38, 40, 42, 43, 44, 45, 46, 50, 51, 52, 53, 56, 59, 60, 61, 62, 65, 66, 67, 68, 69, 70, 72, 73, 74, 75, 76, 77, 79, 81, 83, 84, 87, 91, 93, 97, 99], "absenc": [19, 26, 30, 46, 64, 70, 74], "absent": [45, 99], "absolut": [12, 17, 21, 24, 26, 28, 40, 43, 44, 46, 65, 67, 68, 70, 72], "absorb": 59, "abspath": [13, 14, 15, 16, 17, 18, 19, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 84, 85, 86, 87, 89, 90, 91, 92, 93, 95, 96, 97], "academ": [1, 8, 27, 36, 47, 71, 80], "accent": 20, "accept": [6, 8, 9, 18, 23, 24, 31, 36, 43, 44, 51, 52, 57, 58, 67, 68, 75, 80, 87, 93], "accept_large_spars": [18, 34], "accept_spars": [18, 19, 34, 64], "access": [1, 6, 13, 15, 22, 25, 28, 30, 33, 35, 36, 37, 42, 45, 50, 52, 56, 57, 58, 61, 63, 66, 69, 72, 74, 77, 79, 80, 83], "accessori": [33, 77], "accident": [16, 18, 36, 62, 63, 80], "acclaim": 59, "accommod": 59, "accompani": [8, 13, 59, 60], "accomplish": [36, 39, 80], "accord": [21, 23, 24, 25, 27, 30, 34, 43, 44, 47, 50, 54, 59, 65, 67, 68, 71, 74, 78, 89, 95, 99], "account": [6, 8, 13, 30, 34, 36, 50, 57, 58, 59, 61, 67, 71, 74, 78, 80, 85], "accur": [13, 25, 26, 27, 30, 34, 35, 45, 46, 50, 56, 59, 61, 69, 70, 71, 74, 78, 79, 82, 85, 86, 92], "accuraci": [12, 14, 15, 16, 17, 18, 22, 23, 25, 26, 27, 29, 30, 32, 34, 35, 38, 39, 42, 43, 45, 46, 54, 56, 60, 61, 62, 63, 66, 67, 69, 70, 71, 73, 76, 78, 79, 81, 85, 86, 89, 92, 95, 99], "accuracy_scor": [23, 43, 67], "acdm": [25, 26, 45, 46, 67, 69, 70], "acf": [33, 77], "achiev": [9, 16, 23, 36, 43, 57, 58, 59, 62, 67, 80, 81, 89, 91, 95, 97], "acinonyx": [32, 59, 76], "ackland": 20, "acoust": [18, 22, 42, 62, 63, 66], "acquir": 12, "acquisit": [30, 50, 74], "across": [11, 13, 14, 15, 18, 23, 26, 31, 32, 43, 46, 51, 59, 60, 61, 63, 67, 70, 75, 76, 97, 99], "act": [20, 21, 41, 59, 65, 99], "action": [0, 13, 25, 26, 28, 30, 34, 45, 46, 50, 52, 54, 59, 69, 70, 72, 74, 78, 99], "activ": [4, 5, 11, 22, 32, 42, 59, 66, 76, 85, 99], "actor": [30, 50, 52, 74], "actual": [8, 13, 17, 19, 20, 21, 23, 25, 26, 28, 30, 32, 34, 35, 41, 43, 45, 46, 50, 52, 53, 54, 56, 59, 65, 67, 69, 70, 72, 74, 76, 77, 78, 79, 83, 89, 94, 95, 97], "ad": [6, 11, 13, 17, 19, 20, 21, 22, 25, 26, 27, 29, 31, 32, 34, 42, 45, 46, 47, 51, 52, 54, 64, 65, 66, 67, 69, 70, 71, 73, 75, 76, 77, 78, 82, 90, 91, 96, 97, 98], "adam": 20, "adapt": [0, 18, 19, 31, 33, 35, 45, 52, 56, 59, 63, 64, 67, 69, 75, 77, 79], "add": [1, 8, 9, 11, 18, 24, 25, 26, 27, 29, 33, 34, 44, 45, 46, 47, 52, 54, 59, 63, 64, 68, 69, 70, 71, 73, 77, 78, 81, 82, 83, 88, 89, 90, 91, 94, 95, 96, 97], "add_ind": [40, 45, 46, 63, 64, 68, 69, 70], "addit": [0, 4, 11, 13, 24, 30, 35, 44, 50, 56, 67, 68, 74, 77, 79, 91, 97, 99], "addition": [87, 92, 93], "address": [13, 20, 29, 32, 36, 57, 58, 59, 73, 76, 80], "adekany": [1, 99], "adelaid": [53, 77, 91, 97], "adequ": 59, "adio": [35, 56, 79], "adj": [52, 83], "adject": [31, 51, 52, 75], "adjust": [5, 16, 22, 29, 32, 33, 39, 42, 62, 66, 73, 76, 77, 87, 90, 93, 96], "adm": [25, 26, 45, 46, 67, 69, 70], "admin": [1, 99], "administr": [1, 31], "admit": [59, 61], "adopt": [7, 30, 50, 74], "ador": 20, "adp": [31, 51, 52, 75, 83], "adroitli": 59, "adult": [25, 26, 45, 46, 67, 69, 70], "adult_df_larg": [25, 26, 45, 46, 69, 70], "adv": [31, 51, 52, 75, 83], "advanc": [12, 19, 22, 28, 29, 30, 31, 32, 42, 50, 51, 52, 59, 64, 66, 72, 73, 74, 75, 76, 86, 92], "advantag": [12, 18, 19, 20, 21, 25, 29, 30, 41, 45, 50, 51, 52, 63, 64, 65, 69, 73, 74, 75, 85], "advent": 59, "advic": [34, 47, 59, 78], "advis": [13, 59], "advisor": 99, "af": [26, 45, 46, 70], "affair": 59, "affect": [16, 18, 21, 22, 28, 33, 34, 36, 41, 42, 57, 58, 62, 63, 65, 66, 67, 72, 77, 78, 80, 81, 87, 93], "affix": [52, 83], "africa": 25, "aft": [36, 57, 58, 80], "after": [4, 7, 8, 11, 14, 15, 17, 18, 19, 20, 23, 24, 26, 28, 29, 32, 33, 34, 36, 40, 41, 43, 44, 46, 52, 54, 56, 59, 61, 63, 64, 67, 68, 70, 72, 73, 76, 77, 78, 79, 80, 81, 83, 85, 89, 91, 95, 97, 99], "ag": [17, 20, 21, 24, 25, 26, 27, 28, 30, 40, 44, 45, 46, 47, 49, 50, 59, 65, 67, 68, 69, 70, 71, 74, 89, 95], "again": [14, 15, 17, 18, 29, 30, 31, 34, 36, 38, 39, 40, 50, 51, 52, 54, 57, 58, 59, 60, 61, 63, 73, 74, 75, 78, 80, 83, 87, 89, 91, 93, 95, 97], "against": [20, 30, 33, 50, 52, 67, 74, 77, 83], "agenc": [52, 83], "agent": 1, "agglomerativeclust": [29, 73], "aggress": [52, 83], "aggressive_elimin": [42, 66], "agit": [31, 51, 75], "agnost": [26, 46, 70], "ago": [32, 33, 76, 77], "agre": [14, 59, 99], "agreement": [34, 54, 78, 99], "ahead": [77, 91, 97], "ai": [8, 10, 27, 31, 32, 51, 52, 67, 71, 75, 76], "aight": 59, "aim": [17, 40, 85], "ain": [52, 83], "air": [20, 41, 96], "airplan": [35, 56, 79], "airport": [36, 57, 58, 80, 81, 97], "aka": [21, 34, 54, 65, 78], "al": [25, 31, 45, 51, 52, 69, 75], "alamine_aminotransferas": 59, "alan": [1, 20, 59], "alarm": 67, "alaska": [21, 65], "albani": 97, "albania": 25, "alberta": [31, 51, 52, 75], "album": 66, "albumin": 59, "albumin_and_globulin_ratio": 59, "alburi": [53, 77, 97], "alec": 59, "alex": 59, "alexand": [35, 56, 79], "alexnet": [32, 76], "algebra": [30, 31, 51, 52, 74, 75], "algorithm": [2, 12, 13, 18, 19, 24, 25, 26, 29, 31, 35, 36, 39, 40, 45, 46, 51, 52, 56, 59, 61, 63, 64, 67, 68, 69, 70, 73, 75, 79, 80, 81, 82, 83, 86, 87, 88, 92, 93, 94, 95], "alicespr": 97, "align": [9, 13, 14, 15, 59, 60, 61], "align_kei": [34, 78], "aliv": [36, 57, 58, 59, 80], "alkaline_phosphotas": 59, "all": [0, 1, 4, 5, 6, 7, 8, 9, 14, 15, 16, 17, 18, 19, 20, 22, 24, 25, 26, 27, 31, 32, 33, 34, 36, 38, 39, 40, 41, 42, 44, 45, 46, 47, 49, 51, 52, 53, 54, 55, 57, 58, 59, 61, 62, 64, 66, 68, 69, 70, 71, 75, 76, 77, 78, 80, 81, 82, 83, 84, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 99], "all_featur": [53, 77, 91, 97], "allei": [24, 26, 35, 44, 46, 55, 56, 68, 70, 79], "alley_grvl": [24, 68, 70], "alley_miss": [24, 68, 70], "alley_pav": [24, 68, 70], "alloc": [9, 31, 32, 51, 52, 75, 76], "allow": [5, 8, 13, 18, 22, 27, 33, 34, 36, 40, 42, 52, 53, 54, 57, 58, 59, 61, 63, 66, 67, 71, 77, 78, 80, 81, 87, 91, 92, 93, 97, 99], "allow_nan": 18, "allow_nd": [18, 34], "allpub": [24, 26, 35, 44, 46, 55, 56, 68, 70, 79], "allya": [1, 99], "almond": 96, "almost": [15, 21, 22, 24, 27, 29, 30, 44, 52, 59, 65, 66, 68, 73, 74, 82], "along": [5, 8, 19, 23, 32, 33, 35, 43, 56, 60, 64, 67, 76, 77, 79, 81, 86, 92], "aloof": 59, "alpha": [16, 39, 53, 62, 63, 77, 87, 91, 93, 97], "alpha_": [24, 44, 68], "alphabet": [21, 65], "alphago": [13, 28, 59, 72], "alq": [24, 26, 35, 44, 46, 55, 56, 68, 70, 79], "alreadi": [4, 9, 11, 12, 13, 20, 24, 26, 28, 31, 32, 34, 35, 44, 46, 51, 52, 53, 54, 55, 56, 68, 70, 72, 75, 77, 78, 79, 81, 83, 91, 92, 94, 97], "also": [1, 2, 4, 5, 6, 8, 9, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 39, 40, 42, 43, 44, 45, 46, 50, 51, 52, 53, 54, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 72, 73, 74, 75, 76, 77, 78, 79, 80, 82, 83, 84, 85, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 99], "alt": 11, "altar": [32, 76], "alter": 59, "altern": [9, 22, 28, 39, 56, 66, 72, 79], "although": [25, 28, 30, 34, 45, 50, 61, 69, 72, 74, 78, 96], "alwai": [1, 5, 13, 14, 15, 16, 17, 19, 20, 21, 23, 24, 25, 26, 28, 29, 30, 38, 40, 43, 44, 45, 46, 59, 60, 62, 63, 64, 65, 67, 68, 69, 70, 72, 73, 74, 85, 86, 87, 92, 93, 94, 99], "am": [13, 15, 17, 18, 20, 31, 35, 41, 51, 52, 56, 59, 63, 72, 75, 79, 83, 99], "amatriain": [30, 50, 74], "amaz": [17, 20, 31, 40, 41, 51, 59, 75], "amazon": [13, 28, 30, 50, 59, 72, 74], "ambianc": 17, "ambienc": [17, 40], "ambigu": [13, 31, 52, 59, 75, 83], "ambiti": [31, 51, 75], "ambrosin": 41, "amer": 67, "america": [31, 51, 52, 64, 75], "american": [17, 28, 40, 72], "amicu": 20, "aml": [18, 63], "among": [13, 14, 22, 23, 25, 26, 30, 43, 45, 46, 59, 60, 66, 69, 70, 74, 89, 95, 96], "amount": [4, 13, 15, 20, 21, 22, 23, 24, 26, 27, 28, 32, 33, 34, 36, 42, 43, 44, 46, 53, 59, 61, 65, 66, 67, 68, 70, 72, 76, 77, 78, 80, 81, 91, 97], "amp": [20, 25, 26, 41, 45, 46, 69, 70], "amplifi": [31, 51, 52, 67, 75], "amuel": [18, 63], "amus": 59, "an": [0, 1, 2, 4, 7, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 32, 33, 34, 36, 39, 40, 42, 43, 44, 46, 47, 48, 50, 51, 52, 53, 54, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 70, 71, 72, 73, 74, 75, 76, 77, 78, 80, 81, 82, 83, 84, 85, 88, 89, 91, 93, 94, 95, 97, 99], "anaconda": [11, 26, 46, 70], "anaconda3": [14, 16, 18, 19, 25, 26, 28, 31, 32, 34], "analogi": [16, 29, 31, 35, 51, 52, 56, 73, 75, 79], "analysi": [1, 2, 10, 12, 24, 28, 29, 33, 35, 44, 52, 54, 56, 60, 67, 68, 72, 73, 79], "analyt": [33, 77], "analyz": [12, 20, 23, 31, 34, 35, 41, 42, 43, 51, 53, 64, 66, 67, 71, 75, 77, 78, 79, 91, 97], "anatinu": [32, 76], "anca": [1, 99], "ancestor": [27, 82], "ancestr": 99, "andrea": [1, 10], "andrew": [1, 10, 22, 27, 59, 66, 71], "andr\u00e3": 20, "anemon": [32, 76], "angel": [34, 54, 78], "anger": [31, 51, 75], "angl": 20, "ani": [0, 5, 11, 14, 15, 17, 18, 19, 20, 21, 23, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 38, 40, 43, 45, 46, 47, 50, 51, 52, 53, 54, 56, 59, 60, 61, 63, 64, 65, 67, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 92, 93, 99], "anim": [31, 39, 51, 67, 75, 76], "animal_fac": 39, "anneal": [27, 47, 71, 82], "anniversari": 59, "annoi": 20, "annot": [5, 8, 26, 28, 70, 72, 99], "announc": 8, "annoy": 20, "annoyingli": [24, 44, 68], "annual": 28, "annual_incom": 28, "anomali": [24, 28, 68, 72, 81], "anonym": [33, 77], "anoth": [5, 9, 11, 14, 16, 20, 21, 22, 23, 25, 26, 28, 29, 30, 32, 33, 34, 35, 36, 42, 43, 45, 46, 50, 53, 54, 56, 59, 60, 62, 65, 66, 67, 69, 70, 72, 73, 74, 76, 77, 78, 79, 80, 85, 86, 88, 89, 91, 92, 94, 95, 97], "answer": [4, 7, 8, 13, 15, 22, 25, 28, 30, 31, 33, 35, 41, 45, 52, 56, 59, 60, 61, 66, 69, 72, 74, 75, 77, 79, 84, 85, 86, 87, 89, 91, 92, 93, 95, 97, 99], "anteat": [32, 76], "anthologi": 20, "anthrop": [31, 75], "anti": [34, 54, 59, 78], "anymor": [24, 28, 30, 44, 50, 68, 72, 74, 87, 93], "anyon": [31, 35, 36, 51, 56, 57, 58, 59, 75, 79, 80], "anyth": [0, 13, 15, 17, 19, 23, 30, 34, 36, 40, 43, 52, 54, 57, 58, 59, 61, 64, 67, 74, 78, 80, 83], "anytim": 99, "anywai": 59, "anywher": [19, 31, 51, 64, 75], "ap": [12, 85], "ap_lr": [23, 43, 67], "ap_svc": [23, 43, 67], "apart": [16, 29, 31, 51, 59, 62, 73, 75, 97], "apeendixa": [47, 71], "api": [31, 33, 34, 51, 52, 75, 77, 81, 85], "app": [13, 14, 31, 60, 85], "appdata": [31, 34], "appeal": [31, 52, 75], "appear": [2, 8, 19, 25, 31, 32, 36, 45, 51, 57, 58, 59, 64, 69, 75, 76, 80, 87, 89, 93, 95, 96, 99], "append": [4, 9, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 25, 26, 27, 28, 29, 30, 31, 32, 34, 35, 38, 39, 40, 41, 42, 43, 45, 46, 47, 48, 49, 50, 51, 52, 54, 55, 56, 59, 60, 61, 62, 63, 64, 65, 66, 67, 69, 70, 71, 72, 73, 74, 75, 76, 78, 79, 81, 82, 83, 84, 86, 87, 88, 89, 90, 92, 93, 94, 95, 96], "appendix": [67, 71], "appendix_b": 52, "appendixa": 27, "appendixc": [31, 51, 75], "appendixd": [32, 76], "appl": [11, 31, 51, 52, 75], "appli": [0, 2, 5, 7, 10, 12, 13, 14, 15, 17, 20, 21, 22, 26, 27, 28, 29, 30, 31, 32, 33, 34, 36, 40, 41, 42, 47, 50, 51, 52, 53, 54, 59, 60, 61, 65, 66, 67, 70, 71, 72, 73, 74, 75, 76, 77, 78, 80, 84, 85, 88, 94, 97, 99], "applianc": 93, "applic": [0, 6, 13, 19, 22, 24, 26, 27, 31, 34, 36, 42, 46, 47, 51, 52, 54, 57, 58, 59, 64, 66, 67, 68, 70, 71, 75, 78, 80, 81, 85, 99], "appreci": [12, 36, 72, 80, 99], "apprehens": 41, "apprentic": 41, "approach": [1, 12, 16, 17, 18, 19, 22, 24, 25, 26, 28, 31, 32, 39, 40, 41, 42, 46, 51, 52, 61, 62, 63, 64, 66, 67, 68, 69, 70, 71, 72, 75, 76, 81, 85, 87, 91, 93, 97], "appropri": [0, 4, 12, 14, 15, 19, 24, 28, 29, 33, 34, 36, 38, 41, 44, 54, 59, 60, 64, 67, 68, 72, 73, 77, 78, 80, 85, 90, 96, 99], "approv": [41, 67, 99], "approx": [16, 26, 46, 62, 70], "approxim": [14, 22, 27, 36, 47, 60, 66, 71, 80], "april": [53, 77, 97], "apt": 6, "ar": [0, 1, 2, 4, 6, 7, 8, 9, 10, 11, 14, 15, 16, 17, 19, 20, 22, 23, 24, 25, 26, 27, 32, 33, 34, 35, 36, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 52, 53, 54, 55, 56, 57, 58, 61, 62, 64, 66, 68, 69, 70, 71, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 99], "arang": [9, 15, 16, 20, 21, 22, 23, 24, 38, 39, 41, 42, 43, 44, 49, 61, 62, 65, 66, 67, 68, 87, 93], "arbitrari": [26, 28, 29, 33, 46, 53, 70, 72, 73, 77], "arch": 59, "architectur": [32, 76], "area": [22, 24, 25, 27, 28, 35, 42, 45, 47, 56, 66, 68, 69, 71, 72, 79, 81, 85], "aren": [8, 20, 24, 27, 28, 32, 33, 44, 47, 52, 53, 68, 71, 72, 76, 77, 83, 91, 97], "arena": [27, 47, 71], "arg": [16, 18, 19, 25, 26, 28, 34, 39, 61, 64], "argentina": 25, "argh": [34, 54, 78], "argmax": [20, 39, 41], "argmin": [16, 23, 28, 43, 61, 62, 67, 72], "argsort": [26, 31, 46, 51, 52, 70, 75], "argu": [13, 28, 52, 72], "argument": [9, 14, 19, 22, 23, 24, 26, 35, 42, 43, 44, 46, 56, 59, 60, 64, 66, 67, 68, 70, 79, 85, 88, 94], "arima": [33, 53, 77], "arima_model": [33, 53, 77], "aris": [0, 31, 52, 59, 71, 75, 77], "aristotl": [16, 62], "arithmet": 9, "ariti": 34, "arm": [20, 31, 51, 75], "around": [8, 16, 19, 20, 22, 23, 24, 32, 33, 34, 38, 41, 43, 44, 54, 59, 62, 64, 67, 68, 76, 77, 78, 86, 90, 92, 96], "aroundn": 59, "arr": [34, 78], "arr1": 9, "arr2": 9, "arrai": [14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 38, 40, 41, 42, 43, 44, 45, 46, 47, 48, 50, 51, 52, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 83, 84, 92, 95], "arrang": [32, 76], "array_equ": 9, "array_orig": 18, "arriv": [17, 31, 51, 71, 75], "arson": 20, "art": [35, 56, 59, 79], "arthur": [13, 59], "articl": [1, 14, 18, 28, 30, 31, 32, 35, 51, 52, 56, 60, 61, 63, 67, 72, 74, 75, 76, 79], "articul": [35, 56, 79], "artifici": [1, 13, 31, 51, 52, 59, 75], "artist": [18, 22, 42, 62, 63, 66], "as_fram": [16, 39, 62, 87, 93], "asarrai": 34, "ascend": [9, 17, 19, 20, 21, 22, 24, 25, 26, 27, 33, 34, 38, 41, 44, 45, 46, 47, 53, 54, 64, 65, 66, 68, 69, 70, 71, 77, 78, 85, 89, 95, 97], "ased": [29, 73], "asi": 95, "asia": 64, "asid": [4, 15, 25, 45, 61, 69, 87, 93], "ask": [3, 8, 13, 14, 15, 19, 27, 28, 30, 31, 34, 35, 47, 50, 51, 52, 54, 56, 59, 60, 61, 62, 64, 67, 71, 72, 74, 75, 78, 79, 86, 92, 93, 99], "asleep": [21, 65], "aspartate_aminotransferas": 59, "aspect": [21, 26, 27, 29, 30, 34, 35, 46, 50, 56, 65, 70, 71, 73, 74, 78, 79, 85], "aspir": 20, "assassin": 20, "assault": 99, "assembl": 59, "assert": [8, 19, 25, 26, 45, 46, 64, 67, 69, 70], "assess": [1, 5, 12, 13, 14, 15, 17, 18, 23, 26, 35, 40, 43, 56, 59, 60, 61, 63, 67, 70, 72, 79, 99], "assign": [1, 4, 6, 7, 9, 11, 13, 14, 16, 18, 21, 22, 26, 27, 28, 29, 31, 32, 33, 34, 35, 36, 39, 46, 47, 51, 52, 53, 54, 56, 57, 58, 60, 62, 63, 64, 65, 66, 69, 70, 71, 72, 73, 75, 76, 77, 78, 79, 80, 83, 85, 86, 88, 90, 91, 92, 94, 96, 97], "assist": [13, 31, 59, 75], "assoc": [25, 26, 45, 46, 67, 69, 70], "associ": [0, 13, 14, 15, 16, 20, 24, 26, 27, 28, 31, 32, 33, 34, 36, 37, 41, 44, 46, 51, 52, 53, 54, 56, 57, 58, 59, 61, 62, 67, 68, 70, 71, 72, 75, 76, 77, 78, 79, 80, 85, 89, 95], "assum": [1, 13, 19, 21, 29, 30, 33, 50, 51, 52, 53, 54, 56, 59, 60, 64, 65, 67, 68, 73, 74, 75, 77, 79, 85, 91, 97], "assumpt": [34, 54, 78], "assur": 59, "asterisk": [22, 66], "astonish": 59, "astyp": [9, 20, 33, 34, 39, 41, 53, 54, 77, 78, 91, 97], "astype_arrai": [34, 78], "astype_array_saf": [34, 78], "astype_is_view": 34, "ata": 95, "aten": 32, "atlanta": 59, "atmospher": [17, 20, 59], "atratu": [32, 76], "attack": [14, 60], "attempt": [15, 20, 22, 39, 59, 61], "attend": [13, 99], "attent": [7, 31, 36, 51, 52, 75, 80], "attic": [24, 44, 68], "attract": [31, 41, 52, 75], "attribut": [0, 1, 13, 14, 16, 18, 20, 21, 22, 27, 28, 31, 41, 42, 51, 52, 59, 60, 62, 63, 65, 66, 71, 72, 75, 82, 89, 90, 95, 96], "attrit": [34, 78], "au": 20, "auc": [12, 34, 36, 54, 78, 80, 85], "audienc": [5, 12, 35, 36, 56, 59, 79, 80, 85], "audio": [32, 76, 99], "audit": [36, 80, 99], "auditor": [5, 99], "augment": [31, 51, 75, 81], "august": [33, 53, 77, 97], "austen": 59, "austin": [31, 51, 52, 75], "australia": [25, 53, 77, 91, 97], "authent": [17, 28, 72], "author": [0, 31, 51, 52, 75, 99], "autism": 20, "auto": [13, 22, 27, 28, 35, 39, 40, 42, 45, 46, 48, 49, 56, 59, 63, 64, 66, 67, 68, 69, 70, 72, 79, 81, 82, 95, 96], "autocorrel": [33, 77], "autograd": 78, "autom": [14, 24, 31, 35, 42, 44, 52, 56, 60, 68, 75, 79, 83], "automat": [13, 17, 18, 19, 24, 27, 34, 35, 40, 44, 47, 52, 53, 54, 56, 59, 63, 64, 68, 71, 77, 78, 79, 83, 91, 97], "automodelfortokenclassif": [31, 51, 75], "autoregress": [21, 65], "autotoken": [31, 51, 75], "autumn": [53, 77, 97], "autumn_month": [53, 77, 97], "aux": [52, 83], "av": [24, 26, 31, 35, 44, 46, 51, 52, 55, 56, 68, 70, 75, 79], "avail": [0, 1, 8, 10, 13, 14, 15, 19, 22, 24, 27, 29, 30, 31, 32, 33, 34, 42, 44, 48, 49, 50, 51, 52, 53, 54, 59, 61, 64, 66, 67, 68, 73, 74, 75, 76, 77, 78, 81, 83, 85, 89, 91, 95, 97, 99], "avebedrm": [21, 65], "aveoccup": [21, 65], "averag": [12, 15, 16, 19, 21, 22, 23, 24, 26, 28, 29, 34, 36, 43, 44, 46, 52, 54, 59, 61, 62, 64, 65, 66, 67, 68, 70, 72, 73, 78, 80, 85, 87, 93, 96], "average_precis": [23, 43, 67, 81], "average_precision_scor": [23, 43, 67], "averaging_model": [25, 45, 69, 89, 95], "averaging_model_ndt": [25, 45, 69], "averoom": [21, 65], "avg": [23, 30, 33, 43, 50, 53, 67, 74, 77, 81], "avg_sent_emb": 52, "avocado": [35, 56, 79], "avoid": [4, 5, 8, 9, 18, 24, 29, 33, 34, 35, 36, 41, 44, 59, 60, 63, 67, 68, 73, 77, 78, 79, 80, 84, 85, 87, 93, 99], "aw": [17, 20, 36, 40, 41, 57, 58, 59, 80], "awai": [4, 7, 14, 21, 28, 30, 34, 36, 50, 54, 56, 60, 65, 72, 74, 78, 79, 80, 85], "awar": [13, 19, 31, 35, 51, 54, 56, 64, 75, 78, 79, 94], "award": [13, 59], "awesom": [10, 20], "ax": [14, 16, 21, 28, 29, 32, 34, 35, 39, 54, 55, 56, 61, 62, 65, 67, 72, 73, 76, 78, 79, 86, 87, 90, 92, 93, 96, 98], "axi": [8, 9, 13, 14, 15, 17, 18, 19, 20, 21, 26, 28, 29, 31, 32, 33, 35, 39, 46, 48, 49, 51, 52, 53, 55, 56, 59, 60, 61, 63, 64, 65, 70, 72, 73, 75, 76, 77, 79, 86, 90, 91, 92, 95, 96, 97], "axvlin": [28, 72], "ayanf": [1, 99], "b": [1, 9, 13, 14, 15, 16, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 29, 30, 31, 32, 33, 34, 35, 41, 42, 43, 45, 50, 52, 53, 54, 55, 56, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 71, 73, 74, 75, 76, 77, 78, 79], "b3": [46, 63, 70], "baba": [31, 51, 75], "babe": 59, "babi": [27, 31, 52, 75, 82], "babysitt": 20, "bach": 6, "bachelor": [25, 26, 45, 46, 67, 69, 70], "back": [9, 14, 15, 18, 22, 31, 38, 39, 51, 52, 59, 63, 66, 75, 85, 99], "backdrop": [33, 77], "backend": [16, 25, 26, 28, 31, 32, 48, 49, 51, 75], "background": [12, 35, 36, 56, 60, 79, 80], "backward": [32, 47, 71, 76], "bad": [9, 14, 15, 16, 17, 20, 24, 25, 26, 27, 28, 33, 40, 44, 45, 53, 59, 60, 61, 62, 64, 67, 68, 69, 70, 71, 72, 77], "badgeryscreek": [53, 77, 97], "badli": 59, "bag": [17, 20, 27, 31, 32, 40, 41, 47, 51, 52, 71, 75, 76, 85], "bai": [18, 27, 47, 63, 64, 71, 94], "baidu": 61, "bal_scor": 67, "balanc": [7, 16, 17, 20, 25, 30, 40, 41, 45, 50, 62, 69, 72, 74, 84, 89, 95], "ball": 59, "ballarat": [53, 77, 97], "balltre": 18, "balust": [32, 76], "balustrad": [32, 76], "bambi": [30, 50, 74], "banist": [32, 76], "bank": [26, 33, 34, 46, 54, 67, 70, 77, 78], "bannist": [32, 76], "bar": [23, 24, 26, 32, 34, 35, 36, 43, 44, 46, 53, 54, 55, 56, 67, 68, 70, 76, 77, 78, 79, 80, 91, 96, 97], "barbar": 59, "barbara": 41, "barbu": [1, 99], "bard": [31, 75], "bare": 20, "barnstorm": 59, "barri": [21, 65], "bart": [31, 51, 75], "base": [6, 9, 11, 12, 13, 14, 15, 16, 17, 18, 19, 21, 22, 23, 24, 26, 28, 29, 31, 32, 34, 35, 36, 39, 40, 42, 43, 44, 45, 46, 51, 52, 54, 59, 60, 61, 63, 64, 65, 66, 67, 68, 70, 72, 73, 75, 78, 79, 80, 82, 83, 85, 86, 89, 90, 92, 95, 96, 99], "base_scor": [25, 45, 69], "base_valu": [26, 46, 70], "baseblockmanag": [34, 78], "baselin": [34, 36, 39, 78, 80, 85, 86, 88, 91, 92, 94, 97], "baseline_hazard_": [34, 78], "basement": 59, "basi": [14, 16, 60, 62], "basic": [2, 9, 13, 14, 20, 22, 27, 30, 31, 32, 34, 41, 42, 47, 50, 51, 54, 59, 60, 66, 71, 74, 75, 76, 78, 89, 90, 91, 95, 96, 97], "batch": [31, 32, 39, 51, 52, 75, 76], "batch_siz": [39, 48, 49], "bath": 59, "bathroom": [15, 21, 38, 59, 60, 65], "bayesian": [22, 42, 66], "bayesopt": [22, 42, 66], "bbc": [20, 41, 59], "bc": 5, "beagl": [32, 59, 76], "bear": [32, 76], "beat": [25, 34, 45, 59, 69, 78], "beauti": [20, 30, 35, 50, 52, 56, 74, 79, 83], "beautifulli": [31, 51, 75], "becam": [32, 59, 76], "becaus": [1, 8, 9, 16, 17, 18, 19, 21, 22, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 39, 40, 42, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 56, 57, 58, 59, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 87, 91, 92, 93, 96, 97, 99], "becom": [4, 15, 16, 21, 22, 26, 27, 28, 31, 42, 43, 47, 52, 59, 61, 62, 65, 66, 67, 70, 71, 72, 75, 81, 82, 92], "bed": [36, 57, 58, 80, 81], "bedroom": [14, 15, 21, 38, 59, 60, 65], "bedroomabvgr": [24, 26, 35, 44, 46, 55, 56, 68, 70, 79], "bedrooms_per_household": [18, 63, 64, 88, 94], "beef": [17, 40, 52, 83], "been": [4, 7, 13, 18, 19, 20, 21, 22, 23, 24, 26, 28, 29, 30, 31, 32, 33, 34, 35, 43, 44, 46, 50, 51, 52, 53, 55, 56, 59, 60, 63, 64, 65, 66, 67, 68, 70, 72, 73, 74, 75, 76, 77, 79, 81, 83, 84, 87, 90, 93, 96, 99], "beet_salad": [32, 76], "befor": [1, 4, 5, 6, 14, 15, 16, 17, 19, 20, 21, 24, 25, 28, 29, 30, 32, 33, 34, 36, 40, 44, 45, 48, 50, 52, 53, 54, 57, 58, 59, 60, 61, 62, 64, 65, 68, 69, 72, 73, 74, 76, 77, 78, 80, 83, 86, 87, 89, 90, 91, 92, 93, 95, 96, 97], "began": [31, 51, 75], "begin": [5, 21, 27, 30, 31, 32, 33, 34, 40, 47, 51, 54, 60, 65, 71, 74, 75, 76, 77, 78, 85], "beginn": 6, "beguil": 59, "behav": [22, 26, 42, 46, 66, 70], "behavior": [23, 30, 36, 43, 63, 67, 74, 80], "behaviour": [19, 64, 77, 89, 95], "behind": [12, 13, 21, 22, 31, 32, 59, 65, 75, 76, 99], "being": [4, 13, 15, 18, 23, 24, 25, 29, 31, 34, 35, 43, 44, 45, 46, 51, 52, 55, 56, 59, 61, 63, 67, 68, 69, 70, 73, 75, 78, 79, 83, 87, 93, 99], "belat": 59, "belgian": 20, "belief": [35, 56, 79], "believ": [8, 20, 22, 33, 38, 46, 53, 59, 66, 70, 77], "bell": [32, 76], "belong": [21, 25, 29, 51, 60, 65, 73, 75, 86, 92], "below": [1, 6, 9, 13, 14, 15, 18, 19, 21, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 39, 40, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 83, 85, 86, 87, 89, 90, 91, 92, 93, 95, 96, 97, 99], "ben": 20, "bench": [32, 76], "benchmark": [32, 38, 76], "bendigo": [53, 77, 97], "beneath": 59, "benefici": [19, 35, 56, 64, 79], "benefit": [4, 25, 29, 35, 45, 56, 62, 69, 73, 79, 85], "bengio": [22, 42, 66], "bennet": 59, "bennett": 20, "ber": [51, 52, 75], "bereav": 41, "bergstra": [22, 42, 66], "berni": 59, "berri": [51, 52, 75], "bert": [31, 51, 75], "bertop": [31, 51, 52, 75], "bertsdpaselfattent": [51, 75], "besid": 59, "best": [2, 8, 14, 15, 16, 17, 18, 20, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 34, 35, 36, 38, 39, 42, 43, 44, 45, 46, 47, 50, 51, 56, 57, 58, 59, 60, 61, 62, 66, 67, 68, 69, 70, 72, 73, 74, 75, 78, 79, 80, 81, 82, 86, 87, 89, 92, 93, 95, 96], "best_alpha": [24, 44, 68], "best_c": 39, "best_depth": [15, 38, 61], "best_estimator_": [22, 24, 42, 44, 66, 68], "best_k": 39, "best_n_neighbour": [16, 62], "best_param": [22, 35, 56, 66, 79], "best_paramet": [22, 66], "best_params_": [22, 24, 35, 42, 44, 56, 66, 68, 79], "best_scor": [22, 66], "best_score_": [22, 24, 42, 44, 66, 68], "best_svr": [35, 56, 79], "bestalpha_coeff": [24, 44, 68], "bet": 59, "better": [7, 14, 16, 17, 18, 19, 20, 21, 24, 25, 26, 28, 29, 30, 32, 33, 34, 36, 39, 40, 44, 45, 46, 47, 48, 50, 52, 54, 57, 58, 59, 60, 62, 63, 64, 65, 68, 69, 70, 72, 73, 74, 76, 77, 78, 80, 83, 85, 86, 87, 88, 89, 92, 93, 94, 95, 99], "between": [2, 9, 12, 13, 14, 15, 17, 18, 19, 21, 23, 24, 25, 26, 27, 28, 29, 30, 32, 33, 34, 35, 38, 39, 43, 44, 45, 46, 48, 49, 50, 51, 52, 53, 54, 56, 59, 61, 64, 65, 67, 68, 69, 70, 71, 72, 73, 74, 76, 77, 78, 79, 81, 83, 85, 87, 90, 93, 96], "bewar": [52, 83], "beyond": [15, 22, 27, 47, 56, 59, 61, 66, 71, 79], "bfg": [54, 78], "bhatt": [1, 99], "bia": [21, 26, 34, 36, 46, 65, 67, 70, 78, 80, 85], "bias": [12, 26, 31, 34, 46, 51, 52, 67, 70, 75, 78], "bicycl": [14, 33, 60, 77], "bidirect": [31, 51, 75], "big": [8, 16, 19, 20, 22, 25, 27, 28, 29, 30, 31, 32, 34, 35, 40, 41, 45, 47, 50, 51, 52, 54, 56, 59, 62, 64, 66, 67, 69, 71, 72, 73, 74, 75, 76, 78, 79], "bigalpha_coeff": [24, 44, 68], "bigger": [16, 21, 24, 26, 29, 32, 33, 44, 46, 48, 52, 53, 62, 64, 65, 68, 70, 73, 76, 77, 83], "biggest": [24, 27, 44, 47, 68, 71, 91, 97], "bike": [33, 77], "bilg": 59, "bill": [32, 76], "billboard": [33, 77], "billi": 59, "billie_holidai": [31, 51, 52, 75], "billion": [20, 24, 31, 44, 51, 68, 75], "billionth": [33, 77], "bin": [17, 18, 22, 24, 27, 31, 33, 34, 35, 40, 42, 44, 47, 51, 53, 54, 55, 56, 63, 66, 68, 71, 75, 77, 78, 79, 86, 92], "binar": [14, 19, 60, 64], "binari": [14, 17, 18, 19, 21, 31, 32, 34, 35, 40, 41, 42, 45, 51, 56, 60, 63, 64, 65, 66, 69, 75, 76, 78, 79, 84, 85, 90, 96], "binary_feat": [17, 19, 40, 64], "binary_featur": [25, 26, 45, 46, 67, 69, 70, 89, 95], "binary_transform": [17, 25, 26, 40, 45, 46, 67, 69, 70, 89, 95], "bincount": [25, 45, 49, 67, 69, 81], "bind": [16, 62, 87, 93], "binomi": [22, 66], "biolog": [27, 82], "biologi": [19, 64], "bird": 48, "birds_class": 48, "birds_input": 48, "birnlei": 59, "bit": [14, 15, 18, 19, 20, 21, 22, 23, 24, 25, 26, 32, 33, 34, 35, 39, 41, 42, 43, 44, 45, 46, 48, 54, 56, 60, 61, 63, 64, 65, 66, 67, 68, 69, 70, 72, 76, 77, 78, 79, 81, 91, 96, 97], "black": [16, 26, 28, 32, 53, 59, 62, 70, 72, 76, 77, 91, 97], "blackhawk": [31, 51, 52, 75], "blake": 20, "bland": 20, "blast": 59, "bld": 32, "bldgtype": [24, 26, 35, 44, 46, 55, 56, 68, 70, 79], "bldgtype_1fam": [24, 68, 70], "bldgtype_2fmcon": [24, 68, 70], "bldgtype_duplex": [24, 68, 70], "bldgtype_twnh": [24, 68, 70], "bldgtype_twnhs": [24, 68, 70], "blei": [31, 51, 52, 75], "blend": 52, "blindli": [24, 44, 67, 68], "blob": [84, 90, 96], "block": [21, 31, 34, 51, 65, 75, 78], "blog": [31, 33, 51, 52, 53, 75, 77], "blogspot": [31, 51, 75], "blood": [20, 59], "bloomberg": [1, 10], "blore": 41, "blq": [24, 26, 35, 44, 46, 55, 56, 68, 70, 79], "blue": [14, 16, 22, 26, 27, 28, 33, 42, 46, 47, 53, 60, 62, 66, 67, 70, 71, 72, 77], "bluesman": [31, 51, 52, 75], "bluf": 59, "blunt": 59, "bluntli": 59, "bmatrix": [27, 30, 47, 71, 74], "bmo": [31, 51, 75], "boat": 59, "boathous": [32, 76], "bob_dylan": [31, 51, 52, 75], "bodi": 59, "boggl": [45, 69], "boi": [20, 31, 41, 51, 75], "bold": [35, 56, 79], "bomb": 59, "bon": 96, "bond": [36, 57, 58, 80, 81], "bonehead": 59, "bonu": [13, 25, 45, 69, 99], "book": [10, 24, 30, 31, 33, 35, 50, 51, 52, 55, 56, 68, 74, 75, 77, 79, 81, 99], "bool": [20, 24, 33, 41, 44, 68, 77, 91, 97], "bool_t": 34, "boost": [36, 52, 80, 85], "booster": [25, 45, 69], "boosting_typ": [45, 46, 69, 70, 95], "bootstrap": [35, 45, 56, 79, 95], "border": [21, 29, 52, 60, 65, 73, 83, 84, 86, 92], "bore": [20, 21, 41, 59, 65], "borrow": 59, "boss": 59, "boston": [21, 65], "both": [2, 5, 7, 11, 14, 15, 16, 17, 19, 20, 21, 22, 24, 25, 26, 27, 28, 30, 32, 33, 34, 35, 36, 40, 41, 42, 44, 45, 46, 52, 54, 55, 56, 57, 58, 60, 61, 62, 64, 65, 66, 67, 68, 69, 70, 72, 74, 76, 77, 78, 79, 80, 81, 82, 83, 85, 88, 90, 94, 96, 99], "bother": [26, 46, 70], "bottom": [29, 73], "bought": [30, 50, 74, 98], "bound": [27, 34, 47, 71, 78], "boundari": [15, 29, 35, 36, 52, 56, 61, 73, 79, 80, 83, 87, 93], "bouquet": [31, 51, 75], "bow": [20, 31, 41, 51, 75], "bow_df": [17, 19, 64], "bow_kmean": [51, 75], "box": [10, 26, 70, 85], "boxplot": [26, 46, 70], "boyc": [14, 60], "bp": [31, 51, 75], "br": [20, 41, 52, 59, 83], "bracket": 9, "brain": [27, 32, 71, 76], "brainstorm": 99, "branch": [14, 29, 31, 34, 52, 60, 73, 75, 78], "brand": [35, 56, 79], "brazenli": 41, "brazil": 25, "break": [1, 18, 20, 23, 41, 43, 59, 67, 85, 87, 93], "break_ti": [42, 43, 64, 66], "breakdown": 13, "breakthrough": [13, 59], "breakwat": [32, 76], "breath": 85, "breathless": [31, 51, 75], "breathtak": [31, 51, 52, 75], "breed": 85, "breiman": [25, 45, 69], "brian": 59, "bridg": 59, "brief": [4, 21, 25, 45, 65, 69], "briefest": 59, "briefli": [13, 23, 25, 27, 43, 47, 59, 67, 69, 71, 99], "bring": [6, 7, 11, 26, 29, 31, 36, 38, 46, 51, 57, 58, 59, 70, 73, 75, 80, 85], "brisban": 97, "britain": 59, "british": [1, 31, 51, 52, 59, 75, 83], "british_columbia": [31, 51, 52, 75], "broach": 59, "broad": [13, 16, 39, 52, 59, 62, 87, 93], "broadcast": 52, "broader": [2, 25, 31, 45, 51, 52, 69, 75], "broadest": 52, "broadli": [14, 16, 21, 25, 28, 29, 31, 51, 52, 62, 65, 67, 69, 72, 73, 75], "brook": 20, "broth": [17, 40], "brother": 59, "brownle": [27, 71], "browser": 11, "brush": [5, 32, 76], "bryan": 20, "bsmtcond": [24, 26, 35, 44, 46, 55, 56, 68, 70, 79], "bsmtexposur": [24, 26, 35, 44, 46, 55, 56, 68, 70, 79], "bsmtfinsf1": [24, 26, 35, 44, 46, 55, 56, 68, 70, 79], "bsmtfinsf2": [24, 26, 35, 44, 46, 55, 56, 68, 70, 79], "bsmtfintype1": [24, 26, 35, 44, 46, 55, 56, 68, 70, 79], "bsmtfintype2": [24, 26, 35, 44, 46, 55, 56, 68, 70, 79], "bsmtfullbath": [24, 26, 35, 44, 46, 55, 56, 68, 70, 79], "bsmthalfbath": [24, 26, 35, 44, 46, 55, 56, 68, 70, 79], "bsmtqual": [24, 26, 35, 44, 46, 55, 56, 68, 70, 79], "bsmtunfsf": [24, 26, 35, 44, 46, 55, 56, 68, 70, 79], "btw": [26, 46, 70], "bu": 59, "bubbl": [30, 32, 50, 74, 76], "buck": 59, "bucket": [27, 47, 71], "budget": [22, 30, 42, 50, 59, 66, 74], "buff": 59, "bug": [4, 9], "bui": [30, 36, 74, 80], "build": [0, 2, 12, 15, 17, 18, 19, 25, 27, 28, 31, 32, 33, 35, 40, 45, 47, 51, 52, 56, 61, 63, 64, 69, 71, 72, 75, 76, 77, 79, 83, 84, 85, 87, 91, 93, 97], "built": [9, 13, 14, 21, 22, 26, 31, 35, 36, 42, 46, 51, 53, 56, 57, 58, 59, 60, 61, 65, 66, 70, 75, 77, 79, 80, 91, 97], "bullshit": [1, 34, 78], "bulwark": [32, 76], "bunch": [9, 14, 15, 24, 25, 32, 34, 35, 36, 38, 44, 45, 54, 55, 56, 60, 68, 69, 76, 78, 79, 80], "bundl": 8, "bureau": [21, 65], "burt": 59, "busi": [23, 28, 34, 43, 67, 72, 78], "businessman": 41, "businesswoman": [31, 51, 52, 75], "bust": 59, "bustl": [33, 77], "butterfli": [29, 73], "buzz": [13, 59], "buzzword": [13, 59], "bypass": 99, "bystand": 59, "c": [0, 1, 9, 10, 11, 13, 14, 15, 17, 18, 19, 20, 21, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 34, 35, 36, 39, 40, 41, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 54, 56, 59, 60, 61, 63, 64, 65, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 78, 79, 80, 81, 82, 87, 93, 95, 99], "c1": [29, 73], "c2": [29, 73], "c_1": [28, 72], "c_2": [28, 72], "c_3": [28, 72], "c_log": [16, 39, 62, 87, 93], "c_val": 39, "c_valu": 39, "c_widget": [16, 62, 87, 93], "ca": [1, 10, 13, 36, 59, 80, 99], "ca_transform": [19, 64], "cabl": 59, "cach": 31, "cache_s": [35, 42, 43, 56, 64, 66, 79], "cairn": 97, "cal_hous": [21, 65], "calcul": [8, 15, 16, 18, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 36, 38, 43, 44, 45, 46, 47, 48, 50, 51, 53, 59, 61, 62, 63, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 80, 84, 85, 87, 91, 93, 97], "calendar": [1, 99], "calgary_flam": [31, 51, 52, 75], "calibr": [36, 80], "california": [18, 27, 47, 63, 71], "california_h": [27, 47, 71], "californian": [18, 63], "call": [1, 9, 13, 14, 15, 16, 17, 18, 19, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 40, 42, 43, 44, 45, 46, 47, 50, 51, 52, 53, 54, 55, 56, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 84, 85, 87, 89, 91, 93, 95, 97], "callback": [25, 45, 69], "caller": [36, 80], "came": [33, 77], "camera": [19, 20, 64], "campaign": 59, "campu": [27, 47, 71, 99], "can": [1, 4, 6, 7, 8, 11, 13, 14, 16, 17, 19, 20, 21, 22, 23, 24, 27, 29, 30, 31, 32, 33, 34, 35, 36, 38, 39, 40, 41, 42, 43, 44, 47, 48, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 62, 64, 65, 66, 67, 68, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 99], "canada": [16, 19, 21, 31, 35, 51, 52, 56, 61, 62, 64, 65, 75, 79, 83, 85], "canada_usa_c": [16, 21, 60, 61, 62, 65, 86, 92], "canadian": [17, 31, 40, 51, 52, 75], "canadien": [31, 51, 52, 75], "canberra": [53, 77, 97], "cancel": 99, "cancer": [13, 27, 47, 59, 71], "candi": [90, 96], "candid": [22, 31, 38, 42, 45, 51, 52, 66, 69, 75, 87, 93], "candidate_label": [31, 51, 75], "candy_df": [90, 96], "candy_transform": [90, 96], "cannot": [0, 8, 9, 13, 15, 16, 22, 23, 25, 26, 27, 29, 32, 33, 34, 35, 40, 43, 45, 46, 47, 56, 59, 61, 62, 66, 67, 69, 70, 71, 73, 77, 78, 79, 81, 82, 91, 97, 99], "cant": [31, 51, 75], "canuck": [31, 51, 52, 75], "canva": [1, 8, 13, 36, 80, 99], "capabl": [10, 31, 51, 75], "capit": [25, 26, 45, 46, 67, 69, 70], "caption": [8, 32, 76], "captiv": [31, 51, 52, 75], "captor": 59, "captur": [12, 15, 18, 21, 25, 27, 29, 30, 31, 33, 34, 45, 47, 50, 51, 52, 61, 63, 65, 69, 71, 73, 74, 75, 77, 78, 85], "car": [13, 32, 36, 52, 59, 76, 80, 83], "caramel": 96, "card": [14, 23, 34, 35, 43, 54, 56, 59, 60, 67, 78, 79], "cardin": 40, "care": [5, 8, 15, 18, 22, 23, 24, 26, 27, 28, 31, 33, 34, 40, 43, 44, 46, 47, 50, 51, 53, 54, 59, 61, 63, 66, 67, 68, 70, 71, 72, 75, 77, 78, 85, 89, 91, 95, 97], "carefulli": [1, 5, 8, 13, 24, 44, 67, 68, 85], "cari": 20, "carpent": 59, "carpentri": 6, "carrel": 41, "carri": [14, 15, 16, 17, 19, 20, 22, 24, 25, 28, 30, 31, 33, 36, 38, 40, 42, 44, 45, 50, 51, 52, 53, 60, 61, 62, 64, 66, 67, 68, 69, 72, 74, 75, 77, 80, 87, 91, 93, 97], "caruana": [26, 46, 70], "case": [7, 12, 13, 14, 15, 16, 17, 18, 20, 22, 23, 24, 25, 26, 27, 28, 30, 31, 33, 34, 35, 36, 40, 41, 43, 44, 45, 46, 47, 50, 51, 52, 53, 56, 57, 58, 59, 60, 61, 62, 63, 66, 67, 68, 69, 70, 71, 72, 74, 75, 77, 78, 79, 80, 81, 84, 85, 91, 92, 97, 99], "casei": 59, "cash": 59, "cast": [20, 30, 50, 59, 74], "castl": [32, 76], "cat": [25, 31, 32, 39, 45, 51, 52, 59, 67, 69, 75, 76, 83, 85], "catamount": [32, 59, 76], "catboost": [12, 26, 35, 46, 56, 70, 79, 85], "catboostclassifi": [25, 45, 69], "catboostregressor": [25, 45, 69], "catch": [67, 99], "categir": 40, "categor": [14, 22, 23, 24, 25, 27, 28, 30, 31, 34, 35, 38, 43, 44, 45, 47, 48, 50, 52, 53, 54, 55, 56, 60, 66, 67, 68, 69, 71, 72, 74, 75, 78, 79, 85, 87, 88, 91, 93, 94, 97], "categori": [16, 17, 18, 24, 25, 26, 27, 28, 32, 35, 39, 40, 42, 44, 45, 46, 47, 55, 56, 62, 63, 66, 67, 68, 69, 70, 71, 72, 76, 79, 85, 95], "categorical_feat": [17, 19, 22, 40, 42, 64, 66, 85], "categorical_featur": [24, 25, 26, 34, 35, 44, 45, 46, 53, 54, 55, 56, 64, 67, 68, 69, 70, 77, 78, 79, 89, 91, 94, 95, 97], "categorical_transform": [17, 24, 25, 26, 35, 40, 44, 45, 46, 53, 55, 56, 64, 67, 68, 69, 70, 77, 79, 89, 91, 94, 95, 97], "categories_": [18, 19, 63, 64], "cater": [28, 72], "caus": [26, 27, 30, 31, 32, 34, 46, 50, 51, 54, 59, 70, 74, 75, 76, 78, 81, 82], "causal": [26, 27, 46, 47, 70, 71, 82], "caution": [33, 77], "cautiou": 21, "cb": 20, "cbar": [21, 65], "cbtf": [1, 7, 99], "cc": [0, 1], "cc_df": [23, 43, 67, 81], "cconj": [31, 51, 52, 75, 83], "ccp_alpha": [35, 38, 45, 56, 69, 79, 95], "cd": 11, "cell": [8, 9, 11, 15, 17, 18, 19, 20, 22, 23, 24, 25, 26, 27, 30, 32, 34, 35, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 55, 56, 59, 63, 64, 66, 67, 68, 69, 70, 71, 74, 76, 78, 79, 86, 87, 89, 90, 92, 93, 95, 96], "ceme": 99, "censor": [1, 12, 36, 56, 79, 80, 85], "censorship": 59, "censu": [21, 25, 26, 45, 46, 65, 67, 69, 70], "census_df": 67, "cent": [17, 24, 44, 68], "center": [16, 28, 29, 32, 62, 72, 73, 76, 84, 96], "centers_df": 96, "centers_idx": [28, 72], "central": [6, 31, 51, 75], "centralair": [24, 26, 35, 44, 46, 55, 56, 68, 70, 79], "centralair_i": [24, 68, 70], "centralair_n": [24, 68, 70], "centric": [12, 35, 79], "centroid": [28, 29, 72, 73, 96], "centroids_idx": [28, 72], "centroids_idx_init": [28, 72], "centuri": 52, "certain": [16, 21, 22, 26, 27, 28, 31, 34, 35, 41, 42, 46, 52, 56, 59, 62, 65, 66, 67, 70, 71, 72, 75, 78, 79], "certainli": [86, 92], "certainti": [23, 43, 67], "cesspool": 59, "cezannec": [32, 48, 76], "chaat": 52, "chain": [19, 64], "challeng": [4, 7, 12, 13, 27, 30, 32, 33, 36, 40, 47, 50, 61, 71, 72, 74, 76, 77, 80, 85, 89, 95], "chambar": [17, 40], "chanc": [5, 22, 23, 24, 27, 28, 34, 35, 36, 43, 44, 46, 47, 56, 59, 60, 61, 66, 67, 68, 71, 72, 78, 79, 80], "chang": [0, 6, 8, 9, 13, 14, 15, 16, 17, 18, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 34, 35, 39, 42, 43, 44, 45, 46, 51, 53, 54, 55, 56, 60, 61, 62, 63, 66, 68, 69, 70, 72, 73, 74, 75, 76, 77, 78, 79, 86, 87, 89, 91, 92, 93, 95, 97], "channel": [1, 11, 48], "chap": 59, "chapman": 59, "chapter": 1, "charact": [19, 20, 31, 51, 52, 64, 75, 81], "character": [28, 30], "characterist": [14, 21, 60, 61, 65, 87, 93], "charg": [0, 34, 54, 59, 78], "charl": [20, 21, 59, 65], "charm": [20, 52], "chart": [26, 34, 35, 46, 53, 55, 56, 70, 77, 78, 79, 91, 97], "chase": 59, "chat": 99, "chatbot": [31, 51, 75], "chatgpt": [31, 51, 52, 59, 75, 99], "chatterje": 41, "che210d": 10, "cheaper": [27, 47, 71], "cheat": 10, "cheatsheet": 67, "check": [1, 4, 5, 8, 11, 13, 14, 15, 17, 18, 21, 23, 24, 26, 27, 28, 29, 31, 32, 33, 34, 35, 43, 44, 46, 47, 51, 52, 54, 56, 59, 60, 61, 63, 65, 67, 68, 70, 71, 72, 73, 75, 76, 77, 78, 79, 81, 87, 89, 90, 91, 93, 95, 96, 97, 99], "check_arrai": [18, 34], "check_assumpt": [34, 54, 78], "check_consistent_length": 18, "check_invers": [19, 64, 68], "check_param": [18, 34], "check_x_i": 18, "check_y_param": 18, "checklist": 85, "checkmark": [30, 74], "checkout": [22, 42, 66], "cheetah": [32, 59, 76], "chemic": 20, "chemistri": 20, "cherri": [35, 55, 56, 79], "chess": [13, 59], "chest": [15, 61], "chestpaintyp": [89, 95], "chetah": [32, 59, 76], "chi": [34, 78], "chicken": [17, 28, 72], "chief": 59, "child": [20, 26, 45, 46, 59, 67, 70], "children": [30, 50, 59, 74], "chill": 20, "chines": [17, 40, 52, 83], "chloe": 20, "chn": 9, "chocol": 96, "chocolate_cak": [32, 76], "choic": [2, 5, 11, 15, 22, 24, 25, 26, 28, 29, 30, 33, 44, 45, 46, 50, 59, 66, 67, 68, 69, 70, 72, 73, 74, 77, 87, 88, 93, 94], "cholesterol": [89, 95], "choos": [6, 11, 22, 25, 29, 35, 36, 45, 56, 57, 58, 59, 66, 67, 69, 73, 79, 80, 85, 87, 93], "chop": [35, 52, 55, 56, 66, 79, 83], "chose": [15, 35, 38, 56, 79], "chosen": [15, 22, 23, 34, 35, 43, 56, 61, 66, 78, 79, 81, 85, 89, 95], "chrbv": [34, 54, 78], "christoph": 20, "chrome": 13, "chuckl": 59, "chunki": [28, 72], "churn": [27, 54, 56, 79, 85], "chvcf": 34, "ciml": 1, "cinematograph": 59, "cinematographi": [31, 51, 52, 59, 75], "cinereu": [32, 76], "circl": [16, 23, 43, 62, 67], "circuit": 99, "circumst": 8, "citat": 8, "cite": [5, 34, 54, 78, 99], "citi": [16, 33, 35, 52, 56, 60, 61, 62, 77, 79, 83, 85, 86, 92], "citibik": [33, 77], "cities_df": [16, 21, 62, 65], "citizen": [34, 54, 78], "cityscap": [33, 77], "civ": [25, 26, 45, 46, 67, 69, 70], "clai": [46, 70], "claim": [0, 22, 66, 67], "clarif": 72, "clarifi": [6, 99], "clariti": 12, "class": [1, 4, 6, 8, 14, 15, 16, 18, 19, 21, 27, 28, 31, 34, 35, 36, 59, 60, 61, 62, 63, 64, 65, 71, 72, 77, 78, 79, 80, 86, 87, 89, 92, 93, 95, 97], "class_attend": [14, 15, 60, 61, 85], "class_attendance_enc": [19, 64], "class_attendance_level": [19, 64], "class_label": 67, "class_labels_fil": [13, 59], "class_nam": [14, 16, 25, 32, 39, 45, 48, 49, 60, 62, 69, 76, 86, 92], "class_sep": 81, "class_weight": [25, 35, 41, 42, 43, 45, 46, 56, 64, 66, 69, 70, 76, 79, 95], "classes_": [20, 21, 23, 25, 26, 32, 41, 43, 45, 46, 65, 67, 69, 70, 76, 84], "classic": [16, 32, 59, 62, 76, 84], "classif": [1, 2, 12, 13, 15, 16, 17, 18, 19, 21, 24, 25, 26, 27, 30, 31, 33, 34, 35, 38, 44, 45, 46, 48, 49, 51, 52, 53, 56, 59, 61, 62, 63, 64, 65, 68, 69, 70, 74, 75, 77, 78, 79, 82, 84, 86, 87, 89, 92, 93, 95], "classifi": [15, 16, 18, 19, 22, 23, 26, 31, 32, 35, 39, 42, 43, 46, 48, 49, 51, 56, 61, 62, 63, 64, 66, 67, 70, 75, 76, 79, 84, 86, 88, 89, 92, 94, 95], "classification_df": [14, 15, 60, 61], "classification_report": [23, 43, 67, 81], "classifier_result": 95, "classifiers_ndt": [25, 45, 69], "classify_imag": [13, 32, 59, 76], "classmat": [7, 87, 88, 89, 90, 91, 93, 94, 95, 96, 97, 99], "classroom": [1, 5], "claud": [25, 31, 51, 75, 99], "claudio": 41, "clean": [2, 15, 17, 20, 29, 35, 38, 40, 41, 55, 56, 59, 73, 79, 91, 97, 99], "clean_text": [31, 51, 52, 75], "cleaned_hm": [36, 57, 58, 80, 81], "cleaned_restaurant_data": [17, 40], "cleaner": [26, 45, 46, 67, 70], "clear": [8, 12, 13, 23, 28, 36, 39, 43, 59, 67, 72, 80, 87, 93], "clearli": [4, 8, 22, 25, 26, 33, 45, 46, 66, 69, 70, 77], "cleric": [25, 26, 45, 46, 67, 69, 70], "clever": [35, 55, 56, 79], "clf": [13, 14, 16, 21, 59, 60, 62, 65], "click": [1, 6, 8, 11, 14, 30, 36, 37, 50, 56, 57, 58, 67, 74, 79, 80], "client": [30, 36, 51, 57, 58, 74, 75, 80], "clinic": [14, 31, 60, 75], "clip": [39, 59, 77, 91, 97], "cloak": 20, "clone": [6, 8, 11], "close": [2, 16, 21, 22, 23, 28, 29, 31, 33, 34, 39, 42, 43, 51, 52, 59, 61, 62, 65, 66, 67, 72, 73, 75, 77, 83, 84, 87, 92, 93, 99], "close_default_lr": [23, 43, 67], "close_fd": [16, 25, 26, 28], "close_zero_svm": [23, 43, 67], "closer": [7, 16, 17, 18, 21, 30, 50, 62, 63, 65, 74, 86, 92], "closest": [15, 16, 18, 28, 29, 31, 33, 43, 51, 52, 62, 63, 67, 72, 73, 75, 77], "closet": [20, 41], "cloth": [33, 59, 77], "cloud": [1, 13, 22, 29, 42, 66, 99], "cloud3pm": [53, 77, 91, 97], "cloud9am": [53, 77, 91, 97], "clouzot": 20, "clung": [31, 51, 75], "clust_label": [28, 72], "cluster": [1, 2, 12, 30, 31, 33, 36, 51, 52, 53, 59, 74, 75, 77, 80], "cluster_cent": [28, 72], "cluster_centers_": [28, 48, 49, 72, 90, 96], "cluster_label": 49, "cluster_std": [29, 32, 73, 76], "cluster_summari": 96, "clutter": 60, "cm": [16, 21, 23, 26, 30, 39, 43, 50, 62, 65, 67, 70, 74, 87, 93], "cmap": [22, 26, 42, 63, 66, 67, 70], "cmn": [24, 44, 68, 70], "cmp": [34, 78], "cnn": [33, 53, 77], "co": [19, 31, 51, 52, 59, 64, 75], "coal": 59, "coast": [32, 76], "cobar": 97, "cocain": 59, "cocknei": 59, "cockpit": [35, 56, 79], "code": [4, 6, 8, 9, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 86, 87, 88, 89, 90, 92, 93, 94, 95, 96], "codecademi": 10, "coef": [34, 53, 54, 77, 78, 97], "coef0": [35, 42, 43, 56, 64, 66, 79], "coef_": [20, 21, 24, 25, 26, 27, 30, 32, 33, 34, 41, 44, 45, 46, 47, 50, 53, 54, 65, 68, 69, 70, 71, 74, 76, 77, 78, 84, 89, 95, 97], "coef_df": [21, 26, 46, 65, 70], "coef_nonzero": [33, 77], "coeff": [20, 21, 41, 65], "coeff_df": [53, 77, 97], "coeffici": [24, 25, 27, 30, 32, 33, 34, 44, 45, 47, 50, 53, 54, 56, 68, 69, 71, 74, 76, 77, 78, 79, 84, 85, 89, 91, 95, 97], "coefs_df": [27, 47, 71], "coffsharbour": 97, "coher": [28, 72], "col": [14, 19, 21, 30, 33, 50, 60, 64, 65, 74, 77, 85], "col1": 9, "col2": 9, "col3": 9, "col4": 9, "col5": 9, "col6": 9, "cold": [18, 63], "colinear": [26, 46, 70], "collabor": [5, 6, 12, 30, 50, 74], "collaps": [26, 46, 70], "colleagu": [9, 10], "collect": [12, 13, 14, 17, 18, 19, 25, 26, 27, 30, 31, 32, 33, 34, 36, 40, 45, 46, 47, 50, 51, 52, 54, 59, 60, 63, 64, 67, 69, 70, 71, 74, 75, 76, 77, 78, 80, 81, 85, 89, 90, 95, 96, 99], "colleg": [25, 26, 45, 46, 67, 69, 70], "collinear": [27, 82], "colombia": 25, "color": [21, 26, 27, 28, 29, 35, 46, 47, 48, 53, 56, 65, 70, 71, 72, 73, 77, 79, 96, 98], "color_continuous_scal": [27, 47, 71], "color_threshold": [29, 73], "colorbar": [21, 63, 65], "colour": [19, 21, 22, 26, 28, 29, 32, 42, 46, 49, 64, 65, 66, 70, 72, 73, 76], "colsample_bylevel": [25, 45, 69], "colsample_bynod": [25, 45, 69], "colsample_bytre": [25, 45, 46, 69, 70, 95], "columbia": [1, 10, 31, 51, 52, 75, 83], "column": [8, 13, 14, 15, 16, 17, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 34, 35, 36, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 78, 79, 80, 81, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97], "column_as_label": 34, "column_nam": [19, 64, 90, 94, 96], "column_stack": [27, 47, 71], "columntranform": [88, 94], "columntransform": [1, 17, 18, 22, 24, 25, 26, 27, 33, 34, 35, 40, 42, 44, 45, 46, 47, 53, 54, 55, 56, 63, 66, 67, 68, 69, 70, 71, 77, 78, 79, 89, 90, 91, 95, 96, 97], "columntransformer__countvectorizer__max_featur": [22, 42, 66], "columntransformercolumntransform": [19, 22, 24, 25, 27, 47, 71], "columntransformerifit": [40, 42, 46, 64, 68, 70], "columntransformerifittedcolumntransform": [19, 24, 35, 44, 55, 56, 79], "columntransformerinot": [17, 19, 25, 45, 64, 69], "com": [0, 6, 9, 10, 11, 13, 16, 22, 23, 29, 31, 32, 33, 34, 36, 43, 51, 54, 67, 75, 76, 77, 78, 80, 81, 90, 96], "comat": [31, 51, 52, 75], "combin": [14, 17, 18, 22, 23, 27, 30, 31, 33, 34, 35, 40, 42, 43, 47, 51, 56, 59, 60, 63, 66, 67, 71, 74, 75, 77, 78, 79, 82, 86, 87, 89, 92, 93, 95], "come": [13, 14, 17, 18, 19, 27, 30, 31, 32, 33, 34, 35, 38, 40, 47, 51, 52, 54, 56, 59, 60, 63, 64, 67, 71, 74, 75, 76, 77, 78, 79, 86, 92, 96], "comedi": [20, 30, 41, 50, 59, 74], "comfi": [17, 40], "comfort": [5, 20, 31, 41, 51, 75], "command": [4, 11, 36, 41, 52, 57, 58, 80, 81], "comment": [9, 10, 17, 40, 59, 90, 91, 97], "commerci": [0, 93], "commit": [8, 23, 43, 67, 99], "common": [1, 5, 9, 12, 14, 15, 16, 22, 24, 27, 29, 30, 32, 33, 34, 36, 42, 44, 47, 50, 52, 54, 57, 58, 60, 61, 62, 66, 67, 68, 69, 71, 73, 74, 76, 77, 78, 80, 82, 83, 84, 87, 93, 94, 99], "commonli": [14, 18, 22, 23, 28, 31, 32, 34, 43, 54, 60, 63, 66, 67, 72, 75, 76, 78], "commonwealth": [31, 51, 52, 75], "commun": [1, 2, 7, 12, 19, 22, 24, 36, 59, 64, 66, 68, 80, 99], "commut": 9, "comp_dict": 67, "compact": [22, 27, 47, 66, 71], "compani": [6, 27, 28, 30, 31, 34, 51, 52, 67, 72, 74, 75, 78, 83], "compar": [9, 12, 14, 15, 16, 18, 21, 22, 23, 24, 25, 26, 27, 29, 30, 32, 35, 38, 42, 43, 44, 45, 46, 47, 50, 52, 53, 55, 56, 60, 61, 62, 63, 65, 66, 67, 68, 69, 70, 71, 73, 74, 76, 77, 79, 84, 85, 89, 90, 91, 95, 96, 97, 99], "comparis": 95, "comparison": [29, 32, 34, 40, 67, 73, 76, 78, 85], "compassion": 99, "compat": [9, 46, 70], "compatibitl": 9, "compel": [33, 77], "competit": [25, 32, 69, 76, 84], "competitornam": [90, 96], "complain": 7, "complaint": [7, 99], "complement": 52, "complet": [1, 5, 7, 8, 11, 13, 15, 18, 20, 22, 25, 26, 27, 29, 32, 34, 35, 40, 42, 45, 46, 52, 56, 59, 63, 66, 69, 70, 71, 73, 76, 78, 79, 83, 86, 89, 90, 92, 95, 96, 99], "complex": [12, 13, 14, 16, 21, 24, 25, 26, 27, 29, 31, 32, 33, 34, 36, 39, 40, 45, 46, 47, 51, 52, 57, 58, 59, 60, 62, 65, 66, 68, 69, 70, 71, 73, 75, 76, 77, 80, 87, 93], "complex_warn": 34, "complexwarn": 34, "compli": [0, 99], "complic": [13, 14, 17, 22, 24, 27, 39, 40, 48, 59, 60, 61, 66, 68, 71], "compon": [19, 30, 33, 35, 53, 56, 64, 67, 74, 77, 79, 99], "components_": [31, 51, 52, 75], "compos": [17, 19, 22, 24, 25, 26, 27, 33, 34, 35, 39, 40, 42, 44, 45, 46, 47, 48, 49, 53, 54, 55, 56, 62, 64, 66, 67, 68, 69, 70, 71, 77, 78, 79, 88, 89, 90, 91, 94, 95, 96, 97], "composit": [19, 64], "compound": [32, 34, 52, 76, 78, 83], "comprehend": [31, 39, 51, 52, 75], "comprehens": [28, 72, 85, 99], "compress": [17, 19, 20, 28, 31, 40, 41, 51, 52, 64, 72, 75], "compris": [13, 14, 28, 59, 60, 72], "compromis": [87, 93], "comput": [1, 5, 8, 10, 11, 12, 19, 22, 23, 26, 27, 28, 29, 31, 33, 34, 35, 36, 39, 43, 45, 46, 47, 48, 49, 51, 52, 56, 57, 58, 59, 64, 66, 67, 69, 70, 71, 72, 73, 75, 77, 79, 80, 82, 83, 84, 89, 90, 94, 95, 96, 99], "computation": [27, 47, 71], "compute_class_weight": 67, "computer_programm": [31, 51, 52, 75], "coms4995": [18, 63], "con": [28, 31, 35, 46, 51, 52, 56, 59, 72, 75, 79], "concat": [13, 16, 18, 19, 21, 26, 40, 42, 45, 46, 59, 62, 63, 64, 65, 66, 68, 69, 70, 95], "concaten": [19, 52, 64], "concav": [27, 47, 71], "concensu": 61, "concentr": [42, 66, 85], "concept": [1, 5, 12, 14, 15, 17, 26, 27, 28, 31, 33, 40, 46, 51, 59, 70, 71, 72, 75, 77, 85, 87, 93, 99], "conceptnet": [31, 51, 52, 75], "conceptu": [5, 25, 35, 45, 56, 69, 79], "concern": [4, 12, 13, 15, 19, 25, 31, 38, 45, 59, 64, 69, 75, 99], "concess": [1, 8], "concis": [14, 36, 60, 80], "conclus": [1, 35, 56, 79], "concord": [34, 54, 78], "concordance_index": [34, 54, 78], "concordance_index_": [34, 54, 78], "concret": [13, 35, 56, 59, 79], "conda": [13, 23, 24, 25, 26, 28, 31, 34, 39, 43, 44, 45, 46, 48, 49, 51, 52, 54, 59, 67, 68, 69, 70, 72, 75, 78, 81], "condens": 14, "condit": [0, 14, 15, 19, 20, 27, 34, 38, 41, 52, 54, 59, 60, 64, 78, 82, 83], "condition1": [24, 26, 35, 44, 46, 55, 56, 68, 70, 79], "condition1_arteri": [24, 68, 70], "condition1_feedr": [24, 68, 70], "condition1_norm": [24, 68, 70], "condition1_posa": [24, 68, 70], "condition1_posn": [24, 55, 68, 70], "condition1_rra": [24, 55, 68, 70], "condition1_rran": [24, 55, 68, 70], "condition1_rrn": [24, 55, 68, 70], "condition1_rrnn": [24, 55, 68, 70], "condition2": [24, 26, 35, 44, 46, 55, 56, 68, 70, 79], "condition2_arteri": [24, 46, 68, 70], "condition2_feedr": [24, 46, 68, 70], "condition2_norm": [24, 46, 68, 70], "condition2_posa": [24, 46, 68, 70], "condition2_posn": [24, 44, 46, 68, 70], "condition2_rra": [24, 44, 46, 68, 70], "condition2_rran": [24, 44, 46, 68, 70], "condition2_rrnn": [24, 44, 46, 68, 70], "conditional_aft": [34, 54, 78], "conduct": [12, 13], "confer": [31, 51, 52, 75], "confid": [13, 15, 20, 26, 34, 36, 41, 46, 54, 59, 61, 70, 78, 80, 85, 87, 89, 93, 95], "confidenti": [23, 43, 67], "config": [11, 34], "config_context": [18, 34], "configur": [22, 25, 42, 45, 66, 68, 69], "confin": 20, "confirm": 67, "conflict": [5, 11, 29, 59, 73, 99], "confound": [27, 71, 82], "confus": [9, 16, 19, 24, 36, 44, 62, 64, 68, 72, 80, 87, 93], "confusingli": 13, "confusion_matrix": [23, 34, 43, 54, 67, 78], "confusionmatrixdisplai": [23, 43, 67, 81, 82], "congrat": [19, 64], "conjunct": [27, 47, 71], "connect": [0, 13, 14, 29, 30, 32, 36, 50, 57, 58, 60, 73, 74, 76, 80, 85], "connot": 52, "conort": [27, 47, 71], "consecut": [33, 53, 77], "consequ": [8, 13, 30, 35, 50, 56, 59, 64, 67, 74, 79], "consid": [14, 15, 16, 18, 19, 21, 22, 23, 26, 27, 28, 29, 30, 31, 33, 35, 36, 39, 42, 43, 45, 46, 50, 51, 52, 56, 59, 60, 61, 62, 63, 64, 65, 66, 67, 69, 70, 72, 73, 74, 75, 77, 79, 80, 82, 83, 85, 87, 93, 99], "consider": [2, 12, 25, 28, 30, 34, 36, 45, 50, 56, 57, 58, 59, 69, 72, 74, 78, 79, 80, 81], "consist": [7, 8, 11, 14, 15, 17, 18, 28, 34, 36, 40, 59, 60, 61, 63, 72, 80], "consol": 59, "const": [31, 51, 52, 75], "constant": [14, 17, 24, 25, 26, 33, 34, 35, 40, 44, 45, 46, 53, 55, 56, 60, 67, 68, 69, 70, 77, 78, 79, 91, 97], "constantli": 20, "constitu": [25, 45, 69], "constitut": [31, 51, 52, 75], "construct": [20, 30, 50, 74], "constructor": [17, 18, 60, 63], "consult": [16, 39, 62, 87, 93], "consum": [13, 20, 27, 28, 30, 36, 41, 59, 71, 72, 74, 80, 85], "consumpt": [20, 33, 77, 87, 93], "contact": [1, 13, 20, 59, 99], "contain": [9, 13, 14, 18, 19, 20, 21, 24, 30, 31, 32, 34, 36, 44, 50, 51, 52, 57, 58, 59, 60, 63, 64, 65, 68, 74, 75, 76, 77, 80, 83, 84, 91, 97], "container": [36, 57, 58, 80], "content": [1, 4, 5, 12, 13, 31, 32, 36, 41, 42, 51, 52, 57, 58, 64, 66, 72, 75, 76, 80, 85, 99], "contest": 7, "context": [12, 14, 16, 18, 21, 22, 23, 25, 26, 27, 28, 29, 30, 31, 32, 33, 35, 42, 43, 45, 46, 47, 50, 51, 56, 60, 63, 65, 66, 67, 69, 70, 71, 73, 74, 75, 76, 77, 79, 82, 85, 87, 93], "contextu": [12, 31, 51, 75], "contin": 64, "conting": [29, 73], "continu": [17, 19, 22, 24, 27, 31, 33, 35, 40, 44, 45, 47, 51, 52, 53, 56, 64, 66, 68, 69, 71, 75, 77, 79, 91, 97], "contract": [0, 27, 31, 34, 54, 75, 78], "contract_month": [34, 54, 78], "contract_on": [34, 54, 78], "contract_two": [34, 54, 78], "contracttyp": 27, "contradict": 59, "contrapt": 59, "contrast": [12, 59, 85], "contribut": [16, 21, 26, 32, 46, 59, 62, 65, 70, 76, 89, 95, 99], "control": [5, 6, 9, 14, 16, 19, 21, 24, 25, 32, 44, 45, 60, 61, 62, 64, 65, 68, 69, 76, 99], "convei": 12, "conveni": [9, 13, 22, 23, 28, 31, 33, 34, 35, 36, 42, 43, 46, 51, 52, 54, 56, 57, 58, 66, 67, 72, 75, 77, 78, 79, 80, 83, 96], "convent": [77, 91, 97], "converg": [25, 28, 72], "convers": [24, 26, 31, 36, 44, 46, 52, 68, 70, 75, 80, 81], "convert": [13, 17, 18, 19, 21, 25, 26, 27, 31, 33, 34, 40, 45, 46, 47, 51, 52, 59, 63, 64, 65, 69, 70, 71, 75, 77, 78, 83, 91, 97], "convinc": [19, 20, 35, 56, 64, 79], "convincingli": 59, "convolut": [27, 71], "convolutional_neural_network": [32, 48, 76], "cooccurrencematrix": [31, 51, 52, 75], "cook": [31, 51, 72, 75], "cool": [20, 32, 48, 76], "coolwarm": [21, 65], "coordin": [90, 96, 99], "copi": [0, 8, 9, 14, 18, 25, 26, 28, 30, 32, 34, 35, 40, 42, 43, 45, 46, 50, 53, 55, 56, 60, 63, 64, 66, 68, 69, 70, 72, 74, 76, 77, 78, 79, 89, 91, 95, 97, 99], "copilot": [31, 75], "copy_x": 68, "copyright": [0, 31, 51, 75, 99], "cor": [26, 70], "coral": [32, 76], "core": [10, 12, 17, 18, 19, 22, 23, 24, 27, 29, 30, 34, 36, 42, 43, 44, 47, 53, 54, 61, 63, 64, 66, 67, 68, 71, 73, 74, 77, 78, 80, 85, 93, 95, 97], "corefer": [52, 83], "corei": [36, 57, 58, 80], "corgi": [32, 59, 76], "corner": 11, "corpora": [19, 31, 51, 52, 64, 75], "corpu": [19, 31, 51, 52, 64, 75, 81, 83], "corr": [26, 46, 70], "corr_df": [26, 46, 70], "correct": [8, 13, 14, 15, 16, 23, 25, 26, 34, 35, 42, 43, 45, 46, 54, 56, 59, 60, 61, 62, 66, 67, 69, 70, 78, 79, 86, 87, 89, 92, 93, 95], "correctli": [14, 23, 43, 60, 61, 67], "correl": [33, 77, 85, 94], "correspond": [1, 13, 14, 15, 19, 21, 22, 23, 24, 26, 28, 30, 33, 39, 40, 42, 43, 46, 49, 50, 59, 60, 61, 62, 64, 65, 66, 67, 68, 70, 72, 74, 77, 87, 93], "cos_sim": [31, 51, 75], "cosin": [31, 51, 52, 75], "cosine_similar": [31, 52, 75], "cost": [9, 32, 35, 56, 59, 76, 79, 99], "cost_rep": 9, "costco": [31, 51, 52, 75], "costli": [23, 43, 67], "cot": [32, 76], "cote": [32, 76], "could": [7, 9, 14, 15, 16, 18, 19, 22, 23, 24, 25, 27, 28, 30, 31, 33, 34, 35, 36, 41, 42, 43, 44, 45, 46, 47, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 66, 67, 68, 69, 71, 72, 74, 75, 77, 78, 79, 80, 87, 91, 93, 94, 96, 97, 99], "couldn": [20, 52, 83], "count": [9, 14, 15, 17, 18, 19, 23, 24, 27, 32, 34, 36, 38, 40, 41, 43, 44, 47, 51, 52, 53, 54, 57, 58, 59, 60, 63, 64, 67, 68, 71, 75, 76, 77, 78, 80, 84, 87, 90, 91, 93, 95, 96, 97], "counter": 81, "counti": [15, 38], "countplot": [90, 96], "countri": [16, 21, 25, 26, 45, 46, 52, 61, 62, 64, 65, 67, 69, 70, 83, 99], "country_cambodia": 45, "country_canada": 45, "country_china": 45, "country_columbia": [26, 45, 46, 70], "country_cuba": 45, "country_dominican": [26, 45, 46, 70], "country_ecuador": 45, "country_el": 45, "country_england": 45, "country_fr": 45, "country_germani": 45, "country_greec": 45, "country_guatemala": [26, 45, 46, 70], "country_ha": 45, "country_holand": 45, "country_hondura": [26, 45, 46, 70], "country_hong": [26, 45, 46, 70], "country_hungari": [26, 45, 46, 70], "country_india": [26, 45, 46, 70], "country_iran": [26, 45, 46, 70], "country_ireland": 45, "country_itali": 45, "country_jamaica": 45, "country_japan": 45, "country_lao": 45, "country_mexico": 45, "country_miss": [25, 26, 45, 46, 69, 70], "country_nicaragua": 45, "country_outli": 45, "country_peru": 45, "country_philippin": 45, "country_poland": 45, "country_portug": 45, "country_puerto": [26, 45, 46, 70], "country_scotland": [26, 45, 46, 70], "country_south": [26, 45, 46, 70], "country_taiwan": [26, 45, 46, 70], "country_thailand": [26, 45, 46, 70], "country_trinadad": [25, 26, 45, 46, 69, 70], "country_unit": [25, 26, 45, 46, 69, 70], "country_vietnam": [25, 26, 45, 46, 69, 70], "country_yugoslavia": [25, 26, 45, 46, 69, 70], "countvector": [13, 17, 20, 21, 22, 31, 36, 40, 41, 42, 51, 52, 57, 58, 59, 65, 66, 75, 80, 81, 85], "countvectorizercountvector": [17, 19, 20, 22], "countvectorizersong_titl": 22, "coupl": [4, 5, 22, 29, 60, 66, 73, 90, 91, 96, 97], "cour": [31, 51, 52, 75], "cours": [2, 4, 6, 7, 8, 14, 15, 17, 19, 21, 23, 24, 25, 26, 27, 28, 30, 31, 32, 33, 34, 38, 39, 40, 43, 44, 45, 46, 47, 48, 49, 51, 52, 53, 54, 60, 61, 64, 65, 67, 68, 69, 70, 71, 72, 74, 75, 76, 77, 78, 81, 85, 92], "coursera": [1, 10], "coursework": 99, "court": [31, 51, 52, 75], "covari": [14, 34, 54, 60, 78], "cover": [5, 9, 12, 13, 28, 33, 51, 53, 59, 67, 69, 72, 75, 77, 99], "coverag": [23, 43, 67], "cow": [35, 56, 79], "cox": 12, "coxph_fitt": [54, 78], "coxphfitt": [34, 54, 78], "cph": [34, 54, 56, 78, 79, 85], "cph_param": [34, 54, 78], "cpp": 32, "cpsc": [10, 14, 25, 27, 31, 32, 33, 35, 36, 37, 45, 51, 52, 53, 56, 59, 60, 69, 75, 76, 77, 79, 80, 82, 99], "cpsc330": [0, 1, 11, 13, 14, 16, 18, 19, 25, 26, 28, 31, 32, 34, 36, 39, 46, 51, 52, 54, 59, 60, 61, 64, 70, 75, 76, 78, 80, 84, 99], "cpsc330env": 11, "cpu": [22, 31, 32, 39, 42, 48, 49, 66, 76], "cpu_info": [16, 25, 26, 28], "craft": [16, 25, 26, 28, 45, 46, 62, 67, 69, 70, 72, 87, 93], "cramp": 41, "crap": 20, "crash": [1, 23, 43], "crate": [32, 76], "crazi": [17, 36, 40, 80], "creat": [6, 9, 10, 13, 15, 16, 17, 18, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 31, 32, 33, 34, 35, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 51, 52, 53, 54, 55, 56, 59, 62, 63, 65, 66, 67, 68, 69, 70, 71, 72, 73, 75, 76, 77, 78, 79, 81, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98], "create_lag_df": [33, 77], "create_lag_featur": [53, 77, 91, 97], "create_y_from_r": [30, 50, 74], "createprocess": [16, 25, 26, 28], "creativ": [1, 13, 14, 20, 31, 51, 52, 59, 75], "creatur": 59, "credenc": [35, 56, 79], "credenti": 6, "credit": [0, 14, 23, 31, 33, 34, 35, 43, 45, 51, 52, 54, 56, 59, 60, 67, 69, 75, 77, 78, 79], "creditcard": [23, 43, 67, 81], "creepi": 20, "crime": [21, 59, 65], "crimin": [26, 46, 70], "crispedricewaf": 96, "criteria": [14, 29, 60, 73], "criterion": [29, 35, 38, 45, 49, 56, 69, 73, 79, 95], "critic": [12, 35, 55, 56, 79], "cross": [14, 19, 22, 24, 25, 26, 28, 30, 34, 35, 36, 40, 42, 44, 45, 50, 56, 60, 62, 64, 66, 68, 69, 70, 72, 74, 78, 79, 80, 81, 85, 88, 89, 91, 94, 95, 97, 99], "cross_val": [25, 45, 69], "cross_val_predict": [23, 25, 34, 43, 45, 54, 67, 69, 78], "cross_val_scor": [15, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 33, 34, 35, 40, 41, 42, 43, 44, 45, 46, 47, 53, 54, 55, 56, 63, 64, 65, 66, 67, 68, 69, 70, 71, 77, 78, 79, 81, 82, 84, 85, 88, 89, 91, 94, 95, 97], "cross_valid": [16, 17, 18, 19, 20, 21, 22, 23, 25, 26, 27, 30, 33, 34, 35, 36, 38, 39, 40, 41, 42, 43, 45, 46, 47, 50, 53, 54, 55, 56, 57, 58, 62, 63, 64, 65, 66, 67, 69, 70, 71, 74, 77, 78, 79, 80, 81, 82, 84, 85, 87, 88, 89, 91, 93, 94, 95, 97], "cross_validate_std": 61, "crowd": [5, 25, 29, 69, 73], "crown": 99, "crown_princ": [31, 51, 52, 75], "crucial": [13, 21, 26, 28, 29, 30, 31, 46, 51, 52, 59, 61, 65, 70, 72, 73, 74, 75], "crude": [52, 83], "cs189": 10, "cs189_ch7": 10, "cs324": [31, 51, 75], "csc": 34, "csr": [18, 34], "css": [36, 57, 58, 80], "csv": [13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 30, 31, 32, 33, 34, 35, 36, 38, 40, 41, 42, 43, 44, 45, 46, 47, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 74, 75, 76, 77, 78, 79, 80, 81, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97], "ct": [19, 64, 90, 96], "ctrl": 11, "cuda": [32, 39, 48, 49, 76], "cui": [1, 99], "cuisin": [36, 80], "cultiv": 12, "cultur": [32, 76, 99], "cup": 25, "curios": [13, 59], "curiou": [13, 17, 59, 87, 93], "curl": [36, 57, 58, 80], "current": [1, 5, 25, 31, 32, 33, 34, 35, 36, 45, 51, 52, 53, 56, 69, 75, 76, 77, 78, 79, 80, 83], "curriculum": 12, "curs": [35, 56, 79], "curt": 59, "curv": [8, 9, 12, 21, 28, 56, 72, 79, 85, 87, 93], "cush": 20, "custodi": 59, "custom": [9, 13, 14, 17, 19, 23, 24, 27, 30, 31, 36, 40, 43, 44, 57, 58, 59, 60, 64, 67, 68, 74, 75, 80, 85, 86, 92], "custom_plot_tre": [14, 25, 26, 45, 46, 60, 61, 69, 70, 86, 92], "customerid": [27, 34, 54, 78], "cut": [20, 29, 59, 73], "cv": [15, 19, 24, 25, 26, 27, 33, 34, 35, 36, 39, 42, 44, 45, 46, 47, 53, 56, 61, 64, 68, 69, 70, 71, 77, 78, 79, 80, 81, 82, 85, 87, 93, 94, 95, 97], "cv_results_": [22, 24, 42, 44, 66, 68], "cv_score": [15, 24, 39, 44, 61, 68], "cv_train_scor": [15, 38, 87, 93], "cv_valid_scor": [15, 38, 87, 93], "cyberpunk": 20, "cycl": 9, "cyclic": [33, 77], "cycling_data": 9, "cygnu": [32, 76], "cynic": 41, "c\u00e9zann": 25, "d": [4, 9, 13, 14, 15, 16, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 32, 33, 34, 36, 42, 43, 44, 45, 50, 52, 53, 54, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 72, 73, 74, 76, 77, 78, 80, 83, 89, 95], "d3": [28, 72], "da": 59, "dabeaz": 10, "dad": [27, 82], "dahl": 20, "dai": [1, 4, 9, 17, 27, 32, 34, 35, 40, 47, 53, 56, 59, 71, 76, 78, 79, 85, 87, 91, 93, 97, 99], "daili": [34, 78, 85], "dair": [31, 51, 75], "dall": [33, 77], "dam": 59, "damag": [0, 67], "dan": [31, 51, 52, 75], "dana": 59, "danceabl": [18, 22, 42, 62, 63, 66], "dare": 59, "dark": 59, "darker": [22, 42, 66], "dartmoor": 97, "darwin": 97, "dashboard": [16, 39, 62, 87, 93], "data": [1, 2, 5, 6, 8, 9, 10, 12, 20, 23, 27, 29, 31, 32, 34, 39, 41, 42, 43, 47, 48, 49, 50, 51, 52, 57, 58, 67, 73, 75, 76, 78, 82, 83, 84, 85, 86, 88, 89, 90, 92, 94, 95, 96, 98, 99], "data_dict": [21, 65], "data_dir": [13, 14, 15, 16, 17, 18, 19, 21, 22, 23, 24, 25, 26, 27, 30, 31, 32, 33, 34, 35, 36, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 74, 75, 76, 77, 78, 79, 80, 81, 82, 85, 86, 87, 89, 91, 92, 93, 95, 97], "data_to_wrap": [19, 34, 64], "data_transform": [39, 48, 49], "data_url": [23, 43, 67, 81], "datacamp": 10, "datafram": [13, 14, 15, 16, 17, 18, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 49, 50, 51, 52, 53, 54, 55, 56, 59, 60, 61, 62, 63, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 81, 82, 85, 87, 88, 89, 90, 91, 93, 94, 95, 96, 97], "dataload": [32, 39, 48, 49, 76], "datapoint": [21, 65], "dataquest": 10, "dataset": [9, 12, 13, 15, 16, 19, 25, 26, 27, 28, 29, 31, 34, 36, 38, 39, 40, 42, 45, 46, 47, 48, 49, 51, 54, 57, 58, 59, 61, 62, 69, 70, 71, 72, 73, 75, 78, 80, 81, 84, 85, 87, 93], "dataset2": [28, 72], "dataset_s": [32, 39, 48, 49, 76], "dataviz": [35, 55, 56, 79], "date": [8, 11, 13, 15, 30, 31, 34, 36, 38, 51, 52, 59, 60, 74, 75, 78, 80, 83, 85, 91, 97, 99], "date_rang": [33, 77], "dates_rain": [53, 77, 91, 97], "datetim": [33, 54, 78], "datetime64": [33, 53, 77, 97], "datetimeindex": [33, 77], "datum": 52, "dau": 59, "daughter": [20, 36, 57, 58, 80, 81], "daum\u00e9": 1, "daunt": [30, 74], "dave": [31, 52, 75], "david": [1, 31, 35, 51, 52, 56, 59, 75, 79, 90, 96], "dawn": 20, "day_nam": [33, 53, 77, 91, 97], "daylight": [53, 77, 91, 97], "dayofweek": [33, 77], "days_sinc": [33, 53, 77, 97], "dbscan": [12, 36, 80], "dbscan_label": 49, "dc": [34, 53, 77, 78, 97], "dcc": [21, 65], "dd": [53, 77, 91, 97], "de": [31, 33, 51, 52, 75, 77], "deactiv": 11, "dead": 20, "deadlin": [8, 99], "deal": [0, 15, 16, 17, 18, 23, 24, 34, 40, 51, 52, 54, 56, 59, 61, 62, 63, 68, 75, 78, 79, 85, 88, 94], "dealer": 59, "dear": 59, "death": 99, "debat": [9, 13, 26, 46, 70], "debug": [4, 26, 46, 70, 99], "dec": 1, "decad": [32, 59, 76], "decemb": [1, 15, 33, 38, 53, 77, 97], "decid": [9, 13, 14, 16, 21, 25, 26, 27, 28, 29, 31, 33, 34, 45, 46, 47, 51, 52, 59, 60, 62, 65, 69, 70, 71, 72, 73, 75, 77, 78, 83, 85], "decim": 95, "decis": [1, 2, 7, 13, 18, 20, 22, 25, 27, 31, 32, 35, 40, 41, 43, 45, 51, 59, 61, 63, 66, 67, 69, 71, 75, 76, 81, 82, 84, 85, 86, 88, 89, 92, 94, 95], "decision_boundari": 84, "decision_funct": [23, 43, 67], "decision_function_shap": [42, 43, 64, 66], "decisiontreeclassifi": [15, 16, 18, 19, 21, 22, 26, 39, 40, 42, 46, 61, 62, 63, 64, 65, 66, 70, 86, 87, 88, 89, 92, 93, 94, 95], "decisiontreeclassifierdecisiontreeclassifi": 25, "decisiontreeregressor": [14, 15, 24, 38, 44, 60, 68, 86, 87, 92, 93], "decisiontreeregressorifit": 38, "decisiontreeregressorifitteddecisiontreeregressor": 15, "deck": 10, "decod": [31, 51, 75], "decode_error": [41, 42, 64, 66], "decomposit": [29, 30, 31, 34, 50, 51, 52, 73, 74, 75], "decor": 18, "decreas": [15, 21, 22, 25, 26, 28, 38, 45, 46, 61, 65, 66, 69, 70, 72, 87, 93], "deduct": 8, "dee_learning_cod": [32, 76], "deem": 7, "deep": [2, 10, 13, 22, 26, 27, 31, 34, 36, 46, 47, 51, 52, 54, 59, 66, 70, 71, 75, 78, 80], "deep_learning_cod": [32, 76], "deepen": [31, 51, 75, 85, 99], "deeper": [2, 13, 22, 23, 24, 26, 42, 43, 44, 46, 66, 67, 68, 70], "deepexplain": [26, 46, 70], "deepmind": [31, 75], "def": [16, 18, 20, 22, 23, 24, 26, 28, 29, 30, 31, 33, 34, 36, 39, 41, 42, 43, 44, 46, 48, 49, 50, 51, 52, 53, 57, 58, 61, 62, 63, 66, 67, 68, 70, 72, 73, 74, 75, 77, 80, 86, 87, 91, 92, 93, 97], "default": [6, 8, 11, 13, 14, 15, 19, 21, 22, 23, 24, 25, 28, 29, 31, 33, 34, 35, 39, 43, 44, 45, 51, 54, 56, 60, 61, 64, 65, 66, 67, 68, 69, 72, 73, 75, 77, 78, 79, 84, 91, 95, 97, 99], "default_threshold": [23, 43, 67], "defaultdict": [30, 50, 74], "defend": 59, "defin": [13, 16, 17, 18, 19, 25, 26, 28, 29, 30, 31, 32, 36, 40, 41, 45, 46, 47, 48, 50, 51, 53, 57, 58, 59, 60, 61, 62, 63, 64, 67, 69, 70, 72, 73, 74, 75, 76, 77, 80, 91, 97], "definit": [9, 16, 26, 28, 46, 52, 53, 62, 70, 72, 77, 83, 84, 85, 86, 92], "degrad": 31, "degre": [23, 42, 43, 64, 66, 67], "degrees_freedom": [34, 78], "degrees_of_freedom": [34, 78], "del": [25, 45, 69], "delai": 71, "delayed_func": 34, "deleg": [52, 83], "delet": [4, 8, 18, 35, 56, 63, 79], "delgado": [25, 45, 69], "delight": [31, 51, 52, 75], "deliver": 8, "deliveri": 59, "delud": 59, "delv": [12, 31, 51, 52, 75], "demco": 1, "demo": [1, 5, 13, 25, 35, 45, 69, 79], "demograph": [14, 30, 50, 60, 74], "demonstr": [14, 17, 18, 20, 21, 22, 24, 25, 28, 30, 31, 39, 40, 41, 44, 45, 50, 51, 52, 59, 60, 61, 63, 65, 66, 68, 69, 71, 72, 74, 75, 81], "dendrogram": 49, "denholm": 20, "denomin": [24, 44, 68], "denot": [14, 30, 60, 74], "dens": [17, 29, 31, 51, 52, 73, 75], "densenet": [32, 39, 48, 49, 76], "densenet121": [32, 39, 48, 49, 76], "densenet121_weight": [32, 39, 48, 49, 76], "densiti": [26, 29, 46, 70, 73, 85], "dep": [52, 83], "depart": [5, 59], "departur": 71, "depend": [2, 6, 9, 14, 16, 19, 22, 24, 25, 26, 27, 28, 29, 31, 32, 33, 34, 35, 44, 45, 46, 47, 51, 52, 54, 56, 60, 61, 62, 64, 66, 68, 69, 70, 72, 73, 75, 76, 77, 78, 79, 81, 82, 83, 89, 95], "dependence_plot": [26, 46, 70], "dependents_no": [34, 54, 78], "dependents_y": [34, 54, 78], "deploi": [15, 23, 30, 35, 38, 43, 50, 56, 61, 67, 74, 79, 85], "deploy": [1, 12, 26, 33, 46, 53, 70, 77], "deprec": [23, 24, 40, 41, 42, 43, 44, 45, 46, 51, 54, 63, 64, 66, 68, 69, 70, 75, 76, 78, 81, 84, 95], "deprecationwarn": [25, 45, 54, 69, 78], "depress": 59, "depth": [1, 14, 15, 22, 25, 29, 38, 45, 59, 60, 61, 66, 69, 73, 86, 87, 92, 93], "dequ": [25, 26, 45, 46, 69, 70, 89, 95], "deriv": [0, 14, 21, 30, 34, 60, 65, 67, 74, 78, 85], "descend": [9, 20, 29, 41, 73, 85], "descent": [33, 77], "descr": [21, 65], "describ": [9, 12, 13, 14, 15, 16, 17, 18, 21, 23, 24, 30, 31, 32, 36, 38, 40, 43, 44, 50, 51, 52, 53, 59, 60, 61, 62, 63, 65, 67, 68, 74, 75, 76, 77, 80, 87, 88, 90, 91, 93, 96, 97], "descript": [1, 24, 28, 34, 44, 54, 68, 78, 87, 93], "desenet": 39, "deserv": 7, "design": [12, 14, 26, 29, 31, 35, 46, 51, 55, 56, 59, 60, 70, 73, 75, 79, 99], "desir": [17, 23, 34, 40, 43, 52, 67, 78, 88, 94], "desk": 99, "despit": [27, 31, 47, 51, 52, 59, 71, 75], "destroi": [20, 46], "det": [20, 31, 51, 52, 75, 83], "detach": [39, 48, 49], "detail": [5, 7, 16, 19, 23, 25, 31, 32, 36, 38, 45, 51, 52, 57, 58, 59, 62, 64, 69, 75, 76, 80, 99], "detect": [13, 14, 20, 23, 24, 28, 29, 31, 33, 36, 38, 43, 53, 59, 60, 67, 68, 72, 73, 75, 77, 80, 81], "detector": [32, 76], "determin": [14, 16, 28, 29, 31, 34, 35, 39, 51, 52, 56, 62, 72, 73, 75, 78, 79, 87, 89, 90, 93, 95, 96, 99], "determinist": [13, 59], "detriment": [30, 67, 74], "dev": [61, 84], "develop": [1, 5, 6, 10, 12, 13, 15, 18, 19, 20, 22, 23, 24, 25, 26, 31, 32, 36, 43, 44, 45, 51, 52, 56, 57, 58, 59, 61, 63, 64, 66, 67, 68, 69, 75, 76, 79, 80, 85], "devianc": [34, 78], "deviat": [7, 15, 18, 25, 26, 41, 45, 46, 61, 63, 69, 70], "devic": [25, 31, 32, 34, 39, 45, 48, 49, 51, 69, 75, 76], "deviceprotect": [34, 54, 78], "deviceprotection_no": [34, 54, 78], "deviceprotection_y": [34, 54, 78], "df": [13, 17, 18, 19, 22, 23, 24, 26, 27, 32, 33, 34, 35, 36, 38, 40, 43, 44, 46, 47, 53, 54, 55, 56, 57, 58, 59, 60, 61, 63, 64, 66, 67, 68, 70, 71, 76, 77, 78, 79, 80, 81, 86, 91, 92, 95, 97], "df_binari": [90, 96], "df_concat": [13, 59], "df_float_1": 9, "df_float_2": 9, "df_hour_week_ohe_poli": [33, 77], "df_locat": 53, "df_sim": [31, 51, 75], "df_transform": 40, "di": [34, 54, 59, 78], "diagnos": [26, 46, 61, 70, 85], "diagnosi": 67, "diagnost": [34, 36, 54, 78, 80], "diagon": [16, 23, 26, 43, 46, 62, 67, 70], "diagram": [19, 22, 25, 26, 42, 45, 64, 66, 69, 70], "dialogu": [20, 41, 52, 59], "dict": [30, 50, 67, 74, 95], "dict_kei": [25, 45, 69], "dictat": 59, "dictatorship": 59, "dictionari": [9, 18, 22, 23, 25, 26, 36, 42, 43, 45, 46, 57, 58, 63, 66, 67, 69, 70, 80], "did": [7, 13, 14, 16, 17, 20, 23, 26, 28, 31, 33, 43, 46, 51, 52, 53, 59, 60, 62, 70, 72, 75, 77, 83, 87, 89, 93, 95], "didn": [17, 22, 25, 26, 29, 34, 39, 40, 42, 45, 46, 52, 53, 54, 66, 69, 70, 73, 77, 78, 83], "diet": [14, 31, 51, 52, 60, 75], "diff": [53, 77, 91, 97], "differ": [1, 2, 6, 8, 9, 12, 13, 14, 15, 16, 17, 19, 20, 21, 25, 27, 28, 29, 30, 31, 32, 33, 34, 35, 38, 40, 45, 47, 48, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 64, 65, 67, 69, 71, 72, 73, 74, 75, 76, 77, 78, 79, 81, 83, 84, 86, 87, 89, 90, 91, 92, 93, 95, 96, 97], "differenti": [12, 13, 14, 31, 59, 75], "difficult": [7, 8, 26, 27, 28, 35, 55, 56, 59, 67, 71, 72, 79], "difficulti": [26, 28, 72, 85], "diffid": 59, "dig": [23, 24, 43, 44, 67, 68], "dighton": 59, "digit": [33, 35, 56, 77, 79], "dilemma": [30, 50, 74], "dilut": 59, "dim": [18, 39], "dime": 96, "dimens": [9, 21, 27, 47, 65, 71], "dimension": [2, 9, 14, 21, 22, 23, 25, 27, 28, 31, 39, 42, 43, 45, 47, 51, 52, 59, 65, 66, 67, 69, 71, 72, 75], "dine": [36, 80], "direct": [18, 20, 21, 26, 27, 29, 41, 46, 52, 59, 65, 70, 73, 77, 82], "direct_bilirubin": 59, "directli": [1, 9, 17, 19, 24, 32, 34, 36, 40, 44, 57, 58, 64, 68, 76, 78, 80, 99], "director": [30, 50, 59, 74], "directori": [18, 39, 59, 60, 61, 63], "dirichlet": [31, 32, 51, 52, 75, 76], "dirti": [17, 59], "disabl": [31, 51, 52, 75], "disadvantag": [22, 25, 29, 30, 45, 50, 66, 69, 73, 74, 88, 94], "disagre": 30, "disappoint": [20, 59], "disast": 59, "discard": [27, 31, 47, 51, 52, 71, 75], "disciplin": [27, 47, 67, 71], "disclos": 99, "discomfort": [20, 41], "discourag": 9, "discours": [30, 74], "discov": [27, 28, 47, 59, 71, 72, 82], "discoveri": [13, 59], "discret": [14, 17, 27, 40, 47, 60, 71], "discrete_scatt": [14, 16, 21, 28, 29, 32, 39, 60, 61, 62, 65, 72, 73, 76, 84, 86, 87, 92, 93], "discretization_feat": [27, 47, 71], "discrimin": [45, 69], "discuss": [4, 16, 18, 21, 23, 26, 27, 28, 29, 33, 38, 43, 46, 50, 51, 53, 61, 62, 63, 65, 70, 71, 72, 73, 77, 85, 87, 88, 89, 90, 91, 93, 94, 95, 96, 97, 99], "diseas": [14, 23, 34, 43, 60, 67, 78], "dishonesti": 99, "disk": 31, "dislik": [17, 35, 40, 56, 79], "dismiss": 59, "disp": [54, 78], "disparti": [31, 51, 75], "displac": 41, "displaci": [52, 83], "displai": [8, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 25, 26, 29, 30, 31, 32, 33, 34, 38, 39, 40, 41, 42, 43, 45, 46, 50, 51, 53, 59, 60, 61, 62, 63, 64, 65, 66, 67, 69, 70, 73, 74, 75, 76, 77, 81, 82, 86, 87, 88, 90, 91, 92, 93, 94, 96, 97], "display_heatmap": [22, 42, 66], "display_label": [23, 43, 67], "displaystyl": [31, 51, 52, 75], "disput": 52, "disrespect": 4, "dissemin": [36, 80], "dist": [16, 28, 29, 39, 49, 62, 72, 73], "dist_nam": [42, 66], "distanc": [9, 18, 29, 30, 31, 39, 40, 48, 49, 50, 51, 52, 63, 71, 73, 74, 75], "distilbert": [31, 51, 75], "distinct": [23, 27, 33, 35, 43, 48, 49, 56, 67, 77, 79, 82, 96], "distinguish": [14, 16, 19, 23, 31, 39, 43, 60, 61, 62, 64, 67, 75, 87, 93], "distort": 40, "distract": 99, "distribut": [0, 11, 15, 17, 23, 26, 27, 29, 32, 38, 40, 43, 46, 47, 52, 53, 61, 67, 70, 71, 73, 76, 77, 91, 97, 99], "district": [18, 21, 63, 65], "districtdatalab": [28, 72], "dists_df": 49, "disturb": 59, "dive": [13, 26, 46, 59, 70], "divers": [5, 12, 25, 28, 30, 33, 45, 50, 69, 72, 74, 77], "divid": [21, 25, 26, 33, 45, 46, 65, 69, 70, 77, 81, 87, 93], "divis": [14, 26, 46, 70], "divorc": [25, 26, 45, 46, 69, 70], "dkhundlei": [90, 96], "dktal": [34, 54, 78], "dload": 36, "dlwqn": [34, 54, 78], "dmp": [1, 99], "do": [0, 4, 6, 8, 9, 11, 13, 14, 15, 16, 19, 20, 21, 24, 28, 29, 30, 31, 32, 33, 34, 36, 38, 39, 42, 44, 48, 50, 51, 52, 53, 54, 57, 58, 59, 60, 61, 62, 65, 68, 72, 73, 74, 75, 76, 77, 78, 80, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 99], "dobj": [52, 83], "doc": [9, 10, 16, 20, 22, 31, 36, 41, 51, 52, 57, 58, 75, 80, 83], "doc_id": [31, 51, 52, 75], "docker": [36, 57, 58, 80], "doctor": [25, 26, 45, 46, 67, 69, 70, 99], "document": [0, 1, 8, 13, 15, 17, 18, 19, 20, 22, 23, 24, 25, 26, 27, 31, 32, 33, 34, 35, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 51, 52, 54, 55, 56, 60, 61, 63, 64, 66, 67, 68, 69, 70, 71, 75, 76, 77, 78, 79, 83, 85, 89, 95, 99], "document_top": [31, 51, 52, 75], "documentari": [30, 50, 74], "doe": [6, 9, 13, 16, 17, 18, 20, 22, 24, 25, 26, 27, 28, 30, 31, 33, 34, 36, 40, 42, 44, 46, 47, 50, 52, 53, 54, 57, 58, 59, 61, 62, 63, 66, 68, 69, 70, 71, 72, 74, 77, 78, 80, 82, 83, 85, 87, 89, 91, 93, 95, 97, 99], "doesn": [8, 9, 15, 18, 19, 23, 24, 25, 26, 28, 29, 30, 32, 34, 35, 43, 44, 45, 46, 48, 50, 52, 54, 56, 59, 61, 63, 64, 67, 68, 69, 70, 72, 73, 74, 76, 78, 79, 83, 85], "dog": [32, 39, 67, 76], "dolist": [36, 80], "dollar": [4, 21, 24, 35, 44, 55, 56, 65, 68, 79], "domain": [0, 26, 28, 31, 46, 47, 52, 70, 72, 75], "domin": [18, 20, 24, 32, 44, 63, 68, 76], "domingo": [1, 27, 61, 71], "dominican_republ": [31, 51, 52, 75], "domino": 59, "don": [4, 5, 11, 13, 15, 17, 19, 20, 22, 25, 26, 27, 29, 30, 31, 32, 33, 34, 35, 36, 38, 39, 40, 42, 45, 46, 47, 50, 51, 52, 54, 56, 57, 58, 59, 61, 64, 66, 67, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 99], "done": [13, 15, 19, 20, 22, 32, 35, 42, 53, 55, 56, 59, 61, 64, 66, 67, 76, 77, 79, 88, 94], "dont": [31, 51, 75], "doom": [20, 59], "door": [32, 59, 76], "dosa": 52, "dot": [16, 21, 23, 26, 27, 29, 31, 43, 45, 46, 47, 52, 62, 65, 67, 69, 70, 71, 73, 75], "dot_product": 52, "dot_product_similar": [31, 75], "doubl": [20, 22, 66], "down": [15, 17, 23, 26, 34, 35, 40, 43, 46, 52, 54, 56, 59, 61, 67, 70, 78, 79, 83, 87, 89, 93, 95, 99], "downfal": [30, 50, 74], "download": [6, 8, 11, 13, 15, 18, 21, 23, 24, 26, 31, 32, 35, 38, 43, 44, 46, 51, 52, 55, 56, 59, 60, 63, 65, 67, 68, 70, 75, 76, 79, 83, 87, 89, 90, 93, 95, 96], "downright": [35, 55, 56, 79], "downturn": 59, "dpi": [27, 39, 47, 71, 98], "dr": [5, 52, 83], "draft": 1, "drag": [8, 59], "drama": [30, 50, 59, 74], "dramat": 41, "drastic": 67, "draw": [21, 22, 35, 42, 52, 56, 65, 66, 79], "drawback": [12, 26, 30, 46, 70, 74], "drawn": [25, 45, 69], "dream": [32, 76], "dreampharmaceut": [31, 51, 52, 75], "drink": [35, 55, 56, 79], "drinker": [31, 52, 75], "drive": [13, 20, 26, 41, 46, 59, 70], "driven": [22, 23, 43, 66, 67], "driver": [13, 59], "droit": [31, 51, 52, 75], "drop": [8, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 33, 34, 35, 38, 40, 42, 43, 44, 45, 46, 53, 54, 55, 56, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 77, 78, 79, 81, 85, 87, 88, 89, 90, 91, 93, 94, 95, 96, 97, 99], "drop_dupl": [16, 22, 42, 62, 66], "drop_feat": [17, 19, 40, 64, 85], "drop_featur": [24, 25, 26, 34, 35, 44, 45, 46, 53, 54, 55, 56, 67, 68, 69, 70, 77, 78, 79, 91, 97], "dropdown": 11, "dropdrop": [17, 19, 24, 25, 35, 40, 44, 45, 55, 56, 64, 69, 79], "dropdropdecisiontreeclassifi": [45, 69], "dropdroplgbmclassifi": [45, 69], "dropdroplogisticregress": [45, 69], "dropdroppipelin": [46, 68, 70], "dropdroprandomforestclassifi": [45, 69], "dropdropsvc": 64, "dropdropxgbclassifi": [45, 69], "drope": [18, 63], "dropna": [36, 53, 57, 58, 77, 80, 81, 91, 97], "dropoff": [28, 72], "drought": 41, "drug": [13, 36, 59, 80], "dsci": [1, 10, 26, 35, 56, 79, 84], "dsl": [34, 54, 78], "dt": [15, 38, 87, 93, 95], "dt_best": [87, 93], "dt_final": [15, 38], "dt_pipe": [22, 66], "dt_regr": [15, 38], "dt_score": 95, "dtype": [14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 29, 30, 31, 33, 34, 36, 38, 40, 41, 42, 43, 44, 45, 46, 47, 51, 52, 53, 54, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 77, 78, 80, 81, 83, 89, 92, 93, 95, 97], "dtypelik": 34, "dual": [41, 43, 45, 67, 69, 76, 95], "duck": [32, 35, 55, 56, 76, 79], "duckbil": [32, 76], "dud": 59, "due": [8, 11, 13, 20, 25, 27, 30, 31, 45, 50, 51, 69, 74, 75, 82, 93, 99], "duffel": 20, "dull": [20, 59], "dumb": 59, "dummi": [14, 15, 16, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 32, 33, 34, 35, 38, 41, 42, 43, 44, 45, 46, 47, 53, 54, 55, 56, 60, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 77, 78, 79, 81, 82, 86, 88, 89, 91, 92, 93, 94, 95, 97], "dummy_clf": [14, 60, 86, 92], "dummy_regr": [15, 38, 93], "dummy_scor": [16, 62], "dummy_valid_accuraci": [16, 62], "dummyclassifi": [15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 26, 27, 32, 33, 35, 36, 39, 40, 41, 42, 43, 46, 47, 54, 55, 56, 61, 62, 63, 64, 65, 66, 67, 68, 70, 71, 79, 80, 81, 82, 86, 87, 88, 89, 91, 92, 93, 94, 95, 97], "dummyregressor": [15, 19, 25, 26, 27, 35, 36, 38, 45, 46, 47, 55, 56, 64, 69, 70, 71, 79, 80, 88, 89, 93, 94, 95], "dump": [36, 57, 58, 80], "dun": 59, "dung": 59, "dunham": 20, "dunno": 59, "duplex": [24, 44, 68], "duplic": [9, 31], "durat": [33, 34, 54, 71, 77, 78], "duration_col": [34, 54, 78], "duration_m": [18, 22, 42, 62, 63, 66], "dure": [1, 5, 7, 9, 13, 14, 15, 16, 19, 21, 22, 25, 26, 30, 36, 38, 45, 46, 50, 52, 59, 60, 62, 64, 65, 66, 69, 70, 71, 74, 80, 83, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 99], "durn": 59, "duti": 99, "dwell": [24, 44, 68], "dynam": [51, 75], "d\u00e3": 20, "e": [5, 7, 8, 9, 11, 12, 13, 14, 15, 16, 18, 19, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 46, 47, 50, 51, 52, 53, 54, 55, 56, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 83, 84, 85, 91, 94, 97, 99], "e737c5242822": [34, 54, 78], "e_": [15, 61], "each": [7, 8, 9, 13, 14, 15, 16, 17, 18, 19, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 38, 39, 40, 42, 43, 44, 45, 46, 47, 48, 50, 51, 52, 53, 54, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 83, 84, 85, 86, 87, 89, 90, 91, 92, 93, 95, 96, 97, 99], "eager": [31, 36, 51, 75, 80], "earl": 59, "earli": [5, 26, 31, 34, 35, 51, 54, 56, 70, 75, 78, 79], "earlier": [17, 18, 25, 27, 31, 33, 34, 45, 47, 51, 53, 54, 59, 63, 69, 71, 75, 77, 78], "early_stopping_round": [25, 45, 69], "earnest": [59, 99], "easi": [8, 16, 18, 21, 25, 26, 28, 29, 31, 35, 45, 46, 47, 51, 52, 56, 62, 63, 65, 69, 70, 71, 72, 73, 75, 79], "easier": [8, 23, 26, 27, 30, 35, 43, 46, 47, 48, 50, 56, 67, 70, 71, 74, 79, 81], "easiest": [26, 34, 46, 54, 70, 78], "easili": [13, 20, 25, 27, 35, 36, 45, 53, 56, 57, 58, 59, 69, 71, 77, 79, 80, 86, 91, 92, 97], "east": [17, 40, 59], "eat": 59, "eat_out_freq": [17, 40], "eccentr": 59, "echidna": [32, 76], "econom": [19, 33, 64, 77], "ecosystem": [32, 76], "eda": [17, 31, 34, 38, 40, 51, 52, 61, 75, 78, 85, 91, 97], "edamam": [32, 76], "edg": [14, 22, 59, 60, 66], "edgecolor": [22, 42, 53, 66, 77, 91, 97], "edi": 41, "edinburgh": 59, "edit": [5, 16, 31, 51, 52, 66, 75], "edmund": 59, "edu": 10, "educ": [25, 26, 30, 31, 45, 46, 50, 51, 67, 69, 70, 74, 75], "education_level": [25, 26, 45, 46, 67, 69, 70], "edvard": 25, "edward": 59, "eeri": 59, "effect": [15, 16, 20, 21, 22, 24, 26, 27, 28, 29, 30, 31, 32, 33, 36, 38, 39, 46, 47, 51, 52, 62, 65, 66, 67, 68, 70, 71, 72, 73, 74, 75, 76, 77, 80, 81, 85, 87, 93, 99], "effici": [22, 31, 42, 66], "effort": [4, 22, 27, 28, 30, 32, 47, 66, 71, 72, 74, 76, 99], "egg": [28, 72], "ei": 59, "either": [4, 14, 16, 19, 23, 26, 28, 29, 31, 32, 33, 39, 43, 46, 52, 59, 60, 61, 62, 64, 67, 70, 72, 73, 76, 77, 87, 93], "elast": [34, 54, 78], "elbow": [29, 73, 90, 96], "elect": [31, 51, 52, 75], "electr": [24, 26, 35, 44, 46, 55, 56, 68, 70, 79], "electrical_engin": [31, 51, 52, 75], "electrical_fusea": [24, 35, 68, 70], "electrical_fusef": [24, 35, 68, 70], "electrical_fusep": [24, 35, 68, 70], "electrical_miss": [24, 35, 68, 70, 79], "electrical_mix": [24, 35, 68, 70, 79], "electrical_sbrkr": [24, 35, 68, 70, 79], "electron": [34, 54, 78, 99], "eleg": [18, 31, 35, 51, 52, 56, 63, 75, 79], "elegantli": [51, 52, 75], "element": [0, 1, 10, 17, 19, 20, 31, 40, 41, 51, 52, 61, 64, 75, 83, 86, 92], "eleph": 59, "eli5": [46, 70], "elif": [14, 34, 53, 60, 77, 78, 97], "elimin": 12, "elizabeth": 59, "elliott": 20, "els": [14, 18, 19, 23, 32, 34, 39, 43, 48, 49, 53, 60, 64, 67, 76, 77, 78, 85, 91, 97], "elw": 20, "email": [1, 13, 15, 23, 43, 59, 61, 67, 99], "emb": [8, 16, 23, 28, 29, 43, 62, 67, 72, 73], "embed": [1, 12, 19, 32, 36, 64, 76, 80, 85], "emma": 20, "emoji": 41, "emot": [13, 20, 31, 51, 59, 75], "emoticon": [27, 28, 47, 71, 72], "emp": [26, 45, 70], "empathi": [31, 51, 52, 75], "emphas": [5, 12], "emphasi": [36, 80, 99], "emploi": [33, 34, 36, 39, 77, 78, 80, 85], "employ": [30, 50, 74], "employe": [14, 60], "empti": [21, 39, 52, 53, 65, 77, 91, 97], "en": [31, 34, 35, 53, 54, 56, 77, 78, 79, 97], "en_core_web_lr": 52, "en_core_web_md": [31, 51, 52, 75, 83], "enabl": [30, 31, 33, 39, 51, 52, 74, 75, 77], "enable_categor": [25, 45, 69], "enable_halving_search_cv": [22, 42, 66], "enc": [18, 19, 33, 63, 64, 77], "encapsul": 40, "enclosedporch": [24, 26, 35, 44, 46, 55, 56, 68, 70, 79], "encod": [13, 15, 17, 20, 22, 23, 24, 26, 30, 31, 34, 38, 40, 41, 42, 43, 44, 46, 50, 51, 59, 61, 66, 67, 68, 70, 74, 75, 78, 81, 85, 88, 91, 94, 97], "encoded_missing_valu": [40, 45, 46, 64, 68, 69, 70], "encoder_attention_mask": [51, 75], "encompass": [34, 54, 56, 78, 79, 85], "encount": [19, 64], "end": [4, 9, 12, 13, 15, 16, 20, 21, 22, 23, 27, 28, 29, 30, 31, 33, 34, 35, 36, 43, 47, 51, 52, 54, 56, 59, 60, 61, 62, 63, 64, 65, 66, 67, 71, 72, 73, 74, 75, 77, 78, 79, 80, 87, 93, 94, 96], "endors": 0, "endpoint": [34, 78], "enemi": 59, "energi": [18, 22, 33, 42, 62, 63, 66, 77, 87, 93], "energy_df": [87, 93], "enforc": 41, "engag": [59, 99], "engin": [1, 10, 12, 19, 23, 24, 28, 30, 31, 34, 36, 43, 44, 50, 51, 52, 64, 67, 68, 72, 74, 75, 78, 80, 91, 97], "england": 59, "english": [17, 18, 20, 22, 31, 32, 36, 40, 41, 42, 51, 52, 57, 58, 59, 63, 66, 75, 76, 80, 81, 83], "enhanc": 99, "enjoi": [1, 20, 21, 41, 65], "enjoy_class": [19, 64], "enjoy_cours": [19, 64, 85], "enjoy_course_enc": [19, 64], "enjoy_the_mo": [36, 57, 58, 80, 81], "enough": [8, 16, 23, 24, 25, 26, 28, 30, 43, 44, 45, 50, 62, 64, 67, 68, 69, 72, 74, 81, 85, 87, 91, 93, 97, 99], "enrich": 59, "enrol": 5, "ensambl": 32, "ensembl": [1, 12, 18, 24, 26, 27, 30, 33, 34, 35, 36, 44, 46, 47, 50, 53, 54, 55, 56, 57, 58, 68, 70, 71, 73, 74, 77, 78, 79, 80, 89, 91, 95, 97], "ensiti": [29, 73], "ensur": [8, 12, 18, 25, 38, 45, 53, 63, 69, 77, 90, 91, 96, 97, 99], "ensure_2d": [18, 34], "ensure_all_finit": [18, 34], "ensure_min_featur": [18, 34], "ensure_min_sampl": [18, 34], "ensure_non_neg": [18, 34], "ent": [52, 83], "enter": [6, 11, 19, 34, 35, 54, 56, 64, 78, 79], "entertain": [31, 52, 75], "enthusiast": [13, 35, 56, 59, 79], "entir": [4, 9, 13, 15, 20, 24, 32, 33, 35, 36, 41, 44, 53, 56, 57, 58, 59, 61, 68, 76, 77, 79, 80, 89, 95, 99], "entiti": [27, 30, 47, 52, 71, 74, 83], "entitl": [19, 64], "entlebuch": [32, 59, 76], "entri": [16, 17, 18, 19, 21, 23, 24, 27, 30, 34, 43, 44, 47, 50, 53, 54, 62, 63, 64, 65, 67, 68, 71, 74, 77, 78, 93, 95, 97], "entropi": [14, 35, 56, 60, 79], "enumer": [25, 45, 69, 90, 96], "env": [11, 14, 16, 18, 19, 25, 26, 28, 31, 32, 34, 46, 51, 54, 60, 61, 64, 70, 75, 78, 84], "environ": [3, 6, 9, 13, 15, 17, 18, 19, 20, 22, 23, 24, 25, 26, 27, 31, 32, 34, 35, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 51, 52, 54, 55, 56, 59, 63, 64, 66, 67, 68, 69, 70, 71, 75, 76, 78, 79, 81, 95, 99], "environment": [31, 51, 75, 85], "ep": [16, 21, 29, 49, 60, 61, 62, 65, 73, 86, 92], "epic": 59, "episod": [20, 41], "epoch": [33, 77], "epsilon": [29, 35, 56, 73, 79], "equal": [9, 16, 23, 24, 25, 26, 29, 30, 33, 43, 44, 45, 46, 50, 53, 62, 64, 67, 68, 69, 70, 73, 74, 77, 81, 85, 91, 97, 99], "equat": [4, 13, 21, 65], "equip": [16, 34, 62, 78, 99], "equival": [9, 17, 25, 45, 67, 69], "erik": [31, 51, 52, 75], "err": [51, 52, 75], "error": [4, 5, 7, 8, 9, 12, 14, 16, 17, 18, 19, 21, 25, 26, 27, 31, 34, 35, 36, 40, 45, 46, 47, 51, 52, 54, 56, 57, 58, 60, 62, 64, 65, 69, 70, 71, 75, 78, 79, 80, 85, 87, 89, 93, 95], "error_": [15, 61], "error_scor": [42, 66], "erupt": 59, "erythrocebu": [32, 59, 76], "es": [53, 77, 97], "escap": [20, 60], "eskimo": 67, "esl": 1, "especi": [2, 14, 16, 20, 22, 25, 26, 27, 30, 33, 47, 50, 53, 59, 60, 62, 66, 67, 69, 71, 74, 77], "essai": [13, 59], "essenti": [5, 11, 34, 77, 78, 85, 99], "establish": [38, 90, 96], "estat": [14, 60], "estim": [16, 19, 21, 22, 27, 28, 34, 35, 36, 42, 47, 55, 56, 61, 62, 64, 65, 66, 71, 72, 78, 79, 80, 85, 89, 95, 96], "estimator_nam": 18, "estimators_": [25, 45, 69], "et": [25, 31, 45, 51, 52, 69, 75], "etc": [1, 2, 8, 9, 14, 27, 32, 33, 34, 36, 45, 47, 52, 53, 54, 56, 57, 58, 60, 71, 76, 77, 78, 79, 80, 83, 99], "ethic": [1, 12, 13, 31, 36, 51, 59, 75, 80], "ethnic": 59, "euclidean": [28, 29, 31, 52, 72, 73, 75], "euclidean_dist": [16, 18, 28, 29, 31, 49, 52, 62, 63, 72, 73, 75], "ev": [32, 76], "eva": [30, 50, 74], "eva_model": [30, 50, 74], "eval": [48, 49], "eval_metr": [25, 26, 45, 46, 69, 70], "eval_on_featur": [33, 77], "evalu": [1, 9, 12, 15, 22, 26, 28, 33, 35, 36, 38, 40, 42, 46, 56, 59, 60, 61, 66, 68, 70, 72, 77, 79, 80, 87, 89, 90, 93, 95, 96], "evapor": [53, 77, 91, 97], "even": [0, 8, 12, 13, 14, 15, 17, 20, 21, 28, 29, 30, 31, 33, 34, 35, 40, 42, 50, 51, 56, 59, 60, 61, 65, 66, 67, 71, 72, 73, 74, 75, 77, 78, 79, 81, 85, 87, 88, 93, 94, 97, 99], "event": [0, 24, 59, 68, 81, 99], "event_col": [34, 54, 78], "event_observ": [34, 54, 78], "ever": [14, 20, 59, 60, 84], "everi": [5, 9, 13, 14, 15, 20, 25, 29, 32, 33, 45, 59, 60, 61, 69, 73, 76, 77, 87, 93], "everydai": [9, 13, 31, 52, 59, 75], "everyon": [7, 26, 46, 54, 56, 70, 79, 85], "everyth": [13, 19, 23, 30, 31, 33, 36, 43, 50, 51, 57, 58, 59, 64, 67, 74, 75, 77, 80, 89, 95], "everytown": 59, "everywher": [33, 77], "evil": 59, "evo": [36, 80], "evocarshar": [36, 80], "evok": [31, 51, 52, 75], "evolv": 41, "ex": [24, 26, 31, 35, 44, 46, 51, 55, 56, 68, 70, 75, 79], "ex1_idx": [26, 46, 70], "ex2_idx": [26, 46, 70], "ex_df": [20, 41], "exact": [4, 34, 78], "exactli": [8, 13, 14, 20, 26, 31, 32, 41, 46, 51, 59, 61, 70, 75, 76, 87, 93, 94], "exagger": [35, 55, 56, 79], "exam": [1, 7, 13, 22, 35, 36, 56, 79, 80], "examin": [15, 16, 17, 18, 21, 25, 26, 27, 28, 29, 30, 31, 32, 33, 36, 38, 39, 40, 45, 46, 47, 49, 50, 51, 52, 61, 62, 63, 65, 67, 69, 70, 71, 72, 73, 74, 75, 76, 77, 80, 81, 84, 91, 97], "exampl": [0, 4, 6, 7, 8, 9, 15, 17, 20, 24, 29, 30, 33, 36, 39, 40, 41, 42, 44, 47, 50, 53, 54, 55, 68, 71, 73, 74, 77, 80, 81, 83, 84, 85, 86, 87, 91, 92, 93, 94, 97, 99], "example1": [14, 60], "example2": [14, 60], "excel": [19, 20, 21, 24, 26, 34, 41, 44, 46, 54, 59, 64, 65, 68, 70, 78, 85, 88, 94], "except": [0, 1, 5, 8, 9, 34, 53, 54, 59, 61, 77, 78, 91, 97, 99], "exception": 4, "exchang": [23, 43, 67], "excit": [13, 30, 31, 50, 51, 59, 74, 75], "execut": [4, 8, 16, 20, 25, 26, 28, 36, 57, 58, 72, 80], "exercis": [1, 8, 10, 13, 36, 52, 57, 58, 80, 81, 83, 87, 88, 89, 90, 91, 93, 94, 95, 96, 97], "exerciseangina": [89, 95], "exist": [9, 11, 27, 34, 36, 47, 57, 58, 67, 71, 78, 80], "exmapl": [31, 75], "exp": [21, 34, 35, 56, 65, 78, 79], "expand": [1, 14, 60, 99], "expect": [1, 4, 5, 8, 9, 11, 13, 15, 16, 18, 19, 21, 22, 24, 26, 27, 28, 29, 30, 32, 34, 39, 40, 46, 52, 53, 54, 59, 61, 62, 63, 64, 65, 66, 67, 68, 70, 71, 72, 73, 74, 76, 77, 78, 84, 87, 91, 93, 97, 99], "expected_valu": [26, 46, 70], "expenditur": [33, 53, 77], "expens": [23, 24, 27, 28, 30, 43, 44, 47, 50, 59, 67, 68, 71, 72, 74, 96], "experi": [13, 22, 25, 30, 31, 42, 48, 51, 52, 59, 66, 74, 75, 93, 99], "experienc": 99, "experiment": [20, 22, 36, 42, 66, 80], "expert": [14, 15, 22, 26, 27, 46, 47, 59, 60, 61, 66, 70, 71], "expertis": [13, 59], "explain": [4, 5, 8, 12, 13, 14, 15, 16, 18, 19, 21, 22, 24, 25, 27, 28, 29, 30, 31, 32, 33, 34, 36, 44, 50, 51, 52, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 71, 72, 73, 74, 75, 76, 77, 78, 80, 83, 85, 89, 90, 95, 96, 99], "explan": [4, 16, 61, 62, 67, 85, 99], "explanatori": [14, 60], "explicit": [23, 34, 43, 67, 78, 81], "explicitli": [9, 13, 36, 57, 58, 59, 80], "explod": [32, 76], "exploit": [7, 59], "explor": [15, 19, 20, 22, 23, 26, 27, 30, 31, 32, 36, 38, 39, 41, 42, 43, 46, 47, 49, 51, 52, 57, 58, 59, 60, 61, 64, 66, 67, 70, 74, 75, 76, 80, 82, 87, 93, 96], "exploratori": [24, 34, 36, 44, 68, 78, 80, 85], "expm1": [24, 35, 44, 55, 56, 68, 79], "expon": [22, 42, 66], "exponenti": [22, 42, 66], "export_graphviz": [14, 60, 86, 92], "expos": [20, 41], "exposur": [30, 74], "express": [0, 9, 19, 20, 21, 27, 31, 35, 47, 49, 51, 52, 56, 64, 65, 71, 75, 79, 83], "extend": [32, 52, 76, 83, 84, 99], "extend_block": [34, 78], "extens": [1, 11, 13, 16, 23, 26, 28, 29, 31, 33, 39, 43, 46, 51, 52, 53, 62, 67, 70, 72, 73, 75, 77, 81, 87, 93, 99], "extent": [28, 31, 51, 52, 72, 75], "extercond": [24, 26, 35, 44, 46, 55, 56, 68, 70, 79], "exterior": [26, 46, 59, 70], "exterior1st": [24, 26, 35, 44, 46, 55, 56, 68, 70, 79], "exterior1st_asbshng": [24, 68, 70], "exterior1st_asphshn": [24, 68, 70], "exterior1st_brkcomm": [24, 68, 70], "exterior1st_brkfac": [24, 68, 70], "exterior1st_cblock": [24, 68, 70], "exterior1st_cemntbd": [24, 68, 70], "exterior1st_hdboard": [24, 68, 70], "exterior1st_imstucc": [24, 46, 68, 70], "exterior1st_metalsd": [24, 68, 70], "exterior1st_plywood": [24, 68, 70], "exterior1st_ston": [24, 68, 70], "exterior1st_stucco": [24, 68, 70], "exterior1st_vinylsd": [24, 68, 70], "exterior1st_wd": [24, 68, 70], "exterior1st_wdsh": [24, 68, 70], "exterior2nd": [24, 26, 35, 44, 46, 55, 56, 68, 70, 79], "exterior2nd_asbshng": [24, 68, 70], "exterior2nd_asphshn": [24, 68, 70], "exterior2nd_brk": [24, 68, 70], "exterior2nd_brkfac": [24, 68, 70], "exterior2nd_cblock": [24, 68, 70], "exterior2nd_cmentbd": [24, 68, 70], "exterior2nd_hdboard": [24, 68, 70], "exterior2nd_imstucc": [24, 68, 70], "exterior2nd_metalsd": [24, 68, 70], "exterior2nd_oth": [24, 68, 70], "exterior2nd_plywood": [24, 68, 70], "exterior2nd_ston": [24, 68, 70], "exterior2nd_stucco": [24, 68, 70], "exterior2nd_vinylsd": [24, 68, 70], "exterior2nd_wd": [24, 68, 70], "extern": [16, 25, 26, 28], "external_tool": [36, 80], "exterqu": [24, 26, 35, 44, 46, 55, 56, 68, 70, 79], "extra": [4, 5, 11, 28, 36, 53, 57, 58, 72, 77, 80, 91, 97, 99], "extract": [27, 28, 30, 31, 32, 39, 47, 48, 49, 51, 52, 53, 71, 72, 74, 75, 76, 83, 91, 97, 99], "extractor": [48, 85], "extraordinari": 59, "extrapol": [33, 34, 77, 78], "extratreesclassifi": [45, 69], "extrem": [7, 20, 23, 25, 26, 30, 31, 34, 43, 46, 50, 51, 54, 64, 67, 69, 70, 74, 75, 78, 93], "ey": 59, "f": [9, 11, 13, 14, 15, 16, 18, 19, 20, 23, 26, 27, 28, 29, 31, 32, 33, 34, 36, 39, 43, 46, 52, 53, 57, 58, 59, 60, 61, 62, 63, 64, 67, 70, 72, 73, 75, 76, 77, 78, 80, 82, 87, 89, 91, 93, 95, 97], "f1": [12, 46, 68, 81, 85], "f1_score": [23, 43, 67], "fa": [24, 26, 35, 44, 46, 55, 56, 68, 70, 79], "fabric": 59, "face": [13, 20, 30, 39, 40, 49, 59, 60, 62, 74, 76], "facebook": [30, 31, 50, 51, 52, 74, 75, 99], "facial": [20, 49, 62], "facil": 99, "facilit": [9, 99], "fact": [22, 23, 25, 32, 33, 34, 35, 43, 45, 53, 54, 56, 59, 66, 67, 69, 76, 77, 78, 79, 91, 93, 97], "factor": [14, 22, 26, 27, 29, 30, 34, 42, 46, 60, 66, 70, 71, 73, 74, 78], "fail": [8, 9, 11, 18, 19, 27, 29, 31, 34, 35, 51, 52, 56, 61, 63, 64, 71, 73, 75, 78, 79], "failur": [8, 13, 34, 59, 78, 89, 95, 99], "fair": [7, 18, 24, 26, 28, 36, 44, 46, 61, 63, 68, 70, 72, 80, 85, 99], "fairli": [15, 22, 26, 30, 36, 42, 46, 57, 58, 59, 61, 66, 67, 70, 80], "faith": 59, "fake": [16, 20, 41, 62], "fake_review": [20, 41], "fall": [16, 28, 31, 51, 52, 53, 62, 72, 75, 77], "fals": [9, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 31, 32, 33, 34, 35, 38, 40, 41, 42, 43, 44, 45, 46, 47, 51, 52, 53, 54, 55, 56, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 75, 76, 77, 78, 79, 85, 86, 89, 91, 92, 95, 97], "famili": [13, 17, 20, 22, 24, 25, 26, 28, 36, 41, 42, 44, 45, 46, 59, 66, 67, 68, 69, 70, 72, 80, 99], "familiar": [6, 9, 12, 14, 18, 35, 56, 59, 60, 63, 79, 90, 91, 96, 97, 99], "famou": [1, 10, 20, 31, 32, 41, 51, 52, 75, 76], "fan": [20, 59], "fanat": 41, "fanci": [4, 42, 59, 66], "fancier": [27, 71], "fantast": [20, 59], "far": [16, 18, 19, 21, 23, 26, 28, 29, 31, 32, 33, 34, 43, 46, 51, 52, 54, 59, 60, 62, 63, 64, 65, 67, 70, 71, 72, 73, 75, 76, 77, 78, 84, 85, 87, 89, 93, 95], "farm": 67, "farther": [51, 75], "farthest": [14, 60], "fascin": [31, 51, 75], "fascist": 59, "fashion": [14, 20, 25, 31, 41, 45, 51, 52, 69, 75], "fast": [5, 15, 20, 21, 25, 26, 34, 36, 45, 46, 52, 54, 61, 62, 65, 69, 70, 78, 80, 83], "faster": [16, 22, 25, 27, 32, 42, 45, 47, 66, 69, 71, 76], "fastest": [25, 45, 69], "fastingb": [89, 95], "fasttext": [31, 51, 52, 75], "favorit": [20, 59], "favour": [36, 80], "favourit": [52, 59], "fc": [21, 65], "fcluster": [29, 49, 73], "fear": [20, 31, 51, 75], "feat": [17, 33, 40, 66, 77], "feat1": [28, 72], "feat2": [28, 72], "feat_nam": [17, 33, 77], "feat_vec": [20, 30, 41, 50, 74], "feat_vect": 20, "featur": [1, 12, 15, 20, 23, 25, 28, 29, 31, 34, 36, 38, 39, 41, 43, 45, 48, 51, 52, 54, 61, 67, 69, 72, 73, 75, 78, 80, 81, 84, 87, 88, 89, 90, 92, 93, 94, 95, 96, 99], "feature_extract": [13, 17, 19, 20, 21, 22, 31, 36, 40, 41, 42, 51, 52, 57, 58, 59, 64, 65, 66, 75, 80, 81], "feature_import": 38, "feature_importances_": [27, 38, 47, 71], "feature_nam": [14, 15, 20, 21, 25, 26, 27, 31, 38, 41, 45, 46, 47, 51, 52, 60, 61, 65, 69, 70, 71, 75, 86, 92], "feature_name_combin": [40, 42, 45, 46, 64, 66, 68, 69, 70, 95], "feature_names_in_": 38, "feature_names_out": [19, 64], "feature_select": [27, 47, 71, 82], "feature_typ": [25, 45, 69], "feature_weight": [25, 45, 69], "features_lag": [33, 77], "features_nonzero": [33, 77], "features_poli": [33, 77], "februari": [15, 33, 38, 53, 77, 97], "feder": [26, 31, 33, 46, 51, 52, 67, 70, 75, 77], "feed": [17, 32, 39, 40, 76, 99], "feedback": [14, 36, 60, 80, 85], "feedforward": [32, 76], "feel": [7, 17, 31, 40, 51, 59, 61, 72, 75, 85], "feli": [32, 59, 76], "felin": [31, 51, 75], "felix": [1, 99], "fell": [21, 65], "fellow": 59, "felt": [17, 31, 40, 51, 75], "femal": [25, 26, 34, 45, 46, 54, 59, 67, 69, 70, 78], "female_cm": 67, "female_pr": 67, "fenc": [24, 26, 32, 35, 44, 46, 55, 56, 68, 70, 76, 79], "fens": 20, "fernandez": [25, 45, 69], "festiv": 59, "fetch_california_h": [21, 65], "few": [1, 9, 17, 20, 21, 24, 27, 30, 31, 32, 33, 34, 35, 36, 40, 41, 44, 51, 52, 59, 65, 68, 69, 71, 74, 75, 76, 77, 78, 80, 83, 85, 86, 89, 90, 92, 95, 96, 97], "fewer": [25, 27, 29, 45, 47, 67, 69, 71, 73, 93], "fewest": [89, 95], "feynman": [35, 56, 79], "fiber": [34, 54, 78], "fiction": 59, "field": [2, 4, 12, 13, 19, 31, 32, 33, 36, 51, 52, 53, 59, 64, 75, 76, 77, 80], "fifa": 25, "fig": [16, 21, 27, 28, 29, 32, 39, 47, 61, 62, 65, 67, 71, 72, 73, 76, 86, 87, 92, 93], "fight": [20, 41], "figsiz": [14, 16, 17, 18, 21, 26, 27, 28, 29, 32, 33, 34, 35, 39, 40, 47, 48, 49, 53, 54, 55, 56, 60, 61, 62, 63, 65, 67, 70, 71, 72, 73, 76, 77, 78, 79, 86, 87, 90, 92, 93, 96, 98], "figur": [4, 9, 13, 14, 16, 22, 24, 26, 27, 28, 29, 32, 33, 34, 35, 39, 40, 42, 44, 46, 47, 48, 49, 53, 54, 55, 56, 59, 60, 62, 66, 67, 68, 70, 71, 72, 73, 76, 77, 78, 79, 87, 90, 93, 96, 98], "file": [0, 1, 4, 6, 8, 9, 11, 13, 16, 18, 19, 20, 23, 25, 26, 28, 31, 32, 34, 36, 43, 46, 57, 58, 60, 64, 67, 70, 76, 78, 80, 81, 87, 91, 93, 97], "file_download": 31, "file_nam": [39, 48, 49], "filenam": [32, 76], "fill": [15, 16, 17, 21, 22, 30, 36, 38, 39, 40, 50, 57, 58, 62, 65, 66, 74, 80, 87, 89, 93, 95, 99], "fill_diagon": [16, 49, 62], "fill_valu": [17, 24, 25, 26, 35, 40, 44, 45, 46, 53, 55, 56, 63, 64, 67, 68, 69, 70, 77, 79, 91, 97], "film": [20, 41, 52, 59], "filmic": 59, "filmmak": 59, "filter": [4, 12, 13, 15, 28, 32, 53, 59, 61, 72, 76, 77, 85, 91, 97], "filterwarn": [15, 16, 25, 26, 27, 28, 29, 34, 54, 62, 78, 89, 95], "filth": 59, "final": [1, 5, 7, 8, 13, 15, 18, 25, 26, 27, 34, 35, 36, 38, 45, 47, 56, 59, 61, 63, 67, 69, 71, 79, 80, 86, 88, 89, 92, 94, 95, 96], "final_estim": [25, 45, 69], "final_estimator_": [25, 45, 69, 89, 95], "financ": [31, 32, 33, 75, 76, 77], "find": [1, 5, 8, 9, 13, 17, 18, 20, 22, 24, 25, 26, 28, 29, 30, 31, 32, 35, 39, 40, 41, 42, 44, 45, 46, 47, 51, 52, 56, 59, 60, 63, 66, 68, 69, 70, 72, 73, 74, 75, 76, 79, 84, 87, 93], "fine": [8, 11, 17, 18, 19, 20, 30, 32, 33, 36, 50, 53, 57, 58, 63, 64, 67, 74, 76, 77, 80, 89, 95], "finetun": [31, 51, 75], "finger": 59, "fingertip": 41, "finish": [24, 44, 59, 68], "fira": 0, "firasm": [23, 43, 67, 81], "fire": [20, 39], "firefox": 13, "fireplac": [24, 26, 35, 44, 46, 55, 56, 68, 70, 79], "fireplacequ": [24, 26, 35, 44, 46, 55, 56, 68, 70, 79], "first": [1, 4, 5, 9, 14, 16, 17, 19, 20, 21, 22, 25, 26, 28, 29, 30, 31, 32, 33, 34, 35, 40, 41, 42, 45, 46, 50, 51, 52, 54, 56, 59, 60, 62, 64, 65, 66, 67, 69, 70, 72, 73, 74, 75, 76, 77, 78, 79, 86, 89, 90, 92, 93, 95, 96, 99], "first_cal": 34, "first_dai": [53, 77, 97], "first_day_retail": [33, 77], "first_pass_isfinit": 18, "firth": [31, 51, 52, 75], "fish": [26, 45, 46, 67, 70], "fist": [33, 77], "fit": [0, 13, 15, 16, 17, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 38, 39, 40, 41, 42, 43, 44, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 61, 62, 64, 65, 66, 67, 68, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 84, 86, 87, 89, 91, 92, 93, 95, 96, 97], "fit_intercept": [41, 43, 45, 67, 68, 69, 76, 95], "fit_method": [18, 34], "fit_param": 34, "fit_predict": [29, 49, 73, 96], "fit_resampl": 81, "fit_tim": [15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 33, 34, 39, 40, 41, 43, 44, 45, 46, 47, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 77, 78, 81, 93, 94, 95], "fit_transform": [17, 18, 19, 20, 25, 26, 27, 29, 30, 31, 33, 34, 40, 41, 45, 46, 47, 50, 51, 52, 63, 64, 67, 69, 70, 71, 73, 74, 75, 77, 85, 90, 94, 96], "fittedcolumntransform": [17, 19, 25], "fittedpipelin": [22, 24], "fittedvotingclassifi": 25, "fitter": [54, 78], "five": [22, 66], "fix": [18, 19, 34, 36, 40, 45, 54, 63, 64, 67, 69, 78, 80, 84, 87, 93, 99], "flag": [25, 34, 67, 78], "flaki": 81, "flash": 59, "flashcard": 85, "flask": [36, 57, 58, 80], "flat": [29, 49, 59, 73, 95], "flatten": [20, 25, 26, 29, 32, 39, 41, 45, 46, 48, 53, 69, 70, 73, 76, 77, 89, 95, 97], "flatten_dataload": 48, "flatten_imag": 48, "flatten_train": 48, "flatten_transform": [45, 48, 69, 95], "flatter": 21, "flavour": 96, "flaw": [15, 17, 18, 61, 63], "flawless": [20, 21, 41, 65], "flesh": 59, "flexibl": [13, 27, 32, 59, 71, 76, 85], "flibbertigibbet": [31, 51, 52, 75], "flick": 59, "flight": [27, 47, 59, 71], "flip": [1, 23, 24, 43, 44, 61, 67, 68], "flip_i": 81, "float": [9, 24, 34, 44, 47, 54, 68, 71, 78, 93], "float32": [31, 51, 52, 75, 83], "float64": [16, 17, 18, 19, 22, 23, 24, 25, 26, 27, 30, 34, 39, 40, 42, 43, 44, 45, 46, 47, 53, 54, 60, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 73, 74, 77, 78, 81, 93, 95, 97], "floatlogslid": [16, 62, 87, 93], "floatslid": [16, 23, 28, 29, 43, 62, 67, 72, 73, 87, 93], "floor": [15, 38, 59, 60], "flourish": 59, "flower": [16, 36, 39, 57, 58, 62, 80, 81, 87, 93], "fly": 59, "fmt": [22, 66], "fn": [23, 43, 67], "fnlwgt": [25, 26, 45, 46, 67, 69, 70], "focu": [1, 5, 12, 13, 18, 19, 21, 26, 29, 31, 33, 40, 46, 51, 52, 59, 63, 64, 65, 70, 73, 74, 75, 77, 85, 87, 88, 89, 93, 94, 95, 99], "focus": [13, 20, 21, 28, 31, 32, 52, 59, 65, 72, 75, 76, 85, 91, 97], "fold": [15, 18, 19, 22, 24, 36, 40, 42, 44, 45, 61, 63, 64, 66, 67, 68, 69, 80, 87, 93], "folder": [6, 11, 36, 46, 57, 58, 63, 70, 80], "folk": [34, 54, 59, 78, 99], "follow": [0, 1, 5, 6, 7, 8, 9, 11, 14, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 31, 32, 33, 34, 35, 36, 38, 40, 41, 42, 43, 45, 46, 47, 49, 51, 52, 56, 57, 58, 59, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 75, 76, 77, 78, 79, 80, 84, 85, 87, 90, 93, 96, 99], "fond": 59, "font": [13, 14, 15, 28, 29, 30, 33, 34, 35, 50, 53, 54, 55, 56, 59, 60, 61, 72, 73, 74, 77, 78, 79, 90, 96], "font_scal": [26, 70], "fontsiz": [14, 15, 16, 23, 25, 26, 28, 32, 35, 38, 39, 43, 45, 46, 56, 60, 61, 62, 67, 69, 70, 72, 76, 79, 86, 87, 90, 92, 93, 96], "food": [17, 28, 31, 32, 40, 48, 49, 52, 72, 75, 76, 99], "food_class": [48, 49], "food_input": [48, 49], "food_typ": [17, 40], "food_type_canadian": [17, 40], "food_type_chines": [17, 40], "food_type_fus": [17, 40], "food_type_indian": [17, 40], "food_type_italian": [17, 40], "food_type_mexican": [17, 40], "food_type_nan": [17, 40], "food_type_oth": [17, 40], "food_type_quebecoi": [17, 40], "food_type_thai": [17, 40], "foot": [24, 26, 44, 46, 68, 70], "footag": [21, 65, 87, 93], "footstal": [32, 76], "forc": [26, 45, 46, 59, 70, 81, 87, 93], "force_all_finit": [18, 34], "force_int_remainder_col": [40, 42, 45, 46, 64, 66, 68, 69, 70, 95], "force_plot": [26, 46, 70], "force_writ": [18, 34], "forecast": [12, 14, 34, 35, 53, 56, 60, 78, 79, 85, 91, 97], "forest": [12, 24, 32, 33, 34, 36, 54, 68, 76, 77, 78, 80, 81, 85, 89, 95], "forestcolumntransform": [25, 45, 69, 95], "forev": [33, 77], "forg": [24, 25, 26, 31, 34, 44, 45, 46, 51, 52, 54, 68, 69, 70, 75, 78, 81], "forget": [14, 19, 25, 31, 45, 51, 60, 64, 69, 75, 89, 95], "forgotten": 59, "form": [1, 13, 16, 19, 22, 27, 29, 30, 31, 34, 35, 36, 40, 47, 51, 52, 56, 57, 58, 64, 67, 71, 73, 74, 75, 78, 79, 80, 83, 85], "formal": [13, 41, 59, 99], "format": [0, 1, 14, 15, 17, 18, 19, 20, 23, 29, 31, 33, 34, 38, 42, 43, 49, 51, 52, 53, 54, 60, 66, 67, 73, 75, 77, 78, 83, 91, 97, 99], "former": [34, 54, 78], "formerli": [31, 75], "formul": [4, 22, 66], "formula": [21, 24, 32, 44, 65, 67, 68, 76, 84], "fortun": 59, "forum": 13, "forw": 99, "forward": [32, 34, 36, 47, 51, 54, 57, 58, 71, 75, 76, 78, 80], "foul": 59, "found": [1, 8, 15, 18, 19, 22, 24, 28, 30, 31, 38, 44, 50, 51, 52, 61, 64, 66, 68, 72, 74, 75, 89, 90, 95, 96, 99], "foundat": [1, 10, 12, 24, 26, 35, 44, 46, 51, 55, 56, 68, 70, 75, 79, 81], "foundation_brktil": [24, 44, 68, 70], "foundation_cblock": [24, 44, 68, 70], "foundation_pconc": [24, 44, 68, 70], "foundation_slab": [24, 44, 68, 70], "foundation_ston": [24, 44, 68, 70], "foundation_wood": [24, 44, 68, 70], "fountain": [32, 76], "four": [14, 27, 29, 36, 47, 60, 61, 67, 71, 73, 80, 85, 99], "fourth": [29, 73], "foxhound": [32, 59, 76], "foyer": [24, 44, 68], "fp": [23, 43, 67], "fpr": [23, 43, 67], "fpr_lr": [23, 43, 67], "fpr_svc": [23, 43, 67], "frac": [14, 21, 23, 24, 28, 31, 32, 43, 44, 52, 60, 65, 67, 68, 72, 75, 76], "fractal": [27, 47, 71], "fraction": [19, 23, 30, 43, 50, 64, 67, 74], "fragment": [87, 93], "fraker": 59, "frame": [17, 18, 19, 23, 24, 27, 34, 35, 36, 43, 44, 47, 53, 54, 56, 59, 63, 64, 67, 68, 71, 77, 78, 79, 80, 93, 95, 97], "framework": [22, 60, 66], "frank": [20, 59], "frankli": 59, "fraud": [14, 23, 24, 28, 31, 33, 43, 53, 60, 67, 68, 72, 75, 77, 81], "fraudul": [14, 23, 35, 43, 56, 60, 67, 79], "free": [0, 6, 19, 24, 31, 34, 40, 44, 51, 52, 54, 64, 68, 75, 78], "freedom": 0, "freelanc": [31, 51, 75], "french": [18, 31, 51, 52, 63, 75], "french_fri": [32, 76], "freq": [33, 53, 77, 97], "frequenc": [19, 31, 34, 42, 51, 52, 53, 64, 66, 75, 77, 78, 85, 91, 97], "frequent": [3, 14, 18, 30, 34, 52, 60, 63, 74, 78, 83], "fresh": [30, 31, 50, 51, 52, 74, 75], "fri": [33, 77, 99], "fridai": 1, "friend": [13, 14, 26, 29, 30, 36, 46, 50, 57, 58, 59, 60, 61, 70, 73, 74, 80, 81, 85, 99], "frighteningli": 59, "frisco": 59, "frolick": 59, "from": [0, 1, 2, 4, 6, 7, 8, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 32, 33, 34, 36, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 54, 55, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 76, 77, 78, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 99], "from_block": [34, 78], "from_estim": [23, 43, 67, 81], "front": 99, "fruit": [31, 51, 52, 75], "fruiti": 96, "frustrat": [4, 7, 22, 66], "fry": 59, "fsc": 99, "fu": [1, 99], "full": [5, 15, 20, 22, 25, 31, 32, 33, 34, 38, 45, 51, 59, 66, 69, 75, 76, 77, 78, 99], "fullbath": [24, 26, 35, 44, 46, 55, 56, 68, 70, 79], "fulli": [29, 32, 73, 76], "fun": [20, 31, 32, 51, 52, 75, 76, 81], "func": [9, 17, 19, 21, 24, 34, 35, 44, 55, 56, 64, 65, 68, 79], "function": [2, 13, 14, 15, 16, 17, 19, 22, 23, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 39, 43, 45, 46, 47, 48, 50, 51, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 64, 66, 67, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 82, 84, 85, 86, 87, 90, 91, 92, 93, 96, 97], "functiontransform": [17, 19, 34, 40, 54, 64, 78], "functiontransformerfunctiontransform": 17, "fundament": [1, 2, 5, 10, 12, 18, 21, 22, 24, 27, 32, 34, 44, 47, 63, 65, 66, 68, 71, 76, 78, 87, 93], "funni": [25, 45, 59, 69], "furnish": 0, "furnitur": 85, "further": [15, 27, 28, 32, 34, 36, 38, 45, 47, 52, 54, 67, 69, 71, 72, 76, 78, 80, 83, 87, 93], "furthermor": [35, 56, 79], "fusion": [17, 40], "futur": [12, 13, 15, 22, 23, 24, 31, 32, 34, 36, 42, 43, 44, 51, 53, 54, 59, 61, 63, 66, 68, 75, 76, 78, 80, 85, 91, 97], "futurewarn": [23, 24, 26, 43, 44, 46, 51, 63, 68, 70, 75, 84], "futurist": 59, "fuzzi": [13, 59], "fyi": [34, 54, 78], "g": [5, 7, 8, 9, 11, 12, 13, 14, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 46, 47, 51, 52, 53, 54, 55, 56, 59, 60, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 83, 84, 85, 91, 94, 97, 99], "g26r0dcx4b35vf3nk31216hc0000gr": [46, 63, 70], "gaffer": 41, "gain": [7, 12, 14, 25, 26, 45, 46, 59, 60, 67, 69, 70], "game": [14, 26, 31, 46, 51, 52, 59, 60, 70, 75], "gamma": [21, 22, 25, 35, 39, 42, 43, 45, 56, 64, 65, 66, 69, 79, 87, 93], "gamma_log": [16, 39, 62, 87, 93], "gamma_widget": [16, 62, 87, 93], "gap": [15, 33, 34, 38, 53, 56, 61, 77, 78, 79, 85, 87, 93], "garagearea": [24, 26, 35, 44, 46, 55, 56, 68, 70, 79], "garagecar": [24, 26, 35, 44, 46, 55, 56, 68, 70, 79], "garagecond": [24, 26, 35, 44, 46, 55, 56, 68, 70, 79], "garagefinish": [24, 26, 35, 44, 46, 55, 56, 68, 70, 79], "garagefinish_fin": [24, 56, 68, 70], "garagefinish_miss": [24, 56, 68, 70], "garagefinish_rfn": [24, 56, 68, 70], "garagefinish_unf": [24, 44, 56, 68, 70], "garagequ": [24, 26, 35, 44, 46, 55, 56, 68, 70, 79], "garagetyp": [24, 26, 35, 44, 46, 55, 56, 68, 70, 79], "garagetype_2typ": [24, 68, 70], "garagetype_attchd": [24, 68, 70], "garagetype_bas": [24, 68, 70], "garagetype_builtin": [24, 68, 70], "garagetype_carport": [24, 68, 70], "garagetype_detchd": [24, 68, 70], "garagetype_miss": [24, 68, 70], "garageyrblt": [24, 26, 35, 44, 46, 55, 56, 68, 70, 79], "garbag": 59, "garlic": 72, "gassman": 59, "gaurav": [1, 99], "gauss": [31, 51, 52, 75], "gaussian": [29, 73], "gaussianmixtur": [29, 73], "gave": [17, 20, 30, 40, 53, 59, 74, 77], "gb": [31, 51, 75], "gbdt": [45, 46, 69, 70, 95], "gbm": 95, "gbr": 9, "gca": [28, 29, 34, 54, 72, 73, 78], "gd": [24, 26, 35, 44, 46, 55, 56, 59, 68, 70, 79], "gdprv": [24, 26, 35, 44, 46, 55, 56, 68, 70, 79], "gdtmp": 34, "gdwo": [24, 26, 35, 44, 46, 55, 56, 68, 70, 79], "gear": 59, "geez": 59, "gelbart": [0, 1, 14, 52, 60, 83], "gemini": [31, 51, 75, 99], "genai": 99, "gender": [13, 31, 33, 34, 51, 52, 54, 59, 64, 67, 75, 77, 78], "gender_femal": [34, 54, 78], "gender_mal": [34, 54, 78], "gener": [6, 8, 10, 13, 14, 18, 19, 22, 24, 26, 29, 31, 32, 33, 34, 35, 36, 38, 42, 44, 46, 47, 51, 52, 53, 54, 56, 59, 60, 63, 64, 66, 67, 68, 70, 73, 75, 76, 77, 78, 79, 80, 81, 84, 85, 87, 91, 93, 97, 98], "genet": [27, 47, 71, 82], "geniu": 59, "genom": [27, 71], "genr": [20, 30, 50, 74], "gensim": [31, 51, 52, 75], "gentl": 12, "gentli": 85, "geograph": [21, 36, 65, 80], "geometr": 60, "georg": [52, 83], "geq": [21, 65], "ger": 9, "german": [52, 83], "germani": 25, "get": [4, 7, 11, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 36, 38, 39, 40, 41, 42, 43, 44, 45, 47, 48, 49, 50, 51, 52, 53, 54, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 83, 84, 85, 87, 88, 89, 91, 93, 94, 95, 96, 97, 99], "get_cluster_imag": [48, 49], "get_cmap": 63, "get_depth": [15, 38, 87, 93], "get_dummi": [18, 63], "get_featur": [32, 39, 48, 49, 76], "get_feature_nam": 20, "get_feature_names_out": [17, 18, 19, 20, 24, 25, 26, 27, 31, 33, 34, 35, 40, 41, 44, 45, 46, 47, 51, 52, 53, 54, 55, 56, 63, 64, 67, 68, 69, 70, 71, 75, 77, 78, 79, 91, 94, 97], "get_lr_data_per_us": [30, 50, 74], "get_param": 39, "get_permutation_import": [26, 46, 70], "get_season": [53, 77, 97], "get_stat": [30, 50, 74], "get_text": 60, "get_user_profil": [30, 50, 74], "getattr": [34, 78], "ghassemi": [1, 99], "gif": [28, 29, 31, 51, 72, 73, 75], "gigaword": [31, 51, 52, 75], "gini": [14, 26, 35, 45, 46, 56, 60, 69, 70, 79, 95], "giogio": 41, "girl": 59, "git": [3, 9, 13], "github": [0, 1, 8, 10, 11, 13, 15, 17, 18, 19, 20, 22, 23, 24, 25, 26, 27, 32, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 55, 56, 57, 58, 59, 63, 64, 66, 67, 68, 69, 70, 71, 76, 79, 80, 81, 90, 95, 96], "githubusercont": 9, "gitim": 20, "gitlf": [23, 43, 67], "giulia": [0, 1, 14, 16, 19, 25, 26, 28, 31, 32, 99], "give": [0, 6, 13, 14, 15, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 34, 35, 36, 38, 39, 41, 42, 43, 44, 45, 46, 47, 50, 51, 52, 54, 56, 59, 60, 61, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 78, 79, 80, 81, 86, 87, 92, 93, 99], "given": [0, 15, 16, 18, 19, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 38, 42, 43, 44, 45, 46, 47, 48, 50, 51, 52, 53, 56, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 79, 80, 82, 84, 86, 87, 91, 92, 93, 97], "gladwel": [28, 72], "glanc": 93, "glass": [35, 55, 56, 79], "glob": [13, 32, 39, 48, 49, 59, 76], "global": [18, 23, 25, 28, 43, 45, 51, 52, 63, 67, 69, 72, 75, 85], "global_skip_valid": [18, 34], "glorious": 59, "glove": [12, 31, 51, 52, 75], "glove_wiki_vector": [31, 51, 75], "glq": [24, 26, 35, 44, 46, 55, 56, 68, 70, 79], "gmail": [13, 28, 59, 72], "go": [6, 8, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 29, 30, 31, 32, 33, 34, 35, 36, 39, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 73, 74, 75, 76, 77, 78, 79, 80, 82, 84, 86, 87, 89, 90, 91, 92, 93, 95, 96, 97], "goal": [2, 12, 13, 16, 18, 22, 23, 28, 29, 30, 31, 32, 36, 43, 50, 51, 52, 59, 62, 63, 66, 67, 72, 73, 74, 75, 76, 80, 89, 91, 95, 97], "god": 59, "goe": [2, 13, 15, 16, 19, 23, 26, 29, 30, 32, 35, 36, 43, 45, 46, 56, 57, 58, 59, 61, 62, 64, 67, 69, 70, 73, 74, 76, 79, 80], "gogo": 59, "gold": 9, "goldcoast": [53, 77, 97], "golden": [20, 36, 38, 40, 41, 62, 80, 85, 87, 93], "gone": 59, "good": [10, 14, 15, 16, 17, 18, 19, 20, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 36, 38, 40, 42, 43, 44, 45, 46, 47, 48, 50, 51, 52, 53, 54, 57, 58, 59, 60, 61, 62, 63, 64, 66, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 80, 81, 84, 85, 88, 89, 91, 92, 93, 94, 95, 97], "good_serv": [17, 40], "good_server_y": 40, "goof": 59, "googl": [1, 4, 13, 14, 16, 22, 23, 25, 28, 31, 35, 43, 45, 51, 52, 55, 56, 59, 60, 69, 71, 72, 75, 79], "google_news_vector": [31, 51, 52, 75], "googlenew": [31, 51, 75], "goosebump": 59, "gorgeou": 20, "got": [16, 20, 21, 22, 24, 32, 34, 41, 44, 59, 62, 65, 66, 68, 76, 81], "gotten": [15, 34, 54, 78, 89, 95], "gov": [25, 26, 45, 46, 67, 69, 70], "govern": [31, 51, 52, 59, 75, 99], "governor": 59, "gpe": [52, 83], "gpt": [30, 31, 50, 51, 52, 74, 75], "gpu": [25, 31, 32, 45, 51, 52, 69, 75, 76], "grad": [25, 26, 45, 46, 67, 69, 70], "grade": [3, 8, 15, 19, 20, 22, 35, 38, 56, 59, 61, 64, 66, 79, 85, 87, 88, 89, 90, 91, 93, 94, 95, 96, 97], "grader": 7, "grades_df": 85, "gradescop": [1, 5, 7, 13, 99], "gradient": [32, 36, 76, 80, 85], "gradientboostingclassifi": [25, 45, 69], "gradientboostingregressor": [25, 35, 45, 55, 56, 69, 79], "gradientexplain": [26, 46, 70], "gradual": [32, 76], "graduat": [5, 32, 76], "grain": [21, 26, 46, 65, 70], "gram": [51, 52, 75], "grammar": [31, 51, 75], "grammat": [52, 83], "grand": 96, "grander": 59, "grandma": [27, 82], "grandmoth": [36, 57, 58, 80, 81], "grant": [0, 99], "grant_macewan": [31, 51, 52, 75], "granular": [29, 73], "grapefruit": 98, "graph": [1, 33, 39, 48, 49, 77], "graphic": [32, 76], "graphic_design": [31, 51, 52, 75], "graphviz": [14, 60, 86, 92], "grasp": 12, "gravita": 41, "great": [13, 16, 17, 19, 20, 21, 26, 27, 31, 32, 33, 35, 40, 41, 46, 47, 48, 51, 52, 53, 56, 59, 60, 62, 64, 65, 70, 71, 75, 76, 77, 79], "greater": [11, 27, 28, 47, 71, 72], "greater_is_bett": [24, 44, 68], "greedili": [29, 73], "greek": 20, "green": [16, 22, 28, 35, 42, 56, 62, 66, 72, 79, 84, 98], "grei": 99, "grew": 93, "grid": [21, 24, 32, 34, 44, 53, 54, 65, 68, 76, 77, 78, 85, 90, 91, 96, 97, 98], "grid_result": [35, 56, 79], "grid_search": [22, 35, 42, 56, 66, 79], "gridsearchcv": [16, 25, 26, 45, 46, 55, 62, 69, 70, 89, 95], "gridsearchcvifit": [42, 66], "gridsearchcvifittedgridsearchcv": 22, "gridspec_kw": [86, 92], "grinberg": [36, 57, 58, 80], "grip": 52, "grlivarea": [24, 26, 35, 44, 46, 55, 56, 68, 70, 79], "groak": [31, 51, 52, 75], "groceri": [32, 76], "groin": [32, 76], "ground": [21, 27, 29, 30, 47, 50, 61, 71, 73, 74, 82, 99], "ground_truth_categori": [36, 57, 58, 80, 81], "group": [5, 8, 12, 14, 16, 20, 21, 25, 31, 38, 39, 51, 60, 62, 64, 65, 69, 71, 75, 77, 85, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 99], "groupbi": [53, 77, 91, 96, 97], "grow": [22, 25, 27, 42, 45, 59, 66, 69, 82, 92], "grow_polici": [25, 45, 69], "grown": 59, "growth": [33, 34, 54, 77, 78], "groyn": [32, 76], "gruesom": 59, "grumpi": [31, 51, 75], "grv": [24, 44, 68, 70], "gsc": [35, 56, 79], "gt": [17, 19, 20, 21, 24, 25, 40, 41, 42, 45, 46, 59, 64, 65, 66, 67, 68, 69, 70, 95], "gtl": [26, 46, 70], "gtoti": 1, "guam": 45, "guarante": [22, 23, 25, 28, 32, 43, 45, 66, 67, 69, 72, 76], "guenon": [32, 76], "guerra": [1, 99], "guess": [16, 18, 31, 51, 52, 62, 63, 75], "gui": 59, "guid": [1, 6, 8, 10, 11, 13, 27, 32, 36, 71, 76, 80], "guidanc": [26, 46, 70], "guidelin": [26, 27, 36, 46, 47, 70, 71, 80], "guido": 1, "guin": 59, "gun": 59, "gunman": 59, "gustav": 25, "gusto": 59, "gz": [31, 51, 75], "h": [15, 20, 25, 26, 28, 31, 32, 36, 38, 45, 46, 51, 52, 54, 57, 58, 67, 69, 70, 72, 75, 76, 78, 80], "ha": [2, 5, 7, 14, 15, 16, 18, 19, 20, 21, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 41, 43, 44, 45, 46, 47, 50, 51, 52, 53, 56, 60, 61, 63, 64, 65, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 79, 82, 83, 84, 87, 89, 90, 91, 92, 93, 95, 96, 97, 99], "hab": [31, 51, 52, 75], "habit": [19, 20, 35, 36, 64, 79, 80], "hacki": [32, 76, 84], "had": [18, 19, 20, 21, 26, 32, 33, 34, 36, 50, 52, 53, 54, 57, 58, 59, 63, 64, 65, 74, 76, 77, 78, 80, 81, 83], "hadn": [34, 52, 54, 78, 83], "haidilao": [17, 40], "hair": 49, "hal": 1, "half": [1, 7, 13, 14, 21, 27, 29, 59, 60, 65, 71, 73], "halfbath": [24, 26, 35, 44, 46, 55, 56, 68, 70, 79], "hallidai": 41, "halloween": [59, 90, 96], "hallucin": 5, "halvingrandomsearchcv": [22, 42, 66], "halvingrandomsearchcvifit": [42, 66], "ham": [13, 59], "hand": [4, 5, 10, 12, 17, 23, 30, 31, 40, 43, 50, 51, 59, 67, 74, 75, 99], "hand_picked_clust": 49, "handi": [23, 43, 67], "handl": [12, 15, 18, 25, 26, 29, 31, 32, 34, 36, 38, 40, 45, 46, 51, 54, 57, 58, 59, 69, 70, 73, 75, 78, 80, 84, 85, 87, 93, 94], "handle_unknow": [19, 64, 95], "handle_unknown": [17, 18, 19, 22, 24, 25, 26, 34, 35, 40, 42, 44, 45, 46, 53, 54, 55, 56, 63, 64, 66, 67, 68, 69, 70, 77, 78, 79, 85, 89, 91, 94, 95, 97], "handler": [26, 46, 67, 70], "handrail": [32, 76], "handwritten": [35, 56, 79, 81], "hang": 81, "hapless": 59, "happen": [4, 7, 16, 17, 19, 20, 22, 23, 25, 26, 27, 30, 31, 33, 34, 40, 41, 43, 45, 46, 47, 50, 51, 53, 54, 56, 59, 62, 64, 66, 69, 70, 71, 74, 75, 77, 78, 79, 85, 91, 94, 96, 97, 99], "happi": [15, 17, 23, 28, 31, 34, 38, 40, 43, 51, 67, 72, 75, 78], "happier": [36, 80, 99], "happydb": [36, 57, 58, 80, 81], "har": 59, "hard": [9, 13, 15, 16, 18, 21, 22, 23, 24, 25, 27, 28, 29, 30, 31, 32, 35, 36, 43, 45, 47, 50, 51, 52, 56, 59, 61, 62, 63, 65, 66, 67, 68, 69, 71, 72, 73, 74, 75, 76, 79, 80, 85, 89, 95, 96], "hardli": [30, 50, 59, 74], "hardwar": [32, 76], "harm": [31, 51, 75, 99], "harmon": [23, 43, 67], "harri": [1, 52, 59, 99], "has_nan_error": 18, "hasattr": 34, "hasn": [4, 30, 34, 50, 52, 59, 74, 78, 83], "hassl": [9, 26, 33, 46, 53, 70, 77], "hat": [21, 24, 44, 45, 50, 65, 68, 69], "have": [0, 4, 5, 6, 7, 8, 9, 11, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 27, 28, 29, 30, 31, 32, 33, 34, 36, 38, 39, 40, 41, 42, 43, 44, 47, 48, 50, 51, 52, 53, 54, 55, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 71, 72, 73, 74, 75, 76, 77, 78, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 91, 92, 93, 95, 96, 97, 99], "haven": [17, 34, 36, 40, 52, 54, 56, 61, 78, 79, 80, 83, 85], "haylei": [14, 60], "haystack": [31, 51, 75], "hazard": 12, "hc_truncation_toy_demo": [29, 73], "hdbscan": [29, 73], "he": [1, 15, 19, 20, 52, 59, 61, 64, 83, 99], "head": [9, 13, 14, 15, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 29, 30, 32, 33, 34, 35, 36, 41, 42, 43, 44, 45, 46, 47, 50, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 73, 74, 76, 77, 78, 79, 80, 81, 85, 88, 89, 90, 91, 94, 95, 96, 97], "header": [36, 57, 58, 80], "headlin": [31, 35, 52, 56, 75, 79], "health": [31, 51, 52, 75], "healthcar": [26, 31, 46, 70, 75], "healthi": [31, 35, 52, 75, 79], "heap": 59, "hear": [36, 59, 80], "heard": [13, 15, 59, 61], "hearsai": 59, "heart": [14, 20, 31, 41, 51, 59, 60, 75, 89, 95], "heart_df": [89, 95], "heartdiseas": [89, 95], "hearti": [17, 40], "heat": [22, 24, 26, 35, 42, 44, 46, 55, 56, 59, 66, 68, 70, 79], "heating_floor": [24, 68, 70], "heating_gasa": [24, 68, 70], "heating_gasw": [24, 68, 70], "heating_grav": [24, 68, 70], "heating_othw": [24, 46, 68, 70], "heating_wal": [24, 68, 70], "heatingqc": [24, 26, 35, 44, 46, 55, 56, 68, 70, 79], "heatmap": [26, 46, 70], "heavi": [25, 45, 69], "heavili": [20, 30, 32, 33, 74, 76, 77], "hedg": 59, "heeren": [52, 83], "hei": 41, "height": [14, 15, 31, 39, 51, 52, 60, 61, 67, 75, 86, 92], "heist": 41, "helm": 59, "helmsmen": 59, "help": [1, 3, 6, 8, 11, 13, 14, 15, 17, 18, 22, 23, 26, 28, 29, 30, 31, 32, 33, 34, 35, 36, 40, 42, 43, 46, 47, 51, 52, 53, 54, 56, 57, 58, 59, 61, 63, 64, 66, 67, 70, 72, 73, 74, 75, 76, 77, 78, 79, 80, 82, 85, 86, 87, 88, 90, 91, 92, 93, 94, 96, 97, 99], "helpless": [31, 51, 75], "henc": [23, 24, 26, 28, 43, 44, 46, 68, 70, 72], "henri": 59, "her": [13, 20, 30, 31, 51, 52, 59, 74, 75, 83], "here": [1, 4, 5, 6, 8, 9, 10, 11, 13, 14, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 55, 56, 57, 58, 59, 60, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 79, 80, 83, 84, 85, 86, 87, 88, 90, 91, 92, 93, 97, 99], "herebi": 0, "hero": 59, "heroin": 59, "herself": [52, 83], "hershey\u00f5": 96, "herta": 62, "hesist": [35, 56, 79], "hesit": [35, 56, 79], "heurist": [14, 22, 60, 66], "hf_hub_disable_symlinks_warn": 31, "hi": [20, 41, 52, 59, 83, 87, 93], "hidden": [27, 31, 32, 35, 51, 52, 56, 59, 75, 76, 79, 82], "hide": [9, 31, 32, 51, 60, 75, 76], "hier_label": [29, 73], "hier_labels1": [29, 73], "hier_labels2": [29, 73], "hierarch": [12, 85], "hierarchi": [14, 29, 60, 73], "high": [7, 12, 13, 14, 15, 16, 17, 20, 21, 22, 23, 24, 25, 26, 27, 29, 30, 31, 33, 34, 35, 36, 40, 42, 43, 44, 45, 46, 51, 52, 56, 59, 60, 61, 62, 65, 66, 67, 68, 69, 70, 71, 73, 74, 75, 77, 78, 79, 80, 82, 93], "high_corr": [26, 46, 70], "higher": [14, 15, 16, 21, 23, 24, 25, 26, 27, 28, 30, 34, 35, 36, 43, 44, 45, 46, 54, 56, 60, 61, 62, 65, 67, 68, 69, 70, 71, 72, 74, 78, 79, 80, 81, 87, 93, 98], "highest": [20, 25, 26, 30, 31, 32, 35, 41, 45, 46, 50, 51, 52, 56, 69, 70, 74, 75, 76, 79, 84, 87, 93], "highli": [1, 18, 20, 26, 30, 41, 46, 50, 63, 70, 74, 85, 94], "highlight": [4, 35, 56, 79], "hight": 67, "highwai": [21, 65], "hilari": [20, 59], "him": [20, 52, 59, 83], "himanshu": [1, 99], "himself": [52, 59, 83], "hindi": [18, 63], "hint": [26, 70, 87, 93], "hire": 59, "hist": [17, 18, 22, 24, 27, 34, 40, 42, 44, 47, 54, 63, 66, 68, 71, 78], "histgradientboostingclassifi": [18, 25, 45, 69], "histgradientboostingregressor": [25, 45, 69], "histogram": [34, 42, 54, 66, 78], "histor": 85, "histori": [13, 21, 30, 33, 50, 53, 59, 65, 74, 77, 99], "hit": [22, 59, 66], "hl": [24, 26, 35, 44, 46, 55, 56, 68, 70, 79], "hmid": [36, 57, 58, 80, 81], "hmmm": [34, 54, 59, 78], "hobart": 97, "hockei": [31, 51, 52, 75], "hold": [17, 20, 31, 35, 36, 40, 51, 56, 59, 75, 79, 80], "holder": 0, "holdout": 67, "hole": 59, "holi": [35, 56, 79], "holidai": [30, 50, 74, 99], "holist": [90, 96], "holliman": 59, "home": [14, 17, 21, 32, 36, 40, 57, 58, 60, 65, 76, 80, 81], "homemak": [31, 51, 52, 75], "homepag": 1, "homework": [1, 3, 4, 6, 7, 9, 11, 22, 36, 52, 57, 58, 62, 66, 80, 85, 99], "honest": [35, 55, 56, 79], "honestli": 59, "honour": 99, "hood": [15, 17, 36, 40, 51, 59, 61, 75, 80], "hook": [20, 41], "hoot": 41, "hope": [15, 31, 35, 36, 51, 56, 59, 61, 75, 79, 80], "hopefulli": [36, 80], "hopeless": [27, 71], "hopelessli": [16, 59, 62], "horizont": [14, 17, 19, 40, 60, 64], "horror": 20, "host": [6, 31, 34, 36, 51, 57, 58, 75, 78, 80], "hot": [15, 17, 19, 20, 26, 33, 40, 41, 61, 64, 70, 85, 91, 97], "hotchkin": 59, "hound": [32, 59, 76], "hour": [4, 5, 6, 11, 25, 26, 30, 33, 36, 45, 46, 50, 67, 69, 70, 71, 74, 77, 80, 85, 99], "hourli": [34, 78, 85], "hous": [14, 24, 26, 27, 34, 35, 38, 44, 45, 46, 47, 55, 56, 68, 70, 71, 78, 79], "houseag": [21, 65], "household": [18, 21, 27, 47, 63, 64, 65, 71, 88, 94], "housestyl": [24, 26, 35, 44, 46, 55, 56, 68, 70, 79], "housestyle_1": [24, 68, 70], "housestyle_1stori": [24, 68, 70], "housestyle_2": [24, 68, 70], "housestyle_2stori": [24, 68, 70], "housestyle_sfoy": [24, 68, 70], "housestyle_slvl": [24, 68, 70], "housewif": [31, 51, 52, 75], "housing_df": [15, 18, 27, 38, 47, 60, 63, 64, 71, 88, 94], "housing_median_ag": [18, 27, 47, 63, 64, 71, 94], "how": [0, 3, 9, 12, 13, 19, 20, 22, 23, 24, 28, 30, 31, 33, 34, 36, 38, 39, 42, 43, 44, 48, 50, 51, 52, 53, 54, 55, 59, 64, 66, 67, 68, 72, 74, 75, 77, 78, 80, 82, 83, 84, 85, 86, 87, 89, 90, 91, 92, 93, 95, 96, 97, 99], "howard": [28, 72], "howarth": 59, "howev": [2, 6, 9, 18, 19, 20, 24, 26, 28, 30, 33, 34, 36, 39, 44, 53, 54, 57, 58, 59, 63, 64, 67, 68, 70, 72, 74, 77, 78, 80, 84, 87, 93, 94, 99], "hp": [16, 25, 26, 28], "href": [23, 43], "hsjcy": [34, 78], "hstack": [33, 77], "ht": [16, 25, 26, 28], "html": [8, 10, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 32, 34, 35, 36, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 76, 78, 79, 80, 81, 82, 86, 88, 92, 94, 95], "http": [0, 6, 9, 10, 11, 13, 15, 16, 18, 20, 21, 22, 23, 29, 31, 32, 33, 34, 35, 36, 39, 41, 43, 48, 51, 54, 56, 57, 58, 61, 63, 65, 67, 75, 76, 77, 78, 79, 80, 81, 90, 96], "hub": [6, 31], "hug": [30, 50, 74], "huge": [19, 24, 31, 32, 33, 34, 44, 52, 53, 54, 64, 68, 75, 76, 77, 78, 91, 97], "huggingfac": 31, "huggingface_hub": 31, "human": [0, 13, 18, 19, 20, 21, 22, 26, 27, 28, 31, 32, 41, 46, 47, 49, 51, 52, 59, 62, 63, 64, 65, 66, 67, 70, 71, 72, 75, 76], "humidity3pm": [53, 77, 91, 97], "humidity3pm_lag1": [53, 77, 91, 97], "humidity9am": [53, 77, 91, 97], "hummu": [31, 51, 52, 72, 75], "humor": 59, "humour": [1, 20, 52], "hundlei": [90, 96], "hundr": [21, 31, 51, 65, 75], "hungri": [17, 40], "hurdl": 40, "hurrai": [89, 95], "hurrican": 59, "husband": [25, 26, 45, 46, 67, 69, 70], "hussar": [32, 59, 76], "hw": 59, "hw1": [1, 4, 92], "hw2": [1, 18, 62, 63], "hw3": 1, "hw4": 1, "hw5": 1, "hw6": [1, 31, 51, 75], "hw6a": 8, "hw6b": 8, "hw7": 1, "hw8": 1, "hw9": 1, "hybrid": [30, 74], "hyper": [35, 42, 56, 79], "hyperband": [22, 42, 66], "hyperopt": [22, 42, 66], "hyperparamet": [1, 20, 23, 29, 30, 31, 32, 35, 36, 39, 41, 43, 50, 51, 52, 56, 61, 67, 73, 74, 75, 76, 79, 80, 92], "hyperparameter_": [35, 56, 79], "hyperparamt": [15, 22, 34, 61, 66, 78], "hyperparlan": [21, 65], "hyperplan": [21, 65], "hypothesi": [34, 36, 52, 78, 80], "hypothet": [21, 27, 28, 65, 72, 98], "i": [0, 1, 2, 6, 7, 8, 9, 10, 11, 12, 14, 16, 17, 20, 21, 24, 29, 32, 33, 34, 38, 39, 40, 41, 42, 44, 48, 49, 50, 51, 53, 54, 55, 60, 62, 65, 68, 73, 76, 77, 78, 81, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 99], "i1": [45, 69], "i2": [45, 69], "ic": [31, 51, 52, 75], "icc": [1, 99], "ici": 59, "iclick": [1, 5], "icon": 20, "id": [13, 15, 24, 26, 27, 30, 34, 35, 38, 44, 46, 50, 55, 56, 59, 60, 68, 70, 74, 79, 99], "idea": [9, 14, 15, 17, 18, 20, 22, 23, 26, 28, 29, 30, 32, 33, 34, 36, 38, 39, 40, 43, 46, 47, 50, 52, 53, 54, 57, 58, 59, 60, 61, 63, 66, 70, 71, 72, 73, 74, 76, 77, 78, 80, 85, 87, 91, 93, 97], "ideal": [4, 8, 17, 23, 25, 27, 30, 34, 36, 40, 43, 45, 50, 54, 57, 58, 67, 69, 71, 74, 78, 80], "ident": [13, 32, 39, 48, 49, 52, 59, 76], "identif": [13, 59], "identifi": [11, 12, 14, 15, 18, 20, 22, 23, 24, 28, 29, 31, 32, 34, 35, 36, 38, 41, 43, 44, 49, 51, 52, 53, 55, 56, 60, 62, 63, 66, 67, 68, 72, 73, 75, 76, 77, 79, 80, 83, 85, 90, 91, 94, 96, 97], "idf": [19, 31, 51, 64, 75], "idli": 52, "idx": 39, "idxmax": [15, 16, 38, 41, 62], "if_binari": [17, 19, 25, 26, 40, 45, 46, 64, 67, 69, 70, 85, 88, 89, 94, 95], "ifram": [15, 31, 51, 61, 67, 75], "igloo": 52, "ignor": [14, 15, 16, 17, 18, 19, 21, 22, 23, 24, 25, 26, 27, 28, 29, 31, 32, 34, 35, 40, 42, 43, 44, 45, 46, 51, 52, 53, 54, 55, 56, 59, 60, 62, 63, 64, 65, 66, 67, 68, 69, 70, 75, 76, 77, 78, 79, 83, 85, 89, 91, 94, 95, 97], "ignore_index": 9, "ii": [23, 43, 67], "iidqv": 34, "iii": 1, "ij": [20, 21, 30, 41, 50, 65, 74], "ik": [45, 69], "iliad": 41, "ill": 99, "illus": 67, "illustr": [29, 33, 73, 77], "iloc": [9, 14, 16, 18, 19, 20, 25, 26, 31, 41, 45, 46, 51, 52, 53, 60, 61, 62, 63, 64, 69, 70, 75, 86, 89, 92, 95], "im": [31, 51, 75], "imag": [8, 12, 18, 23, 26, 27, 28, 29, 32, 33, 35, 43, 46, 47, 49, 53, 56, 61, 67, 70, 71, 72, 73, 76, 77, 79, 81, 82, 85], "image2": [31, 51, 75], "image_dataset": [32, 39, 48, 49, 76], "image_fil": [39, 48, 49], "image_s": [39, 48, 49], "image_shap": 48, "imagefold": [39, 48, 49], "imagenet": [32, 76, 84], "imagenet1k_v1": [32, 39, 48, 49, 76], "imagenet_class": [13, 32, 59, 76], "imagin": [1, 13, 14, 18, 21, 23, 26, 27, 28, 31, 34, 35, 36, 43, 46, 47, 51, 52, 56, 59, 60, 61, 63, 65, 67, 70, 71, 72, 75, 78, 79, 80, 85, 86, 92], "imaginari": [15, 52, 61, 85], "imbal": [23, 28, 34, 43, 72, 78], "imbalanc": [23, 24, 43, 67, 68, 81, 84], "imblearn": 81, "imdb": [13, 20, 41], "imdb_df": [13, 20, 41, 59], "imdb_mast": [13, 20, 41, 59], "img": [13, 32, 39, 48, 59, 76], "img_classifi": [13, 59], "img_ind": 39, "img_path": [13, 59], "imit": 59, "immacul": 59, "immatur": [31, 51, 75], "immedi": [17, 26, 30, 34, 40, 50, 70, 74, 99], "imp": [18, 33, 63, 64, 77], "impact": [12, 19, 21, 25, 26, 29, 31, 33, 35, 45, 46, 51, 56, 64, 65, 69, 70, 73, 75, 77, 79, 87, 91, 93, 97], "implement": [2, 4, 18, 24, 25, 27, 29, 30, 31, 34, 35, 36, 40, 44, 45, 50, 51, 52, 54, 56, 60, 63, 68, 69, 71, 73, 74, 75, 78, 79, 80, 81, 84], "impli": [0, 34, 78], "implic": [12, 17, 18, 36, 59, 63, 80, 85], "implicit": [31, 51, 52, 75], "import": [9, 12, 20, 48, 49, 81, 82, 83, 84, 88, 89, 90, 94, 95, 96, 98, 99], "importance_typ": [25, 45, 46, 69, 70, 95], "importances_mean": [26, 46, 70], "impos": [18, 59, 63], "imposs": [28, 59, 72], "impr": 20, "impress": [26, 46, 59, 70], "impression": 20, "improv": [12, 15, 17, 18, 22, 23, 24, 25, 27, 28, 29, 30, 32, 33, 34, 35, 36, 38, 40, 43, 44, 45, 47, 53, 56, 59, 66, 67, 68, 69, 71, 72, 73, 74, 76, 77, 78, 79, 80, 82, 85, 92], "impur": [14, 15, 25, 38, 45, 46, 60, 69, 86, 92], "imput": [15, 17, 19, 20, 21, 22, 24, 25, 26, 27, 28, 33, 34, 35, 36, 40, 42, 44, 45, 46, 47, 53, 54, 55, 56, 61, 64, 65, 66, 67, 68, 69, 70, 71, 72, 77, 78, 79, 80, 85, 88, 89, 91, 94, 95, 97], "imread": [32, 76], "imshow": [13, 32, 39, 48, 49, 59, 76], "imtiaz": 1, "inabl": 13, "inappropri": 77, "inbox": [15, 61], "inc": [26, 45, 52, 70, 83], "incept": [30, 32, 50, 74, 76], "inception": [32, 76], "inch": 59, "incl": [24, 44, 68], "includ": [0, 1, 2, 4, 5, 6, 7, 8, 9, 11, 12, 13, 14, 18, 19, 23, 24, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 39, 42, 43, 44, 47, 51, 52, 53, 54, 56, 60, 63, 64, 67, 68, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 83, 85, 87, 88, 89, 90, 91, 93, 94, 95, 96, 97, 99], "include_bia": [27, 33, 47, 71, 77], "incom": [15, 21, 25, 26, 28, 45, 46, 61, 65, 67, 69, 70], "incomplet": [34, 78], "inconsist": [1, 19, 64], "incorpor": [5, 22, 24, 27, 34, 36, 44, 47, 54, 66, 68, 71, 78, 80, 85], "incorrect": [34, 35, 54, 56, 78, 79], "incorrectli": [13, 23, 43, 59, 67], "increament": [36, 80], "increas": [9, 15, 16, 19, 20, 21, 25, 26, 27, 28, 29, 32, 38, 41, 45, 46, 47, 61, 62, 64, 65, 69, 70, 71, 72, 73, 76, 87, 92, 93], "increasingli": [13, 59], "incred": [32, 76], "incredibli": 20, "increment": [36, 42, 66, 80, 90, 96], "inde": [26, 46, 59, 70], "independ": [9, 10, 14, 22, 24, 25, 27, 31, 32, 33, 42, 44, 45, 51, 59, 60, 66, 68, 69, 75, 76, 77, 82, 94], "index": [13, 14, 15, 16, 17, 18, 19, 20, 21, 23, 24, 25, 26, 27, 29, 30, 31, 32, 33, 34, 35, 38, 39, 40, 41, 43, 44, 45, 46, 47, 49, 50, 51, 53, 54, 55, 56, 59, 60, 61, 62, 63, 64, 65, 67, 68, 69, 70, 71, 73, 74, 75, 76, 77, 78, 79, 87, 89, 91, 93, 95, 96, 97], "index_col": [9, 18, 22, 30, 36, 42, 50, 57, 58, 62, 63, 66, 74, 80, 81], "india": 52, "indian": [17, 40, 67], "indian_liver_pati": [13, 59], "indic": [0, 17, 19, 20, 28, 30, 33, 34, 40, 41, 48, 49, 50, 51, 52, 54, 64, 72, 74, 75, 77, 78, 91, 97], "indirectli": [56, 79], "individu": [17, 25, 26, 28, 30, 31, 34, 36, 40, 45, 46, 51, 52, 54, 69, 70, 72, 74, 75, 78, 80, 89, 95, 96, 99], "induc": 59, "industri": [25, 27, 31, 32, 47, 52, 59, 69, 71, 75, 76, 83, 93], "inequ": 67, "inertia_": [28, 72], "inertia_valu": [28, 72], "inf": [16, 34, 49, 62, 78], "infatu": 59, "infeas": [22, 42, 66], "infer": [31, 32, 33, 36, 51, 52, 53, 60, 75, 76, 77, 80, 86, 92], "infiltr": 41, "infin": [16, 35, 56, 62, 79], "infinit": [22, 66], "inflamm": 10, "inflat": [26, 46, 70], "inflect": [28, 31, 51, 52, 72, 75, 83], "influenc": [14, 15, 20, 22, 26, 28, 30, 34, 42, 46, 54, 60, 61, 66, 70, 72, 74, 77, 78, 87, 93], "info": [1, 9, 17, 18, 19, 23, 24, 27, 31, 34, 43, 44, 47, 51, 52, 53, 54, 63, 64, 67, 68, 71, 75, 77, 78, 87, 88, 89, 91, 93, 95, 97], "infom": [31, 51, 52, 75], "infor_m": [31, 51, 52, 75], "inform": [1, 4, 5, 8, 14, 17, 18, 19, 21, 22, 23, 24, 25, 27, 28, 29, 30, 31, 32, 34, 35, 36, 39, 40, 42, 43, 45, 47, 50, 51, 52, 53, 54, 56, 57, 58, 59, 60, 63, 64, 65, 66, 67, 68, 69, 71, 72, 73, 74, 75, 76, 78, 79, 80, 82, 83, 87, 88, 89, 90, 91, 93, 95, 96, 97, 99], "informa_t": [31, 51, 52, 75], "informaion": [31, 51, 52, 75], "informaiton": [31, 51, 52, 75], "informationabout": [31, 51, 52, 75], "informationon": [31, 51, 52, 75], "ingrid": 20, "inhabit": 99, "inher": [14, 33, 34, 67, 77, 78], "initi": [29, 39, 73], "initj": [26, 46, 70], "inject": [27, 30, 47, 50, 74, 82, 85], "ink": [35, 55, 56, 79], "inland": [18, 27, 47, 63, 64, 71, 94], "inlin": [13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 29, 38, 39, 40, 41, 42, 43, 44, 45, 46, 50, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 73, 74, 81, 82, 86, 87, 89, 90, 92, 93, 95, 96], "inner": [19, 22, 31, 42, 51, 52, 64, 66, 75], "innoc": 59, "inplac": [9, 13, 20, 22, 42, 59, 60, 66], "input": [9, 14, 17, 18, 21, 25, 26, 29, 31, 32, 33, 34, 36, 39, 40, 41, 42, 45, 48, 49, 51, 52, 53, 57, 58, 60, 63, 64, 65, 66, 69, 70, 73, 75, 76, 77, 80, 83, 85, 91, 96, 97], "input_img": [32, 76], "input_nam": [18, 34], "insid": [10, 11, 19, 23, 40, 43, 59, 64, 67], "insight": [2, 12, 16, 23, 26, 28, 43, 46, 62, 67, 70, 72], "insist": 59, "inspct": [45, 67], "inspect": [26, 29, 46, 70, 73], "inspir": [25, 45, 60, 69, 81, 90, 96], "instagram": [13, 59], "instal": [3, 13, 23, 24, 25, 26, 28, 31, 32, 34, 36, 39, 43, 44, 45, 46, 48, 49, 51, 52, 54, 57, 58, 59, 62, 67, 68, 69, 70, 72, 75, 76, 78, 80, 81], "instanc": [13, 14, 15, 18, 19, 20, 21, 23, 28, 29, 30, 32, 33, 34, 39, 43, 50, 52, 59, 60, 61, 64, 65, 67, 72, 73, 74, 76, 77, 81, 83, 84], "instanti": [15, 22, 38, 42, 66, 87, 93], "instead": [6, 9, 11, 13, 14, 17, 18, 19, 21, 22, 23, 24, 25, 27, 28, 29, 30, 31, 32, 34, 35, 43, 44, 45, 47, 50, 51, 52, 54, 55, 56, 59, 60, 61, 63, 64, 65, 66, 67, 68, 69, 71, 72, 73, 74, 75, 76, 77, 78, 79, 81, 84, 87, 89, 91, 93, 95, 97], "instinct": [31, 51, 75], "institut": [52, 59, 83], "instruct": [3, 4, 5, 6, 11, 13, 35, 36, 56, 57, 58, 62, 79, 80, 99], "instructor": [4, 5, 7, 11, 13, 35, 36, 56, 59, 79, 80, 99], "instrument": [18, 22, 42, 62, 63, 66], "insuffici": 59, "int": [18, 19, 25, 26, 31, 33, 45, 46, 51, 52, 53, 63, 64, 67, 69, 70, 75, 77, 89, 90, 91, 93, 95, 96, 97], "int32": [29, 33, 62, 72, 73, 77], "int64": [14, 15, 17, 19, 20, 23, 24, 25, 30, 31, 33, 34, 36, 38, 40, 41, 42, 43, 44, 51, 52, 53, 54, 57, 58, 59, 60, 62, 63, 64, 66, 67, 68, 74, 75, 76, 77, 78, 80, 93, 95, 97], "integ": [9, 18, 22, 25, 26, 33, 45, 46, 63, 66, 69, 70, 77, 94], "integr": [12, 31, 36, 75, 80, 99], "intellig": [1, 13, 31, 51, 52, 59, 75], "intelligen": 52, "intend": [0, 35, 56, 79, 99], "intens": [20, 31, 51, 52, 75], "intent": [51, 75], "intention": 98, "interact": [10, 13, 16, 22, 23, 26, 28, 29, 30, 33, 36, 39, 43, 46, 50, 57, 58, 62, 66, 67, 70, 72, 73, 74, 77, 80, 87, 93], "interaction_constraint": [25, 45, 69], "interaction_onli": [27, 33, 47, 71, 77], "interactive_plot": [16, 62, 87, 93], "intercept": [26, 32, 46, 70, 76, 84], "intercept_": [21, 25, 32, 45, 65, 69, 76, 84], "intercept_sc": [41, 43, 45, 67, 69, 76, 95], "interest": [2, 13, 15, 17, 22, 23, 24, 25, 26, 27, 29, 30, 31, 32, 33, 34, 36, 40, 43, 44, 45, 50, 52, 53, 54, 59, 61, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 80, 81, 83, 89, 91, 95, 97], "interfac": [6, 25, 31, 36, 45, 51, 57, 58, 69, 75, 80], "intermedi": [29, 32, 73, 76], "intern": [0, 1, 14, 32, 33, 34, 60, 76, 77, 78], "internet": [34, 35, 36, 54, 55, 56, 57, 58, 78, 79, 80], "internetservic": [34, 54, 78], "internetservice_dsl": [34, 54, 78], "internetservice_fib": [34, 54, 78], "internetservice_no": [34, 54, 78], "internship": [13, 59], "interpret": [1, 11, 12, 16, 18, 23, 24, 25, 27, 29, 30, 31, 32, 34, 35, 38, 43, 44, 45, 47, 50, 51, 52, 54, 62, 63, 67, 68, 69, 71, 72, 73, 74, 75, 76, 78, 79, 90, 96], "interrupt": 34, "interv": [12, 33, 34, 54, 77, 78, 85], "interweb": [36, 57, 58, 80], "intraop": 32, "intrigu": 59, "intrins": [33, 77], "intro": [1, 32, 52, 76], "introduc": [19, 31, 34, 51, 64, 75, 78, 81], "introduct": [1, 10, 11, 12, 15, 33, 34, 38, 52, 54, 77, 78], "intslid": [16, 62, 87, 93], "intuit": [12, 16, 18, 19, 22, 24, 26, 28, 29, 31, 32, 34, 44, 46, 51, 54, 62, 63, 64, 66, 68, 70, 72, 73, 75, 76, 78, 85], "invad": [31, 51, 75], "invalid": 60, "invari": [32, 76], "invent": 59, "inventor": 59, "inventori": 85, "invers": [21, 24, 44, 65, 68], "inverse_func": [24, 35, 44, 55, 56, 68, 79], "invest": 41, "investig": [16, 26, 39, 46, 62, 70, 87, 93], "involv": [2, 4, 13, 22, 24, 25, 29, 31, 32, 35, 42, 44, 45, 46, 52, 59, 66, 68, 69, 73, 75, 76], "io": [10, 18, 32, 34, 39, 48, 54, 63, 76, 78], "iprint": [54, 78], "ipykernel_24444": 34, "ipykernel_24648": 63, "ipykernel_27559": 70, "ipykernel_35319": 46, "ipynb": [5, 8, 9, 11, 13, 52, 90, 96], "ipython": [13, 14, 15, 16, 18, 19, 20, 21, 23, 31, 43, 51, 52, 59, 60, 61, 62, 63, 64, 65, 67, 75, 81, 82, 86, 88, 92, 94], "ipywidget": [16, 39, 62, 87, 93], "ir1": [24, 26, 35, 44, 46, 55, 56, 68, 70, 79], "ir2": [24, 26, 35, 44, 46, 55, 56, 68, 70, 79], "iri": [16, 39, 62, 87, 93], "iris_df": [16, 39, 62, 87, 93], "irregular": [12, 77], "irregularli": 85, "irrelev": [16, 27, 31, 47, 51, 52, 62, 71, 75, 82, 93], "irrelevant_po": [31, 51, 52, 75], "irrespect": [15, 21, 61, 65, 99], "is_avail": [32, 39, 48, 49, 76], "is_classifi": 18, "is_leap_year": [53, 77, 91, 97], "is_stop": [31, 51, 52, 75], "is_year_end": [53, 77, 91, 97], "isinst": [18, 34, 78], "island": [18, 63, 64], "isn": [11, 16, 24, 25, 44, 45, 52, 56, 59, 61, 62, 67, 68, 69, 79, 83], "isna": 20, "isnul": [17, 18, 40, 63], "iso": [13, 20, 41, 59], "isol": [11, 24, 26, 35, 68, 70, 79, 81], "issu": [7, 13, 25, 30, 32, 34, 38, 45, 46, 50, 69, 71, 74, 76, 78, 85, 99], "issubclass": [34, 78], "itali": [25, 52, 83], "italian": [17, 40], "item": [13, 25, 26, 28, 30, 31, 34, 39, 45, 46, 50, 52, 59, 69, 70, 72, 74, 75, 78, 85, 89, 95], "item_inverse_mapp": [30, 50, 74], "item_kei": [30, 50, 74], "item_mapp": [30, 50, 74], "iter": [22, 27, 28, 29, 32, 34, 36, 39, 42, 47, 48, 49, 66, 71, 72, 73, 76, 77, 80, 90, 96], "iterable_with_config": [19, 34], "iterable_with_config_and_warning_filt": 64, "iterrow": [30, 50, 74], "its": [9, 12, 13, 16, 17, 18, 19, 20, 21, 26, 28, 29, 31, 32, 33, 34, 39, 40, 51, 52, 53, 54, 59, 61, 62, 64, 65, 67, 70, 72, 73, 75, 76, 77, 78, 81, 83, 84, 87, 90, 92, 93, 96, 99], "itself": [8, 25, 29, 45, 52, 59, 67, 69, 73, 83], "j": [9, 21, 26, 27, 28, 30, 32, 46, 47, 50, 65, 70, 71, 72, 74, 76], "jackin": 66, "jackpot": [19, 64], "jaguar": [32, 59, 76], "jake": [20, 41], "jalebi": 52, "jam": 66, "jame": [31, 34, 51, 52, 54, 75, 78], "jane": 59, "januari": [33, 53, 77, 97], "japan": [31, 51, 52, 75], "jargon": [14, 60], "jason": [1, 27, 71], "javascript": [26, 46, 70], "jazz_musician": [31, 51, 52, 75], "jellyfish": [32, 76], "jerki": 59, "jerri": [30, 50, 74], "jest": [31, 51, 75], "jet": 63, "jetti": [32, 76], "jieba": [52, 83], "jim": [30, 50, 74], "jmlr": [22, 42, 66], "joan_baez": [31, 51, 52, 75], "joanna": 20, "job": [19, 20, 34, 48, 53, 59, 64, 77, 78, 91, 97], "joblib": [16, 19, 25, 26, 28, 34, 36, 57, 58, 64, 80], "jobson": 41, "joei": [17, 40], "john": [20, 25, 45, 59, 69], "johnny_cash": [31, 51, 52, 75], "joi": [31, 51, 75], "join": [13, 14, 15, 16, 17, 18, 19, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 89, 90, 91, 92, 93, 95, 96, 97], "jointli": [33, 77], "joke": [20, 30, 59, 74], "jon": 20, "joni_mitchel": [31, 51, 52, 75], "joseph": [1, 99], "joss": 20, "journal": [31, 51, 52, 75], "journei": [1, 29, 31, 51, 73, 75, 99], "joy": [31, 51, 75], "jpg": [32, 39, 48, 49, 76], "jr": 59, "json": [36, 57, 58, 80], "ju": 59, "jubatu": [32, 59, 76], "judg": [27, 47, 71], "judgment": [35, 56, 79], "juic": [31, 51, 52, 75], "juli": [53, 77, 97], "jump": [13, 59], "jun": [1, 99], "june": [53, 77, 97], "junior": 96, "jupyt": [1, 8, 9, 10, 11, 15, 17, 18, 19, 20, 22, 23, 24, 25, 26, 27, 32, 35, 36, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 55, 56, 57, 58, 59, 63, 64, 66, 67, 68, 69, 70, 71, 76, 79, 80, 95], "jupyter_notebook": [34, 78], "jupyterlab": [5, 26, 39, 46, 70], "jurafski": [31, 51, 52, 75], "juri": 99, "jurisdict": [31, 51, 52, 75], "just": [4, 8, 9, 13, 14, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 31, 33, 34, 35, 36, 39, 40, 41, 43, 44, 45, 46, 47, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 75, 77, 78, 79, 80, 82, 83, 87, 89, 91, 93, 94, 95, 97, 99], "justic": [26, 46, 52, 70], "justif": [89, 95], "justifi": 5, "k": [1, 8, 12, 15, 20, 21, 24, 27, 31, 32, 34, 36, 39, 41, 44, 45, 47, 48, 49, 51, 52, 54, 61, 65, 68, 69, 71, 75, 76, 77, 78, 80, 81, 84, 87, 91, 93, 97], "k_neighbor": 81, "k_valu": [16, 62], "kaggl": [13, 18, 23, 24, 25, 26, 27, 35, 39, 43, 44, 46, 47, 55, 56, 60, 63, 67, 68, 69, 70, 71, 76, 79, 89, 90, 95, 96], "kaggler": [27, 47, 71], "kangaroo": [32, 76], "kanwal": [1, 99], "kaplan": 12, "kaplanmeierfitt": [34, 54, 78], "katherin": 97, "kathleen": 20, "kazmi": [1, 99], "kb": [17, 19, 24, 34, 44, 54, 64, 68, 78, 93, 95], "kbinsdiscret": [27, 47, 71], "kbinsdiscretizer__latitude_0": [27, 47, 71], "kbinsdiscretizer__latitude_1": [27, 47, 71], "kbinsdiscretizer__latitude_2": [27, 47, 71], "kbinsdiscretizer__latitude_3": [27, 47, 71], "kbinsdiscretizer__latitude_4": [27, 47, 71], "kbinsdiscretizer__latitude_5": [27, 47, 71], "kbinsdiscretizer__latitude_6": [27, 47, 71], "kbinsdiscretizer__latitude_7": [27, 47, 71], "kbinsdiscretizer__latitude_8": [27, 47, 71], "kbinsdiscretizer__latitude_9": [27, 47, 71], "kbinsdiscretizer__longitude_11": [27, 47, 71], "kbinsdiscretizer__longitude_12": [27, 47, 71], "kbinsdiscretizer__longitude_13": [27, 47, 71], "kbinsdiscretizer__longitude_14": [27, 47, 71], "kbinsdiscretizer__longitude_15": [27, 47, 71], "kbinsdiscretizer__longitude_16": [27, 47, 71], "kbinsdiscretizer__longitude_17": [27, 47, 71], "kbinsdiscretizer__longitude_18": [27, 47, 71], "kbinsdiscretizer__longitude_19": [27, 47, 71], "kbinsdiscretizerkbinsdiscret": [27, 47, 71], "kc_house_data": [13, 15, 38, 59, 60], "kdtree": 18, "keep": [1, 5, 11, 15, 16, 18, 19, 20, 23, 25, 26, 27, 30, 31, 34, 36, 38, 40, 43, 45, 46, 47, 50, 51, 52, 54, 59, 61, 62, 63, 64, 67, 69, 70, 71, 72, 74, 75, 78, 80, 87, 88, 93, 94], "keep_empty_featur": [30, 40, 45, 46, 50, 63, 64, 68, 69, 70, 74], "kei": [5, 6, 10, 12, 14, 16, 18, 22, 23, 24, 25, 30, 31, 34, 42, 43, 44, 45, 50, 51, 52, 54, 60, 62, 63, 66, 67, 68, 69, 74, 75, 78, 89, 95, 99], "keith": 59, "kelbowvisu": [28, 72, 90, 96], "kellei": [21, 65], "kept": [15, 61], "kera": [26, 46, 70], "kernel": [1, 8, 11, 18, 21, 22, 26, 27, 32, 35, 39, 42, 43, 46, 47, 56, 63, 64, 65, 66, 70, 71, 76, 79, 87, 93], "kernelexplain": [26, 46, 70], "keyedvector": [31, 51, 75], "keyword": [4, 22, 66], "kfold": 67, "kick": [31, 52, 75], "kid": 59, "kiddi": 41, "kidnappe": 41, "kilian": [26, 46, 70], "kill": [34, 59, 78], "killer": [20, 59], "kimia": [1, 99], "kind": [0, 13, 14, 15, 18, 19, 20, 21, 23, 24, 26, 28, 29, 30, 32, 33, 34, 36, 43, 44, 46, 53, 59, 60, 61, 63, 64, 65, 67, 68, 70, 72, 73, 74, 76, 77, 78, 80, 81, 84, 88], "king": [15, 30, 31, 38, 50, 51, 52, 74, 75], "kingdom": 59, "kingslei": 20, "kiss": [25, 96], "kitchenabvgr": [24, 26, 35, 44, 46, 55, 56, 68, 70, 79], "kitchenqu": [24, 26, 35, 44, 46, 55, 56, 68, 70, 79], "kiwi": [31, 51, 52, 75, 98], "kk": [28, 72], "klbuhzv_ofw": [31, 51, 75], "klimt": 25, "km": [34, 48, 49, 51, 54, 56, 75, 78, 79, 85], "km_flatten": 48, "km_label": [28, 72], "kmean": [28, 29, 48, 49, 51, 72, 73, 75, 85, 90, 96], "kmeans_bow": [51, 75], "kmeans_bow_label": [51, 75], "kmeansifittedkmean": [48, 49], "kmf": [34, 54, 78], "kmqfw": [34, 78], "kneighbor": 39, "kneighborregressor": [18, 63], "kneighborsclassifi": [17, 18, 19, 21, 27, 40, 47, 63, 64, 65, 71, 87, 88, 93, 94, 95], "kneighborsclassifierifit": 40, "kneighborsclassifierifittedkneighborsclassifi": 17, "kneighborsclassifierkneighborsclassifi": 17, "kneighborsregressor": [17, 18, 19, 21, 63, 64, 65, 88, 94], "kneighborsregressorkneighborsregressor": 18, "knew": [28, 31, 51, 72, 75], "knn": [2, 15, 16, 18, 21, 26, 27, 30, 32, 36, 46, 47, 50, 61, 62, 63, 64, 65, 70, 71, 74, 76, 80, 84, 85, 89, 95], "knn1": [16, 62], "knn100": [16, 62], "knn_pipe": [64, 94], "knn_scale": [18, 63], "knn_score": 95, "knn_unscal": [18, 63], "knn_valid_accuraci": [16, 62], "knncolumntransform": 95, "knnimput": [30, 50, 74], "knob": [14, 35, 56, 60, 79], "knock": [20, 59], "know": [1, 9, 11, 13, 14, 16, 18, 19, 21, 22, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 41, 42, 44, 45, 46, 47, 50, 51, 52, 53, 54, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 82, 84, 85, 86, 90, 91, 92, 96, 97, 99], "knowledg": [9, 13, 14, 19, 22, 27, 28, 31, 35, 47, 51, 52, 56, 59, 60, 64, 66, 71, 72, 75, 79, 85], "knowleg": 85, "known": [30, 34, 39, 50, 52, 54, 67, 74, 78, 83], "koala": [32, 76], "kolhatkar": [0, 1, 14, 52, 83, 99], "ksatr": [34, 78], "kvarada": [1, 46, 51, 52, 54, 60, 61, 64, 70, 75, 76, 78, 83, 84], "kwantlen": [31, 51, 52, 75], "kwarg": [16, 18, 19, 25, 26, 28, 34, 61, 63, 64, 78], "l": [11, 20, 54, 78], "l1": [34, 54, 78], "l123": 4, "l17": 4, "l1_ratio": [41, 43, 45, 67, 69, 76, 95], "l2": [31, 34, 41, 43, 45, 52, 54, 67, 69, 75, 76, 78, 95], "l6": [31, 51, 75], "l9": 4, "la": [35, 56, 79], "lab": [11, 13, 28, 60, 61, 72], "lab1": [14, 15, 19, 60, 61, 64, 85], "lab2": [14, 15, 19, 60, 61, 64, 85], "lab3": [14, 15, 19, 60, 61, 64, 85], "lab4": [14, 15, 19, 60, 61, 64, 85], "label": [8, 9, 14, 15, 16, 18, 19, 23, 24, 26, 27, 29, 30, 31, 32, 33, 34, 38, 39, 40, 43, 44, 45, 46, 47, 49, 51, 52, 53, 54, 55, 60, 61, 62, 63, 64, 67, 68, 69, 70, 71, 73, 74, 75, 76, 77, 78, 83, 88, 90, 92, 94, 96, 98], "label_": [52, 83], "label_encod": [25, 26, 45, 46, 69, 70], "label_n_clust": [29, 73], "labelencod": [25, 26, 45, 46, 69, 70], "labels": [23, 28, 43, 67, 72], "labels_": [28, 29, 51, 72, 73, 75], "laboratori": 59, "lack": [15, 30, 32, 35, 50, 56, 59, 61, 74, 76, 79], "lag": [34, 78, 85], "lag_df": [33, 77], "lai": 59, "lakehead_univers": [31, 51, 52, 75], "lakeshor": [32, 76], "lakesid": [32, 76], "lakshmi25npathi": 13, "lamb": [17, 40], "lambda": [9, 14, 17, 21, 29, 33, 34, 40, 48, 53, 60, 65, 73, 77, 97], "land": [34, 78], "landcontour": [24, 26, 35, 44, 46, 55, 56, 68, 70, 79], "landcontour_bnk": [24, 44, 68, 70], "landcontour_hl": [24, 68, 70], "landcontour_low": [24, 68, 70], "landcontour_lvl": [24, 68, 70], "landmark": 85, "landsburi": 41, "landscap": [28, 31, 51, 52, 72, 75], "landslop": [24, 26, 35, 44, 46, 55, 56, 68, 70, 79], "landslope_gtl": [24, 26, 35, 46, 68, 70], "landslope_mod": [24, 26, 35, 46, 68, 70], "landslope_sev": [24, 26, 35, 46, 68, 70], "lang": 59, "langara_colleg": [31, 51, 52, 75], "langchain": [31, 51, 75], "languag": [2, 10, 18, 19, 30, 32, 36, 50, 63, 64, 74, 76, 80, 83], "language_enc": [18, 63], "language_english": [18, 63], "language_french": [18, 63], "language_hindi": [18, 63], "language_mandarin": [18, 63], "language_spanish": [18, 63], "language_vietnames": [18, 63], "laptop": [6, 11, 13, 36, 57, 58, 59, 80], "lar": 59, "larg": [13, 15, 16, 18, 20, 21, 23, 24, 28, 29, 32, 36, 38, 41, 42, 43, 44, 52, 57, 58, 59, 61, 62, 63, 65, 67, 68, 72, 73, 76, 80, 81, 85, 87, 93], "larger": [16, 18, 21, 22, 24, 25, 26, 28, 29, 31, 34, 42, 44, 45, 46, 51, 54, 60, 61, 62, 63, 65, 66, 68, 69, 70, 72, 73, 75, 78], "largest": [24, 44, 68, 87, 93], "larvatu": [32, 59, 76], "last": [9, 13, 14, 15, 17, 18, 19, 20, 26, 30, 31, 32, 34, 36, 39, 43, 46, 48, 49, 50, 51, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 67, 70, 74, 75, 76, 77, 78, 79, 80, 81, 87, 88, 89, 91, 93, 95, 97, 99], "last_row": 9, "lastp": [29, 73], "lat": [15, 38, 59, 60], "late": [13, 20, 81, 99], "latent": [30, 31, 32, 51, 52, 74, 75, 76], "latentdirichletalloc": [31, 51, 52, 75], "later": [11, 14, 19, 23, 32, 33, 36, 43, 59, 60, 64, 67, 76, 77, 80], "latest": [19, 34, 46, 54, 64, 70, 78], "latex": [4, 8, 13], "latin": [13, 23, 43, 59, 67, 81], "latitud": [16, 18, 21, 27, 47, 61, 62, 63, 64, 65, 71, 94], "latitude_0": [27, 47, 71], "latitude_1": [27, 47, 71], "latitude_10": [27, 47, 71], "latitude_11": [27, 47, 71], "latitude_12": [27, 47, 71], "latitude_13": [27, 47, 71], "latitude_14": [27, 47, 71], "latitude_15": [27, 47, 71], "latitude_16": [27, 47, 71], "latitude_17": [27, 47, 71], "latitude_18": [27, 47, 71], "latitude_19": [27, 47, 71], "latitude_2": [27, 47, 71], "latitude_3": [27, 47, 71], "latitude_4": [27, 47, 71], "latitude_5": [27, 47, 71], "latitude_6": [27, 47, 71], "latitude_7": [27, 47, 71], "latitude_8": [27, 47, 71], "latitude_9": [27, 47, 71], "latter": [24, 44, 68], "laudabl": 59, "laugh": [20, 59], "laughabl": 59, "launceston": 97, "launch": [11, 13, 39], "laura": 59, "law": [17, 31, 40, 51, 52, 75, 83], "lawsuit": [31, 51, 52, 75], "lawyer": [31, 51, 75], "layer": [13, 32, 39, 48, 49, 59, 76], "layout": [16, 62, 87, 93], "lazi": [16, 62], "lbfg": [41, 43, 45, 67, 69, 76, 95], "lda": [32, 76], "ldot": [22, 42, 66], "lead": [9, 15, 21, 24, 29, 30, 34, 35, 44, 52, 54, 56, 61, 65, 68, 73, 74, 78, 79], "leaf": [14, 29, 31, 51, 52, 60, 73, 75], "leaf_siz": [39, 40, 63, 64, 95], "leagu": [31, 51, 52, 75], "leak": [17, 18, 34, 40, 63, 78, 85], "leakag": 85, "leaner": 61, "learn": [2, 5, 10, 17, 40, 42, 45, 46, 47, 48, 50, 51, 52, 54, 57, 58, 81, 84, 85, 86, 87, 88, 89, 91, 92, 93, 94, 95, 97, 99], "learner": [16, 25, 45, 61, 62, 69], "learning_method": [31, 51, 52, 75], "learning_r": [25, 45, 46, 69, 70, 95], "learnxinyminut": 10, "least": [1, 4, 6, 14, 15, 16, 20, 23, 24, 26, 27, 28, 29, 41, 43, 44, 46, 47, 56, 59, 61, 62, 67, 68, 70, 71, 72, 73, 79, 89, 91, 95, 96, 97], "least_confident_i": [21, 65], "least_confident_x": [21, 65], "leav": [8, 14, 29, 32, 34, 35, 54, 56, 60, 73, 76, 78, 79, 84], "lectur": [6, 8, 9, 11, 85], "lecun": [26, 46, 70], "lee": [20, 26, 46, 70], "left": [8, 13, 22, 23, 24, 26, 28, 29, 31, 33, 34, 35, 36, 42, 43, 44, 51, 52, 54, 56, 59, 66, 67, 68, 72, 73, 75, 77, 78, 79], "legal": [0, 31, 51, 52, 75], "legend": [8, 9, 16, 21, 23, 24, 27, 28, 32, 33, 34, 35, 43, 44, 47, 53, 54, 55, 56, 62, 65, 67, 68, 71, 72, 76, 77, 78, 79, 84, 90, 96], "legitim": 99, "leisur": [36, 57, 58, 80, 81], "lemma": [31, 51, 52, 75, 83], "lemma_": [31, 51, 52, 75, 83], "lemmat": [31, 51, 52, 75, 83], "lemon": 72, "len": [13, 18, 22, 24, 25, 26, 29, 30, 31, 32, 33, 35, 39, 42, 43, 44, 45, 46, 48, 49, 50, 51, 52, 53, 55, 56, 61, 63, 66, 67, 68, 69, 70, 73, 74, 75, 76, 77, 79], "length": [14, 15, 16, 20, 21, 24, 26, 28, 29, 31, 33, 34, 38, 39, 44, 46, 51, 52, 53, 60, 61, 62, 65, 68, 70, 72, 73, 75, 77, 78, 87, 93, 97], "lens": 59, "leo": [25, 45, 69], "leoni": 20, "leopard": [32, 59, 76], "leq": [27, 28, 47, 71, 72], "less": [1, 7, 16, 19, 21, 22, 24, 25, 26, 27, 29, 30, 34, 35, 44, 45, 46, 47, 50, 54, 56, 59, 62, 64, 65, 66, 67, 68, 69, 70, 71, 73, 74, 78, 79, 85, 87, 93], "lesson": [10, 18, 60, 61, 62, 63, 64], "lesssim": [15, 61], "let": [6, 14, 15, 20, 21, 22, 25, 27, 28, 29, 30, 31, 32, 33, 34, 36, 38, 39, 41, 42, 45, 47, 49, 50, 51, 52, 53, 54, 57, 58, 59, 60, 61, 65, 66, 69, 71, 72, 73, 74, 75, 76, 77, 78, 80, 81, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 99], "letter": [21, 65], "lev": [24, 44, 68], "level": [12, 13, 16, 21, 24, 26, 27, 29, 31, 33, 35, 36, 44, 46, 49, 51, 52, 56, 59, 60, 62, 65, 67, 68, 69, 70, 71, 73, 75, 77, 79, 80], "leverag": [26, 30, 46, 50, 70, 74], "lexic": [31, 52, 75], "lgbm": [12, 25, 26, 45, 46, 69, 70, 85], "lgbm_classifi": 95, "lgbm_score": 95, "lgbmclassifi": [13, 25, 26, 45, 46, 59, 69, 70, 89, 95], "lgbmclassifierifit": [46, 70], "lgbmclassifierifittedlgbmclassifi": [26, 59], "lgbmclassifierlgbmclassifi": 25, "lgbmregressor": [13, 25, 45, 59, 69], "li": [21, 65], "liabil": 0, "liabl": 0, "liao": 59, "lib": [14, 16, 18, 19, 25, 26, 28, 31, 32, 34, 46, 51, 54, 60, 61, 64, 70, 75, 78, 84], "librari": [4, 5, 9, 15, 17, 26, 27, 31, 32, 33, 35, 38, 40, 46, 47, 51, 52, 56, 61, 70, 71, 75, 76, 77, 79, 81, 83, 87, 93], "libtorch_1741738354177": 32, "licens": [31, 51, 75], "licensor": 0, "licenti": 41, "lie": [51, 75], "life": [20, 21, 28, 30, 31, 35, 36, 40, 50, 51, 56, 57, 58, 59, 60, 65, 72, 74, 75, 79, 80, 86, 92, 99], "lifelin": [12, 34, 54, 78], "lifetim": [34, 54, 78], "lift": 59, "light": [20, 41, 49, 95], "lighter": [22, 42, 66], "lightgbm": [13, 26, 36, 46, 59, 70, 80, 89, 95], "lightgbmcolumntransform": [25, 45, 69, 95], "lightweight": [11, 52, 83], "likabl": 20, "like": [1, 2, 4, 6, 8, 9, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 40, 41, 42, 43, 44, 45, 46, 47, 48, 50, 51, 52, 53, 54, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 87, 89, 90, 93, 94, 95, 96, 99], "likelihood": [23, 34, 43, 54, 78], "likewis": 8, "lime": [26, 46, 70], "limit": [0, 15, 19, 25, 26, 31, 32, 35, 36, 45, 46, 51, 56, 60, 61, 64, 69, 70, 75, 76, 79, 80, 85, 86, 90, 92, 93, 96], "linalg": [31, 52, 75], "line": [4, 9, 11, 13, 14, 16, 18, 19, 20, 21, 22, 24, 25, 26, 28, 32, 33, 34, 35, 42, 44, 52, 54, 56, 59, 60, 64, 65, 66, 68, 72, 76, 77, 78, 79, 81, 83, 87, 93, 98], "line2d": 9, "linear": [1, 22, 23, 25, 27, 29, 30, 32, 33, 34, 36, 42, 43, 45, 47, 50, 54, 56, 66, 67, 69, 71, 73, 74, 76, 77, 78, 79, 80, 82, 84, 85, 94], "linear_model": [13, 20, 21, 23, 24, 25, 26, 27, 30, 31, 32, 33, 34, 35, 36, 41, 43, 44, 45, 46, 47, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 65, 67, 68, 69, 70, 71, 74, 75, 76, 77, 78, 79, 80, 81, 82, 84, 89, 91, 95, 97], "linear_svc": [21, 65], "linearli": [21, 27, 33, 47, 65, 71, 77], "linearregress": [21, 24, 27, 34, 44, 47, 54, 65, 68, 71, 78], "linestyl": [28, 53, 72, 77, 91, 97, 98], "linewidth": [33, 35, 56, 77, 79], "linger": 62, "lingual": [52, 83], "linguist": [19, 51, 64, 75], "link": [0, 4, 6, 8, 13, 23, 29, 34, 35, 36, 43, 56, 57, 58, 73, 78, 79, 80], "linkag": [29, 73], "linkage_arrai": [29, 73], "linkage_typ": [29, 73], "linkedin": [30, 74], "linspac": [21, 22, 24, 27, 35, 42, 44, 47, 56, 65, 66, 68, 71, 79], "linux": [6, 11], "lion": [30, 50, 74], "list": [4, 8, 9, 15, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 30, 31, 32, 34, 35, 38, 41, 42, 43, 44, 45, 46, 50, 51, 52, 54, 55, 56, 59, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 72, 74, 75, 76, 77, 78, 79, 83, 89, 90, 91, 94, 95, 96, 97, 99], "listedcolormap": [21, 65], "listen": [13, 59], "literatur": [25, 69], "littl": [9, 20, 23, 31, 32, 35, 36, 41, 43, 51, 56, 57, 58, 59, 67, 75, 76, 79, 80], "live": [1, 5, 13, 18, 19, 22, 28, 34, 35, 36, 42, 54, 56, 57, 58, 59, 62, 63, 64, 66, 72, 78, 79, 80], "liver": [14, 60], "livestream": 99, "ll": [1, 5, 6, 7, 8, 11, 13, 14, 16, 17, 18, 19, 20, 22, 23, 24, 25, 26, 27, 28, 30, 31, 32, 33, 34, 35, 36, 38, 39, 40, 41, 42, 43, 44, 45, 46, 48, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 62, 63, 64, 66, 67, 68, 69, 70, 71, 72, 74, 75, 76, 77, 78, 79, 80, 83, 84, 85, 87, 91, 93, 97, 99], "llama": [31, 51, 75], "llazx": [34, 78], "load": [9, 13, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 31, 32, 35, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 51, 52, 55, 56, 59, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 75, 76, 79, 81, 83, 87, 88, 93, 94, 95], "load_breast_canc": [27, 47, 71], "load_citibik": [33, 77], "load_dataset": [31, 51, 75], "load_digit": [35, 56, 79], "load_iri": [16, 39, 62, 87, 93], "load_word2vec_format": [31, 51, 75], "loan": 67, "loc": [9, 16, 21, 23, 26, 30, 33, 34, 35, 43, 46, 50, 53, 54, 55, 56, 62, 65, 67, 70, 74, 77, 78, 79, 91, 97], "local": [6, 8, 18, 23, 25, 26, 27, 31, 32, 34, 39, 43, 45, 46, 47, 51, 59, 67, 69, 70, 75, 76, 82], "localhost": 39, "locat": [1, 9, 19, 28, 30, 39, 50, 52, 53, 64, 72, 74, 77, 83, 89, 90, 91, 95, 96, 97, 99], "location_katherin": [53, 77, 97], "location_mountginini": [53, 77, 97], "location_townsvil": [53, 77, 97], "location_witchcliff": [53, 77, 97], "location_wollongong": [53, 77, 97], "lock": [15, 61], "log": [6, 16, 17, 24, 25, 34, 35, 36, 40, 42, 44, 45, 54, 56, 57, 58, 62, 66, 68, 69, 78, 79, 80, 87, 89, 93, 95], "log10": [24, 42, 44, 66, 68], "log1p": [24, 35, 44, 55, 56, 68, 79], "log2": [34, 78], "log_likelihood_ratio_test": [34, 54, 78], "log_loss": [35, 55, 56, 79], "logarithm": [16, 42, 62, 66, 87, 93], "logic": [13, 27, 31, 40, 47, 51, 59, 71, 75], "logical_xor": [27, 47, 71], "login": [13, 30, 50, 59, 74], "logisit": [32, 76], "logist": [20, 25, 26, 32, 34, 35, 36, 41, 45, 46, 53, 54, 56, 69, 70, 76, 77, 78, 79, 80, 84, 85, 89, 91, 95, 97], "logisticregress": [13, 20, 21, 23, 24, 25, 26, 27, 31, 32, 33, 36, 41, 43, 44, 45, 46, 47, 51, 52, 54, 57, 58, 59, 65, 68, 69, 70, 71, 75, 76, 80, 81, 82, 84, 89, 91, 95, 97], "logisticregressionifit": 76, "logisticregressionifittedlogisticregress": 32, "logisticregressionlogisticregress": [20, 23, 25, 67], "logloss": [26, 46, 70], "lognorm": [22, 42, 66], "logspac": [22, 39, 42, 66], "loguniform": [22, 42, 66], "loki": [16, 25, 26, 28], "lol": [19, 64], "lone": [29, 73], "long": [0, 14, 15, 21, 25, 29, 30, 31, 34, 36, 38, 45, 50, 51, 54, 59, 60, 65, 69, 73, 74, 75, 78, 80, 81, 85, 99], "longer": [20, 22, 31, 32, 34, 35, 36, 42, 51, 54, 56, 66, 67, 75, 76, 78, 79, 80], "longest": [14, 60], "longitud": [16, 18, 21, 27, 47, 61, 62, 63, 64, 65, 71, 94], "longitude_0": [27, 47, 71], "longitude_1": [27, 47, 71], "longitude_10": [27, 47, 71], "longitude_11": [27, 47, 71], "longitude_12": [27, 47, 71], "longitude_13": [27, 47, 71], "longitude_14": [27, 47, 71], "longitude_15": [27, 47, 71], "longitude_16": [27, 47, 71], "longitude_17": [27, 47, 71], "longitude_18": [27, 47, 71], "longitude_19": [27, 47, 71], "longitude_2": [27, 47, 71], "longitude_3": [27, 47, 71], "longitude_4": [27, 47, 71], "longitude_5": [27, 47, 71], "longitude_6": [27, 47, 71], "longitude_7": [27, 47, 71], "longitude_8": [27, 47, 71], "longitude_9": [27, 47, 71], "look": [1, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 24, 25, 26, 27, 29, 30, 31, 32, 33, 34, 35, 36, 40, 41, 42, 44, 45, 46, 47, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 68, 69, 70, 71, 73, 74, 75, 76, 77, 78, 79, 80, 85, 86, 87, 89, 92, 93, 95], "lookatm": 59, "loop": [22, 33, 45, 66, 69, 77, 84, 85], "loos": [29, 36, 73, 80], "lose": [7, 19, 64], "loss": [2, 24, 25, 26, 32, 34, 44, 45, 46, 51, 52, 54, 67, 68, 69, 70, 75, 76, 78], "lost": [20, 59], "lot": [6, 10, 13, 14, 15, 16, 17, 19, 20, 21, 22, 24, 26, 27, 29, 32, 33, 34, 35, 36, 40, 43, 44, 46, 47, 53, 54, 56, 59, 60, 62, 64, 65, 66, 67, 68, 70, 71, 73, 76, 77, 78, 79, 80, 81, 99], "lotarea": [24, 26, 35, 44, 46, 55, 56, 68, 70, 79], "lotconfig": [24, 26, 35, 44, 46, 55, 56, 68, 70, 79], "lotconfig_corn": [24, 68, 70], "lotconfig_culdsac": [24, 68, 70], "lotconfig_fr2": [24, 68, 70], "lotconfig_fr3": [24, 68, 70], "lotconfig_insid": [24, 68, 70], "lotfrontag": [24, 26, 35, 44, 46, 55, 56, 68, 70, 79], "lotshap": [24, 26, 35, 44, 46, 55, 56, 68, 70, 79], "lotshape_ir1": [24, 68, 70], "lotshape_ir2": [24, 68, 70], "lotshape_ir3": [24, 68, 70], "lotshape_reg": [24, 68, 70], "loud": [17, 18, 22, 40, 42, 62, 63, 66, 85], "loui": [33, 77], "lourenzutti": [22, 66], "lousiest": 41, "love": [20, 31, 36, 41, 51, 57, 58, 59, 75, 80], "low": [7, 15, 16, 17, 22, 23, 24, 26, 27, 29, 34, 35, 36, 38, 40, 42, 43, 44, 55, 56, 57, 58, 61, 62, 66, 67, 68, 70, 71, 72, 73, 78, 79, 80, 82, 93], "lower": [15, 16, 23, 24, 26, 28, 30, 31, 34, 35, 43, 44, 46, 50, 51, 52, 54, 56, 61, 62, 67, 68, 70, 72, 74, 75, 78, 79, 83, 93], "lowerbound_peopl": [17, 40], "lowercas": [17, 18, 19, 41, 42, 63, 64, 66], "lowest": [59, 87, 93, 99], "lowqualfinsf": [24, 26, 35, 44, 46, 55, 56, 68, 70, 79], "lr": [21, 23, 24, 26, 32, 33, 34, 41, 43, 44, 46, 54, 65, 67, 68, 70, 76, 77, 78, 84, 95], "lr_1": [27, 47, 71], "lr_2": [27, 47, 71], "lr_3": [27, 47, 71], "lr_classifi": 95, "lr_coef": [26, 34, 46, 53, 54, 70, 77, 78, 91, 97], "lr_coefs_landslop": [26, 46, 70], "lr_item": [30, 50, 74], "lr_pipe": [24, 26, 44, 46, 53, 68, 70, 77, 97], "lr_pred": [23, 24, 43, 44, 67, 68], "lr_scale": [26, 46, 70], "lr_score": 95, "lr_x": [30, 50, 74], "lr_y": [30, 50, 74], "ls15hb": 59, "lstm": [31, 33, 51, 53, 75, 77], "lt": [15, 17, 18, 19, 20, 24, 25, 26, 27, 34, 40, 41, 42, 45, 46, 47, 59, 61, 63, 64, 66, 67, 68, 69, 70, 71, 78, 94, 95], "ltorgo": [21, 65], "luck": [36, 80], "lucki": [16, 22, 62, 66, 93], "luckili": [89, 95], "luddit": 59, "lundberg": [26, 46, 70], "luster": [29, 73], "luxuri": 59, "lvert": [31, 52, 75], "lvh": 95, "lvl": [24, 26, 35, 44, 46, 55, 56, 68, 70, 79], "lwq": [24, 26, 35, 44, 46, 55, 56, 68, 70, 79], "lynch": 59, "lynx": [32, 59, 76], "lyric": 59, "l\u00e3": 20, "l\u00e9cuyer": [52, 83], "m": [15, 22, 24, 25, 26, 27, 29, 30, 33, 34, 35, 36, 38, 39, 40, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 56, 57, 58, 59, 61, 66, 68, 69, 70, 71, 72, 73, 74, 75, 77, 78, 79, 80, 83, 84, 95, 96], "m_neighbor": 81, "ma": [52, 83], "macaqu": [32, 59, 76], "macdougal": 59, "mach": [31, 51, 52, 75], "machin": [2, 5, 10, 12, 17, 18, 19, 22, 24, 25, 26, 27, 30, 31, 32, 33, 34, 35, 39, 40, 42, 44, 46, 47, 50, 51, 52, 53, 56, 57, 58, 63, 64, 66, 68, 69, 70, 71, 74, 75, 76, 77, 78, 79, 85, 87, 91, 93, 97, 99], "machine_learn": [35, 56, 79], "mackendrick": 59, "mackworth": 1, "maco": 11, "macro": [23, 43, 67], "mad": 59, "made": [0, 7, 8, 9, 14, 23, 26, 30, 31, 32, 33, 35, 36, 43, 45, 46, 50, 51, 52, 56, 59, 60, 67, 69, 70, 74, 75, 76, 77, 79, 80], "madsen": 20, "magazin": [31, 52, 75], "magic": 59, "magnitud": [18, 20, 22, 24, 26, 31, 41, 42, 46, 52, 53, 66, 68, 70, 75, 77, 91, 97], "maguir": [30, 50, 74], "mai": [0, 5, 6, 8, 9, 11, 13, 14, 15, 16, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 33, 34, 36, 42, 43, 44, 45, 46, 47, 51, 52, 53, 54, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 72, 73, 74, 75, 77, 78, 80, 82, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 99], "mail": [34, 54, 78], "main": [9, 11, 13, 14, 15, 16, 19, 25, 28, 29, 31, 32, 38, 45, 59, 60, 62, 64, 69, 72, 73, 75, 76, 85, 90, 96, 99], "mainland": [21, 65], "mainli": 99, "maintain": [25, 30, 35, 45, 50, 69, 74, 79, 85], "mainten": [25, 45, 69], "maj1": [24, 26, 35, 44, 46, 55, 56, 68, 70, 79], "maj2": [24, 26, 35, 44, 46, 55, 56, 68, 70, 79], "major": [2, 15, 16, 18, 19, 20, 25, 31, 52, 61, 62, 63, 64, 75, 85, 86, 89, 92, 95], "major_biologi": [19, 64], "major_comput": [19, 64], "major_econom": [19, 64], "major_linguist": [19, 64], "major_mathemat": [19, 64], "major_mechan": [19, 64], "major_phys": [19, 64], "major_psychologi": [19, 64], "make": [2, 4, 5, 6, 7, 8, 11, 12, 13, 14, 16, 17, 18, 19, 20, 22, 23, 24, 25, 26, 27, 28, 29, 31, 32, 33, 34, 36, 38, 40, 41, 43, 44, 45, 46, 47, 51, 52, 53, 54, 55, 57, 58, 59, 60, 61, 62, 63, 64, 66, 67, 68, 69, 70, 71, 72, 73, 75, 76, 77, 78, 80, 82, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 99], "make_blob": [16, 28, 29, 32, 62, 72, 73, 76, 84], "make_circl": [29, 73], "make_classif": [16, 62, 81], "make_column_transform": [17, 22, 24, 25, 26, 27, 33, 34, 35, 40, 42, 44, 45, 46, 47, 53, 54, 55, 56, 66, 67, 68, 69, 70, 71, 77, 78, 79, 88, 89, 90, 91, 94, 95, 96, 97], "make_forg": [16, 62], "make_grid": [32, 39, 48, 49, 76], "make_imb_pipelin": 81, "make_moon": [29, 73], "make_num_tree_plot": [25, 45, 69], "make_pipelin": [13, 19, 20, 21, 22, 23, 24, 25, 26, 27, 31, 32, 33, 34, 35, 36, 40, 41, 42, 43, 44, 45, 46, 47, 51, 52, 53, 54, 55, 56, 57, 58, 59, 64, 65, 66, 67, 68, 69, 70, 71, 75, 76, 77, 78, 79, 80, 81, 82, 88, 89, 90, 91, 94, 95, 96, 97], "make_scor": [24, 27, 44, 47, 68, 71], "maker": [56, 79], "malcolm": [28, 30, 50, 72, 74], "malcom": [28, 72], "male": [25, 26, 34, 45, 46, 54, 67, 69, 70, 78], "male_cm": 67, "male_pr": 67, "mall": 59, "mal\u00e3": 41, "man": [20, 30, 31, 50, 51, 52, 59, 74, 75], "manag": [6, 11, 12, 33, 34, 35, 56, 59, 77, 78, 79, 85], "manageri": 45, "mandarin": [18, 63], "mango": [31, 51, 52, 75], "mani": [1, 2, 5, 6, 9, 13, 14, 15, 16, 17, 18, 19, 20, 21, 23, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 38, 39, 40, 43, 45, 46, 47, 50, 51, 52, 53, 54, 56, 57, 58, 59, 60, 61, 62, 63, 65, 67, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 82, 83, 84, 85, 87, 89, 91, 93, 95, 97], "manipul": [35, 55, 56, 79], "mankind": 59, "manner": [0, 25, 45, 59, 69], "manual": [11, 14, 19, 23, 27, 28, 29, 31, 39, 43, 47, 51, 52, 64, 67, 71, 72, 73, 75], "manual_se": [39, 48, 49], "manufactur": [32, 76], "map": [1, 14, 15, 19, 20, 22, 30, 41, 42, 50, 54, 60, 61, 64, 66, 74, 77, 78, 91, 97], "mape": [36, 80, 85], "mape_scor": [24, 44, 68], "maple_leaf": [31, 51, 52, 75], "mapper": [30, 50, 74], "marathon": 59, "march": [53, 77, 97], "margareta": 59, "marit": [25, 26, 45, 46, 67, 69, 70], "mark": [7, 8, 22, 23, 29, 43, 66, 67, 73, 99], "markdown": 13, "marker": [16, 21, 28, 62, 65, 72], "markers": [21, 23, 43, 65, 67], "market": [13, 28, 31, 32, 33, 35, 36, 55, 56, 59, 72, 75, 76, 77, 79, 80], "marketplac": 11, "markov": 52, "marri": [25, 26, 45, 46, 67, 69, 70], "martin": [31, 51, 52, 75], "marvel": 59, "masculin": 20, "mask": [22, 42, 66], "massei": 59, "massiv": [19, 22, 31, 51, 59, 64, 66, 75], "master": [9, 22, 23, 25, 26, 31, 42, 43, 45, 46, 51, 52, 66, 67, 69, 70, 75, 81, 83], "masterpiec": 59, "masvnrarea": [24, 26, 35, 44, 46, 55, 56, 68, 70, 79], "masvnrtyp": [24, 26, 35, 44, 46, 55, 56, 68, 70, 79], "masvnrtype_brkcmn": [24, 56, 68, 70], "masvnrtype_brkfac": [24, 56, 68, 70], "masvnrtype_miss": [24, 56, 68, 70], "masvnrtype_ston": [24, 56, 68, 70], "mat": [31, 51, 75], "match": [19, 21, 23, 25, 26, 32, 43, 45, 46, 53, 64, 65, 67, 69, 70, 76, 77, 89, 90, 91, 95, 96, 97], "mate": 59, "materi": [6, 9, 11, 13, 15, 16, 31, 34, 51, 52, 54, 59, 60, 61, 62, 72, 75, 78, 85, 99], "matern": [27, 82], "math": [2, 28, 30, 34, 50, 72, 74, 78], "mathcal": 62, "mathemat": [2, 19, 25, 31, 36, 45, 51, 64, 69, 75, 80, 85], "mathematician": [31, 51, 52, 75], "matlab": 9, "matplotlib": [13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 32, 33, 34, 35, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 53, 54, 55, 56, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 76, 77, 78, 79, 81, 82, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98], "matplotlibdeprecationwarn": [46, 70], "matric": [13, 16, 30, 50, 62, 67, 74], "matrix": [17, 19, 20, 29, 31, 36, 40, 41, 51, 52, 64, 73, 75, 80, 85], "mattei": [20, 41], "matter": [18, 19, 20, 25, 29, 35, 45, 56, 59, 63, 64, 67, 69, 73, 79, 85], "max": [9, 15, 17, 18, 20, 21, 22, 23, 24, 25, 28, 29, 33, 38, 40, 41, 43, 44, 45, 53, 61, 63, 65, 66, 67, 68, 69, 72, 73, 77, 93, 96, 97], "max_bin": [25, 45, 69], "max_cat_threshold": [25, 45, 69], "max_cat_to_onehot": [25, 45, 69], "max_categori": [40, 42, 45, 46, 64, 66, 68, 69, 70, 95], "max_clust": [29, 73], "max_colwidth": [13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 29, 30, 38, 39, 40, 41, 42, 43, 50, 59, 60, 61, 62, 63, 64, 65, 66, 67, 73, 74, 81, 82, 86, 87, 88, 92, 93, 94], "max_delta_step": [25, 45, 69], "max_depth": [15, 16, 22, 25, 26, 35, 38, 39, 42, 45, 46, 56, 61, 62, 66, 69, 70, 79, 86, 87, 92, 93, 95], "max_depth_widget": [16, 62, 87, 93], "max_df": [19, 41, 42, 64, 66], "max_displai": [26, 46, 70], "max_featur": [13, 17, 19, 20, 22, 25, 35, 38, 40, 41, 42, 45, 56, 59, 64, 66, 69, 79, 95], "max_it": [13, 20, 23, 25, 26, 27, 31, 32, 34, 35, 36, 41, 42, 43, 45, 46, 47, 51, 52, 53, 54, 56, 57, 58, 59, 64, 66, 67, 68, 69, 70, 71, 75, 76, 77, 78, 79, 80, 81, 82, 84, 95, 97], "max_leaf_nod": [14, 35, 38, 45, 56, 60, 69, 79, 95], "max_leav": [25, 45, 69], "max_opt": [16, 23, 28, 29, 43, 62, 67, 72, 73], "max_resourc": [42, 66], "max_row": 34, "max_sampl": [35, 45, 56, 69, 79, 95], "maxabsscal": [17, 40], "maxclust": [29, 49, 73], "maxent": 84, "maxhr": [89, 95], "maxim": [13, 24, 28, 44, 59, 67, 68, 72], "maximum": [14, 17, 18, 20, 24, 25, 28, 29, 40, 41, 44, 45, 60, 63, 68, 69, 72, 73, 87, 93], "maxtemp": [53, 77, 91, 97], "may": 1, "mayb": [26, 33, 35, 46, 56, 67, 70, 77, 79, 99], "maybe_coerce_valu": [34, 78], "ma\u00e3": 41, "mb": [18, 23, 27, 34, 43, 47, 53, 54, 63, 64, 67, 71, 77, 78, 97], "mcld": 99, "mcml158": 99, "md": [11, 52, 60, 83], "me": [9, 13, 20, 22, 31, 35, 41, 51, 52, 55, 56, 59, 66, 75, 79, 83, 99], "mean": [6, 7, 9, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 25, 26, 27, 30, 34, 36, 38, 39, 40, 41, 42, 43, 45, 46, 47, 49, 50, 53, 54, 59, 60, 61, 62, 63, 64, 65, 66, 67, 69, 70, 71, 74, 77, 78, 80, 81, 82, 83, 84, 85, 87, 89, 93, 94, 95, 97, 99], "mean_absolute_error": [36, 57, 58, 80], "mean_absolute_percentage_error": [24, 44, 68], "mean_cv_error": 61, "mean_cv_scor": [16, 20, 21, 22, 39, 41, 62, 65, 66], "mean_fit_tim": [22, 24, 42, 44, 66, 68], "mean_scor": [18, 22, 61, 63, 66], "mean_score_tim": [22, 24, 42, 66], "mean_squared_error": [24, 27, 44, 47, 68, 71], "mean_std_cross_val_scor": [18, 25, 26, 34, 45, 46, 61, 63, 64, 69, 70, 78], "mean_test_neg_mean_squared_error": 24, "mean_test_scor": [22, 24, 42, 44, 66, 68], "mean_train_error": 61, "mean_train_neg_mean_squared_error": 24, "mean_train_scor": [16, 20, 21, 22, 24, 39, 41, 42, 44, 62, 65, 66, 68], "meaning": [12, 16, 19, 23, 26, 28, 39, 43, 46, 52, 62, 64, 67, 70, 72, 88, 94], "meaningfulli": [31, 51, 75], "meaningless": [29, 73], "meant": 59, "measur": [0, 13, 14, 15, 16, 23, 24, 26, 27, 28, 29, 30, 32, 33, 34, 35, 36, 43, 44, 46, 50, 51, 52, 53, 54, 56, 59, 60, 61, 62, 67, 68, 70, 72, 73, 74, 76, 77, 78, 79, 80, 82, 85, 87, 89, 91, 93, 95, 97], "meat": [17, 40, 59], "mechan": [19, 64, 85, 99], "mechanical_engin": [31, 51, 52, 75], "medal": 9, "media": [35, 55, 56, 79], "median": [14, 17, 18, 21, 24, 26, 27, 34, 35, 40, 44, 46, 47, 53, 54, 55, 56, 60, 63, 64, 65, 68, 70, 71, 77, 78, 79, 90, 91, 94, 96, 97], "median_house_valu": [18, 27, 47, 63, 64, 71, 88, 94], "median_incom": [18, 27, 47, 63, 64, 71, 94], "mediat": [56, 79], "medic": [28, 31, 32, 67, 72, 75, 76, 99], "medinc": [21, 65], "medit": [36, 57, 58, 80, 81], "mediterranean": 59, "medium": [0, 16, 17, 34, 40, 54, 62, 78, 85], "meek": 59, "meet": [31, 51, 52, 75], "mehreen": [1, 99], "meier": 12, "mel": 20, "melbourn": 97, "melbourneairport": [53, 77, 97], "mele": 59, "melodrama": 59, "member": [21, 25, 65, 69, 99], "membership": [19, 28, 29, 64, 72, 73], "memori": [9, 17, 18, 19, 23, 24, 25, 27, 31, 32, 34, 41, 42, 43, 44, 45, 47, 51, 53, 54, 63, 64, 66, 67, 68, 69, 71, 75, 76, 77, 78, 85, 93, 94, 95, 97], "men": 20, "menstrual": [31, 51, 75], "mental": [35, 56, 79], "mention": [0, 4, 20, 21, 34, 35, 41, 54, 56, 59, 65, 78, 79], "menu": [11, 36, 80], "merchant": 0, "mere": 59, "merg": [0, 6, 29, 73], "meshgrid": [27, 47, 71], "mess": [30, 34, 50, 59, 74], "messag": [4, 11, 15, 18, 19, 31, 34, 51, 54, 61, 64, 75, 78], "message_clsnam": 34, "messi": [27, 52, 71, 83], "met": [59, 99], "meta": [25, 45, 69], "metacademi": 1, "metal": [20, 32, 76], "method": [2, 5, 12, 14, 15, 16, 18, 20, 21, 23, 25, 26, 29, 30, 31, 32, 33, 34, 35, 36, 38, 39, 41, 43, 45, 46, 47, 50, 51, 52, 53, 56, 57, 58, 60, 62, 63, 65, 67, 69, 70, 71, 73, 74, 75, 76, 77, 78, 79, 80, 81, 84, 85, 89, 90, 91, 95, 96, 97], "methodologi": [17, 18, 33, 63, 77], "metric": [1, 12, 16, 18, 19, 25, 26, 27, 28, 29, 30, 31, 34, 35, 36, 39, 40, 45, 46, 47, 49, 50, 52, 54, 55, 56, 57, 58, 62, 63, 64, 69, 70, 71, 72, 73, 74, 75, 78, 79, 80, 82, 89, 95], "metric_param": [39, 40, 63, 64, 95], "metropoli": 59, "mexican": [17, 40], "mexico": 67, "mglearn": [14, 15, 16, 18, 19, 20, 21, 22, 23, 28, 31, 32, 33, 39, 41, 42, 43, 51, 52, 60, 61, 62, 63, 64, 65, 66, 67, 72, 75, 76, 77, 81, 82, 84, 86, 87, 90, 92, 93, 96], "mi": [13, 23, 35, 43, 48, 56, 59, 66, 67, 79], "mice": 41, "michael": 59, "microsoft": [31, 75], "mid": 59, "middl": [20, 41], "midnight": [33, 77], "midterm": [1, 5, 7, 13, 26], "might": [1, 13, 14, 15, 16, 17, 18, 19, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 33, 35, 36, 39, 40, 42, 43, 44, 45, 46, 50, 51, 52, 54, 56, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 77, 79, 80, 81, 83, 85, 87, 88, 93, 99], "mightn": [52, 83], "miguel": [36, 57, 58, 80], "mike": [0, 1, 10, 14, 36, 60, 80], "mikolov": [31, 51, 52, 75], "mildli": 59, "mildura": 97, "milk": [31, 52, 75], "mill": [25, 45, 59, 69], "millennia": 99, "million": [32, 76], "min": [1, 17, 18, 21, 23, 24, 29, 31, 33, 38, 40, 43, 44, 49, 53, 65, 67, 68, 73, 77, 83, 93, 96, 97], "min1": [24, 26, 35, 44, 46, 55, 56, 68, 70, 79], "min2": [24, 26, 35, 44, 46, 55, 56, 68, 70, 79], "min_child_sampl": [45, 46, 69, 70, 95], "min_child_weight": [25, 45, 46, 69, 70, 95], "min_df": [19, 41, 42, 64, 66], "min_frequ": [40, 42, 45, 46, 64, 66, 68, 69, 70, 95], "min_impurity_decreas": [35, 38, 45, 56, 69, 79, 95], "min_impurity_split": [35, 56, 79], "min_resourc": [42, 66], "min_sampl": [29, 49, 73], "min_samples_leaf": [14, 35, 38, 45, 56, 60, 69, 79, 95], "min_samples_split": [14, 35, 38, 45, 56, 60, 69, 79, 95], "min_split_gain": [45, 46, 69, 70, 95], "min_token_len": [31, 51, 52, 75], "min_token_length": [31, 51, 52, 75], "min_weight_fraction_leaf": [35, 38, 45, 56, 69, 79, 95], "mind": [5, 15, 18, 25, 26, 30, 31, 34, 35, 45, 46, 50, 51, 56, 59, 61, 63, 64, 69, 70, 74, 75, 78, 79, 85], "mine": 1, "minibatchkmean": [29, 73], "miniconda3": 11, "miniforge3": [11, 46, 51, 54, 60, 61, 64, 70, 75, 78, 84], "minilm": [31, 51, 75], "minim": [5, 14, 24, 28, 29, 31, 35, 44, 51, 56, 60, 68, 72, 73, 75, 79], "minimum": [9, 15, 18, 29, 31, 51, 52, 61, 63, 73, 75], "minkowski": [39, 40, 63, 64, 95], "minmaxscal": [17, 18, 19, 35, 40, 55, 56, 63, 64, 79], "minor": [5, 7, 34, 78], "mint": 96, "mintemp": [53, 77, 91, 97], "minut": [4, 5, 13, 14, 30, 34, 60, 71, 78, 85], "mir": 1, "misc": 78, "miscfeatur": [24, 26, 35, 44, 46, 55, 56, 68, 70, 79], "miscfeature_gar2": [24, 26, 55, 68, 70, 79], "miscfeature_miss": [24, 26, 55, 56, 68, 70, 79], "miscfeature_othr": [24, 26, 55, 68, 70, 79], "miscfeature_sh": [24, 26, 55, 68, 70, 79], "miscfeature_tenc": [24, 26, 55, 56, 68, 70, 79], "misconduct": 99, "miscval": [24, 26, 35, 44, 46, 55, 56, 68, 70, 79], "mishaal": [1, 99], "mishra": [1, 99], "misinform": [31, 51, 75], "mislead": [15, 23, 43, 61, 67], "miss": [11, 16, 17, 18, 19, 20, 21, 23, 24, 25, 26, 27, 28, 30, 33, 34, 35, 38, 40, 43, 44, 45, 46, 50, 53, 54, 55, 56, 59, 62, 63, 64, 65, 67, 68, 69, 70, 72, 74, 77, 78, 79, 82, 85, 87, 91, 93, 97, 99], "missing_valu": [40, 45, 46, 63, 64, 68, 69, 70], "mission": 59, "mistak": [17, 18, 25, 34, 35, 45, 56, 59, 63, 69, 78, 79, 87, 93], "misus": 99, "mit": [0, 1], "mitig": [12, 30, 74], "mitlp": [34, 78], "mitt": 52, "mitten": 52, "mix": [5, 13, 20, 24, 35, 36, 44, 55, 56, 68, 79, 80, 96], "mixtur": [29, 31, 32, 51, 52, 59, 73, 75, 76], "ml": [1, 2, 5, 10, 12, 14, 18, 22, 25, 29, 31, 32, 36, 40, 45, 51, 52, 60, 63, 69, 73, 75, 76, 80, 83, 87, 93], "ml_experi": [14, 15, 19, 60, 61, 64, 85], "mlpclassifi": [32, 76], "mlpregressor": [32, 76], "mm": [53, 77, 91, 97], "mmsto": 59, "mn": [24, 26, 35, 44, 46, 55, 56, 68, 70, 79], "mnli": [31, 51, 75], "mnprv": [24, 26, 35, 44, 46, 55, 56, 68, 70, 79], "mnww": [24, 26, 35, 44, 46, 55, 56, 68, 70, 79], "mo": [31, 51, 52, 75], "mobil": [19, 32, 64, 76], "mobilenet": [32, 76], "mock": 59, "mod": [24, 26, 35, 44, 46, 55, 56, 68, 70, 79], "mode": [18, 22, 31, 42, 62, 63, 66, 95], "model": [1, 2, 12, 16, 22, 28, 29, 30, 33, 35, 42, 48, 49, 50, 53, 56, 66, 67, 72, 73, 74, 77, 79, 81, 82, 83, 84, 86, 91, 92, 94, 95, 96, 97], "model_nam": [30, 31, 50, 51, 74, 75], "model_path": [31, 51, 75], "model_select": [13, 15, 16, 17, 18, 19, 20, 21, 23, 24, 25, 26, 27, 30, 32, 33, 34, 35, 36, 38, 39, 40, 41, 43, 44, 45, 46, 47, 50, 53, 54, 55, 56, 57, 58, 59, 61, 62, 63, 64, 65, 67, 68, 69, 70, 71, 74, 76, 77, 78, 79, 80, 81, 82, 84, 87, 88, 89, 91, 93, 94, 95, 97], "modern": [1, 16, 31, 35, 51, 52, 55, 56, 59, 62, 75, 79], "modif": [34, 78], "modifi": [0, 15, 34, 36, 54, 57, 58, 78, 80, 81], "modul": [10, 14, 15, 18, 39, 51, 60, 61, 67, 75], "moe": [22, 42, 66], "mole": [32, 76], "molla": 41, "mom": [27, 82], "moment": [20, 59, 81, 85, 89, 90, 95, 96, 99], "moment_predictor": [36, 57, 58, 80], "mon": [33, 77], "monarch": [31, 51, 52, 75], "monarchi": [31, 51, 52, 75], "mondai": [1, 33, 77, 99], "mone": [20, 41], "monei": [9, 20, 34, 41, 54, 78], "monet": 25, "monitor": [52, 83], "monkei": [32, 59, 76], "monotone_constraint": [25, 45, 69], "monotonic_cst": [38, 45, 69, 95], "monster": 59, "month": [19, 24, 27, 33, 34, 44, 61, 64, 68, 91, 97], "month_jun": 97, "month_mai": 97, "month_march": 97, "month_nam": [15, 33, 38, 53, 77, 91, 97], "month_novemb": 97, "month_octob": 97, "month_septemb": 97, "monthli": [27, 34, 54, 78], "monthlycharg": [27, 34, 54, 78], "montreal": [31, 51, 52, 75], "mood": 59, "moon": [29, 73], "moosvi": [0, 52, 83], "moral": [0, 59, 72], "more": [1, 2, 7, 8, 9, 13, 20, 22, 23, 25, 26, 28, 30, 31, 32, 33, 34, 35, 36, 38, 39, 40, 42, 44, 45, 46, 47, 48, 50, 51, 52, 54, 56, 57, 58, 59, 61, 66, 69, 70, 72, 74, 75, 76, 78, 79, 80, 81, 83, 84, 85, 86, 87, 89, 92, 93, 95, 96, 99], "morn": 59, "morpholog": [52, 83], "morri": 20, "moskowitz": [28, 72], "mosold": [24, 26, 35, 44, 46, 55, 56, 68, 70, 79], "mosold_1": [24, 68, 70], "mosold_10": [24, 26, 68, 70], "mosold_11": [24, 26, 68, 70], "mosold_12": [24, 26, 68, 70], "mosold_2": [24, 68, 70], "mosold_3": [24, 68, 70], "mosold_4": [24, 68, 70], "mosold_5": [24, 68, 70], "mosold_6": [24, 68, 70], "mosold_7": [24, 68, 70], "mosold_8": [24, 26, 68, 70], "mosold_9": [24, 26, 68, 70], "most": [8, 9, 13, 14, 15, 16, 17, 18, 19, 22, 25, 26, 27, 28, 29, 30, 31, 32, 34, 35, 36, 38, 39, 40, 42, 45, 46, 47, 50, 51, 52, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 66, 67, 69, 70, 71, 72, 73, 74, 75, 76, 78, 79, 80, 83, 84, 89, 92, 95, 96, 99], "most_confident_i": [21, 65], "most_confident_x": [21, 65], "most_frequ": [14, 16, 17, 18, 23, 24, 26, 35, 40, 43, 44, 46, 55, 56, 60, 62, 63, 67, 68, 70, 79, 86, 92, 97], "most_neg": 20, "most_negative_id": 41, "most_posit": 20, "most_positive_id": 41, "most_similar": [31, 51, 52, 75], "mostli": [9, 19, 33, 38, 59, 64, 77, 96], "motiv": [13, 19, 64], "mound": 96, "mountgambi": 97, "mountginini": [53, 77, 97], "move": [8, 20, 21, 26, 27, 41, 45, 46, 47, 59, 65, 70, 71, 86, 87, 89, 92, 93, 95], "movi": [20, 21, 31, 41, 51, 52, 65, 75], "movie_feat": 50, "movie_feats_df": [30, 50, 74], "movie_id": [30, 50, 74], "movie_nam": [30, 50, 74], "movies_rated_by_pat": [30, 50, 74], "movies_to_pr": [30, 50, 74], "mp": [48, 49, 51, 75], "mpimg": [32, 76], "mr": [20, 41, 59], "mri": 85, "mrtssm448usn": [33, 77], "mse": [14, 30, 36, 50, 60, 74, 80, 85], "msg": [19, 34, 64, 78], "msg_dtype": 18, "msg_err": 18, "mssubclass": [24, 26, 35, 44, 46, 55, 56, 68, 70, 79], "mssubclass_120": [24, 68, 70], "mssubclass_160": [24, 68, 70], "mssubclass_180": [24, 68, 70], "mssubclass_190": [24, 35, 68, 70], "mssubclass_20": [24, 68, 70], "mssubclass_30": [24, 68, 70], "mssubclass_40": [24, 68, 70], "mssubclass_45": [24, 68, 70], "mssubclass_50": [24, 68, 70], "mssubclass_60": [24, 68, 70], "mssubclass_70": [24, 68, 70], "mssubclass_75": [24, 68, 70], "mssubclass_80": [24, 68, 70], "mssubclass_85": [24, 68, 70], "mssubclass_90": [24, 68, 70], "mszone": [24, 26, 35, 44, 46, 55, 56, 68, 70, 79], "mszoning_c": [24, 46, 68, 70], "mszoning_fv": [24, 68, 70], "mszoning_rh": [24, 68, 70], "mszoning_rl": [24, 68, 70], "mszoning_rm": [24, 68, 70], "much": [4, 9, 14, 15, 16, 18, 19, 23, 25, 26, 28, 29, 30, 32, 33, 34, 35, 36, 43, 45, 46, 50, 52, 53, 54, 56, 57, 58, 59, 60, 61, 62, 63, 64, 67, 69, 70, 72, 73, 74, 76, 77, 78, 79, 80, 83, 87, 93, 99], "mueller": 1, "multi": [5, 13, 24, 26, 28, 31, 33, 36, 44, 46, 51, 52, 57, 58, 59, 67, 68, 70, 72, 75, 77, 80, 83], "multi_class": [41, 43, 45, 67, 69, 76, 84, 95], "multi_output": 18, "multi_strategi": [25, 45, 69], "multiclass": [32, 36, 57, 58, 76, 80, 84], "multicoliniar": [26, 46, 70], "multicultur": [52, 83], "multilevel": [24, 44, 68], "multimod": [28, 72], "multinomi": 84, "multinomin": [32, 76], "multipl": [5, 8, 9, 15, 21, 22, 25, 32, 33, 34, 38, 45, 46, 51, 52, 53, 54, 61, 65, 66, 69, 70, 75, 76, 77, 78, 91, 96, 97], "multiplelin": [34, 54, 78], "multiplelines_no": [34, 54, 78], "multiplelines_y": [34, 54, 78], "multipli": [21, 22, 25, 27, 34, 42, 45, 47, 54, 65, 66, 69, 71, 78, 81], "munch": 25, "murder": 20, "museum": 41, "music": [17, 30, 40, 59, 74], "musket": 96, "musqueam": 99, "must": [0, 7, 8, 9, 13, 14, 18, 20, 25, 26, 29, 31, 32, 34, 40, 46, 51, 52, 54, 59, 60, 61, 63, 70, 73, 75, 76, 78, 99], "mustn": [52, 83], "mutil": 59, "mutual": [29, 73], "my": [7, 15, 20, 31, 35, 36, 51, 52, 56, 57, 58, 59, 66, 67, 72, 75, 79, 80, 81, 83, 99], "my_heatmap": [22, 42, 66], "my_map": [24, 44, 68], "myer": [20, 59], "mypreprocessor": [31, 51, 52, 75], "myself": [20, 31, 35, 51, 52, 56, 59, 60, 75, 79, 83], "m\u00fcller": 10, "n": [1, 14, 16, 18, 20, 21, 22, 24, 25, 26, 27, 29, 30, 31, 33, 34, 35, 39, 41, 42, 44, 45, 46, 47, 50, 51, 52, 53, 55, 56, 60, 62, 65, 66, 68, 69, 70, 71, 73, 74, 75, 77, 79, 83, 84, 87, 91, 93, 95, 96, 97], "n_bin": [27, 47, 71], "n_candid": [42, 66], "n_class": [16, 62, 67, 81], "n_cluster": [28, 29, 48, 49, 51, 72, 73, 75, 96], "n_clusters_per_class": 81, "n_compon": [31, 51, 52, 75], "n_constitu": [25, 45, 69], "n_estim": [27, 33, 34, 35, 46, 47, 55, 56, 70, 71, 77, 78, 79, 82, 95], "n_estimators_valu": [35, 55, 56, 79], "n_exampl": [28, 72], "n_feat": [16, 62], "n_featur": [16, 28, 62, 72, 81], "n_features_to_select": [27, 47, 71, 82], "n_imag": [39, 48, 49], "n_img": [48, 49], "n_inform": 81, "n_init": [28, 48, 49, 72, 96], "n_job": [19, 24, 25, 34, 35, 39, 40, 41, 43, 44, 45, 46, 56, 63, 64, 67, 68, 69, 70, 76, 79, 81, 95], "n_neighbor": [30, 39, 40, 50, 63, 64, 74, 87, 93, 95], "n_neighbors_selector": [16, 62], "n_neighbors_widget": [16, 62, 87, 93], "n_peopl": [17, 40], "n_redund": 81, "n_rental": [33, 77], "n_rentalsin3hour": [33, 77], "n_rentalsin6hour": [33, 77], "n_repeat": [26, 46, 70], "n_resourc": [42, 66], "n_sampl": [16, 28, 29, 32, 42, 62, 66, 67, 72, 73, 76, 81, 84], "n_samples_seen_": 34, "n_split": [33, 77], "n_threshold": [43, 67], "n_top_feat": 41, "n_top_featur": [20, 41], "n_topic": [31, 51, 52, 75], "n_train": [33, 77], "n_word": [31, 51, 52, 75], "na": [24, 26, 35, 44, 46, 55, 56, 68, 70, 79], "nadir": 59, "nafter": [52, 83], "nah": [19, 64], "nail": 59, "naiv": [40, 73], "name": [1, 4, 5, 8, 9, 11, 13, 14, 16, 17, 18, 19, 20, 22, 23, 25, 26, 27, 28, 32, 33, 34, 35, 36, 38, 40, 41, 42, 43, 45, 46, 47, 52, 53, 54, 56, 57, 58, 59, 60, 62, 63, 64, 66, 67, 69, 70, 71, 72, 76, 77, 78, 79, 80, 83, 87, 89, 90, 91, 93, 95, 96, 97, 99], "named_estimators_": [25, 45, 69], "named_step": [17, 20, 21, 24, 25, 26, 27, 35, 41, 44, 45, 46, 47, 53, 55, 56, 65, 67, 68, 69, 70, 71, 77, 79, 91, 97], "named_transformers_": [17, 19, 24, 25, 26, 27, 34, 35, 40, 44, 46, 47, 53, 55, 56, 64, 67, 68, 69, 70, 71, 77, 79, 91, 94, 97], "namespac": 34, "nan": [17, 18, 19, 24, 25, 26, 27, 30, 33, 34, 35, 40, 42, 44, 45, 46, 47, 50, 53, 54, 55, 56, 63, 64, 66, 67, 68, 69, 70, 71, 74, 77, 78, 79, 85, 91, 93, 97], "nanmax": 49, "nanmean": [30, 50, 74], "nanosecond": [33, 77], "nap": 95, "narcot": 59, "narr": 52, "narrat": 20, "narrow": [13, 30, 35, 55, 56, 74, 79], "nasali": [32, 59, 76], "nation": [1, 59, 99], "nativ": [18, 25, 26, 32, 45, 46, 67, 69, 70, 76, 84], "natur": [2, 12, 17, 19, 25, 27, 32, 36, 40, 45, 51, 57, 58, 59, 64, 69, 71, 76, 80, 81, 83, 84], "navig": [8, 11, 36, 57, 58, 80], "nazism": 59, "nbsp": [38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 55, 56, 59, 63, 64, 66, 67, 68, 69, 70, 71, 76, 79, 95], "nbviewer": [15, 17, 18, 19, 20, 22, 23, 24, 25, 26, 27, 32, 35, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 55, 56, 59, 63, 64, 66, 67, 68, 69, 70, 71, 76, 79, 95], "nc": 1, "ncluster": 96, "ncol": [21, 65], "ndarrai": [9, 19, 34, 64], "ndframe": [27, 34, 47, 71, 78], "ndim": [9, 18], "ne": [53, 77, 97], "nearbi": [16, 28, 62, 72], "nearest": [29, 39, 73, 81, 87, 93], "nearestneighbor": 39, "nearestneighborsifit": 39, "nearing": 59, "nearli": [15, 38, 59], "necessari": [0, 8, 17, 21, 22, 40, 59, 60, 66, 85, 88, 94], "necessarili": [15, 24, 25, 30, 36, 44, 45, 50, 61, 68, 69, 74, 80], "necvq": [34, 54, 78], "need": [6, 8, 9, 11, 13, 14, 15, 16, 17, 19, 20, 23, 24, 25, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 38, 39, 40, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 62, 64, 67, 68, 69, 70, 71, 72, 73, 74, 75, 77, 78, 79, 80, 81, 83, 84, 85, 87, 88, 89, 91, 93, 94, 95, 97, 99], "needn": [52, 83], "neg": [13, 14, 15, 16, 21, 24, 25, 26, 31, 34, 44, 45, 46, 51, 52, 53, 54, 59, 60, 61, 62, 65, 68, 69, 70, 75, 77, 78, 87, 91, 93, 97], "neg_mean_absolute_percentage_error": [24, 44, 68], "neg_mean_squared_error": [24, 35, 44, 56, 68, 79], "neg_prob": [20, 41], "neg_root_mean_square_error": [24, 44, 68], "neg_root_mean_squared_error": [24, 44, 68], "negative300": [31, 51, 75], "neglig": 59, "nehotencoder__major_comput": 64, "neigh": [16, 39, 62], "neighbor": [14, 16, 17, 18, 19, 21, 27, 29, 31, 39, 40, 47, 51, 62, 63, 64, 65, 71, 73, 75, 81, 87, 88, 93, 94, 95], "neighborhood": [21, 24, 26, 35, 44, 46, 55, 56, 65, 68, 70, 79], "neighborhood_blmngtn": [24, 68, 70], "neighborhood_bluest": [24, 68, 70], "neighborhood_brdal": [24, 68, 70], "neighborhood_brksid": [24, 68, 70], "neighborhood_clearcr": [24, 68, 70], "neighborhood_collgcr": [24, 44, 68, 70], "neighborhood_crawfor": [24, 68, 70], "neighborhood_edward": [24, 44, 68, 70], "neighborhood_gilbert": [24, 44, 68, 70], "neighborhood_idotrr": [24, 68, 70], "neighborhood_meadowv": [24, 68, 70], "neighborhood_mitchel": [24, 68, 70], "neighborhood_nam": [24, 68, 70], "neighborhood_noridg": [24, 44, 68, 70], "neighborhood_npkvil": [24, 68, 70], "neighborhood_nridght": [24, 44, 46, 68, 70], "neighborhood_nwam": [24, 68, 70], "neighborhood_oldtown": [24, 68, 70], "neighborhood_sawy": [24, 68, 70], "neighborhood_sawyerw": [24, 68, 70], "neighborhood_somerst": [24, 68, 70], "neighborhood_stonebr": [24, 46, 68, 70], "neighborhood_swisu": [24, 68, 70], "neighborhood_timb": [24, 68, 70], "neighborhood_veenk": [24, 68, 70], "neighborsbas": 18, "neighbour": [28, 29, 31, 38, 39, 46, 51, 52, 61, 70, 72, 73, 75, 87, 90, 93, 96], "neighbourhood": [21, 27, 29, 47, 65, 71, 73, 88, 94], "neither": [15, 19, 30, 50, 61, 64, 74], "nelson": 20, "neo": [1, 99], "nep": 49, "neq": [26, 30, 46, 70, 74], "ner": [31, 51, 52, 75], "nervou": [14, 60], "nest": [22, 42, 66, 85], "net": [32, 34, 54, 76, 78], "netflix": [30, 45, 50, 74], "netherland": 45, "network": [1, 12, 13, 19, 25, 27, 28, 30, 31, 33, 36, 45, 48, 50, 51, 52, 53, 57, 58, 59, 64, 69, 71, 72, 74, 75, 77, 80], "neural": [1, 12, 13, 27, 31, 33, 51, 53, 59, 71, 75, 77], "neuron": [32, 76], "never": [25, 26, 30, 31, 32, 34, 40, 45, 46, 50, 51, 54, 59, 67, 69, 70, 74, 75, 76, 78, 99], "nevertheless": 99, "new": [1, 6, 11, 13, 14, 15, 16, 17, 18, 20, 21, 22, 23, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 39, 40, 41, 42, 43, 45, 46, 47, 50, 51, 52, 53, 54, 59, 60, 61, 62, 63, 64, 65, 66, 67, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 82, 85, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97], "new_cent": [28, 72], "new_column": [24, 26, 34, 35, 44, 46, 53, 54, 55, 56, 68, 70, 77, 78, 79, 91, 97], "new_data": [34, 78], "new_df": 53, "new_exampl": [14, 28, 60, 72], "new_feature_nam": [53, 77, 91, 97], "new_text": 60, "new_valu": [34, 78], "newaxi": 9, "newcastl": 97, "newer": [24, 44, 68], "newli": [18, 24, 27, 29, 44, 47, 63, 68, 71, 73], "newsgroup": 52, "newswir": 52, "newtonian": 41, "next": [1, 14, 16, 17, 18, 22, 23, 24, 25, 31, 32, 33, 34, 35, 39, 43, 44, 45, 48, 49, 51, 52, 53, 56, 59, 60, 61, 62, 63, 64, 67, 68, 69, 75, 76, 77, 79, 88, 89, 94, 95, 99], "nfeat": [16, 62], "nfeats_accuraci": [16, 62], "ng": [1, 10, 22, 27, 66, 71], "ngram": [27, 47, 71], "ngram_rang": [19, 41, 42, 64, 66], "nhil": 97, "nhl": 52, "nhqxu": [34, 78], "nice": [4, 13, 20, 23, 25, 26, 29, 32, 34, 35, 36, 42, 43, 45, 46, 54, 56, 57, 58, 66, 67, 69, 70, 73, 76, 78, 79, 80], "nicki": 66, "nifti": 20, "night": [33, 36, 57, 58, 77, 80, 81], "nightmar": [35, 56, 79], "nlemma": [52, 83], "nlp": [19, 32, 64, 76], "nltk": [31, 51, 52, 75, 83], "nltk_data": [31, 51, 52, 75, 83], "nmax": [35, 55, 56, 79], "nn": [1, 18, 20, 32, 39, 41, 48, 49, 51, 63, 75, 76, 87, 93], "nne": [53, 77, 97], "nnw": [53, 77, 97], "nnz": [19, 64], "no_class": 1, "no_grad": [39, 48, 49], "no_label": 49, "no_val_i": 34, "no_val_x": [18, 34], "nobodi": 59, "node": [25, 29, 32, 45, 60, 69, 73, 76, 86, 92], "nois": [17, 29, 49, 73, 85, 87, 93], "noise_cat": [17, 40], "noise_level": [17, 40], "noise_ord": [17, 40], "non": [1, 9, 13, 14, 15, 17, 18, 21, 22, 23, 24, 25, 26, 27, 29, 30, 32, 33, 34, 36, 43, 44, 45, 47, 50, 53, 54, 59, 60, 61, 63, 65, 66, 67, 68, 69, 71, 73, 74, 76, 77, 78, 80, 81, 82, 85, 93, 95, 97, 99], "noncommerci": 1, "none": [1, 15, 18, 19, 21, 22, 25, 27, 29, 33, 34, 35, 38, 39, 40, 41, 42, 43, 45, 46, 56, 61, 63, 64, 65, 66, 67, 68, 69, 70, 73, 76, 77, 78, 79, 81, 82, 86, 89, 91, 92, 95, 97], "noninfring": 0, "nonzero": [19, 64], "noodl": [17, 40], "nope": 59, "noqa": [22, 42, 66], "nor": [8, 15, 19, 52, 61, 64, 83], "norahhead": 97, "norfolkisland": 97, "norg": [52, 83], "norm": [17, 22, 31, 40, 42, 52, 66, 75], "normal": [7, 11, 17, 18, 23, 24, 25, 26, 28, 29, 31, 32, 33, 35, 39, 40, 42, 43, 44, 45, 46, 48, 49, 52, 53, 55, 56, 66, 67, 68, 69, 70, 72, 73, 75, 76, 77, 79, 83, 89, 95, 98], "north": [31, 51, 52, 75], "north_america": [17, 40], "north_america_don": [17, 40], "north_america_no": [17, 40], "north_america_y": [17, 40], "norvig": 1, "nose": 20, "notat": 62, "note": [0, 1, 3, 5, 8, 10, 11, 13, 14, 15, 16, 17, 18, 19, 21, 22, 23, 25, 26, 27, 30, 31, 36, 42, 43, 45, 46, 47, 50, 51, 52, 53, 59, 60, 62, 63, 64, 65, 66, 67, 69, 70, 71, 74, 75, 80, 84, 85, 91, 97, 99], "notebook": [5, 6, 8, 10, 15, 17, 18, 19, 20, 22, 23, 24, 25, 26, 27, 32, 35, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 52, 55, 56, 59, 60, 61, 62, 63, 64, 66, 67, 68, 69, 70, 71, 76, 79, 88, 90, 91, 94, 95, 96, 97], "noth": 59, "nothin": 20, "notic": [0, 17, 19, 21, 24, 40, 44, 59, 64, 65, 67, 68, 71], "notion": [16, 22, 28, 30, 31, 32, 50, 51, 62, 66, 72, 74, 75, 76], "notna": [53, 77, 91, 97], "nougat": 96, "noun": [31, 51, 52, 75, 83], "nov": [1, 53, 77], "novel": 59, "novemb": [1, 33, 53, 77, 97], "novic": 10, "now": [9, 11, 13, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 30, 31, 32, 33, 35, 36, 39, 40, 41, 43, 44, 45, 46, 47, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 74, 75, 76, 77, 79, 80, 82, 83, 86, 87, 88, 89, 90, 92, 93, 94, 95, 96], "nowher": 59, "np": [9, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 81, 82, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98], "npie": 9, "npo": [52, 83], "npr": [27, 31, 47, 51, 52, 71, 75, 85], "npt": 34, "nsubj": [52, 83], "ntest": [16, 22, 62, 66, 87, 93], "ntoken": [52, 83], "ntree": [25, 45, 69], "nuclear": 59, "null": [17, 18, 19, 23, 24, 27, 34, 43, 44, 47, 53, 54, 63, 64, 67, 68, 71, 77, 78, 93, 95, 97], "null_distribut": [34, 78], "num": [25, 26, 45, 46, 67, 69, 70], "num_leav": [45, 46, 69, 70, 95], "num_parallel_tre": [25, 45, 69], "num_sent": [36, 57, 58, 80, 81], "num_thread": 32, "num_work": [39, 48, 49], "number": [1, 4, 8, 9, 13, 14, 15, 16, 18, 19, 21, 22, 23, 24, 26, 27, 29, 30, 31, 32, 33, 34, 36, 40, 42, 43, 44, 46, 47, 48, 49, 50, 51, 52, 54, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 70, 71, 73, 74, 75, 76, 78, 80, 81, 83, 85, 87, 90, 91, 93, 94, 96, 97, 98, 99], "number_test": [22, 66], "numberbatch": [31, 51, 52, 75], "numer": [2, 14, 17, 18, 19, 21, 23, 24, 25, 30, 31, 33, 34, 35, 39, 40, 43, 44, 45, 50, 52, 53, 54, 56, 60, 63, 64, 65, 67, 68, 69, 74, 75, 77, 78, 79, 87, 88, 91, 93, 94, 97], "numeric_feat": [17, 19, 22, 27, 40, 42, 47, 64, 66, 71, 85], "numeric_featur": [24, 25, 26, 34, 35, 44, 45, 46, 53, 54, 55, 56, 64, 67, 68, 69, 70, 77, 78, 79, 89, 91, 94, 95, 97], "numeric_looking_column": [24, 44, 68], "numeric_onli": 96, "numeric_transform": [17, 24, 25, 26, 35, 40, 44, 45, 46, 53, 55, 56, 64, 67, 68, 69, 70, 77, 79, 89, 91, 94, 95, 97], "numpi": [10, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 81, 82, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98], "numpy_dtyp": [34, 78], "nuriootpa": 97, "nutrit": [31, 51, 52, 75], "nw": [53, 77, 97], "nwith": [16, 62], "nyre": 20, "nyt": [35, 55, 56, 79], "o": [13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97], "obelisk": [32, 76], "object": [15, 17, 18, 19, 20, 21, 22, 24, 26, 27, 28, 38, 40, 41, 42, 44, 45, 46, 47, 51, 52, 53, 54, 56, 61, 63, 64, 65, 66, 67, 68, 70, 71, 72, 81, 83, 85, 86, 87, 92, 93, 95, 97], "obscur": 14, "observ": [13, 14, 16, 25, 26, 28, 29, 33, 34, 39, 45, 46, 59, 60, 61, 62, 69, 70, 72, 73, 77, 78, 85, 87, 89, 91, 93, 95, 97], "obsess": [41, 59], "obtain": [0, 20, 21, 28, 29, 30, 34, 39, 41, 50, 65, 72, 73, 74, 78, 87, 93], "obviou": [29, 31, 51, 52, 73, 75], "obvious": 59, "occas": 59, "occasion": [23, 43, 67], "occup": [25, 26, 45, 46, 67, 69, 70, 93], "occupation_adm": 45, "occupation_arm": 45, "occupation_craft": 45, "occupation_exec": 45, "occupation_farm": [26, 45, 46, 70], "occupation_handl": 45, "occupation_machin": 45, "occupation_miss": [26, 45, 46, 70], "occupation_oth": 45, "occupation_priv": [26, 45, 46, 70], "occupation_prof": 45, "occupation_protect": 45, "occupation_sal": 45, "occupation_tech": 45, "occupation_transport": 45, "occupi": 99, "occur": [9, 14, 19, 34, 52, 60, 61, 64, 78, 83], "occurr": [31, 34, 51, 52, 75, 78, 99], "ocean": [18, 27, 47, 63, 64, 71, 94], "ocean_proxim": [18, 27, 47, 63, 64, 71, 88, 94], "ocean_proximity_": [18, 63, 94], "ocean_proximity_inland": [18, 63, 94], "ocean_proximity_island": [18, 63, 94], "ocean_proximity_near": [18, 63, 94], "oct": 1, "octob": [15, 38, 53, 77, 97], "odd": [31, 51, 59, 75], "odditi": 59, "oe": [19, 64, 85], "oe_encod": 85, "off": [12, 20, 21, 22, 23, 24, 27, 28, 32, 34, 35, 39, 42, 43, 44, 48, 49, 52, 54, 55, 56, 59, 65, 66, 67, 68, 71, 72, 76, 78, 79, 83, 85], "off_shelf": [89, 95], "offens": 4, "offer": [9, 20, 25, 30, 34, 41, 45, 52, 69, 74, 78, 99], "offic": [4, 5, 6, 11, 31, 75, 85, 99], "offici": [5, 11, 31, 51, 52, 75, 99], "offlin": [30, 50, 74], "offset": [21, 65], "often": [5, 9, 13, 15, 16, 18, 19, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 35, 36, 42, 43, 45, 46, 47, 50, 51, 52, 53, 56, 57, 58, 59, 61, 62, 63, 64, 65, 66, 67, 69, 70, 71, 72, 73, 74, 75, 76, 77, 79, 80, 84, 85, 87, 93, 96], "ogunrind": 59, "oh": [1, 17, 26, 27, 32, 33, 34, 36, 40, 46, 47, 53, 54, 59, 70, 71, 76, 77, 78, 80, 85, 91, 97, 99], "ohe_column": [24, 26, 35, 44, 55, 56, 68, 79], "ohe_enc": [19, 64], "ohe_encod": 85, "ohe_feat": [17, 40], "ohe_feat_nam": [17, 40], "ohe_feature_nam": [26, 53, 77, 91, 97], "ohehotencod": [19, 64], "ois": [29, 73], "ok": [13, 16, 24, 33, 34, 36, 44, 53, 54, 57, 58, 59, 62, 68, 77, 78, 80, 85, 91, 97], "okai": [36, 57, 58, 72, 80], "ola": [52, 83], "old": [10, 20, 41, 45, 46, 59, 69, 70], "old_cent": [28, 72], "older": [24, 44, 68], "oldpeak": [89, 95], "olymp": 9, "omit": [26, 46, 70], "omnibu": 59, "omp_num_thread": [13, 32], "omw": [52, 83], "onc": [1, 6, 7, 8, 9, 11, 14, 15, 18, 19, 22, 27, 29, 30, 31, 32, 36, 39, 47, 50, 51, 52, 57, 58, 59, 60, 61, 63, 64, 66, 71, 73, 74, 75, 76, 80, 83, 89, 95, 99], "onca": [32, 59, 76], "one": [5, 6, 7, 9, 10, 11, 13, 14, 15, 16, 17, 18, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33, 34, 35, 38, 39, 40, 42, 43, 44, 45, 46, 50, 51, 52, 53, 54, 56, 59, 60, 61, 62, 63, 65, 66, 67, 68, 69, 70, 72, 73, 74, 75, 76, 77, 78, 79, 81, 82, 83, 84, 85, 87, 89, 90, 91, 93, 95, 96, 97, 99], "one_c": [16, 62], "one_ex_preprocess": [26, 46, 70], "one_ex_preprocessed_perturb": [26, 46, 70], "one_exampl": [26, 46, 70], "one_example_perturb": [26, 46, 70], "onedr": 32, "onehot": [19, 27, 47, 64, 71], "onehotencod": [17, 18, 21, 22, 24, 25, 26, 27, 33, 34, 35, 40, 42, 44, 45, 46, 47, 53, 54, 55, 56, 63, 65, 66, 67, 68, 69, 70, 71, 77, 78, 79, 85, 88, 89, 91, 94, 95, 97], "onehotencoder__major_biologi": [19, 64], "onehotencoder__major_comput": [19, 64], "onehotencoder__major_econom": [19, 64], "onehotencoder__major_linguist": [19, 64], "onehotencoder__major_mathemat": [19, 64], "onehotencoder__major_mechan": [19, 64], "onehotencoder__major_phys": [19, 64], "onehotencoder__major_psychologi": [19, 64], "onehotencoder__ocean_proximity_": 64, "onehotencoder__ocean_proximity_inland": 64, "onehotencoder__ocean_proximity_island": 64, "onehotencoder__ocean_proximity_near": 64, "onehotencoderonehotencod": [17, 19, 22, 24, 25, 35, 44, 55, 56, 79], "ones": [9, 16, 18, 25, 26, 28, 30, 31, 34, 38, 39, 46, 50, 51, 52, 59, 62, 63, 69, 70, 72, 74, 75, 87, 89, 93, 95], "onevsoneclassifi": 84, "onevsrestclassifi": 84, "onli": [2, 4, 5, 6, 9, 13, 14, 15, 16, 17, 18, 20, 21, 22, 23, 25, 26, 27, 28, 29, 30, 31, 32, 33, 35, 36, 39, 40, 41, 42, 43, 45, 46, 47, 50, 51, 52, 53, 54, 56, 59, 60, 61, 62, 63, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 79, 80, 82, 83, 85, 87, 88, 92, 93, 94, 99], "onlin": [3, 6, 8, 14, 28, 31, 51, 52, 60, 75, 99], "online_act": 28, "onlinebackup": [34, 54, 78], "onlinebackup_no": [34, 54, 78], "onlinebackup_y": [34, 54, 78], "onlinesecur": [34, 54, 78], "onlinesecurity_no": [34, 54, 78], "onlinesecurity_y": [34, 54, 78], "onrend": [36, 80], "ontario": [31, 51, 52, 75], "ontonot": 52, "oob_scor": [35, 45, 56, 69, 79, 95], "op": [45, 67], "open": [5, 6, 7, 13, 32, 36, 57, 58, 59, 76, 80, 99], "openai": [31, 51, 75], "openai_api_kei": [51, 75], "openporchsf": [24, 26, 35, 44, 46, 55, 56, 68, 70, 79], "oper": [4, 6, 9, 11, 19, 27, 31, 36, 47, 51, 52, 64, 71, 75, 80], "opera": [20, 41], "operand": 9, "opinion": [25, 45, 59, 69], "opportun": [15, 30, 38, 50, 74, 99], "oppos": [24, 25, 44, 45, 68, 69], "opposit": [9, 24, 25, 26, 45, 68, 69, 70, 91, 94, 97], "opt": [25, 45, 69], "optic": [34, 54, 78], "optim": [1, 2, 14, 16, 20, 23, 25, 26, 27, 28, 29, 32, 34, 35, 36, 39, 41, 43, 45, 46, 56, 60, 61, 62, 64, 67, 69, 70, 71, 72, 73, 76, 78, 79, 80], "optimist": [22, 31, 51, 66, 75], "optimized_c": [20, 41], "option": [1, 8, 9, 14, 24, 25, 35, 44, 51, 52, 56, 60, 68, 71, 72, 75, 77, 79, 89, 91, 95, 97, 99], "oral": 99, "orang": [21, 65], "ord_enc": 17, "ord_imput": 17, "order": [6, 8, 9, 13, 14, 15, 17, 18, 19, 20, 21, 22, 23, 24, 26, 28, 29, 30, 31, 33, 34, 35, 36, 40, 41, 42, 43, 44, 46, 51, 52, 55, 56, 59, 60, 61, 63, 64, 65, 66, 67, 68, 70, 71, 72, 73, 74, 75, 77, 79, 80, 83, 85, 90, 96], "ordering_ordinal_oth": [24, 26, 35, 44, 46, 55, 56, 68, 70, 79], "ordering_ordinal_reg": [24, 26, 35, 44, 46, 55, 56, 68, 70, 79], "ordin": [24, 44, 68, 85, 88, 94], "ordinal_feat": [17, 19, 40, 64], "ordinal_featur": [25, 26, 45, 46, 67, 69, 70], "ordinal_features_oth": [24, 26, 35, 44, 46, 55, 56, 68, 70, 79], "ordinal_features_reg": [24, 26, 35, 44, 46, 55, 56, 68, 70, 79], "ordinal_transform": [17, 25, 26, 40, 45, 46, 67, 69, 70], "ordinal_transformer_oth": [24, 26, 35, 44, 46, 55, 56, 68, 70, 79], "ordinal_transformer_reg": [24, 26, 35, 44, 46, 55, 56, 68, 70, 79], "ordinalencod": [17, 18, 19, 24, 25, 26, 27, 33, 34, 35, 40, 44, 45, 46, 47, 53, 54, 55, 56, 63, 64, 67, 68, 69, 70, 71, 77, 78, 79, 85, 88, 89, 91, 94, 95, 97], "ordinalencoder__class_attend": 64, "ordinalencoderordinalencod": [17, 19, 24, 25, 35, 44, 55, 56, 79], "ordinari": [24, 44, 59, 68], "oreilli": [32, 33, 76, 77], "org": [10, 15, 17, 18, 19, 20, 22, 23, 24, 25, 26, 27, 32, 35, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 52, 55, 56, 59, 61, 63, 64, 66, 67, 68, 69, 70, 71, 76, 79, 83, 95], "organ": [14, 18, 31, 35, 36, 52, 56, 60, 63, 75, 79, 80], "orgin": 9, "orig_featur": [53, 77, 91, 97], "orig_pr": [26, 46, 70], "orig_scor": 67, "origin": [13, 17, 18, 19, 25, 26, 30, 31, 32, 34, 45, 46, 50, 51, 52, 53, 54, 63, 64, 67, 69, 70, 71, 72, 74, 75, 76, 77, 78, 81, 87, 90, 91, 93, 96, 97, 99], "original_hm": [36, 57, 58, 80, 81], "ornithorhynchu": [32, 76], "oscar": [21, 65], "osp_misc": 78, "ostblom": [52, 83], "other": [0, 1, 4, 5, 6, 7, 8, 11, 13, 14, 15, 17, 18, 19, 20, 21, 22, 23, 25, 26, 29, 30, 31, 32, 36, 38, 39, 40, 41, 42, 43, 45, 46, 48, 50, 51, 55, 57, 58, 59, 60, 61, 63, 64, 65, 66, 67, 69, 70, 71, 73, 74, 75, 76, 80, 84, 85, 87, 89, 90, 91, 93, 95, 96, 97, 99], "otherwis": [0, 8, 11, 19, 32, 59, 64, 76, 99], "ouid": 22, "ounc": [32, 59, 76], "our": [5, 6, 7, 9, 13, 14, 15, 16, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 38, 39, 40, 41, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 60, 62, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 81, 83, 85, 86, 87, 88, 89, 90, 91, 92, 93, 95, 96, 97, 99], "ourselv": [14, 23, 32, 43, 52, 53, 60, 67, 76, 77, 83], "out": [0, 1, 4, 5, 8, 9, 13, 14, 15, 16, 17, 19, 20, 22, 23, 24, 25, 26, 28, 29, 30, 31, 33, 34, 38, 40, 42, 43, 44, 45, 46, 48, 50, 51, 52, 53, 54, 57, 58, 59, 60, 61, 62, 64, 66, 67, 68, 69, 70, 72, 73, 74, 75, 77, 78, 81, 82, 83, 85, 87, 89, 91, 93, 95, 97, 99], "out_col": [18, 61, 63], "out_step": 81, "outburst": 41, "outcom": 44, "outdat": 11, "outlier": [17, 24, 29, 36, 40, 44, 68, 73, 80, 85], "outlook": 34, "output": [5, 8, 9, 13, 14, 15, 17, 19, 21, 23, 25, 26, 31, 32, 33, 34, 35, 36, 40, 43, 45, 46, 48, 49, 51, 52, 56, 59, 60, 61, 64, 65, 67, 69, 70, 75, 76, 77, 79, 80, 85, 89, 91, 95, 97], "outset": 59, "outsid": [8, 21, 23, 25, 26, 30, 31, 33, 34, 43, 45, 46, 50, 51, 52, 67, 69, 70, 74, 75, 77, 78], "outstand": 59, "over": [20, 22, 24, 31, 32, 33, 34, 35, 36, 44, 51, 52, 54, 56, 59, 61, 66, 68, 75, 76, 77, 78, 79, 80, 83, 85, 99], "over_confident_i": [21, 65], "over_confident_x": [21, 65], "over_sampl": 81, "overal": [8, 17, 20, 26, 28, 31, 32, 35, 40, 41, 46, 48, 52, 56, 67, 70, 72, 75, 76, 79, 85, 89, 95, 99], "overallcond": [24, 26, 35, 44, 46, 55, 56, 68, 70, 79], "overallqu": [24, 26, 35, 44, 46, 55, 56, 68, 70, 79], "overconfid": [26, 27, 36, 46, 47, 70, 71, 80, 82], "overfit": [1, 12, 16, 20, 21, 24, 25, 27, 36, 38, 39, 40, 41, 44, 45, 47, 62, 65, 68, 69, 71, 80, 87, 89, 93, 95], "overflow": 8, "overhead": [19, 34, 64], "overlap": [2, 15, 21, 28, 36, 61, 72, 80], "overli": [16, 22, 39, 62, 66, 87, 93], "overload": [30, 34, 74, 78], "overpredict": [24, 68], "oversampl": 67, "oversample_pip": 81, "overshadow": [31, 51, 52, 75], "overst": [35, 56, 79], "overus": [25, 45, 69, 99], "overview": [13, 28, 29, 30, 50, 52, 59, 72, 73, 74], "overwhelm": 72, "overzeal": 7, "ovr": [42, 43, 64, 66], "own": [4, 9, 11, 13, 18, 23, 24, 26, 27, 28, 29, 30, 31, 32, 33, 35, 36, 43, 44, 46, 47, 51, 52, 53, 55, 56, 57, 58, 59, 61, 63, 67, 68, 70, 71, 72, 73, 75, 76, 77, 79, 80, 83, 84, 99], "oz": [20, 41], "p": [11, 20, 21, 29, 34, 36, 39, 40, 41, 42, 49, 52, 63, 64, 65, 66, 73, 78, 80, 83, 95], "p_i": [28, 72], "p_value_threshold": [34, 78], "pace": [5, 20, 21, 31, 51, 52, 59, 65, 72, 75], "packag": [6, 9, 11, 12, 14, 16, 18, 19, 22, 23, 25, 26, 28, 29, 30, 31, 32, 34, 36, 42, 43, 46, 51, 52, 54, 57, 58, 60, 61, 64, 66, 67, 70, 72, 73, 74, 75, 76, 78, 80, 83, 84], "packagenam": 11, "packet": 96, "pad": [32, 39, 48, 49, 76], "page": [1, 4, 8, 13, 15, 17, 18, 19, 20, 22, 23, 24, 25, 26, 27, 31, 32, 35, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 51, 52, 55, 56, 59, 63, 64, 66, 67, 68, 69, 70, 71, 75, 76, 79, 83, 87, 89, 90, 93, 95, 96, 99], "pai": [26, 27, 31, 36, 45, 51, 59, 70, 75, 80], "paid": [27, 59], "pain": [4, 32, 35, 53, 56, 76, 77, 79, 91, 97], "paint": [25, 59], "pair": [14, 29, 31, 51, 52, 59, 73, 75, 84], "pairwis": [16, 29, 31, 49, 51, 62, 73, 75], "paladin": 20, "palett": 11, "panda": [10, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 31, 32, 33, 34, 35, 36, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 75, 76, 77, 78, 79, 80, 81, 82, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97], "pane": [16, 62, 87, 93], "panel": [16, 23, 26, 28, 29, 39, 43, 46, 62, 67, 70, 72, 73, 87, 93], "panther": [32, 59, 76], "panthera": [32, 59, 76], "papa": 59, "paper": [8, 26, 27, 31, 32, 34, 36, 46, 47, 51, 52, 54, 70, 71, 75, 76, 78, 80, 81], "paperlessbil": [34, 54, 78], "paperlessbilling_no": [34, 54, 78], "paperlessbilling_y": [34, 54, 78], "paradigm": [13, 14, 28, 52, 59, 60, 72], "paradox": [30, 50, 74], "paragraph": [31, 51, 52, 75], "paraleg": [31, 51, 52, 75], "parallel": [19, 22, 25, 31, 32, 34, 42, 45, 51, 64, 66, 69, 75], "paralleln": 32, "param": [16, 19, 22, 24, 34, 42, 62, 64, 66, 87, 93], "param_columntransformer__countvectorizer__max_featur": [22, 42, 66], "param_dist": [22, 42, 66], "param_distribut": [22, 42, 66], "param_grid": [16, 22, 24, 35, 42, 44, 56, 61, 62, 66, 68, 79], "param_grid1": [22, 42, 66], "param_grid2": [22, 42, 66], "param_grid3": [22, 42, 66], "param_grid4": [22, 42, 66], "param_ridge__alpha": [24, 44, 68], "param_svc__c": [22, 42, 66], "param_svc__gamma": [22, 42, 66], "paramet": [16, 18, 19, 25, 28, 29, 31, 32, 33, 34, 35, 38, 39, 40, 41, 43, 45, 46, 51, 52, 53, 56, 62, 63, 64, 68, 69, 70, 72, 73, 75, 76, 77, 78, 79, 86, 87, 89, 91, 92, 93, 95, 97], "parametr": [29, 73], "params_": [34, 54, 78], "params_str": [22, 42, 66], "paramter": [16, 62], "parapsychologist": 41, "pardu": [32, 59, 76], "parent": [20, 29, 41, 73], "park": [27, 32, 36, 47, 71, 76, 80], "pars": [52, 83], "parse_d": [9, 33, 53, 77, 91, 97], "parser": [31, 51, 52, 75], "part": [1, 4, 10, 18, 20, 21, 22, 23, 25, 26, 27, 29, 31, 32, 33, 35, 36, 42, 43, 45, 46, 47, 51, 52, 53, 56, 57, 58, 59, 63, 64, 65, 66, 67, 69, 70, 71, 73, 75, 76, 77, 79, 80, 82, 83, 89, 95, 99], "part1": [30, 50, 74], "part2": [30, 50, 74], "parti": [31, 51, 52, 59, 75], "partial": [4, 34, 35, 54, 56, 78, 79], "partial_fit": 34, "particip": [5, 13, 99], "particular": [0, 10, 15, 18, 19, 22, 25, 26, 27, 28, 30, 31, 32, 33, 34, 35, 36, 40, 42, 45, 50, 51, 52, 53, 56, 57, 58, 59, 63, 64, 66, 67, 69, 70, 72, 74, 75, 76, 77, 78, 79, 80, 81, 82, 87, 93], "particularli": [25, 30, 31, 45, 51, 59, 69, 74, 75, 90, 93, 96], "partit": [19, 28, 29, 64, 72, 73], "partner": [34, 54, 78, 99], "partner_no": [34, 54, 78], "partner_y": [34, 54, 78], "pass": [9, 15, 16, 17, 18, 19, 21, 23, 24, 25, 26, 27, 28, 31, 32, 40, 43, 44, 45, 46, 47, 48, 51, 52, 59, 61, 62, 63, 64, 65, 67, 68, 69, 70, 71, 72, 75, 76, 87, 93, 99], "passthrough": [19, 22, 34, 42, 54, 64, 66, 78, 89, 90, 95, 96], "passthrough__ml_experi": [19, 64], "passthrough_feat": [19, 22, 42, 64, 66, 85], "passthrough_featur": [34, 54, 78, 89, 95], "passthroughpassthrough": [19, 22], "passthroughpassthroughcountvectorizersong_titlecountvector": [42, 66], "passthroughpassthroughdecisiontreeclassifi": 95, "passthroughpassthroughkneighborsclassifi": 95, "passthroughpassthroughlgbmclassifi": 95, "passthroughpassthroughlogisticregress": 95, "passthroughpassthroughonehotencod": 64, "passthroughpassthroughrandomforestclassifi": 95, "password": 6, "past": [5, 14, 15, 33, 34, 35, 55, 56, 59, 60, 61, 69, 77, 78, 79, 85, 91, 97, 99], "pat": [6, 30, 50, 74], "pat_i": [30, 50, 74], "pat_model": [30, 50, 74], "pat_x": [30, 50, 74], "pata": [32, 59, 76], "path": [9, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97], "patial": [29, 73], "patient": [14, 36, 60, 80, 89, 95], "patio": [32, 76], "patric": [26, 46, 70], "pattern": [13, 14, 15, 19, 22, 28, 31, 32, 33, 35, 38, 51, 52, 53, 55, 56, 59, 60, 61, 64, 66, 71, 72, 75, 76, 77, 79, 87, 91, 93, 97], "paul": 25, "paus": [13, 59], "pav_bhaji": 52, "pave": [24, 26, 35, 44, 46, 55, 56, 68, 70, 79], "paveddr": [24, 26, 35, 44, 46, 55, 56, 68, 70, 79], "paveddrive_i": [24, 68, 70], "paveddrive_n": [24, 68, 70], "paveddrive_p": [24, 68, 70], "paydai": 96, "payment": 27, "paymentmethod": [27, 34, 54, 78], "paymentmethod_bank": [34, 54, 78], "paymentmethod_credit": [34, 54, 78], "paymentmethod_electron": [34, 54, 78], "paymentmethod_mail": [34, 54, 78], "pca": [23, 29, 30, 43, 50, 67, 73, 74], "pcarter": 10, "pd": [9, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97], "pdf": [8, 10], "peac": [31, 51, 52, 75], "peanut": 96, "peanutyalmondi": 96, "pearceraaf": 97, "pedest": [32, 59, 76], "pedro": [1, 27, 61, 71], "peek": [51, 61, 75, 91, 97], "peer": [5, 36, 59, 80, 99], "pembrok": [32, 59, 76], "penal": [7, 34, 54, 78], "penalti": [31, 41, 43, 45, 51, 52, 67, 69, 75, 76, 95, 99], "penrith": 97, "peopl": [4, 14, 15, 18, 20, 21, 25, 28, 30, 31, 32, 33, 34, 35, 36, 40, 49, 50, 51, 52, 54, 56, 57, 58, 60, 61, 63, 65, 67, 69, 72, 74, 75, 76, 77, 78, 79, 80, 85, 87, 93, 99], "per": [5, 9, 21, 24, 25, 26, 28, 30, 31, 32, 35, 44, 45, 46, 50, 51, 53, 55, 56, 65, 67, 68, 69, 70, 74, 75, 76, 77, 79, 84, 85, 91, 97], "perceiv": 7, "percent": [24, 44, 68], "percent_error": [24, 44, 68], "percentag": [14, 30, 35, 56, 60, 67, 74, 79, 90, 96], "perfect": [7, 14, 15, 20, 23, 24, 26, 30, 34, 38, 39, 41, 43, 44, 46, 50, 54, 59, 60, 61, 67, 68, 70, 74, 78], "perfectli": [2, 50, 52, 59, 74], "perform": [12, 13, 14, 15, 16, 17, 18, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 33, 35, 36, 38, 39, 42, 43, 44, 45, 46, 47, 51, 52, 56, 57, 58, 59, 60, 61, 62, 63, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 77, 79, 80, 81, 85, 86, 88, 89, 91, 92, 94, 95, 97], "performac": 61, "perhap": [24, 33, 44, 53, 59, 68, 77, 84], "perimet": [27, 47, 71], "period": [33, 34, 52, 59, 77, 78, 83, 91, 97, 99], "perm_sorted_idx": [26, 46, 70], "perman": 9, "permiss": [0, 99], "permit": [0, 17, 18, 63, 67, 99], "permut": [26, 70], "perpetu": 41, "perplex": [31, 75], "persist": [30, 50, 74], "person": [0, 1, 4, 6, 7, 11, 13, 23, 30, 31, 32, 33, 34, 36, 43, 51, 52, 53, 54, 59, 67, 72, 75, 76, 77, 78, 80, 83, 99], "perspect": [25, 30, 45, 69, 74], "perth": 97, "perthairport": [53, 77, 97], "perturb": [17, 26, 29, 40, 46, 70, 73], "perturbed_pr": [26, 46, 70], "pertwe": 20, "perus": 59, "pete_seeg": [31, 51, 52, 75], "peter": [1, 20], "petter": [20, 41], "ph": [52, 83], "pharma": [36, 80], "phascolarcto": [32, 76], "phase": [15, 61], "phd": [52, 83], "phdei": [34, 78], "phenomenon": [30, 34, 50, 74, 78, 87, 93], "philosoph": 52, "phone": [34, 54, 59, 78, 99], "phoneservic": [34, 54, 78], "phoneservice_no": [34, 54, 78], "phoneservice_y": [34, 54, 78], "photo": [13, 59, 85], "photograph": 99, "phrase": [31, 51, 52, 75], "physic": [19, 33, 64, 77], "pi": 9, "piazza": [1, 8, 13], "pick": [14, 21, 23, 26, 27, 28, 29, 32, 35, 36, 38, 42, 43, 45, 46, 47, 55, 56, 57, 58, 60, 65, 67, 69, 70, 71, 72, 73, 76, 79, 80, 81, 82, 84, 86, 87, 89, 92, 93, 95], "pictur": [25, 26, 29, 31, 32, 33, 35, 45, 46, 52, 56, 59, 67, 69, 70, 73, 75, 76, 77, 79], "pid": [16, 25, 26, 28], "pie": 9, "piec": [21, 31, 34, 51, 59, 65, 75, 78], "pierr": 20, "pil": [13, 39, 48, 49, 59], "pimpl": 59, "pin": [8, 32, 76], "pineappl": [31, 51, 52, 75, 83], "pip": [11, 26, 31, 32, 36, 46, 51, 52, 57, 58, 70, 75, 76, 80], "pipe": [17, 18, 19, 21, 22, 23, 31, 42, 43, 45, 51, 52, 63, 64, 65, 66, 67, 69, 75], "pipe_bestalpha": [24, 44, 68], "pipe_bigalpha": [24, 44, 68], "pipe_catboost": [25, 45, 69], "pipe_dt": [25, 26, 45, 46, 69, 70, 89, 95], "pipe_forward": [27, 82], "pipe_knn": [17, 40, 89, 95], "pipe_lgbm": [25, 26, 45, 46, 69, 70, 89, 95], "pipe_lr": [20, 23, 25, 26, 36, 41, 43, 45, 46, 57, 58, 67, 69, 70, 76, 80, 81, 89, 95], "pipe_lr_all_feat": [27, 47, 71], "pipe_lr_balanc": 67, "pipe_lr_model_bas": [27, 47, 71], "pipe_lr_weight": 67, "pipe_ohe_knn": [17, 40], "pipe_ordinal_knn": [17, 40], "pipe_rf": [25, 26, 45, 46, 69, 70, 89, 95], "pipe_rf_demo": [25, 45, 69], "pipe_ridg": [21, 24, 44, 65, 68], "pipe_sklearn_gb": [25, 45, 69], "pipe_sklearn_histgb": [25, 45, 69], "pipe_smallalpha": [24, 44, 68], "pipe_svc": [23, 43, 67], "pipe_svm": [22, 42, 66], "pipe_xgb": [25, 26, 45, 46, 69, 70], "pipe_xor": [27, 47, 71], "pipelin": [1, 2, 12, 13, 15, 19, 20, 21, 22, 23, 24, 25, 26, 27, 32, 33, 34, 35, 36, 41, 42, 43, 44, 45, 46, 47, 53, 54, 55, 56, 57, 58, 59, 61, 64, 65, 66, 67, 68, 69, 70, 71, 76, 77, 78, 79, 80, 81, 82, 83, 88, 89, 90, 91, 94, 95, 96, 97], "pipeline__bedrooms_per_household": 64, "pipeline__household": 64, "pipeline__housing_median_ag": 64, "pipeline__lab1": [19, 64], "pipeline__lab2": [19, 64], "pipeline__lab3": [19, 64], "pipeline__lab4": [19, 64], "pipeline__latitud": 64, "pipeline__longitud": 64, "pipeline__median_incom": 64, "pipeline__population_per_household": 64, "pipeline__quiz1": [19, 64], "pipeline__rooms_per_household": [27, 47, 64, 71], "pipeline__university_year": [19, 64], "pipelinecolumntransform": [42, 66], "pipelineifit": [41, 43, 63, 64, 66], "pipelineifittedpipelin": [17, 18, 19, 20, 22, 23, 27, 47, 67, 71], "pipelineinot": [22, 24, 42, 64, 66, 68], "pipelinepipelin": 22, "piper": 59, "pitch": [35, 56, 79], "pitfal": [33, 35, 77, 79], "pitt": 20, "pixel": [26, 32, 46, 70, 76], "pizza": [32, 52, 59, 76], "pla": [31, 51, 52, 75], "place": [14, 20, 33, 52, 53, 59, 67, 77, 90, 96, 99], "plagiar": [13, 59], "plai": [13, 14, 16, 20, 22, 26, 29, 31, 32, 42, 46, 51, 52, 59, 60, 62, 66, 70, 73, 75, 76, 86, 87, 92, 93], "plain": [28, 72], "plan": [13, 24, 25, 34, 36, 44, 47, 54, 59, 68, 71, 78, 80, 88, 89, 94, 95, 99], "plane": [14, 21, 65], "plant": 85, "plaster": 41, "plastic": 52, "platform": [4, 6, 7, 11], "platypu": [32, 76], "plausibl": [31, 51, 75], "player": [26, 31, 32, 46, 51, 52, 70, 75, 76], "pleas": [1, 4, 5, 8, 13, 15, 17, 18, 19, 20, 22, 23, 24, 25, 26, 27, 32, 35, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 55, 56, 59, 63, 64, 66, 67, 68, 69, 70, 71, 76, 79, 95, 99], "plenti": 20, "plinth": [32, 76], "plot": [8, 14, 15, 16, 17, 18, 20, 21, 22, 23, 24, 27, 29, 30, 31, 32, 33, 35, 36, 38, 39, 40, 41, 42, 43, 44, 47, 50, 51, 52, 53, 55, 56, 59, 60, 61, 62, 63, 65, 66, 67, 68, 71, 73, 74, 75, 76, 77, 79, 80, 86, 87, 90, 91, 92, 93, 96, 97, 98], "plot_2d_scor": [21, 65], "plot_2d_separ": [16, 21, 39, 62, 65, 87, 93], "plot_coeff_exampl": [20, 41], "plot_confusion_matrix": 67, "plot_confusion_matrix_exampl": [23, 43, 67], "plot_cross_valid": [15, 33, 61, 77], "plot_dbscan": [29, 73], "plot_dbscan_with_label": [29, 73], "plot_dendrogram_clust": [29, 73], "plot_distribut": [42, 66], "plot_elbow": [28, 72], "plot_example_dist": [28, 72], "plot_fruit_tre": 60, "plot_grid_search_overview": [22, 42, 66], "plot_improper_process": [17, 40], "plot_k_means_dbscan_comparison": [29, 73], "plot_km_initi": [28, 72], "plot_km_it": [28, 72], "plot_km_iter": [28, 72], "plot_kmean": [29, 73], "plot_knn_clf": [16, 62], "plot_knn_decision_boundari": [16, 62], "plot_knn_regress": [16, 62], "plot_lda_w_vector": [51, 52, 75], "plot_linkage_criteria": [29, 73], "plot_logistic_regress": [21, 65], "plot_logistic_regression_graph": [32, 76], "plot_loss_diagram": [35, 56, 79], "plot_multiclass_lr_ovr": 84, "plot_original_clust": [29, 73], "plot_partial_effects_on_outcom": [34, 54, 78], "plot_proper_process": [17, 40], "plot_result": [16, 39, 62, 87, 93], "plot_sample_img": [39, 48, 49], "plot_scal": [18, 63], "plot_silhouette_dist": [28, 72], "plot_single_hidden_layer_graph": [32, 76], "plot_support_vector": [16, 62], "plot_survival_funct": [34, 54, 78], "plot_svc_c": [16, 62], "plot_svc_gamma": [16, 62], "plot_time_spacing_distribut": [53, 77, 91, 97], "plot_train_test_point": [16, 62], "plot_tre": [15, 38], "plot_tree_decision_boundari": [61, 86, 92], "plot_tree_decision_boundary_and_tre": [14, 15, 60, 61, 86, 92], "plot_two_hidden_layer_graph": [32, 76], "plot_typ": [26, 46, 70], "plot_x_dendrogram": [29, 73], "plotli": [27, 47, 51, 52, 71, 75], "plotting_funct": [14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 25, 26, 28, 29, 30, 32, 35, 38, 39, 40, 41, 42, 43, 45, 46, 48, 50, 55, 56, 60, 61, 62, 63, 64, 65, 66, 67, 69, 70, 72, 73, 74, 76, 79, 81, 82, 84, 86, 87, 88, 89, 92, 93, 94, 95], "plotting_functions_unsup": [28, 29, 30, 31, 48, 49, 50, 51, 52, 72, 73, 74, 75], "plt": [9, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 32, 33, 34, 35, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 53, 54, 55, 56, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 76, 77, 78, 79, 81, 82, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98], "plu": [20, 21, 32, 65, 76], "plural": [19, 64], "pluribu": 96, "pm": [1, 13, 53, 77, 91, 97, 99], "pmltt": 1, "pn": [16, 23, 28, 29, 39, 43, 62, 67, 72, 73, 87, 93], "po": [13, 20, 21, 24, 26, 31, 35, 41, 44, 46, 51, 52, 55, 56, 63, 65, 68, 70, 75, 79, 83], "pobox": 59, "poet": [31, 51, 52, 75], "point": [1, 4, 5, 12, 13, 14, 15, 17, 18, 19, 20, 21, 22, 24, 27, 29, 34, 35, 36, 38, 40, 42, 44, 47, 48, 49, 54, 56, 59, 60, 61, 63, 64, 65, 66, 68, 71, 73, 78, 79, 80, 81, 84, 85, 87, 93, 99], "point_ind": [28, 72], "point_index": [28, 72], "poison": 17, "pole": [32, 76], "polic": 59, "polici": [3, 4, 5, 8, 13, 99], "polit": [30, 31, 32, 50, 51, 52, 59, 74, 75, 76], "politician": 59, "poll": 35, "poly_transform": [33, 77], "polynomialfeatur": [27, 33, 47, 71, 77], "pomegran": [32, 76], "ponder": 59, "pool": [1, 41], "poolarea": [24, 26, 35, 44, 46, 55, 56, 68, 70, 79], "poolqc": [24, 26, 35, 44, 46, 55, 56, 68, 70, 79], "poor": [19, 24, 27, 44, 47, 64, 68, 71, 85, 88, 94], "poorli": [16, 20, 24, 29, 33, 44, 62, 68, 73, 77], "pop": 96, "pope": [31, 52, 75], "popen": [16, 25, 26, 28], "popenarg": [16, 25, 26, 28], "popul": [18, 21, 27, 33, 47, 63, 64, 65, 71, 77, 88, 94], "popular": [9, 12, 16, 18, 19, 21, 23, 24, 25, 28, 29, 30, 31, 32, 35, 43, 44, 45, 46, 50, 51, 52, 55, 56, 61, 62, 63, 64, 65, 67, 68, 69, 70, 72, 73, 74, 75, 76, 79, 83, 90, 96], "population_per_household": [18, 63, 64, 88, 94], "port": [36, 57, 58, 80], "portent": 59, "porter": [20, 52, 83], "porterstemm": [52, 83], "portion": [0, 15, 18, 20, 22, 24, 26, 35, 41, 44, 46, 55, 56, 61, 63, 66, 68, 70, 79, 89, 91, 95, 97], "portland": 97, "portrai": 59, "portrait": [20, 41], "portug": [26, 46, 67, 70], "pos_": [31, 51, 52, 75, 83], "pos_label": 68, "pos_prob": [20, 41], "posit": [13, 15, 16, 21, 24, 25, 26, 31, 32, 33, 34, 44, 45, 46, 51, 52, 53, 54, 59, 60, 61, 62, 63, 65, 68, 69, 70, 75, 76, 77, 78, 91, 97], "posix": [34, 78], "possess": [56, 79], "possibl": [4, 6, 7, 9, 13, 14, 15, 17, 18, 20, 22, 23, 25, 26, 27, 29, 30, 32, 34, 35, 38, 40, 41, 43, 45, 46, 47, 48, 50, 52, 55, 56, 59, 60, 61, 63, 66, 67, 69, 70, 71, 73, 74, 76, 78, 79, 83, 85, 87, 88, 90, 93, 94, 96, 99], "possibli": [8, 31, 51, 52, 75, 96], "post": [1, 4, 7, 8, 9, 13, 26, 31, 33, 36, 51, 52, 53, 57, 58, 75, 77, 80, 99], "postprocess": [32, 76], "postur": 59, "potenti": [12, 16, 18, 28, 31, 35, 36, 38, 51, 52, 56, 57, 58, 62, 63, 72, 75, 79, 80], "powder": [31, 52, 75], "powel": 59, "power": [9, 15, 17, 25, 30, 31, 32, 35, 40, 41, 51, 52, 55, 56, 61, 69, 74, 75, 76, 79, 83], "pplicat": [29, 73], "pr": 85, "practic": [0, 1, 5, 7, 10, 13, 15, 17, 18, 27, 32, 35, 36, 55, 56, 59, 61, 63, 67, 71, 76, 79, 80, 85, 87, 88, 90, 93, 94, 96, 99], "practition": [35, 56, 79], "prai": 59, "prairielearn": [1, 5, 7, 13, 99], "pre": [1, 5, 13, 25, 27, 35, 36, 39, 45, 47, 48, 52, 55, 56, 59, 69, 71, 79, 80, 85], "pre_dispatch": [42, 66], "precipit": [36, 80], "precis": [12, 24, 35, 36, 68, 79, 80, 81, 85], "precision_lr": [23, 43, 67], "precision_recall_curv": [23, 43, 67], "precision_scor": [23, 43, 67], "precision_svc": [23, 43, 67], "precisionrecallcurvedisplai": [23, 43, 67], "precisionrecalldisplai": [23, 43, 67], "pred": [23, 24, 30, 33, 34, 43, 44, 50, 54, 67, 68, 74, 77, 78, 81], "pred_df": [13, 30, 50, 59, 74], "pred_dict": [13, 59], "pred_g": [30, 50, 74], "pred_lin_reg": [30, 50, 74], "pred_train": [24, 44, 68], "pred_x": [30, 50, 74], "prediciton": [34, 54, 78], "predict": [2, 12, 15, 16, 17, 18, 19, 20, 22, 23, 24, 25, 27, 28, 29, 33, 35, 36, 38, 40, 41, 42, 43, 44, 47, 52, 53, 56, 57, 58, 61, 62, 63, 66, 67, 68, 71, 72, 73, 77, 79, 80, 81, 82, 85, 87, 88, 89, 90, 91, 93, 94, 95, 96, 97, 98], "predict_expect": [34, 54, 78], "predict_for_usr": [30, 50, 74], "predict_prob": 95, "predict_proba": [20, 23, 25, 26, 32, 41, 43, 45, 46, 67, 69, 70, 76, 84, 89, 95], "predict_survival_funct": [34, 54, 78], "predicted_categori": [36, 57, 58, 80, 81], "predicted_n_rent": [33, 77], "predicted_quiz2": [14, 60], "predicted_sal": [33, 77], "predicted_target": [13, 59], "predicted_valu": 98, "predictor": [14, 60, 85], "preexec_fn": [16, 25, 26, 28], "prefer": [6, 11, 13, 25, 28, 30, 45, 50, 59, 69, 72, 74, 99], "prefer_skip_nested_valid": [18, 34], "prefix": [9, 64], "preliminari": [18, 27, 63, 71], "prepar": [18, 27, 63, 71], "preprocess": [1, 12, 15, 16, 17, 21, 22, 23, 25, 26, 27, 29, 30, 31, 32, 33, 34, 38, 39, 40, 42, 43, 45, 46, 47, 50, 51, 54, 61, 62, 65, 66, 67, 69, 70, 71, 73, 74, 75, 76, 78, 81, 82, 87, 88, 89, 93, 94, 95], "preprocess_featur": [53, 77, 91, 97], "preprocessing_fin": [34, 54, 78], "preprocessing_notenur": [34, 78], "preprocessor": [17, 22, 24, 25, 26, 34, 35, 40, 41, 42, 44, 45, 46, 53, 54, 55, 56, 64, 66, 67, 68, 69, 70, 77, 78, 79, 88, 89, 91, 94, 95, 97], "preprocessor1": [27, 47, 71], "preprocessor2": [27, 47, 71], "preprocessor3": [27, 47, 71], "prereq": [36, 80], "prerequisit": [2, 34, 54, 78, 99], "preschool": [25, 26, 45, 46, 67, 69, 70], "presenc": [19, 23, 26, 34, 46, 59, 64, 70, 78], "present": [8, 16, 20, 30, 31, 32, 34, 35, 36, 39, 41, 51, 52, 53, 55, 56, 59, 61, 74, 75, 76, 77, 78, 79, 80, 81, 85, 87, 91, 93, 97], "preserv": [28, 59, 67, 72], "pressburg": 59, "pressure3pm": [53, 77, 91, 97], "pressure9am": [53, 77, 91, 97], "presum": 59, "pretend": [15, 33, 60, 61, 77], "pretrain": [32, 48, 52, 76], "pretti": [14, 17, 21, 23, 25, 28, 31, 33, 34, 40, 43, 45, 48, 52, 53, 60, 64, 65, 67, 69, 72, 75, 77, 78, 81, 91, 92, 97], "prevent": [22, 34, 52, 54, 66, 78], "preview": 5, "previou": [13, 14, 15, 24, 25, 28, 29, 31, 33, 34, 35, 38, 45, 51, 53, 56, 60, 68, 69, 72, 73, 75, 77, 78, 79, 85, 91, 97], "previous": [17, 30, 32, 33, 74, 76, 77], "price": [9, 14, 15, 17, 18, 21, 24, 26, 34, 35, 38, 40, 44, 46, 47, 55, 56, 63, 65, 68, 70, 71, 78, 79, 90, 96], "pricei": 96, "priceperc": [90, 96], "primari": [9, 16, 20, 41, 62], "primarili": [13, 14, 26, 32, 36, 46, 60, 70, 76, 80], "princ": [31, 51, 52, 75], "princess": [31, 51, 52, 75], "principl": [10, 12, 55, 60, 85], "print": [8, 9, 13, 14, 15, 16, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 39, 41, 42, 43, 44, 45, 46, 47, 49, 50, 51, 52, 53, 54, 55, 56, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 81, 83, 84, 87, 91, 93, 96, 97], "print_dbscan_clust": 49, "print_dbscan_noise_imag": 49, "print_hierarchical_clust": 49, "print_progress": 34, "print_top": [31, 51, 52, 75], "prior": [28, 33, 72, 77, 85], "priorit": [5, 27, 71, 85], "privaci": [0, 12, 28, 31, 36, 51, 57, 58, 72, 75, 80], "privat": [5, 6, 8, 25, 26, 45, 46, 67, 69, 70], "privileg": 7, "prize": [19, 45, 64], "pro": [20, 28, 35, 46, 56, 59, 72, 79], "prob": [21, 25, 45, 65, 69, 95], "proba": [32, 76], "probabilist": [2, 31, 51, 52, 75], "probabl": [13, 16, 17, 18, 20, 23, 24, 25, 26, 27, 29, 31, 32, 34, 35, 36, 40, 41, 43, 44, 45, 46, 47, 51, 52, 53, 54, 56, 57, 58, 59, 62, 63, 64, 67, 68, 69, 70, 71, 73, 75, 76, 77, 78, 79, 80, 82, 83, 85, 89, 91, 92, 95, 97], "problem": [1, 4, 5, 7, 12, 13, 17, 19, 20, 21, 23, 24, 25, 26, 28, 29, 31, 32, 34, 35, 38, 40, 43, 44, 45, 46, 47, 51, 52, 54, 56, 57, 58, 59, 64, 65, 67, 68, 69, 70, 71, 72, 73, 75, 76, 78, 79, 81, 84, 85, 87, 89, 91, 93, 94, 95, 97, 99], "problemat": [11, 26, 34, 54, 67, 70, 78], "probosci": [32, 59, 76], "proce": [39, 87, 93, 99], "procedur": [45, 69], "proceed": [61, 91, 97], "process": [2, 6, 8, 12, 14, 16, 18, 19, 22, 25, 26, 27, 28, 29, 32, 35, 36, 38, 39, 42, 47, 51, 56, 60, 62, 63, 64, 66, 71, 72, 73, 76, 79, 80, 83, 87, 90, 93, 96, 99], "process_rout": 34, "procfil": [36, 57, 58, 80], "proclaim": 59, "prod": [19, 22, 42, 64, 66], "produc": [2, 5, 8, 14, 17, 24, 26, 32, 34, 40, 56, 68, 70, 73, 76, 78, 79, 85, 87, 93], "product": [20, 22, 30, 31, 35, 41, 42, 50, 52, 56, 66, 74, 75, 79], "prof": [25, 26, 45, 46, 67, 69, 70], "profession": [30, 36, 74, 80], "profil": [24, 44, 68], "profile_df": [30, 50, 74], "profilereport": [24, 44, 68], "profit": [56, 79], "program": [0, 4, 5, 10, 13, 31, 51, 52, 59, 75, 83, 99], "programm": [31, 51, 52, 75], "progress": 72, "project": [11, 17, 18, 27, 32, 35, 36, 56, 63, 69, 71, 76, 79, 80, 85], "promin": [31, 51, 52, 75], "promis": [13, 33, 36, 38, 52, 53, 57, 58, 59, 77, 80, 96], "promot": [34, 78], "prompt": [11, 31, 51, 75, 99], "pron": [31, 51, 52, 75, 83], "prone": [22, 59, 66], "proper": [32, 76, 86, 92], "properli": [8, 13, 34, 35, 55, 56, 78, 79], "properti": [14, 24, 26, 41, 44, 46, 47, 60, 68, 70, 71], "prophet": [33, 53, 77], "propn": [52, 83], "proport": [12, 14, 15, 19, 21, 23, 24, 25, 26, 35, 43, 44, 45, 46, 55, 56, 59, 60, 61, 64, 65, 67, 68, 69, 70, 79, 81, 95], "proportional_hazard_test": [34, 78], "prostitut": [31, 52, 75], "protagonist": 59, "protect": [31, 51, 59, 75], "protocol": [36, 57, 58, 80], "prototyp": [36, 80, 85], "prove": 81, "provid": [0, 5, 6, 8, 12, 14, 15, 19, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 33, 35, 39, 43, 44, 46, 47, 50, 51, 52, 56, 60, 61, 64, 65, 66, 67, 68, 70, 71, 72, 73, 74, 75, 77, 79, 85, 89, 90, 91, 93, 95, 96, 97, 99], "provinc": [19, 52, 64, 83], "provinci": [31, 51, 52, 75], "proxi": [15, 61], "proxim": [21, 51, 52, 65, 75, 99], "prune": 71, "psychic": 20, "psychologi": [19, 64, 85], "pt": [21, 32, 65, 66, 76], "public": [0, 6, 8, 31, 51, 52, 75], "publish": [0, 21, 31, 51, 52, 65, 75], "puck": [31, 51, 52, 75], "pud": [24, 44, 68], "pull": [6, 11, 21, 31, 51, 52, 65, 75], "pump": 59, "punct": [31, 51, 52, 75, 83], "punctuat": [19, 31, 51, 52, 64, 75, 83], "punish": [35, 56, 79], "purchas": [30, 36, 39, 59, 74, 80], "pure": [14, 33, 38, 60, 77], "purpos": [0, 14, 15, 18, 20, 30, 31, 33, 36, 41, 50, 51, 52, 57, 58, 59, 60, 61, 63, 74, 75, 77, 80, 83, 85, 86, 87, 89, 92, 93, 95, 99], "pursu": 59, "pursuit": [35, 56, 59, 79], "push": [6, 8, 26, 46, 70], "put": [8, 9, 15, 17, 18, 19, 20, 27, 28, 29, 30, 31, 36, 39, 40, 41, 47, 51, 57, 58, 59, 60, 61, 63, 64, 67, 71, 72, 73, 74, 75, 80], "px": [27, 47, 51, 52, 71, 75], "py": [14, 16, 18, 19, 25, 26, 28, 29, 31, 32, 34, 36, 45, 46, 48, 51, 54, 57, 58, 60, 61, 63, 64, 69, 70, 72, 73, 75, 76, 78, 80, 84], "pybo": [22, 42, 66], "pydata": [27, 71], "pyplot": [9, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 32, 33, 34, 35, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 53, 54, 55, 56, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 76, 77, 78, 79, 81, 82, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98], "pysurviv": [34, 54, 78], "python": [1, 3, 4, 5, 12, 22, 24, 30, 31, 32, 33, 34, 35, 36, 44, 50, 51, 52, 53, 54, 56, 57, 58, 59, 66, 68, 74, 75, 76, 77, 78, 79, 80, 99], "python3": [10, 46, 51, 54, 60, 61, 64, 70, 75, 78, 84], "pythonwarn": [23, 24, 43, 44, 68], "pytorch": [13, 32, 48, 49, 59, 76], "pyviz": [23, 43, 67], "q": 1, "qualit": [17, 40], "qualiti": [23, 26, 27, 28, 29, 35, 43, 46, 51, 55, 56, 59, 67, 70, 72, 73, 75, 79, 82], "quantifi": 67, "quantil": [17, 40], "quantit": [17, 40], "quarter": 96, "quebecoi": [17, 40], "queen": [31, 51, 52, 75], "queen_consort": [31, 51, 52, 75], "queri": [18, 25, 28, 31, 33, 34, 39, 45, 50, 51, 52, 53, 54, 63, 67, 69, 72, 74, 75, 77, 78, 91, 97], "query_img": 39, "query_point": [16, 62], "quest": [27, 47, 71], "question": [1, 3, 7, 8, 44, 51, 54, 90, 96, 99], "queuepredictor": [36, 80], "quick": [4, 13, 31, 36, 51, 52, 57, 58, 59, 75, 80, 99], "quickli": [14, 16, 17, 18, 22, 29, 31, 34, 42, 51, 54, 59, 60, 62, 63, 66, 73, 75, 78, 85, 99], "quickstart": 10, "quirk": [15, 61], "quirki": 20, "quit": [7, 13, 14, 18, 20, 22, 24, 26, 27, 29, 32, 33, 34, 35, 39, 42, 44, 46, 47, 48, 49, 52, 54, 56, 59, 60, 63, 66, 67, 68, 70, 71, 73, 76, 77, 78, 79, 83, 87, 93], "quiz": [1, 13, 25, 52, 83, 99], "quiz1": [14, 15, 19, 60, 61, 64, 85], "quiz2": [15, 19, 61, 64, 85], "quizz": [14, 60], "r": [12, 14, 15, 19, 21, 23, 33, 35, 41, 43, 53, 55, 56, 60, 64, 65, 67, 77, 79, 89, 95], "r1": [25, 45, 69], "r2": [15, 24, 25, 38, 44, 45, 68, 69, 85, 87, 93], "r2_score": [24, 27, 44, 47, 68, 71], "r4": [45, 69], "rabi": 41, "race": [25, 26, 45, 46, 64, 67, 69, 70], "rachel": 59, "radial": [16, 62], "radiu": [27, 29, 39, 47, 71, 73], "rag": [31, 51, 75], "rail": [32, 76], "rain": [53, 77, 91, 97], "rain_df": [53, 77, 91, 97], "rain_df_modifi": [53, 77, 91, 97], "rainfal": [53, 77, 91, 97], "rainfall_ahead1": 77, "rainfall_lag1": [53, 77, 91, 97], "rainfall_lag2": [53, 77, 91, 97], "rainfall_lag3": [53, 77, 91, 97], "raintodai": [53, 77, 91, 97], "raintoday_miss": [53, 77, 97], "raintoday_no": [53, 77, 97], "raintoday_y": [53, 77, 97], "raintomorrow": [53, 77, 91, 97], "rais": [7, 13, 18, 19, 23, 34, 43, 53, 59, 64, 67, 77, 78, 91, 97], "ralph": 59, "rand": [9, 25, 45, 69], "randint": [22, 42, 66], "randn": [21, 27, 47, 65, 71], "random": [7, 9, 12, 15, 16, 21, 23, 27, 28, 29, 30, 31, 32, 33, 34, 36, 39, 43, 47, 48, 49, 50, 51, 52, 54, 61, 62, 65, 67, 71, 72, 73, 74, 75, 76, 77, 78, 80, 81, 82, 84, 85, 89, 90, 95, 96, 98], "random_forest_data": [25, 69], "random_search": [22, 42, 66], "random_st": [13, 15, 16, 17, 18, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 54, 55, 56, 57, 58, 59, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 84, 87, 88, 89, 93, 94, 95, 96], "randomforestclassifi": [26, 27, 33, 35, 46, 47, 53, 54, 55, 56, 70, 71, 77, 79, 82, 89, 91, 95, 97], "randomforestclassifierrandomforestclassifi": 25, "randomforestregressor": [24, 25, 26, 27, 33, 34, 35, 36, 44, 45, 46, 47, 54, 55, 56, 57, 58, 68, 69, 70, 71, 77, 78, 79, 80, 89, 95], "randomizedsearchcv": [16, 25, 26, 35, 45, 46, 56, 62, 69, 70, 79, 89, 95], "randomizedsearchcvifit": [42, 66], "randomizedsearchcvifittedrandomizedsearchcv": 22, "randomli": [15, 21, 22, 23, 25, 43, 45, 61, 65, 66, 67, 69, 78], "randomoversampl": 81, "randomst": [27, 29, 47, 71, 73], "randomundersampl": 81, "rang": [4, 9, 12, 16, 17, 18, 19, 21, 25, 28, 30, 31, 32, 33, 34, 35, 40, 45, 48, 49, 50, 51, 52, 55, 56, 61, 62, 63, 64, 65, 69, 72, 74, 75, 76, 77, 78, 79, 90, 94, 96], "rangeindex": [19, 27, 34, 47, 53, 54, 64, 71, 77, 78, 93, 95, 97], "rank": [23, 27, 30, 31, 34, 43, 47, 52, 54, 67, 71, 74, 75, 78], "rank_test_mape_scor": [24, 44, 68], "rank_test_neg_mean_squared_error": 24, "rank_test_scor": [22, 24, 42, 44, 66, 68], "ranking_": [27, 47, 71], "rapidli": 59, "rare": [24, 28, 52, 64, 67, 68, 72, 81, 85], "rate": [13, 21, 23, 25, 28, 34, 35, 43, 45, 54, 56, 59, 65, 67, 69, 72, 78, 79, 85], "rated_item": [30, 50, 74], "rather": [13, 17, 19, 20, 22, 24, 25, 26, 28, 31, 32, 40, 42, 44, 45, 46, 51, 52, 59, 64, 66, 67, 68, 69, 70, 72, 75, 76, 81, 87, 93, 99], "ratings_df": [30, 50, 74], "ratio": [25, 34, 45, 51, 52, 69, 75, 78, 81], "rational": 8, "ravel": [20, 23, 39, 41, 43, 67, 85], "raven": 59, "raw": [9, 19, 23, 26, 27, 32, 35, 40, 43, 46, 52, 56, 59, 64, 67, 70, 71, 76, 79, 81, 84], "raw_model_output": [21, 65], "raw_scor": [26, 46, 70], "rayat": 1, "raymond": 59, "rbf": [1, 15, 18, 21, 22, 25, 26, 27, 35, 36, 42, 43, 45, 46, 47, 56, 61, 63, 64, 65, 66, 69, 70, 71, 79, 80, 85, 87, 93], "rcparam": [13, 14, 15, 23, 28, 29, 30, 33, 34, 35, 43, 50, 53, 54, 55, 56, 59, 60, 61, 67, 72, 73, 74, 77, 78, 79, 86, 91, 92, 97], "re": [4, 5, 6, 8, 9, 11, 13, 14, 15, 19, 20, 22, 24, 25, 26, 28, 30, 31, 32, 33, 34, 36, 41, 42, 44, 45, 46, 50, 51, 52, 53, 54, 57, 58, 59, 60, 61, 64, 66, 67, 68, 69, 70, 72, 74, 75, 76, 77, 78, 80, 83, 85, 86, 91, 92, 97], "reach": [1, 5, 7, 28, 59, 72, 99], "react": [32, 76], "read": [1, 4, 5, 8, 13, 16, 18, 19, 23, 24, 25, 26, 31, 32, 35, 36, 39, 43, 44, 45, 46, 51, 52, 53, 55, 56, 59, 62, 63, 64, 68, 69, 70, 75, 76, 77, 79, 80, 81, 89, 90, 91, 93, 95, 96, 97], "read_csv": [9, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 30, 31, 33, 34, 35, 36, 38, 40, 41, 42, 43, 44, 45, 46, 47, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 74, 75, 77, 78, 79, 80, 81, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97], "read_data": [32, 76], "read_excel": 9, "read_html": 9, "read_img_dataset": [39, 48, 49], "read_json": 9, "readabl": [0, 9], "reader": [12, 31, 51, 75], "readi": [6, 8, 11, 13, 15, 16, 18, 21, 40, 61, 62, 63, 65], "readlin": [32, 76], "readm": [34, 78], "readthedoc": [34, 54, 78], "real": [5, 14, 15, 16, 17, 18, 19, 21, 26, 28, 29, 30, 31, 32, 35, 40, 46, 50, 51, 52, 56, 59, 61, 62, 63, 64, 65, 67, 70, 72, 73, 74, 75, 76, 79, 83, 85], "realis": 59, "realism": [20, 41], "realist": [18, 33, 36, 39, 63, 77, 80, 91, 97], "realiti": [24, 34, 44, 51, 61, 68, 75, 78], "realiz": [56, 79], "realli": [9, 13, 15, 20, 21, 22, 27, 29, 30, 32, 33, 34, 36, 45, 47, 50, 54, 59, 61, 65, 66, 69, 71, 73, 74, 76, 77, 78, 80, 82], "reanim": 20, "rear": 59, "reason": [0, 2, 4, 5, 9, 12, 15, 18, 22, 23, 24, 26, 28, 30, 31, 33, 34, 35, 36, 43, 44, 46, 50, 51, 52, 54, 56, 59, 61, 63, 66, 67, 68, 70, 72, 74, 75, 77, 78, 79, 80, 85, 99], "rec": [24, 26, 35, 44, 46, 55, 56, 68, 70, 79], "recal": [12, 15, 18, 19, 21, 24, 28, 31, 33, 36, 40, 44, 51, 57, 58, 59, 60, 61, 62, 63, 64, 65, 68, 72, 75, 77, 80, 81, 85], "recall_lr": [23, 43, 67], "recall_scor": [23, 43, 67], "recall_svc": [23, 43, 67], "recap": 19, "receiv": [5, 7, 8, 13, 19, 29, 31, 32, 36, 51, 53, 57, 58, 64, 73, 75, 76, 77, 80, 81, 99], "recent": [9, 11, 13, 18, 19, 24, 27, 30, 31, 33, 34, 44, 50, 51, 52, 53, 59, 64, 71, 74, 75, 77, 78], "recip": [15, 31, 51, 61, 75], "reclin": 41, "recogn": [12, 15, 20, 29, 31, 33, 35, 56, 61, 73, 75, 79, 99], "recognit": [13, 52, 59, 60, 62, 81, 83, 99], "recommend": [1, 2, 5, 9, 12, 15, 20, 22, 23, 26, 28, 31, 32, 36, 39, 41, 42, 51, 52, 56, 59, 61, 62, 66, 67, 72, 75, 76, 79, 80, 81, 82, 89, 90, 95, 96], "reconcili": 1, "reconstruct": 50, "record": [14, 34, 46, 60, 78], "recreat": [91, 97], "rectangular": [28, 72], "recurr": [31, 33, 51, 53, 75, 77], "recurs": 12, "red": [14, 16, 23, 26, 27, 28, 31, 33, 43, 46, 47, 51, 53, 59, 60, 62, 67, 70, 71, 72, 75, 77, 98], "redbon": [22, 42, 66], "redeem": 59, "redefin": [34, 54, 78], "redistribut": [0, 99], "reduc": [8, 9, 13, 16, 22, 24, 25, 26, 27, 30, 32, 44, 45, 46, 47, 52, 59, 62, 66, 67, 68, 69, 70, 71, 74, 76, 83, 84, 87, 93, 99], "reduct": [2, 23, 25, 27, 28, 43, 45, 59, 67, 69, 71, 72], "redund": [21, 26, 46, 65, 70], "ref": [23, 34, 43, 67, 78, 81], "refer": [4, 9, 13, 14, 15, 16, 18, 19, 21, 26, 28, 30, 31, 32, 46, 51, 52, 60, 61, 62, 63, 64, 65, 67, 70, 72, 74, 75, 76, 83, 87, 93, 98, 99], "referenti": [31, 52, 75], "refin": [16, 39, 62, 87, 93], "refit": [24, 42, 44, 66, 68], "reflect": [16, 24, 26, 31, 44, 46, 51, 52, 62, 68, 70, 75, 87, 93, 99], "reflection_period": [36, 57, 58, 80, 81], "reg": [14, 25, 45, 60, 69, 89, 95], "reg_alpha": [45, 46, 69, 70, 95], "reg_lambda": [45, 46, 69, 70, 95], "reg_model": [14, 60], "regard": [20, 59], "regardless": 8, "regex": [52, 83], "regim": [36, 80], "region": [14, 29, 32, 36, 53, 60, 73, 76, 77, 80, 81, 84, 91, 97], "region_data": [53, 77, 91, 97], "regist": [13, 36, 57, 58, 80, 99], "registered_nurs": [31, 51, 52, 75], "regrad": [7, 13], "regress": [1, 2, 12, 13, 15, 17, 18, 19, 20, 25, 26, 30, 32, 33, 34, 35, 36, 41, 46, 50, 53, 54, 56, 59, 63, 64, 70, 71, 74, 76, 77, 78, 79, 80, 84, 85, 87, 89, 91, 93, 95, 97], "regression_df": [14, 60], "regressioncolumntransform": [25, 45, 69, 95], "regressor": [14, 15, 17, 18, 19, 24, 33, 38, 60, 63, 64, 68, 77, 88, 89, 93, 94, 95], "regular": [16, 19, 21, 33, 34, 45, 52, 54, 56, 62, 64, 65, 69, 77, 78, 79, 83, 85, 99], "regularli": 5, "regulatori": [26, 46, 70], "rei": [1, 99], "reinforc": [13, 28, 59, 72, 85], "reinstal": 11, "reject": 67, "rel": [15, 17, 21, 26, 29, 40, 45, 46, 52, 65, 70, 73, 83, 84], "relabel": [28, 72], "relat": [2, 7, 13, 20, 21, 24, 25, 26, 27, 28, 30, 31, 33, 34, 41, 44, 46, 47, 51, 52, 54, 59, 65, 68, 69, 70, 71, 72, 74, 75, 77, 78, 81, 89, 95, 99], "relationship": [12, 25, 26, 27, 31, 33, 45, 46, 47, 51, 52, 53, 56, 59, 67, 69, 70, 71, 75, 77, 79, 82, 85, 86, 87, 90, 91, 92, 93, 96, 97, 99], "relationship_husband": [26, 45, 46, 70], "relationship_not": 45, "relationship_oth": 45, "relationship_own": [26, 45, 46, 70], "relationship_unmarri": 45, "relationship_wif": 45, "relearn": [32, 76], "releas": [1, 8], "relev": [1, 4, 9, 12, 14, 16, 18, 22, 26, 42, 46, 47, 53, 60, 62, 63, 66, 70, 77, 81], "reli": [13, 15, 16, 27, 29, 30, 33, 39, 47, 59, 61, 62, 71, 73, 74, 77, 87, 93, 99], "reliabl": [13, 15, 28, 59, 72], "religi": [52, 59], "reluct": 59, "remad": 59, "remain": [17, 24, 27, 30, 33, 35, 44, 47, 50, 55, 56, 68, 71, 74, 77, 79], "remaind": [7, 40, 42, 45, 46, 64, 66, 68, 69, 70, 95], "remak": 59, "rememb": [8, 13, 16, 19, 20, 22, 23, 26, 27, 29, 31, 32, 34, 41, 42, 43, 46, 47, 51, 53, 54, 59, 62, 64, 66, 67, 70, 71, 73, 75, 76, 77, 78, 86, 87, 91, 92, 93, 97, 99], "remind": [86, 92], "remix": 0, "remov": [8, 11, 18, 25, 26, 27, 31, 32, 34, 39, 45, 46, 47, 48, 49, 51, 52, 54, 63, 67, 69, 70, 71, 75, 76, 78, 82, 83, 84, 91, 97], "renam": [13, 33, 36, 46, 53, 57, 58, 59, 70, 77, 80, 81, 96], "render": [4, 8, 13, 15, 17, 18, 19, 20, 22, 23, 24, 25, 26, 27, 28, 32, 35, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 52, 55, 56, 59, 63, 64, 66, 67, 68, 69, 70, 71, 72, 76, 79, 83, 95], "rent": [33, 59, 77], "rental": [33, 36, 77, 80], "rentals_df": [33, 77], "rentals_lag5": [33, 77], "rentals_lag5_i": [33, 77], "rentals_lag5_x": [33, 77], "rentals_model": [33, 77], "renter": 41, "repair": [25, 26, 45, 46, 67, 69, 70], "repeat": [9, 27, 28, 29, 32, 36, 47, 71, 72, 73, 76, 80, 82, 89, 93, 95], "repeatedli": 7, "rephras": [35, 56, 79], "replac": [13, 17, 18, 20, 25, 26, 34, 40, 41, 45, 46, 50, 54, 59, 63, 67, 69, 70, 74, 78, 81, 90, 96], "replace_tag": [20, 41], "replic": [36, 59, 80], "repo": [1, 6, 23, 36, 43, 57, 58, 67, 80], "report": [7, 14, 15, 22, 24, 27, 31, 44, 47, 51, 53, 60, 66, 67, 68, 71, 75, 77], "repositori": [0, 1, 6, 11, 13, 17, 21, 23, 36, 37, 39, 40, 43, 57, 58, 65, 67, 80], "repres": [14, 15, 16, 18, 19, 21, 23, 25, 26, 27, 28, 29, 30, 31, 32, 33, 35, 43, 46, 50, 51, 52, 54, 56, 59, 60, 61, 62, 63, 64, 65, 67, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 83, 85, 89, 95], "represent": [14, 15, 17, 18, 20, 22, 23, 24, 25, 26, 27, 28, 29, 32, 35, 36, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 52, 55, 56, 57, 58, 59, 60, 63, 66, 67, 68, 69, 70, 71, 72, 73, 76, 79, 80, 85, 95], "reproduc": [4, 5, 15, 22, 25, 36, 42, 45, 61, 66, 69, 80, 98, 99], "republ": [26, 45, 46, 70], "request": [7, 13, 31, 52, 75, 99], "requir": [6, 8, 11, 16, 17, 18, 22, 23, 25, 26, 27, 28, 29, 30, 31, 32, 34, 35, 39, 40, 42, 43, 45, 46, 47, 51, 52, 56, 57, 58, 59, 62, 63, 66, 67, 69, 70, 71, 72, 73, 74, 75, 76, 78, 79, 81, 85, 90, 91, 96, 97, 99], "rerun": [15, 17, 18, 19, 20, 22, 23, 24, 25, 26, 27, 32, 35, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 55, 56, 59, 63, 64, 66, 67, 68, 69, 70, 71, 76, 79, 95], "res_mean": 61, "resampl": 81, "research": [5, 15, 22, 30, 36, 42, 50, 51, 52, 59, 61, 66, 74, 75, 80], "resembl": 59, "reserv": [33, 77, 99], "reset": [18, 32, 34, 85, 97], "reset_index": [13, 59, 96], "reshap": [9, 17, 21, 22, 33, 40, 42, 48, 65, 66, 77], "reshape_for_countvector": [17, 40], "resid": [21, 65], "residenti": 93, "residu": [45, 69], "resiz": [39, 48, 49], "resnet": [32, 76], "resolut": [52, 83], "resolv": 99, "resort": [21, 65], "resourc": [1, 3, 5, 6, 25, 26, 31, 32, 36, 42, 45, 46, 51, 52, 57, 58, 59, 60, 69, 70, 75, 76, 80, 85], "respect": [21, 22, 25, 26, 42, 43, 45, 46, 59, 65, 66, 67, 69, 70, 90, 96], "respons": [4, 5, 8, 14, 31, 35, 51, 52, 56, 59, 60, 72, 75, 79, 99], "responsibli": [5, 99], "rest": [20, 21, 22, 31, 32, 34, 36, 46, 51, 54, 57, 58, 59, 65, 66, 75, 76, 78, 80, 85, 91, 93, 97], "restart": [8, 11], "restaur": [17, 30, 36, 40, 74, 80], "restaurant_df": [17, 40], "restaurant_nam": [17, 40], "restingbp": [89, 95], "restingecg": [89, 95], "restrain": 59, "restraint": 59, "restrict": [0, 24, 25, 31, 44, 45, 51, 52, 68, 69, 75], "resubmit": 13, "result": [2, 5, 8, 9, 12, 13, 14, 15, 16, 17, 18, 19, 21, 23, 24, 25, 26, 27, 29, 32, 33, 34, 36, 38, 39, 40, 43, 45, 46, 47, 53, 54, 61, 62, 63, 64, 65, 67, 68, 69, 70, 71, 72, 73, 76, 77, 78, 80, 87, 89, 90, 91, 93, 95, 96, 97, 99], "result_block": [34, 78], "result_img": [32, 76], "results_df": [15, 16, 20, 21, 38, 39, 41, 61, 62, 65, 87, 93], "results_dict": [16, 18, 22, 39, 61, 62, 63, 64, 66], "results_proba": 95, "results_single_valid_df": [15, 38, 87, 93], "retail": 85, "retail_df": [33, 77], "retail_df_test": [33, 77], "retail_df_train": [33, 77], "retail_lag_5": [33, 77], "retail_model": [33, 77], "retail_test_5": [33, 77], "retail_test_5_pr": [33, 77], "retail_train_5": [33, 77], "retail_train_5_d": [33, 77], "retail_train_5_i": [33, 77], "retail_train_5_x": [33, 77], "retent": [34, 78], "retrain": [22, 36, 66, 80], "retriev": [31, 51, 75], "return": [6, 9, 11, 14, 15, 16, 18, 19, 20, 23, 24, 27, 28, 29, 30, 31, 32, 33, 34, 36, 39, 41, 43, 44, 48, 49, 50, 51, 52, 53, 54, 57, 58, 60, 61, 62, 63, 64, 67, 68, 72, 73, 74, 75, 76, 77, 78, 80, 82, 85, 87, 91, 93, 97], "return_gener": [19, 34, 64], "return_predict": [36, 57, 58, 80], "return_train_scor": [15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 33, 34, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 77, 78, 82, 87, 89, 93, 94, 95], "return_tupl": 34, "reus": 67, "reveal": 85, "revenu": [30, 50, 74], "revers": [19, 24, 44, 64, 68], "review": [4, 21, 31, 35, 55, 56, 65, 72, 75, 79, 85, 89, 95, 99], "review_pp": [20, 41], "revisit": [23, 43, 67, 85], "revok": 0, "revolv": 59, "reward": [13, 19, 28, 59, 64, 72], "reynold": 59, "rf": [33, 34, 77, 78, 95], "rf_classifi": 95, "rf_imp_df": [26, 46, 70], "rf_score": 95, "rfe_cv": [27, 47, 71], "rfe_pip": [27, 47, 71], "rfecv": [27, 47, 71], "rgb": [13, 59], "rhode_island": [31, 51, 52, 75], "rich": [5, 26, 34, 46, 52, 54, 56, 70, 78, 79, 85], "richard": [35, 56, 79], "richardson": 59, "richer": [31, 75], "richmond": 97, "rickman": 20, "rico": [26, 45, 46, 70], "rid": [17, 19, 25, 26, 34, 40, 45, 46, 52, 64, 69, 70, 78, 83], "ridg": [26, 27, 30, 33, 34, 35, 36, 46, 47, 50, 54, 55, 56, 70, 71, 74, 77, 78, 79, 80], "ridge__alpha": [24, 44, 68], "ridge_pr": [24, 44, 68], "ridge_tun": [24, 44, 68], "ridgecv": [27, 47, 71], "ridgecv_pip": [24, 44, 68], "ridgeridg": [24, 27, 47, 68, 71], "ridicul": 41, "right": [0, 1, 11, 12, 13, 15, 17, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 35, 36, 38, 40, 41, 42, 43, 44, 47, 50, 52, 54, 56, 59, 65, 66, 67, 68, 71, 72, 73, 74, 75, 79, 80, 85, 93], "rightarrow": [16, 21, 23, 24, 25, 28, 29, 30, 31, 32, 36, 43, 44, 45, 50, 51, 52, 56, 57, 58, 60, 62, 65, 67, 68, 69, 72, 73, 74, 75, 76, 79, 80, 85], "rindfleischetikettierungs\u00fcberwachungsaufgaben\u00fcbertragungsgesetz": [52, 83], "rip": 20, "rise": [27, 47, 52, 71, 83], "risk": [23, 27, 31, 35, 43, 51, 56, 67, 71, 75, 79, 87, 89, 93, 95], "riti": 29, "river": [21, 65], "rl": [24, 26, 35, 44, 46, 55, 56, 68, 70, 79], "rmse": [30, 50, 74, 85], "rng": [27, 29, 47, 71, 73], "rnn": [31, 33, 51, 53, 75, 77], "ro": 81, "roam": 31, "roast": 72, "robberi": 20, "roberta": [31, 51, 75], "robin": 20, "robot": [30, 31, 50, 51, 52, 74, 75], "robust": [13, 15, 16, 17, 18, 22, 25, 29, 40, 45, 59, 61, 62, 63, 66, 69, 73, 87, 93], "robustscal": [17, 40], "roc": [12, 36, 80, 85], "roc_auc": [23, 43, 67, 81], "roc_auc_scor": [23, 43, 67], "roc_curv": [23, 43, 67], "roc_lr": [23, 43, 67], "roc_svc": [23, 43, 67], "roccurvedisplai": [23, 43, 67], "rock": 20, "rodolfo": [22, 66], "rodr\u00edguez": [52, 83], "roger": [27, 47, 59, 71], "role": [20, 21, 22, 26, 31, 32, 42, 46, 59, 65, 66, 70, 75, 76], "roll": 59, "roman": [30, 50, 74], "romanc": [30, 50, 74], "romant": [30, 50, 74], "ronald": [21, 65], "roof": [46, 70], "roofmatl": [24, 26, 35, 44, 46, 55, 56, 68, 70, 79], "roofmatl_clytil": [24, 44, 46, 68, 70], "roofmatl_compshg": [24, 46, 68, 70], "roofmatl_membran": [24, 68, 70], "roofmatl_met": [24, 68, 70], "roofmatl_rol": [24, 68, 70], "roofmatl_tar": [24, 68, 70], "roofmatl_wdshak": [24, 68, 70], "roofmatl_wdshngl": [24, 46, 68, 70], "roofstyl": [24, 26, 35, 44, 46, 55, 56, 68, 70, 79], "roofstyle_flat": [24, 68, 70], "roofstyle_g": [24, 44, 68, 70], "roofstyle_gambrel": [24, 68, 70], "roofstyle_hip": [24, 68, 70], "roofstyle_mansard": [24, 68, 70], "roofstyle_sh": [24, 68, 70], "room": [14, 17, 21, 24, 27, 40, 44, 47, 59, 60, 65, 68, 71, 99], "rooms_per_household": [18, 27, 47, 63, 64, 71, 88, 94], "rooms_per_household_0": [27, 47, 71], "rooms_per_household_1": [27, 47, 71], "rooms_per_household_10": [27, 47, 71], "rooms_per_household_11": [27, 47, 71], "rooms_per_household_12": [27, 47, 71], "rooms_per_household_13": [27, 47, 71], "rooms_per_household_14": [27, 47, 71], "rooms_per_household_15": [27, 47, 71], "rooms_per_household_16": [27, 47, 71], "rooms_per_household_17": [27, 47, 71], "rooms_per_household_18": [27, 47, 71], "rooms_per_household_19": [27, 47, 71], "rooms_per_household_2": [27, 47, 71], "rooms_per_household_3": [27, 47, 71], "rooms_per_household_4": [27, 47, 71], "rooms_per_household_5": [27, 47, 71], "rooms_per_household_6": [27, 47, 71], "rooms_per_household_7": [27, 47, 71], "rooms_per_household_8": [27, 47, 71], "rooms_per_household_9": [27, 47, 71], "root": [16, 30, 39, 46, 48, 49, 50, 60, 62, 74, 85, 92], "rose": [52, 83], "rostin": [1, 99], "rotat": [33, 53, 77, 91, 97], "rotten": [31, 51, 75], "rough": 4, "roughli": [32, 36, 52, 61, 76, 80, 83, 85], "round": [9, 16, 18, 22, 23, 25, 29, 31, 39, 42, 43, 45, 51, 62, 63, 66, 67, 69, 73, 75, 87, 93, 95], "rounder": 20, "rout": [14, 33, 53, 60, 77], "routed_param": [34, 64], "row": [14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 29, 30, 31, 32, 33, 34, 35, 36, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 49, 50, 51, 52, 53, 54, 55, 56, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 73, 74, 75, 76, 77, 78, 79, 80, 81, 87, 89, 90, 91, 92, 93, 94, 95, 96, 97, 99], "rry": [51, 52, 75], "rsh": [22, 42, 66], "ru": [9, 81], "rube": 41, "rubia": [1, 99], "rubric": [13, 21, 65], "rug": [31, 51, 75], "rule": [1, 5, 9, 13, 14, 20, 21, 36, 38, 40, 41, 45, 52, 59, 60, 62, 65, 67, 69, 80, 83, 85, 87, 92, 93, 99], "run": [1, 4, 5, 6, 8, 13, 16, 19, 22, 23, 24, 25, 26, 28, 29, 31, 32, 34, 36, 39, 42, 43, 44, 46, 48, 49, 51, 52, 55, 57, 58, 59, 61, 62, 64, 66, 67, 68, 70, 72, 73, 75, 76, 80, 83, 84, 86, 87, 89, 92, 93, 95], "ruscorpora": [31, 51, 52, 75], "rush": 71, "russel": 1, "rusti": 5, "rv": [22, 42, 66], "rv_continuous_frozen": [42, 66], "rv_discrete_frozen": [42, 66], "rvert_2": [31, 52, 75], "s1": [9, 52], "s1600": [31, 51, 75], "s19": [18, 63], "s2": [9, 52], "s_lag": 53, "sa": 1, "sabr": [31, 51, 52, 75], "sabrina": 1, "sad": [31, 51, 75], "sadli": [31, 51, 52, 59, 75], "safe": [18, 63], "safeti": [32, 76], "saga": 59, "sai": [9, 14, 16, 18, 19, 20, 24, 25, 26, 33, 35, 44, 45, 46, 52, 56, 59, 60, 62, 63, 64, 67, 68, 69, 70, 77, 79, 85, 92, 94], "said": [6, 18, 21, 26, 29, 30, 31, 35, 46, 51, 52, 56, 61, 63, 65, 70, 73, 74, 75, 79], "sail": 59, "saint": 20, "sal": [24, 26, 35, 44, 46, 55, 56, 68, 70, 79], "sale": [9, 15, 24, 33, 38, 44, 56, 67, 68, 77, 79, 97], "salecondit": [24, 26, 35, 44, 46, 55, 56, 68, 70, 79], "salecondition_abnorml": [24, 68, 70], "salecondition_adjland": [24, 68, 70], "salecondition_alloca": [24, 68, 70], "salecondition_famili": [24, 68, 70], "salecondition_norm": [24, 68, 70], "salecondition_parti": [24, 68, 70], "salepric": [24, 26, 35, 44, 46, 55, 56, 68, 70, 79], "sales_data": [33, 77], "saleswoman": [31, 51, 52, 75], "saletyp": [24, 26, 35, 44, 46, 55, 56, 68, 70, 79], "saletype_cod": [24, 68, 70], "saletype_con": [24, 68, 70], "saletype_conld": [24, 68, 70], "saletype_conli": [24, 68, 70], "saletype_conlw": [24, 68, 70], "saletype_cwd": [24, 68, 70], "saletype_new": [24, 68, 70], "saletype_oth": [24, 68, 70], "saletype_wd": [24, 44, 68, 70], "salmongum": 97, "salt": [21, 26, 46, 65, 70], "salvador": 45, "salvag": 59, "sam": [30, 50, 74], "same": [7, 8, 13, 14, 15, 16, 17, 18, 19, 21, 22, 23, 24, 27, 28, 29, 30, 31, 32, 33, 34, 35, 38, 43, 44, 47, 50, 51, 52, 53, 54, 55, 56, 60, 61, 62, 63, 64, 65, 66, 67, 68, 71, 72, 73, 74, 75, 76, 77, 78, 79, 81, 82, 83, 85, 86, 87, 91, 92, 93, 94, 96, 97], "samosa": 52, "sampl": [13, 14, 15, 16, 18, 21, 22, 26, 29, 32, 33, 34, 35, 36, 39, 42, 45, 46, 48, 49, 56, 60, 62, 63, 65, 66, 67, 70, 73, 76, 77, 78, 79, 80, 86, 87, 89, 91, 92, 93, 95, 96, 97], "sample_df": [36, 57, 58, 80, 81], "sample_weight": 34, "samples_x": 95, "sampling_method": [45, 69], "sampling_strategi": 81, "samuel": [13, 59], "sand": [32, 76], "sandbar": [32, 76], "sandhu": [1, 99], "sane": 59, "saniti": [14, 34, 54, 60, 78], "sarah": 1, "sarcast": 59, "sat": [31, 33, 51, 75, 77], "satir": 59, "satisfactori": [28, 72], "satisfi": [28, 72], "satur": [35, 55, 56, 79], "saturdai": [33, 77], "sauc": [17, 40], "save": [8, 9, 19, 22, 26, 32, 35, 42, 46, 52, 53, 56, 64, 66, 70, 76, 77, 79, 87, 88, 91, 93, 94, 97], "saw": [18, 20, 21, 22, 29, 31, 32, 51, 63, 65, 66, 67, 73, 75, 76, 85], "sayid": 41, "sb": [27, 47, 71, 90, 96], "scalabl": [29, 73], "scalar": 9, "scale": [15, 16, 19, 22, 23, 24, 25, 27, 29, 31, 32, 34, 35, 36, 38, 42, 43, 44, 45, 47, 51, 54, 56, 57, 58, 61, 62, 64, 66, 67, 68, 69, 71, 73, 75, 76, 78, 79, 80, 85, 87, 88, 90, 93, 94, 96], "scale_pos_weight": [25, 45, 69], "scaler": [17, 18, 26, 27, 34, 40, 46, 47, 63, 70, 71], "scan": 85, "scare": 20, "scari": [36, 57, 58, 59, 80], "scariest": 59, "scatter": [24, 26, 27, 44, 46, 47, 63, 68, 70, 71, 90, 96, 98], "scatter_3d": [27, 47, 71], "scatterplot": [27, 36, 47, 71, 80, 90, 96, 98], "scc": [31, 51, 52, 75], "scenario": [12, 15, 19, 26, 27, 29, 33, 34, 36, 61, 64, 69, 70, 71, 73, 77, 78, 80, 85], "scene": 59, "scenic": 59, "sceptic": 59, "schafer": [36, 57, 58, 80], "schedul": [5, 7, 54, 78, 85, 99], "schmidt": [22, 66], "scholarship": [13, 59], "school": [25, 26, 30, 45, 46, 50, 59, 67, 69, 70, 74], "schoolteach": [31, 51, 52, 75], "scienc": [1, 2, 5, 6, 10, 12, 19, 28, 31, 33, 35, 51, 56, 59, 64, 72, 75, 77, 79, 85], "scientif": [30, 31, 52, 59, 74, 75], "scientist": [1, 10, 29, 73], "scikit": [5, 10, 12, 14, 16, 21, 22, 23, 25, 28, 29, 32, 33, 35, 42, 43, 45, 56, 60, 62, 65, 66, 67, 69, 72, 73, 76, 77, 79, 81, 84], "scipi": [22, 29, 31, 42, 51, 52, 66, 73, 75, 78], "scm": 6, "scope": [13, 31, 33, 51, 52, 59, 75, 77], "score": [12, 15, 16, 17, 18, 19, 20, 25, 26, 29, 30, 31, 32, 33, 34, 35, 36, 38, 39, 40, 41, 42, 45, 46, 47, 51, 52, 53, 54, 55, 56, 57, 58, 59, 62, 63, 64, 69, 70, 71, 73, 75, 76, 77, 78, 79, 80, 81, 84, 85, 86, 87, 89, 91, 92, 93, 94, 95, 96, 97, 99], "score_func": [24, 44, 68], "score_gb_test": [35, 55, 56, 79], "score_gb_train": [35, 55, 56, 79], "score_lr_print_coeff": [53, 77, 91, 97], "score_param": [19, 64], "score_rf_test": [35, 55, 56, 79], "score_rf_train": [35, 55, 56, 79], "score_tim": [15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 33, 34, 39, 40, 41, 43, 44, 45, 46, 47, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 77, 78, 81, 93, 94, 95], "scorer": [19, 24, 44, 64, 68], "scores_averag": [89, 95], "scores_dict": [20, 21, 41, 65], "scores_imag": [21, 65], "scores_stack": [89, 95], "scoring_method": [34, 54, 78], "scoring_metr": [25, 26, 45, 46, 69, 70], "scotland": [52, 83], "scott": [35, 56, 59, 79], "scratch": [2, 32, 36, 76, 80], "screen": [8, 20, 41], "screenplai": 52, "screenporch": [24, 26, 35, 44, 46, 55, 56, 68, 70, 79], "screenshot": [35, 55, 56, 79], "script": 59, "sdng": [24, 44, 68, 70], "se": [34, 53, 77, 78, 97], "sea": [32, 76], "seaborn": [26, 27, 28, 29, 30, 46, 47, 50, 70, 71, 72, 73, 74, 90, 96], "seacoast": [32, 76], "seamless": 59, "search": [4, 6, 11, 24, 31, 44, 51, 52, 68, 75, 83, 85, 87, 93], "search_multi": [24, 44, 68], "seashor": [32, 76], "season": [91, 97], "season_autumn": [53, 77, 97], "season_fal": [53, 77], "season_spr": 97, "season_summ": [53, 77, 97], "season_wint": [53, 77, 97], "seat": [5, 32, 76, 99], "seawal": [32, 76], "second": [4, 7, 13, 14, 21, 25, 26, 29, 31, 32, 33, 35, 45, 46, 51, 56, 60, 65, 69, 70, 73, 75, 76, 77, 79], "secondari": 59, "section": [1, 8, 13, 14, 27, 47, 59, 60, 61, 71, 89, 95, 99], "secur": [26, 31, 36, 46, 51, 57, 58, 70, 75, 80, 99], "see": [1, 4, 7, 8, 9, 11, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 31, 32, 33, 34, 35, 36, 38, 39, 40, 43, 44, 45, 46, 48, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 72, 73, 75, 76, 77, 78, 79, 80, 85, 86, 87, 89, 90, 91, 92, 93, 95, 96, 97, 99], "seed": [21, 22, 28, 29, 36, 39, 42, 48, 49, 65, 66, 72, 73, 80, 98], "seem": [14, 16, 18, 19, 20, 21, 22, 24, 25, 26, 28, 30, 33, 34, 41, 42, 44, 45, 46, 48, 50, 53, 54, 59, 60, 62, 63, 64, 65, 66, 67, 68, 69, 70, 72, 74, 77, 78, 81, 84, 87, 93, 96], "seemingli": 67, "seen": [9, 13, 16, 18, 19, 20, 21, 25, 27, 29, 30, 31, 34, 47, 50, 51, 59, 61, 62, 63, 64, 65, 71, 73, 74, 75, 78, 82, 85, 87, 89, 92, 93, 95], "segment": [12, 32, 34, 36, 52, 59, 76, 78, 80, 81, 83, 85], "segmentspher": [36, 80], "select": [1, 5, 6, 12, 14, 15, 16, 18, 19, 21, 22, 23, 24, 25, 26, 32, 33, 34, 35, 36, 38, 41, 42, 43, 45, 56, 59, 61, 62, 63, 64, 65, 66, 67, 68, 69, 76, 77, 78, 79, 80, 81], "select_dtyp": [24, 44, 68, 90, 96], "select_knn": [27, 47, 71], "select_rf": [27, 47, 71], "select_svc": [27, 47, 71], "selectfrommodel": [27, 47, 71], "self": [13, 16, 17, 18, 19, 25, 26, 28, 31, 34, 40, 51, 54, 59, 64, 75, 78, 99], "sell": [0, 9, 14, 56, 59, 60, 79], "semant": [12, 28, 29, 51, 52, 72, 73, 75], "semest": [5, 13, 99], "semi": [1, 52], "semicolon": 9, "semilogx": [24, 44, 68], "send": [4, 59], "senior": [34, 54, 78], "seniorcitizen": [34, 54, 78], "sens": [7, 15, 19, 20, 21, 24, 26, 27, 28, 30, 31, 33, 34, 36, 41, 44, 46, 47, 50, 51, 52, 53, 54, 59, 61, 64, 65, 67, 68, 70, 71, 72, 74, 75, 77, 78, 80, 84, 88, 94], "sensibl": [8, 36, 80], "sensit": [5, 15, 18, 22, 23, 24, 28, 34, 42, 43, 44, 54, 61, 63, 66, 67, 68, 72, 78, 90, 94, 96, 99], "sent": [52, 59, 83], "sent_token": [31, 51, 52, 75, 83], "sentenc": [35, 52, 56, 79, 83], "sentence_transform": [31, 51, 75], "sentencetransform": [31, 51, 75], "sentiment": [20, 21, 41, 52, 60, 65], "sentiment_predict": [13, 59], "sep": [1, 13], "sepal": [16, 39, 62, 87, 93], "separ": [11, 14, 15, 17, 18, 19, 21, 23, 27, 28, 30, 31, 33, 40, 43, 47, 50, 51, 52, 53, 60, 61, 63, 64, 65, 67, 71, 72, 74, 75, 77, 83, 84, 85, 86, 87, 88, 92, 93, 94], "sept": [1, 13], "septemb": [13, 33, 53, 77, 97], "sequel": 59, "sequenc": [15, 19, 31, 32, 33, 51, 53, 59, 60, 61, 64, 75, 76, 77], "sequenti": [14, 25, 33, 34, 45, 60, 69, 77, 78, 85], "sequentialfeatureselector": [27, 82], "ser": [34, 63, 78], "seri": [1, 2, 12, 18, 19, 23, 27, 32, 34, 36, 43, 47, 57, 58, 59, 61, 63, 64, 67, 71, 76, 78, 80], "serial": [25, 45, 69], "seriou": [7, 30, 31, 34, 36, 52, 57, 58, 59, 74, 75, 78, 80, 81], "serious": 99, "serv": [12, 14, 26, 45, 46, 60, 70], "server": [31, 39, 51, 75], "servic": [17, 25, 26, 30, 31, 34, 40, 45, 46, 54, 69, 70, 74, 75, 78], "session": [5, 72, 85, 99], "set": [1, 6, 8, 9, 10, 14, 15, 16, 17, 18, 19, 20, 21, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 39, 40, 42, 43, 44, 45, 46, 50, 51, 52, 53, 54, 55, 56, 59, 60, 62, 63, 64, 65, 68, 69, 70, 72, 73, 74, 75, 76, 77, 78, 79, 81, 82, 83, 85, 87, 88, 89, 90, 91, 93, 94, 95, 96, 97, 98], "set_axis_off": [86, 92], "set_config": [22, 25, 42, 45, 66, 69], "set_index": [16, 22, 23, 24, 39, 42, 43, 44, 61, 62, 66, 67, 68], "set_num_thread": 32, "set_opt": [13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 29, 30, 38, 39, 40, 41, 42, 43, 50, 59, 60, 61, 62, 63, 64, 65, 66, 67, 73, 74, 81, 82, 86, 87, 88, 92, 93, 94], "set_properti": [13, 59], "set_se": [39, 48, 49], "set_titl": [16, 21, 32, 39, 62, 65, 67, 76, 87, 93], "set_xlabel": [16, 21, 28, 39, 62, 65, 72, 87, 90, 93, 96], "set_ylabel": [16, 21, 28, 39, 62, 65, 72, 87, 90, 93, 96], "set_ylim": [90, 96], "setosa": [32, 76], "settl": 85, "setup": [3, 8, 11, 13, 50, 51, 75, 92], "sev": [24, 26, 35, 44, 46, 55, 56, 68, 70, 79], "sever": [18, 21, 28, 29, 31, 32, 51, 52, 53, 63, 65, 72, 73, 75, 76, 77, 84, 91, 97, 99], "sewag": 59, "sex": [25, 26, 27, 45, 46, 67, 69, 70, 82, 89, 95], "sex_mal": [45, 46, 70], "sexual": 99, "sfu": [31, 51, 52, 75], "shall": [0, 31, 51, 52, 59, 75], "shallow": [25, 41, 45, 69], "shame": 59, "shan": [52, 83], "shap": [36, 80], "shape": [14, 15, 16, 17, 18, 19, 20, 22, 23, 24, 26, 27, 28, 30, 31, 32, 33, 34, 35, 38, 39, 40, 41, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 60, 61, 62, 63, 64, 66, 67, 68, 69, 70, 71, 72, 74, 75, 76, 77, 78, 79, 81, 84, 85, 87, 91, 93, 97], "shape_df": 61, "shape_dict": 61, "share": [0, 5, 16, 17, 18, 20, 22, 27, 36, 40, 57, 58, 59, 80, 82, 99], "sharealik": 1, "sharex": 63, "sharki": 59, "sharp": 59, "she": [13, 20, 30, 50, 52, 59, 74, 83], "shed": [20, 24, 26, 35, 44, 46, 55, 56, 68, 70, 79], "sheet": [10, 36, 57, 58, 80, 85], "shelf": [25, 45, 52, 69, 83], "shell": [10, 13], "sheriff": 20, "shift": [11, 31, 33, 51, 53, 59, 75, 77, 91, 97], "shipyard": [17, 40], "shitti": [31, 51, 75], "shiver": 41, "shng": [24, 44, 68, 70], "shock": 20, "shoe": 59, "shoot": 59, "shop": [30, 31, 51, 74, 75], "short": [1, 11, 22, 25, 31, 35, 42, 45, 51, 52, 59, 61, 66, 69, 75, 99], "shorter": [34, 59, 78], "shorthand": [17, 18, 63], "shortli": [8, 36, 57, 58, 80], "shot": [20, 27, 31, 47, 51, 59, 71, 75], "should": [5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 19, 21, 23, 26, 27, 28, 31, 32, 33, 34, 36, 38, 39, 40, 41, 43, 46, 47, 50, 51, 52, 53, 57, 58, 59, 60, 61, 62, 63, 64, 65, 67, 70, 71, 72, 75, 76, 77, 78, 80, 81, 82, 83, 85, 86, 87, 88, 89, 91, 92, 93, 94, 95, 97, 99], "shouldn": [23, 25, 43, 45, 52, 67, 69, 81, 83, 87, 93], "shove": 59, "show": [4, 8, 13, 15, 17, 18, 19, 20, 22, 23, 24, 25, 27, 28, 29, 30, 31, 32, 33, 34, 36, 38, 39, 40, 41, 42, 43, 44, 45, 47, 48, 49, 51, 53, 54, 55, 59, 61, 63, 64, 66, 67, 68, 69, 71, 72, 73, 74, 75, 76, 77, 78, 80, 85, 86, 87, 89, 91, 92, 93, 95, 96, 97, 98], "show_nearest_neighbor": 39, "show_plot": [34, 78], "showcas": [31, 51, 52, 75], "shown": [8, 13, 14, 16, 23, 25, 28, 29, 33, 35, 43, 45, 53, 56, 59, 60, 62, 67, 69, 72, 73, 77, 79], "showtim": 59, "shrink": [22, 27, 35, 42, 43, 56, 64, 66, 79, 82], "shuffl": [15, 39, 46, 48, 49, 53, 61, 77, 91, 97], "si": 59, "sibl": [27, 82], "sick": [28, 72], "side": [7, 17, 32, 35, 56, 59, 76, 79], "sidnei": 59, "sift": [30, 74], "sigma": [32, 76], "sign": [4, 20, 24, 26, 32, 41, 44, 46, 68, 70, 76, 87, 89, 93, 95, 99], "signal": [15, 52, 61], "signific": [12, 17, 18, 32, 35, 40, 56, 63, 76, 79, 87, 93], "significantli": [19, 30, 64, 67, 74], "sigoptsearchcv": [22, 42, 66], "silhouett": [29, 73, 90, 96], "silhouettevisu": [28, 29, 72, 73, 90, 96], "silicon": 11, "silli": 59, "silva": 59, "sim": [26, 46, 70], "sim_word": [31, 51, 52, 75], "simard": [26, 46, 70], "similar": [1, 11, 13, 14, 15, 19, 21, 22, 23, 24, 25, 27, 28, 29, 30, 32, 34, 35, 39, 42, 43, 44, 45, 47, 50, 51, 52, 54, 56, 60, 61, 64, 65, 66, 67, 68, 69, 71, 72, 73, 74, 76, 78, 79, 83, 84, 90, 96], "similarity_": [31, 52, 75], "similarli": [24, 26, 28, 34, 46, 54, 70, 72, 78], "simon_fras": [31, 51, 52, 75], "simp": [33, 77], "simpl": [1, 6, 14, 16, 17, 18, 24, 25, 26, 27, 29, 30, 32, 33, 34, 35, 36, 45, 46, 47, 50, 52, 56, 57, 58, 59, 60, 62, 63, 67, 68, 69, 70, 71, 73, 74, 76, 77, 78, 79, 80, 81, 85, 86, 92, 99], "simplefilt": [25, 26, 45, 46, 69, 70], "simpleimput": [18, 19, 21, 22, 24, 25, 26, 27, 33, 34, 35, 42, 44, 45, 46, 47, 53, 54, 55, 56, 63, 64, 65, 66, 67, 68, 69, 70, 71, 77, 78, 79, 85, 88, 89, 91, 94, 95, 97], "simpleimputersimpleimput": [17, 18, 19, 24, 25, 27, 35, 44, 47, 55, 56, 71, 79], "simpler": [15, 16, 21, 22, 36, 38, 65, 66, 80, 87, 93], "simplest": [19, 48, 64], "simpli": [18, 20, 27, 28, 31, 47, 51, 52, 63, 71, 72, 75, 82, 93], "simplic": [14, 19, 30, 50, 60, 64, 74], "simplist": [16, 20, 26, 39, 41, 62, 70, 87, 93], "simul": [27, 47, 71, 82], "sin": [9, 59], "sinatra": 59, "sinc": [6, 13, 21, 24, 26, 27, 28, 30, 32, 33, 34, 35, 39, 44, 46, 47, 50, 53, 54, 55, 56, 59, 65, 68, 70, 71, 72, 74, 76, 77, 78, 79, 84, 85, 86, 91, 92, 93, 94, 97], "singer_songwriter_bob_dylan": [31, 51, 52, 75], "singl": [9, 16, 18, 21, 22, 23, 25, 26, 29, 31, 33, 34, 39, 40, 43, 45, 46, 51, 53, 59, 62, 63, 65, 66, 67, 69, 70, 73, 75, 77, 78, 85, 86, 87, 92, 93], "sit": [5, 17, 20, 40, 41, 99], "sitarist_ravi_shankar": [31, 51, 52, 75], "site": [14, 16, 18, 19, 25, 26, 28, 31, 32, 34, 46, 51, 54, 60, 61, 64, 70, 75, 78, 84, 99], "situat": [7, 13, 23, 28, 32, 34, 43, 45, 59, 67, 69, 72, 76, 78, 99], "six": [25, 33, 36, 61, 69, 77, 80], "size": [13, 14, 15, 16, 19, 22, 23, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 39, 42, 43, 45, 49, 50, 51, 52, 53, 54, 55, 56, 59, 60, 61, 62, 64, 66, 67, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 85, 86, 87, 89, 90, 91, 92, 93, 95, 96, 97, 98, 99], "skeleton": [35, 56, 79], "skeptic": [35, 79], "skew": [24, 44, 68], "skill": [5, 12, 36, 59, 69, 80], "skin": 49, "skinhead": 41, "skip": [11, 59], "skip_check_arrai": [18, 34], "skip_parameter_valid": [18, 34], "skipna": [34, 78], "sklearn": [1, 13, 15, 16, 20, 21, 23, 24, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 38, 39, 41, 43, 44, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 61, 62, 65, 68, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97], "sklearn_gb": [25, 45, 69], "sklearn_histgb": [25, 45, 69], "sktime": [33, 53, 77], "skyblu": [53, 77, 91, 97], "skyscrap": [33, 77], "sl": [31, 51, 52, 75], "slash": 59, "slasher": 59, "slate": [91, 97], "slice": 9, "slide": [1, 10, 16, 18, 19, 32, 37, 63, 76, 99], "slight": 59, "slightli": [19, 21, 23, 25, 31, 34, 39, 40, 43, 45, 51, 52, 54, 59, 64, 65, 67, 69, 75, 78, 96], "slipper": [35, 55, 56, 79], "slope": [21, 65], "sloppi": [18, 63], "slow": [16, 25, 27, 31, 32, 45, 47, 51, 59, 62, 69, 71, 75, 76], "slower": [20, 25, 28, 41, 45, 69, 72], "slowest": [89, 95], "sm": [13, 19, 59, 64], "smac": [22, 42, 66], "small": [15, 16, 17, 19, 22, 24, 25, 26, 28, 30, 32, 34, 39, 40, 42, 44, 45, 46, 48, 49, 51, 59, 61, 62, 64, 66, 68, 69, 70, 71, 72, 74, 75, 76, 78, 85, 87, 89, 90, 93, 95, 96], "small_citi": [16, 62], "small_train_df": [16, 62], "smallalpha_coeff": [24, 44, 68], "smaller": [15, 16, 18, 19, 21, 23, 24, 25, 26, 27, 28, 29, 31, 33, 34, 35, 38, 43, 44, 45, 46, 47, 53, 56, 62, 63, 64, 65, 67, 68, 69, 70, 71, 72, 73, 75, 77, 78, 79, 87, 93], "smallest": [21, 24, 28, 29, 31, 42, 44, 51, 65, 66, 68, 72, 73, 75], "smart": [28, 35, 56, 72, 79], "smooth": [16, 62, 87, 93], "smoothli": 11, "smote": 67, "smote_pip": 81, "sms_df": [13, 59], "sn": [26, 28, 29, 46, 70, 72, 73], "snake": [21, 32, 65, 76], "snake_length": [21, 65], "snakes_df": [21, 65], "snippet": [8, 13], "snort": 59, "snow": [32, 59, 76], "snp": [27, 82], "snub": 20, "so": [0, 1, 4, 5, 8, 9, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 40, 41, 42, 43, 44, 45, 46, 47, 48, 50, 51, 52, 53, 54, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 87, 88, 89, 90, 91, 93, 94, 95, 96, 97, 99], "soap": [20, 41, 59], "soccer": 25, "social": [28, 29, 30, 33, 50, 59, 72, 73, 74, 77], "socialist": 59, "societ": 12, "societi": [31, 51, 52, 67, 75], "sofist": [87, 93], "soft": [17, 21, 25, 40, 45, 65, 69, 89, 95], "softmax": 85, "softwar": [1, 6, 11, 34, 54, 78], "sohail": 41, "sohbat": [1, 99], "solar": [30, 50, 74], "sold": [9, 24, 44, 68], "sole": [29, 67, 73], "solid": [20, 85], "solidifi": 85, "solut": [8, 13, 14, 15, 28, 34, 35, 36, 54, 56, 59, 60, 61, 69, 72, 78, 79, 80, 85, 92, 93, 94, 95, 97, 99], "solv": [4, 13, 14, 16, 27, 31, 35, 36, 47, 51, 52, 56, 59, 62, 71, 75, 79, 80, 87, 93, 99], "solver": [41, 43, 45, 54, 67, 68, 69, 76, 78, 95], "sombr": 59, "some": [4, 5, 6, 7, 8, 9, 11, 13, 15, 16, 17, 18, 19, 20, 21, 23, 24, 26, 28, 29, 30, 31, 32, 33, 34, 35, 38, 39, 40, 41, 42, 44, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 61, 62, 63, 64, 65, 68, 70, 72, 73, 74, 75, 76, 77, 78, 79, 81, 82, 83, 84, 86, 87, 88, 90, 91, 92, 93, 94, 96, 97, 98, 99], "somebodi": 20, "someon": [14, 15, 27, 34, 35, 56, 59, 60, 61, 78, 79, 82, 85], "someth": [4, 8, 14, 15, 19, 23, 24, 26, 28, 31, 33, 34, 35, 36, 43, 44, 45, 46, 51, 53, 54, 55, 56, 57, 58, 59, 60, 64, 67, 68, 69, 70, 72, 75, 77, 78, 79, 80, 81], "sometim": [7, 11, 14, 15, 19, 20, 21, 22, 25, 26, 31, 35, 36, 41, 42, 45, 51, 52, 55, 56, 57, 58, 60, 61, 64, 65, 66, 67, 69, 70, 75, 79, 80, 83], "somewhat": [20, 24, 68], "somewher": [13, 24, 44, 59, 68], "song": [13, 18, 30, 59, 62, 63, 74], "song_titl": [18, 22, 42, 62, 63, 66], "soo": [1, 99], "soon": [16, 18, 33, 36, 53, 57, 58, 59, 62, 63, 77, 80], "sooooooo": 20, "sopha": 59, "sophist": [22, 26, 42, 46, 52, 66, 70, 83], "sort": [1, 15, 18, 20, 22, 23, 26, 30, 31, 32, 33, 36, 41, 43, 46, 50, 51, 52, 53, 57, 58, 60, 61, 63, 70, 74, 75, 76, 77, 80, 91, 97], "sort_index": [9, 22, 24, 33, 42, 44, 53, 66, 68, 77, 91, 97], "sort_valu": [17, 18, 19, 20, 21, 22, 24, 25, 26, 27, 33, 34, 38, 41, 44, 45, 46, 47, 53, 54, 63, 64, 65, 66, 68, 69, 70, 71, 77, 78, 89, 91, 95, 97], "sorted_bow": 17, "sound": [26, 27, 46, 59, 70, 71, 87, 93], "soundtrack": 52, "sourc": [13, 14, 15, 17, 18, 19, 22, 25, 27, 28, 29, 30, 31, 32, 40, 42, 45, 46, 48, 51, 52, 59, 60, 61, 62, 63, 64, 66, 69, 70, 71, 72, 73, 74, 75, 76, 86, 92], "south": [25, 64], "space": [5, 11, 14, 16, 21, 22, 27, 28, 29, 31, 42, 47, 51, 52, 62, 65, 66, 72, 73, 75, 82, 83, 91, 97, 99], "spaci": [27, 31, 47, 51, 71, 75, 83], "spam": [15, 23, 28, 43, 61, 67, 72], "spam_predict": [13, 59], "span": [33, 52, 77, 83], "spanish": [18, 63], "spars": [13, 16, 17, 20, 21, 25, 30, 31, 40, 41, 45, 50, 51, 52, 62, 65, 69, 74, 75, 85], "sparse_output": [17, 18, 19, 24, 25, 26, 34, 35, 40, 42, 44, 45, 46, 53, 54, 55, 56, 63, 64, 66, 67, 68, 69, 70, 77, 78, 79, 85, 89, 91, 95, 97], "sparse_output_": 34, "sparse_threshold": [40, 42, 45, 46, 64, 66, 68, 69, 70, 95], "spatial": [21, 32, 65, 76], "spawn": 59, "speak": [36, 80], "spearmint": [22, 42, 66], "speci": [16, 39, 48, 62, 85, 87, 93], "special": [12, 13, 19, 30, 31, 32, 33, 34, 51, 52, 59, 64, 74, 75, 76, 77, 78], "specialti": [25, 26, 45, 46, 67, 69, 70], "specif": [9, 12, 14, 15, 18, 22, 26, 28, 30, 31, 32, 33, 34, 35, 36, 42, 46, 51, 52, 56, 57, 58, 60, 61, 66, 67, 70, 72, 74, 75, 76, 77, 78, 79, 80, 81, 82, 85, 87, 89, 93, 95], "specifi": [9, 14, 15, 17, 19, 22, 28, 29, 32, 35, 36, 39, 42, 56, 57, 58, 60, 61, 64, 66, 67, 72, 73, 76, 79, 80, 89, 95, 99], "spectacl": 59, "spectacular": 59, "spectrogram": [27, 71], "speech": [13, 27, 31, 47, 51, 52, 59, 71, 75, 83], "speechi": [18, 22, 42, 62, 63, 66], "speed": [9, 14, 20, 25, 32, 36, 41, 45, 57, 58, 60, 69, 76, 80, 99], "spend": [13, 17, 18, 20, 27, 28, 40, 41, 56, 59, 63, 71, 79], "spending_scor": 28, "spent": [7, 18, 27, 36, 47, 63, 71], "spheric": [29, 73, 85], "spici": [28, 72], "spini": [32, 76], "spit": [32, 76], "split": [12, 14, 16, 19, 20, 21, 22, 23, 24, 25, 27, 30, 34, 36, 41, 43, 44, 45, 46, 47, 50, 52, 60, 62, 64, 65, 66, 68, 69, 70, 71, 74, 78, 80, 83, 85, 89, 91, 92, 95, 97, 99], "split0_test_r2": 24, "split0_test_scor": [22, 42, 66], "split0_train_neg_mean_squared_error": 24, "split0_train_scor": [22, 42, 66], "split1_test_r2": 24, "split1_test_scor": [22, 42, 66], "split1_train_neg_mean_squared_error": 24, "split1_train_scor": [22, 42, 66], "split2_test_r2": 24, "split2_test_scor": [22, 42, 66], "split2_train_neg_mean_squared_error": 24, "split2_train_scor": [22, 42, 66], "split3_test_r2": 24, "split3_test_scor": [22, 42, 66], "split3_train_neg_mean_squared_error": 24, "split3_train_scor": [22, 42, 66], "split4_test_scor": [22, 42, 66], "split4_train_neg_mean_squared_error": 24, "split4_train_scor": [22, 42, 66], "splitter": [38, 45, 69, 95], "spoil": [20, 59], "spoiler": 59, "spoken": [19, 64], "spooki": 59, "sport": [31, 32, 33, 51, 52, 75, 76, 77], "spot": [23, 24, 36, 41, 43, 59, 67, 68, 80, 81, 87, 93], "spotifi": [13, 30, 42, 59, 62, 74], "spotify_df": [18, 22, 42, 62, 63, 66], "spotlight": 6, "spous": [25, 26, 45, 46, 67, 69, 70], "spout": 59, "spread": [29, 73], "spring": 97, "spring_month": [53, 77, 97], "spring_rol": [32, 76], "sqft": [26, 46, 70, 93], "sqft_abov": [15, 38, 59, 60], "sqft_basement": [15, 38, 59, 60], "sqft_live": [15, 38, 59, 60], "sqft_living15": [15, 38, 59, 60], "sqft_lot": [15, 38, 59, 60], "sqft_lot15": [15, 38, 59, 60], "sqrt": [16, 24, 26, 30, 31, 44, 45, 46, 50, 52, 62, 68, 69, 70, 74, 75, 95], "squar": [9, 12, 14, 16, 21, 26, 30, 34, 35, 46, 50, 56, 60, 62, 65, 70, 74, 78, 79, 85, 87, 93], "squared_error": 38, "squash": [21, 32, 65, 76], "squeez": [9, 17, 34, 40, 54, 78], "src": [15, 32, 61, 67], "sse": [53, 77, 97], "ssfbc": 34, "ssh": 6, "sst": [31, 51, 75], "ssw": [53, 77], "st": [33, 77, 95], "st_slope": [89, 95], "stabl": [11, 13, 15, 18, 25, 45, 59, 61, 67, 69, 87, 93], "stack": [8, 12, 17, 36, 40, 80, 85], "stack_method": [89, 95], "stacking_model": [25, 45, 69, 89, 95], "stacking_model_tre": [25, 45, 69], "stackingclassifi": [25, 45, 69, 89, 95], "stackingregressor": [25, 45, 69], "staff": 7, "stage": 59, "stai": [11, 13, 20, 23, 34, 43, 54, 59, 67, 78, 99], "stair": 59, "stakehold": [12, 35, 36, 56, 79, 80], "stale": [28, 72], "stand": [16, 22, 36, 42, 52, 57, 58, 59, 62, 66, 80], "standard": [4, 7, 15, 18, 22, 25, 26, 27, 36, 40, 45, 46, 47, 52, 61, 63, 66, 69, 70, 71, 77, 80], "standardscal": [17, 19, 21, 22, 23, 24, 25, 26, 27, 29, 30, 32, 33, 34, 35, 40, 42, 43, 44, 45, 46, 47, 50, 53, 54, 55, 56, 64, 65, 66, 67, 68, 69, 70, 71, 73, 74, 76, 77, 78, 79, 81, 82, 85, 88, 89, 90, 91, 94, 95, 96, 97], "standardscaler__lab1": 64, "standardscaler__lab3": 64, "standardscaler__lab4": 64, "standardscaler__quiz1": 64, "standardscaler__university_year": 64, "standardscalerstandardscal": [17, 18, 19, 22, 23, 24, 25, 27, 35, 44, 47, 55, 56, 67, 71, 79], "stanford": [31, 51, 52, 75], "stanisla": 20, "stanlei": 59, "star": [16, 28, 30, 50, 59, 62, 72, 74], "start": [5, 8, 9, 14, 15, 17, 20, 23, 25, 26, 27, 28, 29, 31, 32, 33, 34, 35, 36, 40, 43, 45, 46, 47, 48, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 67, 69, 70, 71, 72, 73, 75, 76, 77, 78, 79, 80, 81, 85, 86, 87, 88, 90, 91, 92, 93, 94, 96, 97], "startl": 59, "startswith": [13, 20, 23, 26, 43, 46, 70], "starttim": [33, 77], "stat": [22, 34, 42, 66, 78], "state": [9, 15, 20, 25, 26, 30, 34, 36, 45, 46, 52, 57, 58, 59, 61, 67, 69, 70, 74, 80, 83], "statement": [8, 14, 15, 16, 18, 19, 21, 22, 24, 32, 34, 35, 56, 61, 62, 63, 64, 65, 66, 67, 68, 71, 76, 78, 79], "static": [13, 36, 57, 58, 80], "station": [33, 59, 77], "statist": [1, 10, 12, 14, 21, 26, 30, 34, 46, 51, 52, 54, 60, 65, 70, 74, 75, 78], "statistician": [16, 62], "statlib": [21, 65], "statsmodel": [33, 34, 53, 54, 77, 78], "statu": [20, 25, 26, 45, 46, 67, 69, 70], "status_divorc": 45, "status_marri": [26, 45, 46, 70], "status_nev": [26, 45, 46, 70], "status_separ": [45, 46, 70], "status_widow": 45, "std": [15, 16, 17, 18, 23, 24, 38, 39, 40, 43, 44, 53, 61, 62, 63, 67, 68, 77, 84, 93, 96, 97], "std_cv_error": 61, "std_cv_score": [16, 39, 62], "std_fit_tim": [22, 24, 42, 66], "std_score": [18, 61, 63], "std_score_tim": [22, 24, 42, 66], "std_test_neg_mean_squared_error": 24, "std_test_scor": [22, 42, 61, 66], "std_train_error": 61, "std_train_neg_mean_squared_error": 24, "std_train_scor": [16, 22, 39, 42, 61, 62, 66], "stdki": [34, 78], "steadi": 59, "steal": 20, "steeman": 20, "stellar": 59, "stem": [52, 83], "step": [8, 13, 15, 16, 17, 18, 19, 20, 22, 23, 24, 25, 26, 27, 28, 29, 31, 32, 33, 34, 35, 36, 40, 41, 42, 43, 44, 45, 46, 47, 50, 51, 55, 56, 59, 61, 62, 63, 64, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 85, 87, 89, 90, 92, 93, 95, 96, 99], "stereotyp": [31, 51, 52, 75], "stick": [17, 33, 41, 53, 59, 77], "sticki": [31, 51, 75], "still": [4, 11, 14, 17, 20, 22, 24, 25, 27, 28, 31, 33, 34, 42, 45, 47, 48, 51, 53, 54, 59, 66, 67, 68, 69, 71, 72, 75, 77, 78, 88, 94], "stinker": [20, 59], "stipul": [35, 56, 79], "stochast": [27, 28, 47, 72, 82], "stock": [13, 33, 59, 77], "stomach": 41, "stop": [9, 15, 17, 28, 32, 34, 38, 40, 52, 54, 72, 76, 78, 83, 87, 93], "stop_word": [17, 20, 22, 31, 36, 40, 41, 42, 51, 52, 57, 58, 64, 66, 75, 80, 81, 83], "stopword": [31, 51, 52, 75, 83], "storag": 62, "store": [8, 9, 16, 17, 18, 19, 20, 22, 23, 25, 26, 29, 30, 31, 32, 33, 34, 36, 38, 40, 41, 43, 45, 46, 50, 51, 52, 62, 63, 64, 66, 67, 69, 70, 73, 74, 75, 76, 77, 78, 80], "stori": [20, 24, 25, 44, 59, 68, 69], "storylin": [31, 51, 52, 75], "storytel": 59, "str": [13, 20, 22, 23, 26, 31, 33, 34, 39, 42, 43, 46, 51, 52, 53, 66, 70, 75, 77, 78, 91, 97], "straight": [34, 36, 57, 58, 78, 80], "straightforward": [26, 30, 46, 70], "strain": 8, "strang": [26, 34, 46, 54, 70, 78], "strata": [34, 78], "strategi": [14, 16, 17, 18, 19, 23, 24, 26, 28, 30, 34, 35, 36, 40, 43, 44, 46, 50, 53, 54, 55, 56, 60, 62, 63, 64, 67, 68, 70, 72, 74, 77, 78, 79, 80, 85, 86, 88, 91, 92, 93, 94, 97], "stratif": [34, 78], "stratifi": [34, 78], "stratifiedkfold": [15, 61, 67], "stratton": 59, "strawberri": 96, "stream": [34, 78], "streamingmovi": [34, 54, 78], "streamingmovies_no": [34, 54, 78], "streamingmovies_y": [34, 54, 78], "streamingtv": [34, 54, 78], "streamingtv_no": [34, 54, 78], "streamingtv_y": [34, 54, 78], "street": [24, 26, 35, 44, 46, 55, 56, 68, 70, 79], "street_grvl": [24, 68, 70, 79], "street_pav": [24, 68, 70, 79], "strength": [20, 32, 52, 76, 83, 85], "stress": [59, 72, 85], "strftime": [33, 54, 77, 78], "strict": [41, 42, 64, 66], "strictli": 40, "string": [9, 16, 23, 24, 25, 26, 31, 34, 40, 43, 44, 45, 46, 51, 52, 53, 59, 62, 67, 68, 69, 70, 75, 77, 78, 83, 87, 89, 93, 95, 97], "strip": [26, 32, 46, 70, 76], "strip_acc": [41, 42, 64, 66], "strong": [25, 34, 45, 54, 69, 78], "stronger": [25, 45, 69], "strongli": [25, 45, 69], "struck": [20, 41], "structur": [9, 28, 31, 32, 52, 59, 72, 75, 76, 83], "struggl": [33, 72, 77], "stuart": [1, 25, 45, 69], "stuck": [4, 6, 9, 11], "student": [1, 4, 5, 7, 8, 12, 13, 14, 17, 21, 24, 26, 27, 28, 29, 30, 32, 36, 57, 58, 59, 60, 65, 67, 68, 70, 71, 72, 73, 74, 76, 80, 99], "studi": [13, 19, 27, 31, 34, 51, 52, 54, 59, 64, 71, 75, 78, 83], "studio": 11, "stuff": [16, 32, 34, 39, 48, 49, 54, 59, 62, 76, 78], "stump": [14, 15, 16, 38, 45, 60, 61, 62, 69, 86, 92], "stun": [20, 41], "stunningli": 20, "stupid": 59, "style": [24, 27, 28, 30, 32, 36, 44, 47, 49, 50, 52, 57, 58, 59, 68, 71, 72, 74, 76, 80, 83, 90, 96], "sub": [20, 28, 34, 36, 41, 51, 52, 54, 60, 66, 72, 75, 78, 80, 85], "subdirectori": [26, 36, 46, 57, 58, 70, 80], "subgroup": [34, 54, 78], "subject": [0, 1, 34, 78], "sublicens": 0, "submiss": [3, 59], "submit": [1, 9, 13, 36, 57, 58, 80, 99], "subplot": [16, 21, 28, 32, 34, 35, 39, 54, 55, 56, 61, 62, 65, 67, 72, 76, 78, 79, 86, 87, 90, 92, 93, 96], "subplot_kw": [39, 61, 86, 92], "subplots_adjust": [90, 96], "subprocess": [16, 23, 24, 25, 26, 28, 43, 44, 68], "subsampl": [45, 46, 69, 70, 95], "subsample_for_bin": [45, 46, 69, 70, 95], "subsample_freq": [45, 46, 69, 70, 95], "subscrib": [34, 78], "subscript": [33, 34, 77, 78], "subset": [13, 14, 15, 22, 25, 32, 33, 39, 42, 45, 48, 49, 59, 60, 61, 66, 69, 76, 77, 84, 87, 91, 93, 97], "substanc": [20, 59], "substanti": 0, "substitut": [0, 5, 99], "subtl": [31, 52, 59, 75], "subtleti": [15, 24, 44, 61, 68], "subtract": [13, 16, 26, 43, 46, 62, 67, 70], "subword": [31, 51, 52, 75], "succe": [27, 71], "success": [5, 6, 9, 13, 25, 30, 31, 32, 33, 36, 51, 52, 53, 59, 69, 74, 75, 76, 77, 80, 81, 99], "successfulli": [13, 59, 67], "suddenl": [20, 41], "suddenli": 59, "sudo": 6, "suei": 66, "suffer": [22, 66], "suffici": [8, 52, 83, 99], "sugari": 96, "sugarperc": [90, 96], "suggest": [0, 1, 14, 25, 30, 34, 50, 54, 60, 74, 78, 96], "suicid": [52, 59], "suit": [18, 30, 32, 59, 74, 76], "suitabl": [12, 13, 28, 30, 36, 38, 59, 72, 74, 80, 85, 89, 95], "suitcas": 41, "sultan": [31, 51, 52, 75], "sum": [9, 16, 17, 18, 19, 20, 21, 25, 26, 28, 32, 45, 46, 59, 62, 63, 64, 65, 69, 70, 72, 76], "sum_": [16, 24, 28, 31, 32, 44, 52, 62, 68, 72, 75, 76], "sum_i": [26, 31, 46, 52, 70, 75], "sum_prob_ex1_class_0": [25, 45, 69], "sum_prob_ex1_class_1": [25, 45, 69], "summar": [1, 13, 21, 23, 24, 28, 31, 36, 43, 44, 51, 52, 59, 65, 67, 68, 72, 75, 80], "summari": [0, 84, 85, 87, 90, 93, 96], "summary_plot": [26, 46, 70], "summat": [25, 35, 45, 56, 69, 79], "summer": [20, 30, 31, 41, 50, 51, 53, 74, 75, 77, 97], "summer_month": [53, 77, 97], "sun": [31, 33, 51, 52, 75, 77], "sundai": [33, 59, 77], "sundial": [32, 76], "sunshin": [53, 77, 91, 97], "super": [19, 31, 34, 51, 59, 64, 75, 85], "superb": 59, "superfici": [16, 62], "superior": 12, "supervis": [12, 18, 19, 22, 23, 24, 27, 29, 31, 33, 34, 43, 44, 47, 51, 52, 53, 54, 63, 64, 66, 67, 68, 71, 73, 75, 77, 78, 82, 85, 91, 97, 99], "suppli": 99, "support": [5, 11, 14, 18, 23, 25, 26, 29, 31, 34, 35, 39, 43, 45, 46, 47, 51, 52, 56, 60, 63, 67, 69, 70, 71, 73, 75, 79, 81, 83, 84, 85, 87, 93, 99], "support_": [16, 27, 47, 62, 71], "suppos": [13, 15, 16, 17, 18, 19, 21, 22, 23, 25, 26, 27, 28, 29, 30, 31, 35, 40, 42, 43, 46, 47, 50, 51, 52, 56, 59, 60, 61, 62, 63, 64, 65, 66, 67, 69, 70, 71, 72, 73, 74, 75, 79, 82, 85, 86, 92], "suppress": 9, "suprem": [31, 51, 52, 75], "supr\u00eam": [31, 51, 52, 75], "suptitl": [90, 96], "sure": [4, 5, 8, 9, 11, 16, 19, 23, 24, 25, 26, 29, 32, 34, 35, 36, 43, 44, 45, 46, 53, 56, 57, 58, 61, 62, 64, 67, 68, 69, 70, 73, 76, 77, 79, 80, 87, 89, 90, 91, 93, 95, 96, 97, 99], "surfac": [14, 59], "surgeri": [34, 78], "surpass": 59, "surpris": [20, 26, 30, 31, 46, 50, 51, 70, 74, 75, 93], "surprisingli": [19, 21, 64, 65], "surround": [4, 12, 31, 35, 51, 75, 79], "survei": [17, 28, 40, 72], "surveil": 59, "surviv": [1, 2, 12, 36, 56, 79, 80], "survival_function_": [34, 54, 78], "suscept": [29, 36, 73, 80], "sushi": [32, 76], "suspect": [22, 59, 66, 99], "suspens": [20, 59], "svc": [16, 17, 18, 19, 21, 22, 25, 26, 27, 32, 39, 40, 42, 45, 46, 47, 62, 63, 64, 65, 66, 69, 70, 71, 76, 84, 87, 88, 89, 93, 94, 95], "svc__c": [22, 42, 66], "svc__gamma": [22, 42, 66], "svc_all_pip": [17, 40], "svc_num_cat_text_pip": [17, 40], "svc_pipe": [22, 42, 66], "svc_pred": [23, 43, 67], "svcsvc": [19, 22, 23, 67], "svm": [1, 15, 17, 18, 19, 22, 25, 26, 27, 32, 33, 35, 36, 40, 42, 45, 46, 47, 56, 61, 63, 64, 66, 69, 70, 71, 76, 77, 79, 80, 84, 85, 87, 88, 89, 93, 94, 95], "svm_estim": 81, "svr": [16, 26, 35, 46, 56, 62, 64, 70, 79, 94], "svr_c_pipe": 64, "svr_pipe": 64, "sw": [53, 77, 97], "swai": 59, "swamp": [16, 62], "swan": [32, 76], "swcarpentri": 10, "sweep": [23, 43, 67], "sweet": [20, 59], "switch": [26, 28, 34, 35, 46, 53, 54, 56, 70, 72, 77, 78, 79, 91, 94, 97], "swoop": 59, "sy": [13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 25, 26, 27, 28, 29, 30, 31, 32, 34, 35, 36, 38, 39, 40, 41, 42, 43, 45, 46, 47, 48, 49, 50, 51, 52, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 69, 70, 71, 72, 73, 74, 75, 76, 78, 79, 80, 81, 82, 84, 85, 86, 87, 88, 89, 90, 92, 93, 94, 95, 96], "sydnei": [53, 77, 97], "sydneyairport": 97, "syllabu": [3, 13], "symbol": [14, 60], "symlink": 31, "symmetri": [27, 47, 71], "sync": 6, "synonym": 52, "synopsi": [31, 51, 52, 75], "syntact": [51, 52, 75], "syntax": [4, 9, 13, 27, 31, 34, 47, 51, 54, 59, 71, 75, 78], "syntaxwarn": 60, "synthet": [27, 47, 71, 84], "syrupi": 41, "system": [1, 2, 4, 6, 7, 11, 12, 13, 15, 23, 26, 28, 31, 33, 36, 39, 43, 46, 51, 56, 59, 61, 62, 64, 67, 70, 72, 75, 77, 79, 80], "systemat": [14, 22, 26, 31, 46, 51, 52, 60, 64, 66, 70, 75], "t": [1, 4, 5, 8, 9, 11, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 38, 39, 40, 42, 43, 44, 45, 46, 47, 48, 50, 51, 52, 53, 54, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 87, 89, 91, 93, 95, 97, 99], "t0f6lfzl": [31, 51, 75], "t1a": 99, "t1b": 99, "t1c": 99, "t1d": 99, "t1e": 99, "t1f": 99, "t1g": 99, "t1h": 99, "t1j": 99, "t1k": 99, "t1l": 99, "t5": [31, 51, 75], "ta": [5, 8, 13, 24, 26, 35, 36, 44, 46, 55, 56, 59, 68, 70, 79, 80, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97], "tab": [1, 13], "tabbi": [32, 59, 76], "tabl": [1, 8, 17, 25, 31, 40, 51, 75, 89, 95], "tabular": [9, 13, 33, 39, 59, 77], "tackl": [17, 18, 29, 61, 63, 73, 75, 81], "taco": [27, 82], "tag": [4, 13, 31, 51, 52, 59, 75, 83], "tail": [9, 33, 77], "tailor": [12, 28, 35, 36, 72, 79, 80], "take": [2, 4, 7, 13, 14, 15, 16, 17, 18, 21, 22, 24, 25, 26, 27, 28, 30, 31, 32, 34, 35, 36, 40, 42, 43, 44, 45, 46, 47, 50, 51, 52, 53, 54, 56, 57, 58, 59, 60, 61, 62, 63, 65, 66, 67, 68, 69, 70, 71, 72, 74, 75, 76, 77, 78, 79, 80, 81, 84, 86, 87, 88, 89, 90, 91, 92, 93, 95, 96, 97, 99], "takeawai": [31, 51, 75], "taken": [33, 59, 77, 84, 99], "talent": 59, "talk": [14, 15, 18, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 36, 43, 44, 45, 46, 50, 51, 52, 57, 58, 60, 61, 63, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 80, 81, 83, 84, 85, 87, 93, 99], "tall": [31, 51, 52, 75], "target": [15, 16, 17, 18, 20, 21, 22, 23, 25, 26, 27, 30, 32, 33, 34, 35, 36, 38, 39, 40, 41, 42, 43, 45, 46, 47, 53, 54, 56, 57, 58, 61, 62, 63, 65, 66, 67, 69, 70, 71, 74, 76, 77, 78, 79, 80, 81, 85, 87, 88, 89, 91, 93, 94, 95, 97], "target_column": [25, 26, 34, 45, 46, 54, 69, 70, 78, 89, 95], "target_nam": [23, 43, 67, 81], "target_names_toi": 81, "target_tag": 18, "tariff": 52, "task": [12, 13, 18, 19, 21, 22, 26, 27, 28, 30, 31, 32, 33, 34, 35, 36, 38, 39, 42, 46, 47, 51, 53, 56, 59, 63, 64, 65, 66, 70, 71, 72, 74, 75, 76, 77, 78, 79, 80, 82, 85, 87, 91, 93, 97, 99], "tast": [17, 28, 30, 40, 50, 72, 74], "tasti": [17, 40], "taught": [19, 31, 51, 52, 64, 75, 99], "tax": [35, 55, 56, 79], "tba": 1, "tea": 20, "teach": [4, 13, 18, 31, 51, 52, 59, 63, 75, 83, 85], "team": [4, 9, 13, 26, 31, 46, 51, 52, 59, 69, 70, 75, 83, 89, 95], "tech": [26, 46, 62, 67, 70], "technic": [31, 35, 36, 51, 75, 79, 80, 99], "technician": [31, 51, 75], "techniqu": [1, 12, 16, 20, 22, 23, 27, 30, 32, 34, 36, 41, 42, 43, 50, 59, 62, 66, 67, 71, 74, 76, 78, 80, 84], "technocrat": 59, "technolog": 0, "technologi": [31, 52, 59, 75], "techsupport": [34, 54, 78], "techsupport_no": [34, 54, 78], "techsupport_y": [34, 54, 78], "ted": [28, 72], "tediou": [29, 73], "telco": [34, 54, 78], "telecom": [34, 78], "telephon": [31, 51, 52, 75], "tell": [15, 18, 20, 21, 23, 26, 27, 30, 31, 34, 35, 36, 41, 43, 46, 47, 50, 51, 52, 53, 54, 56, 57, 58, 61, 62, 63, 65, 67, 70, 71, 74, 75, 77, 78, 79, 80, 82, 87, 91, 93, 97], "temp": 34, "temp3pm": [53, 77, 91, 97], "temp9am": [53, 77, 91, 97], "temperatur": [14, 60, 93], "templat": [36, 57, 58, 80], "tempo": [18, 22, 42, 62, 63, 66], "tempor": [34, 53, 78, 85, 91, 97], "ten": 59, "tend": [15, 16, 21, 25, 30, 31, 33, 34, 45, 50, 51, 54, 59, 61, 62, 65, 69, 71, 74, 75, 77, 78, 96, 99], "tendenc": [15, 61], "tension": 59, "tensor": 39, "tensorflow": [26, 32, 46, 70, 76], "tenur": [27, 34, 54, 56, 78, 79, 85], "tenure_lm": [34, 78], "tenure_predict": [34, 78], "term": [0, 2, 5, 6, 14, 16, 19, 21, 23, 26, 27, 30, 31, 34, 35, 36, 38, 43, 46, 47, 50, 51, 52, 56, 59, 60, 62, 64, 65, 67, 70, 71, 74, 75, 78, 79, 80, 82, 83, 85, 99], "termin": [6, 11, 28, 36, 57, 58, 59, 60, 72, 80], "terminologi": [43, 61, 67, 85, 86, 92], "terrac": [32, 76], "terribl": [20, 24, 30, 31, 41, 44, 50, 51, 68, 74, 75], "territori": 99, "terror": 59, "terrorist": 41, "tesoro": 66, "test": [1, 8, 9, 11, 13, 14, 16, 17, 18, 19, 20, 21, 23, 24, 25, 26, 29, 31, 34, 35, 36, 39, 40, 41, 42, 43, 44, 45, 46, 51, 54, 55, 56, 57, 58, 59, 60, 62, 63, 64, 65, 67, 68, 69, 70, 73, 75, 78, 79, 80, 84, 85, 87, 89, 91, 92, 93, 95, 97, 99], "test_accuraci": [23, 43, 67], "test_average_precis": [23, 43, 67, 81], "test_df": [13, 15, 18, 20, 21, 23, 24, 25, 26, 27, 33, 34, 35, 36, 41, 43, 44, 45, 46, 47, 53, 54, 55, 56, 57, 58, 59, 63, 64, 65, 67, 68, 69, 70, 71, 77, 78, 79, 80, 81, 88, 89, 91, 94, 95, 97], "test_df_churn": [34, 78], "test_df_nan": [25, 26, 45, 46, 67, 69, 70], "test_df_sort": [33, 53, 77], "test_df_surv": [34, 54, 78], "test_exampl": [25, 45, 69], "test_f1": [23, 43, 67], "test_format": [16, 62], "test_g50k": [25, 45, 69], "test_idx": 39, "test_imag": [13, 32, 59, 76], "test_l50k": [25, 45, 69], "test_mape_scor": [24, 68], "test_nam": [34, 78], "test_neg_mean_squared_error": [24, 68], "test_neg_root_mean_square_error": [24, 68], "test_point": [16, 62, 84], "test_precis": [23, 43, 67], "test_r2": [24, 68], "test_recal": [23, 43, 67], "test_roc_auc": [23, 43, 67, 81], "test_sampl": [89, 95], "test_scor": [15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 33, 34, 38, 39, 40, 41, 43, 44, 45, 46, 47, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 77, 78, 87, 93, 94, 95], "test_shap_valu": [26, 46, 70], "test_siz": [13, 15, 16, 17, 18, 20, 21, 22, 23, 24, 25, 26, 27, 30, 32, 33, 35, 36, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 50, 55, 56, 57, 58, 59, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 74, 76, 77, 79, 80, 81, 84, 87, 88, 89, 93, 94, 95], "test_sklearn": [24, 68], "test_statist": [34, 78], "test_x": [34, 54, 78], "text": [1, 8, 12, 13, 14, 18, 20, 21, 22, 23, 24, 25, 26, 27, 30, 32, 35, 36, 41, 42, 43, 44, 45, 46, 47, 50, 56, 57, 58, 59, 60, 65, 66, 67, 68, 69, 70, 71, 74, 76, 79, 80, 81, 85, 90, 96], "text_count": 17, "text_feat": [17, 22, 40, 42, 66], "text_pip": [17, 40], "text_pp": [31, 51, 52, 75], "text_transform": [17, 40], "textbook": [3, 10, 13, 35, 55, 56, 79], "textil": 59, "textrm": [15, 61], "textual": 12, "textur": [27, 47, 71], "tf": [19, 31, 51, 64, 75], "tfidfvector": [21, 41, 65], "th": [13, 21, 30, 65, 74], "thai": [17, 40], "than": [7, 13, 14, 15, 16, 17, 18, 20, 21, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33, 34, 39, 40, 41, 42, 43, 44, 45, 46, 47, 50, 51, 52, 54, 59, 60, 61, 62, 63, 65, 67, 68, 69, 70, 72, 73, 74, 75, 76, 77, 78, 81, 83, 84, 86, 87, 89, 92, 93, 95, 96, 99], "thank": [52, 59, 87, 93], "thankfulli": [53, 77, 91, 97], "theater": [20, 41, 59], "thei": [1, 8, 9, 14, 15, 16, 17, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 40, 41, 42, 43, 44, 46, 47, 50, 51, 52, 53, 54, 56, 59, 60, 61, 62, 65, 66, 67, 68, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 86, 87, 89, 90, 91, 92, 93, 95, 96, 97, 99], "theirs": [52, 83], "them": [1, 2, 4, 5, 8, 12, 14, 15, 16, 18, 19, 21, 22, 24, 25, 26, 27, 30, 31, 32, 33, 34, 35, 36, 39, 44, 45, 46, 47, 50, 51, 52, 54, 55, 56, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 74, 75, 76, 77, 78, 79, 80, 82, 83, 85, 86, 87, 89, 92, 93, 94, 95, 99], "themat": 59, "theme": [17, 31, 52, 59, 75], "themselv": [28, 29, 52, 72, 73, 83], "theoret": [18, 25, 63, 67, 69, 85], "theori": [26, 46, 70], "thereaft": 20, "therefor": [87, 90, 93, 96], "theresult": [90, 96], "thermostat": [14, 60], "thi": [0, 1, 2, 4, 6, 7, 8, 11, 12, 14, 15, 16, 20, 21, 22, 24, 25, 27, 28, 29, 30, 31, 32, 33, 34, 39, 41, 42, 44, 45, 47, 48, 49, 50, 51, 52, 53, 54, 55, 57, 58, 60, 61, 62, 65, 66, 67, 68, 69, 71, 72, 73, 74, 75, 76, 77, 78, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 99], "thick": [17, 20, 28, 40, 72], "thing": [1, 5, 8, 9, 13, 14, 15, 16, 20, 22, 23, 26, 27, 28, 29, 30, 31, 32, 33, 34, 36, 41, 42, 43, 46, 50, 51, 52, 53, 54, 59, 60, 61, 62, 66, 67, 70, 71, 72, 73, 74, 75, 76, 77, 78, 80, 82, 83, 87, 89, 91, 93, 94, 95, 97], "think": [4, 6, 13, 14, 15, 16, 17, 19, 20, 21, 24, 26, 27, 28, 30, 31, 32, 34, 35, 36, 40, 41, 44, 46, 47, 50, 51, 53, 54, 56, 59, 60, 61, 62, 64, 65, 67, 68, 70, 71, 72, 74, 75, 76, 77, 78, 79, 80, 81, 85, 86, 87, 90, 91, 92, 93, 96, 97, 99], "third": [29, 73], "thk": 59, "thompson": 20, "thorough": [89, 95], "those": [9, 11, 12, 18, 20, 24, 25, 26, 30, 34, 35, 36, 44, 45, 46, 50, 52, 54, 56, 57, 58, 59, 63, 64, 68, 69, 70, 74, 78, 79, 80, 83, 99], "thou": 59, "though": [14, 15, 17, 19, 21, 28, 29, 30, 36, 40, 50, 51, 59, 61, 64, 65, 72, 73, 74, 75, 80, 92], "thought": [4, 16, 20, 34, 41, 54, 59, 62, 78], "thousand": [21, 29, 30, 65, 73, 74], "thrasher": [31, 51, 52, 75], "thread": 32, "threahold": [27, 47, 71], "three": [9, 11, 18, 21, 23, 25, 26, 27, 28, 29, 31, 32, 33, 39, 43, 45, 46, 47, 51, 52, 59, 60, 63, 65, 67, 69, 70, 71, 72, 73, 75, 76, 77, 82, 84, 85, 99], "thresh": 9, "threshold": [13, 14, 21, 25, 27, 29, 31, 34, 45, 47, 51, 52, 59, 60, 65, 69, 71, 73, 75, 78], "thresholds_lr": [23, 43, 67], "thresholds_svc": [23, 43, 67], "thriller": [20, 59], "throat": 20, "through": [1, 7, 13, 14, 22, 23, 24, 27, 29, 30, 31, 32, 43, 44, 47, 48, 51, 52, 56, 60, 67, 68, 71, 73, 74, 75, 76, 79, 83, 90, 96, 99], "throughout": [6, 15, 20, 35, 56, 61, 79], "throw": [19, 34, 54, 56, 64, 78, 79, 85], "thu": [1, 7, 22, 33, 34, 54, 66, 77, 78, 99], "thumb": [14, 60], "thursdai": [1, 13], "ti": [19, 59, 64], "tick": [33, 59, 77], "tick_label": [46, 70], "tick_param": [28, 72], "tid": [16, 25, 26, 28], "tiffin": 52, "tiger": [32, 59, 76], "tight": [16, 29, 62, 73, 87, 93], "tight_layout": [32, 35, 55, 56, 76, 79], "tightrop": [16, 39, 62, 87, 93], "tile": [46, 70], "till": [16, 31, 34, 51, 52, 62, 75, 78], "tim": 20, "timber": [52, 83], "time": [1, 2, 4, 5, 9, 12, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 35, 36, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 54, 55, 56, 57, 58, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 79, 80, 81, 82, 84, 87, 88, 89, 90, 92, 93, 94, 95, 96, 99], "time_diff": [53, 77, 91, 97], "time_signatur": [18, 22, 42, 62, 63, 66], "timedelta": [53, 77, 97], "timeit": [9, 84], "timeless": 59, "timelin": [56, 79], "timeseri": [32, 53, 76, 77], "timeseriessplit": [33, 34, 53, 77, 78, 85, 91, 97], "timestamp": [33, 53, 77, 91, 97], "timezon": [1, 54, 78], "tinder": [30, 50, 74], "tini": [8, 15, 23, 29, 32, 43, 48, 49, 61, 67, 73, 76], "tip": [5, 11, 52, 83], "tire": [20, 31, 51, 75], "titan": [30, 50, 74], "titi": 59, "titl": [8, 15, 16, 21, 24, 25, 27, 29, 30, 32, 33, 34, 35, 38, 39, 42, 44, 47, 48, 49, 53, 54, 55, 56, 59, 61, 62, 65, 66, 68, 71, 73, 76, 77, 78, 79, 87, 90, 91, 93, 96, 97, 98], "tl": 5, "tldr": 13, "tn": [23, 43, 67], "to_datetim": [15, 38, 53, 77, 91, 97], "to_html": [13, 59, 60, 61], "to_list": [23, 43], "to_notebook_ifram": [24, 44, 68], "to_numpi": [16, 30, 33, 50, 62, 74, 77], "to_scal": [90, 96], "to_str": [13, 32, 59, 76], "toarrai": [17, 19, 20, 26, 31, 33, 41, 46, 51, 64, 70, 75, 77], "tobago": [25, 26, 45, 46, 69, 70], "todai": [13, 14, 30, 31, 32, 34, 36, 51, 53, 54, 59, 60, 74, 75, 76, 77, 78, 80, 85, 89, 91, 95, 97], "todens": [26, 27, 46, 47, 70, 71], "togeth": [9, 13, 14, 16, 17, 18, 19, 28, 31, 40, 51, 52, 59, 60, 62, 63, 64, 67, 72, 75, 87, 90, 93, 96], "toi": [9, 15, 16, 27, 28, 29, 30, 33, 39, 47, 50, 61, 62, 71, 72, 73, 74, 77, 81, 85], "toilet": [32, 76], "toke": 99, "token": [6, 13, 31, 41, 42, 51, 64, 66, 75, 99], "token_pattern": [19, 41, 42, 64, 66], "tol": [27, 35, 41, 42, 43, 45, 56, 64, 66, 67, 68, 69, 76, 79, 82, 95], "told": 99, "toler": 41, "tolist": [13, 14, 15, 17, 19, 21, 24, 25, 26, 27, 28, 30, 33, 34, 38, 39, 40, 41, 44, 46, 47, 50, 53, 59, 60, 61, 64, 65, 67, 68, 69, 70, 71, 72, 74, 77, 86, 91, 92, 97], "tom": [20, 59], "tomasbeuzen": 9, "tomorrow": [14, 34, 53, 60, 77, 78, 85, 91, 97], "ton": [20, 22, 66], "tonal": 59, "tone": [49, 59], "too": [7, 8, 13, 14, 15, 16, 18, 19, 20, 22, 24, 25, 26, 32, 33, 34, 35, 36, 39, 41, 42, 44, 45, 46, 52, 53, 55, 56, 57, 58, 59, 61, 62, 64, 66, 68, 69, 70, 76, 77, 78, 79, 80, 83, 87, 88, 91, 93, 97, 99], "took": [17, 33, 53, 77], "tool": [1, 5, 8, 9, 11, 12, 13, 15, 19, 20, 21, 23, 24, 26, 29, 30, 31, 32, 33, 34, 36, 41, 43, 44, 46, 51, 53, 54, 57, 58, 59, 64, 65, 67, 68, 70, 73, 74, 75, 76, 77, 78, 80, 85, 99], "toolbox": [16, 25, 45, 52, 62, 69], "toolkit": [52, 83], "tootsi": 96, "top": [11, 14, 19, 20, 22, 23, 29, 32, 35, 36, 41, 42, 43, 53, 56, 57, 58, 59, 60, 64, 66, 67, 73, 76, 77, 79, 80, 90, 96, 97, 99], "topi": [31, 51, 52, 75], "topic": [1, 2, 9, 12, 14, 24, 28, 30, 32, 36, 50, 60, 68, 72, 74, 76, 80, 81, 85, 99], "topic2vec": [31, 51, 52, 75], "topics_per_chunk": [31, 51, 52, 75], "topn": [13, 59], "torch": [31, 32, 39, 48, 49, 51, 75, 76], "torch_util": 32, "torchvis": [13, 32, 39, 48, 49, 59, 76], "toronto": [31, 35, 51, 52, 56, 75, 79], "tort": 0, "total": [1, 9, 14, 17, 18, 19, 23, 24, 25, 26, 27, 31, 33, 34, 36, 43, 44, 46, 47, 51, 52, 53, 54, 56, 59, 60, 63, 64, 67, 68, 69, 70, 71, 75, 77, 78, 79, 81, 93, 95, 97], "total_bedroom": [18, 27, 47, 63, 64, 71, 88, 94], "total_bilirubin": 59, "total_protien": 59, "total_room": [18, 27, 47, 63, 64, 71, 88, 94], "total_second": [53, 77, 91, 97], "totalbsmtsf": [24, 26, 35, 44, 46, 55, 56, 68, 70, 79], "totalcharg": [27, 34, 54, 78], "totem": [32, 76], "totensor": [39, 48, 49], "toti": [0, 1, 52, 83, 99], "totrmsabvgrd": [24, 26, 35, 44, 46, 55, 56, 68, 70, 79], "touch": [36, 80], "toward": [13, 20, 21, 26, 31, 41, 46, 51, 52, 59, 65, 70, 75, 99], "towardsdatasci": [32, 34, 54, 76, 78], "town": 59, "townsvil": [53, 77, 97], "toxic": [31, 51, 75], "toy_clust": [31, 51, 52, 75], "toy_clust_df": [28, 72], "toy_df": [19, 31, 51, 52, 64, 75], "toy_lda_data": [31, 51, 52, 75], "toy_movie_feat": [30, 50, 74], "toy_rat": [30, 50, 74], "toy_spam": [19, 64], "toy_x": [31, 51, 52, 75], "tp": [23, 43, 67], "tpot": [22, 42, 66], "tpr": [23, 43, 67], "tpr_lr": [23, 43, 67], "tpr_svc": [23, 43, 67], "tr_score": [15, 38, 87, 93], "traceback": [4, 9, 18, 19, 34, 64, 78], "track": [1, 6, 19, 36, 64, 67, 80, 99], "trade": [12, 21, 23, 27, 28, 43, 65, 67, 71, 72, 85], "tradeoff": [16, 18, 21, 24, 27, 28, 32, 38, 44, 47, 62, 63, 65, 68, 71, 72, 76], "tradit": [13, 30, 31, 34, 50, 51, 54, 59, 74, 75, 78, 99], "tradition": 99, "trail": 9, "train": [8, 16, 17, 18, 20, 22, 23, 24, 25, 26, 27, 28, 30, 34, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 54, 62, 63, 66, 68, 69, 70, 71, 72, 74, 78, 84, 85, 86, 87, 88, 89, 91, 92, 93, 94, 95, 97], "train_accuraci": [23, 43, 67], "train_df": [13, 15, 18, 20, 21, 23, 24, 25, 26, 27, 33, 34, 35, 36, 41, 43, 44, 45, 46, 47, 53, 54, 55, 56, 57, 58, 59, 63, 64, 65, 67, 68, 69, 70, 71, 77, 78, 79, 80, 81, 88, 89, 91, 94, 95, 97], "train_df_churn": [34, 78], "train_df_nan": [25, 26, 45, 46, 67, 69, 70], "train_df_ord": [53, 77, 91, 97], "train_df_sort": [33, 53, 77], "train_df_surv": [34, 54, 78], "train_df_surv_not_churn": [34, 54, 78], "train_dir": 39, "train_energy_data": [87, 93], "train_f1": [23, 43, 67], "train_for_usr": [30, 50, 74], "train_mape_scor": [24, 68], "train_mat": [30, 50, 74], "train_mat_imp": [30, 50, 74], "train_neg_mean_squared_error": [24, 68], "train_neg_root_mean_square_error": [24, 68], "train_precis": [23, 43, 67], "train_r2": [24, 68], "train_recal": [23, 43, 67], "train_scor": [15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 33, 34, 38, 39, 40, 41, 43, 44, 45, 46, 47, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 77, 78, 87, 93, 94, 95], "train_shap_valu": [26, 46, 70], "train_sklearn": [24, 68], "train_test_split": [13, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 30, 32, 33, 34, 35, 36, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 50, 53, 54, 55, 56, 57, 58, 59, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 74, 76, 77, 78, 79, 80, 81, 82, 84, 87, 88, 89, 91, 93, 94, 95, 97], "train_x": [30, 50, 74], "training_energy_data": [87, 93], "trane": 61, "transact": [14, 23, 33, 35, 43, 53, 56, 60, 67, 77, 79], "transfer": [20, 34, 36, 48, 54, 57, 58, 78, 80], "transform": [0, 16, 20, 22, 23, 25, 26, 29, 32, 33, 34, 36, 39, 41, 42, 43, 45, 46, 47, 48, 49, 52, 53, 54, 62, 66, 67, 69, 70, 73, 76, 77, 78, 80, 85, 87, 88, 90, 91, 93, 94, 95, 96, 97], "transform_input": [41, 42, 43, 63, 64, 66, 68], "transformed_exampl": [25, 45, 69], "transformed_oh": [18, 63], "transformedtargetregressor": [24, 27, 35, 44, 47, 55, 56, 68, 71, 79, 85], "transformedtargetregressortransformedtargetregressor": 24, "transformer_weight": [40, 42, 45, 46, 64, 66, 68, 69, 70, 95], "translat": [1, 10, 31, 32, 51, 75, 76], "transpar": [23, 43, 67, 85], "transpos": [27, 32, 39, 47, 48, 49, 71, 76], "trasform": [18, 63], "trash": [86, 92], "traumat": 99, "treat": [9, 18, 19, 24, 30, 31, 32, 34, 44, 50, 51, 53, 56, 63, 64, 67, 68, 74, 75, 76, 77, 78, 79, 85, 91, 97, 99], "treati": 99, "treatment": [19, 64], "tree": [1, 2, 16, 18, 19, 20, 21, 22, 24, 29, 32, 33, 34, 36, 39, 40, 41, 42, 44, 61, 62, 63, 64, 65, 66, 68, 71, 73, 76, 77, 78, 80, 84, 85, 86, 88, 89, 92, 94, 95], "tree1": [25, 69], "tree2": [25, 69], "tree3": [25, 69], "tree_method": [45, 69], "tree_numeric_transform": [26, 46, 70], "treecolumntransform": [25, 45, 69, 95], "treeexplain": [26, 46, 70], "tremend": 59, "trend": [12, 31, 34, 75, 78, 85], "tri": [14, 25, 26, 31, 35, 45, 46, 51, 56, 69, 70, 75, 79, 84, 89, 95], "trial": [22, 34, 42, 54, 66, 78], "triangl": [16, 28, 62, 72], "triangular": 41, "trick": [6, 24, 44, 68], "tricki": [19, 22, 26, 30, 42, 46, 50, 64, 66, 70, 74], "trifl": 59, "trigger": [16, 32, 62], "trigram": [51, 52, 75], "trivia": 25, "trivial": [29, 73], "troma": 20, "true": [9, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 31, 32, 33, 34, 35, 36, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 51, 52, 53, 54, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 87, 89, 91, 93, 94, 95, 96, 97, 98], "true_": 40, "true_valu": 98, "truli": [24, 31, 44, 51, 52, 59, 68, 75, 83], "truncat": [29, 73], "truncate_mod": [29, 49, 73], "truncation_mod": [29, 73], "trust": [15, 17, 18, 19, 20, 22, 23, 24, 25, 26, 27, 30, 31, 32, 35, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 55, 56, 59, 63, 64, 66, 67, 68, 69, 70, 71, 74, 75, 76, 79, 95], "trustworthi": [29, 73, 89, 95], "truth": [1, 21, 25, 27, 28, 29, 30, 33, 45, 47, 50, 69, 71, 72, 73, 74, 77, 82], "try": [1, 4, 9, 13, 14, 15, 16, 19, 20, 21, 22, 23, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 38, 39, 41, 42, 43, 45, 46, 47, 48, 49, 50, 51, 52, 54, 55, 57, 58, 59, 60, 61, 62, 64, 65, 66, 67, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 82, 83, 85, 86, 87, 89, 90, 91, 92, 93, 95, 96, 97, 99], "tsa": [33, 53, 77], "tscv": [33, 77], "tslearn": [33, 53, 77], "tsunami": 59, "ttr": [24, 44, 68], "ttr_pipe": [24, 44, 68], "tue": [1, 33, 77, 99], "tuesdai": [1, 13, 27, 53, 77, 82, 97, 99], "tug": 59, "tuggeranong": [53, 77, 97], "tulip": [31, 51, 75], "tumor": 85, "tune": [15, 22, 25, 29, 30, 32, 35, 36, 38, 42, 45, 50, 56, 57, 58, 61, 66, 69, 73, 74, 76, 79, 80, 89, 95], "tupl": 34, "turn": [4, 15, 31, 34, 39, 48, 49, 52, 54, 59, 61, 75, 78, 85, 88, 94, 99], "turnaround": 59, "turturro": 20, "tusker": [32, 76], "tutori": [4, 5, 6, 10, 11, 13, 30, 36, 50, 57, 58, 74, 80, 85, 99], "tv": [20, 59], "tweak": [16, 39, 62, 87, 93], "tweet": [31, 51, 52, 75], "twelv": 59, "twice": [9, 19, 21, 61, 64, 65], "twinx": [35, 55, 56, 79], "twist": [20, 31, 51, 52, 75], "twitter": [31, 51, 52, 75], "two": [4, 5, 6, 7, 8, 9, 10, 11, 13, 14, 15, 16, 17, 18, 21, 22, 23, 25, 26, 27, 28, 29, 30, 32, 33, 34, 35, 36, 39, 40, 42, 43, 45, 46, 47, 48, 52, 54, 56, 57, 58, 59, 60, 61, 62, 63, 65, 66, 67, 69, 70, 71, 72, 73, 74, 76, 77, 78, 79, 80, 81, 83, 84, 85, 88, 90, 94, 96, 99], "two_citi": [16, 62], "two_song": [18, 63], "two_songs_subset": [18, 63], "tx": [21, 65], "tx_i": [35, 56, 79], "txt": [13, 32, 36, 57, 58, 59, 76, 80], "typ": [24, 26, 35, 44, 46, 55, 56, 68, 70, 79], "type": [4, 5, 9, 11, 12, 14, 17, 18, 19, 20, 22, 25, 27, 29, 30, 31, 32, 36, 40, 45, 47, 48, 49, 50, 51, 52, 57, 58, 60, 62, 63, 64, 66, 69, 71, 73, 74, 75, 76, 80, 83, 85, 87, 88, 90, 91, 93, 94, 96, 97], "typeerror": [34, 78], "typic": [2, 13, 14, 15, 16, 18, 21, 22, 23, 24, 25, 26, 28, 30, 31, 33, 35, 36, 43, 44, 45, 46, 51, 53, 56, 59, 60, 62, 63, 64, 65, 66, 67, 68, 69, 70, 72, 74, 75, 77, 79, 80, 85, 99], "u": [1, 4, 15, 16, 18, 19, 20, 21, 23, 25, 26, 27, 28, 29, 30, 31, 32, 34, 36, 38, 39, 41, 42, 43, 45, 46, 47, 51, 52, 53, 54, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 80, 81, 83, 86, 87, 88, 89, 91, 92, 93, 94, 95, 97], "u6": [14, 60, 92], "u_1": [16, 62], "u_2": [16, 62], "u_i": [16, 62], "u_n": [16, 62], "ubc": [0, 4, 5, 9, 10, 11, 13, 14, 15, 16, 18, 19, 21, 22, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 45, 46, 47, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 83, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 99], "ubc_img": [32, 76], "ubc_okanagan": [31, 51, 52, 75], "ubco": [31, 51, 52, 75], "ubyssei": [31, 51, 52, 75], "ucsb": 10, "ud036": 10, "udac": 10, "ufunc": [24, 68], "ufv": [31, 51, 52, 75], "uint8": 39, "ultim": [15, 56, 59, 61, 79], "ultralyt": [32, 76], "uluru": [53, 77, 97], "umbrella": [30, 74], "un": [24, 34, 44, 68, 78], "unabl": [13, 15, 17, 18, 19, 20, 22, 23, 24, 25, 26, 27, 29, 32, 34, 35, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 55, 56, 59, 63, 64, 66, 67, 68, 69, 70, 71, 73, 76, 78, 79, 95, 99], "unambigu": [52, 83], "unassign": [28, 29, 72, 73], "unassum": [20, 41], "unbias": 67, "unbidden": 41, "uncas": [31, 51, 75], "unced": 99, "uncertain": [21, 59, 65, 89, 95], "uncertain_indic": [89, 95], "uncertainti": [21, 23, 35, 36, 43, 56, 65, 67, 79, 80], "unchang": [26, 70], "uncia": [32, 59, 76], "uncom": 17, "uncomfort": [30, 31, 50, 51, 74, 75], "uncommit": [31, 51, 75], "uncorrel": [26, 70], "uncov": [31, 75], "under": [0, 1, 8, 15, 17, 24, 31, 32, 34, 36, 40, 44, 51, 52, 59, 60, 61, 68, 75, 76, 78, 80, 81, 83], "under_sampl": 81, "underestim": [34, 78], "underfit": [16, 21, 22, 32, 38, 39, 62, 65, 66, 76, 87, 93], "undergradu": 5, "underground": 59, "underli": [2, 26, 27, 28, 46, 70, 71, 72], "underneath": 8, "underpredict": [24, 68], "underr": [20, 59], "undersampl": 67, "undersample_pip": 81, "understand": [0, 1, 4, 8, 12, 13, 16, 19, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 38, 39, 43, 44, 45, 46, 47, 50, 51, 52, 53, 56, 59, 60, 61, 62, 64, 65, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 83, 85, 86, 92, 99], "understood": 81, "undertaken": 59, "undoubtedli": 59, "unemploi": [34, 78], "unexpect": [19, 21, 22, 31, 51, 52, 64, 65, 66, 75], "unexplain": [24, 44, 68], "unf": [24, 26, 35, 44, 46, 55, 56, 68, 70, 79], "unfinish": [24, 44, 68], "unflatten_input": 48, "unforgett": [20, 59], "unfortun": [7, 22, 28, 29, 46, 59, 66, 70, 72, 73, 93], "unfunni": [20, 59], "unhappi": 38, "unifi": [31, 51, 75], "uniform": [22, 29, 40, 63, 64, 67, 73, 92, 95], "unimport": [22, 26, 42, 46, 66, 70], "uninform": 40, "uninterest": 59, "uninterpret": [26, 46, 70], "unintuit": 9, "union": 9, "uniqu": [15, 18, 19, 24, 25, 26, 27, 30, 31, 34, 38, 43, 44, 45, 46, 49, 50, 51, 52, 53, 63, 64, 67, 68, 69, 70, 74, 75, 77, 78, 88, 91, 97], "unit": [17, 21, 24, 25, 26, 31, 32, 34, 40, 44, 45, 46, 51, 52, 54, 65, 67, 68, 69, 70, 75, 76, 78], "unitless": [24, 68], "univers": [1, 10, 31, 51, 52, 75, 83], "university_year": [19, 64, 85], "unix": [33, 77], "unknown": [7, 13, 51, 52, 59, 75, 85], "unknown_valu": [40, 45, 46, 64, 68, 69, 70], "unlabel": [13, 15, 29, 59, 61, 73], "unless": [8, 99], "unlik": [9, 13, 15, 16, 19, 24, 26, 28, 29, 44, 46, 59, 61, 62, 64, 68, 70, 72, 73], "unlimit": [33, 77], "unlucki": [15, 61], "unmarri": [25, 26, 45, 46, 69, 70], "unnam": [13, 20, 59], "uno": [17, 40], "unoffici": 99, "unpleas": 59, "unpredict": 20, "unqualifi": 67, "unrealist": [59, 61], "unreason": [7, 13, 24, 44, 68], "unrecogniz": 13, "unrel": [51, 75], "unreli": [15, 61], "unrespond": 13, "unrev": 41, "unsatisfi": 59, "unscal": [18, 63], "unseen": [15, 17, 27, 28, 32, 36, 60, 71, 72, 76, 80, 87, 93], "unstructur": [52, 83], "unsubtl": 59, "unsupervis": [13, 30, 31, 32, 34, 36, 50, 51, 52, 59, 74, 75, 76, 80, 99], "unsur": [8, 35, 56, 79], "unthink": 59, "until": [4, 14, 15, 22, 27, 28, 29, 31, 34, 35, 36, 42, 47, 51, 52, 56, 60, 61, 66, 71, 72, 73, 75, 78, 79, 80, 83, 93], "unus": [87, 93], "unusu": [17, 40], "unwieldi": [14, 17, 18, 60, 63], "unzip": [26, 46, 70], "uoft": [31, 51, 52, 75], "up": [5, 6, 8, 9, 14, 17, 18, 19, 20, 21, 22, 23, 26, 27, 28, 29, 30, 31, 32, 33, 34, 38, 40, 41, 42, 43, 46, 47, 50, 51, 52, 55, 59, 60, 63, 64, 65, 66, 67, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 81, 83, 85, 86, 92, 94, 95, 96, 97, 99], "uparrow": [29, 73], "upcom": 72, "updat": [6, 11, 16, 18, 19, 25, 28, 31, 32, 39, 45, 51, 62, 63, 64, 69, 72, 75, 76, 87, 93], "update_cent": [28, 72], "update_plot": [16, 39, 62, 87, 93], "update_z": [28, 72], "upei": [31, 51, 52, 75], "upgrad": [31, 51, 52, 75], "upload": [8, 36], "upon": [0, 14, 19, 25, 26, 28, 29, 31, 32, 45, 51, 52, 59, 60, 61, 64, 69, 70, 71, 72, 73, 75, 76, 81], "upper": [23, 34, 43, 67, 78], "upperbound_pric": [17, 40], "upto": [33, 77], "ur": 59, "urgent": [19, 31, 52, 64, 75], "url": [4, 15, 23, 31, 34, 36, 43, 51, 54, 57, 58, 61, 67, 75, 78, 80, 81, 99], "us": [0, 1, 2, 4, 6, 12, 17, 20, 21, 22, 23, 26, 27, 29, 30, 33, 34, 36, 38, 40, 41, 42, 43, 46, 47, 48, 49, 50, 53, 54, 55, 57, 58, 65, 66, 67, 70, 73, 74, 77, 78, 80, 82, 85, 87, 88, 89, 90, 91, 93, 94, 95, 96, 97], "usa": [9, 16, 21, 52, 61, 62, 65, 83], "usabl": [36, 80], "usag": [5, 17, 18, 19, 23, 24, 27, 31, 34, 43, 44, 47, 51, 52, 53, 54, 63, 64, 67, 68, 71, 75, 77, 78, 93, 95, 97], "usec_": [34, 54, 78], "useless": [22, 26, 27, 42, 46, 47, 66, 70, 71], "user": [13, 14, 16, 18, 19, 22, 25, 26, 28, 29, 31, 32, 34, 36, 39, 42, 45, 46, 48, 51, 52, 54, 56, 57, 58, 59, 60, 61, 63, 64, 66, 69, 70, 72, 73, 75, 76, 78, 79, 80, 83, 84, 85], "user_id": [30, 50, 74], "user_inverse_mapp": [30, 50, 74], "user_kei": [30, 50, 74], "user_mapp": [30, 50, 74], "user_nam": [30, 50, 74], "usernam": 6, "userwarn": [14, 19, 25, 31, 32, 34, 45, 46, 60, 61, 64, 69, 70], "usf": [19, 64], "using_copy_on_writ": [34, 78], "using_cow": [34, 78], "usp": [16, 22], "usual": [1, 13, 14, 15, 16, 17, 18, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33, 34, 35, 36, 40, 43, 44, 45, 46, 47, 50, 51, 52, 53, 54, 55, 56, 59, 60, 61, 62, 63, 65, 66, 67, 68, 69, 70, 72, 73, 74, 75, 76, 77, 78, 79, 80, 83, 91, 97, 99], "usvi": 45, "utc": [33, 54, 77, 78], "utcnow": [54, 78], "utf": [41, 42, 64, 66], "util": [6, 14, 15, 16, 17, 18, 19, 20, 21, 22, 24, 25, 26, 31, 32, 34, 35, 38, 39, 40, 41, 42, 44, 45, 46, 48, 49, 51, 54, 55, 56, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 75, 76, 78, 79, 85, 86, 87, 88, 89, 92, 93, 94, 95], "utilities_allpub": [24, 46, 68, 70], "utilities_nosewa": [24, 46, 68, 70], "utility_mat": [30, 50, 74], "uvic": [31, 51, 52, 75], "v": [1, 3, 5, 8, 19, 29, 33, 34, 38, 39, 52, 53, 54, 56, 64, 65, 73, 77, 78, 79, 83, 85, 98], "v1": [13, 23, 31, 43, 59, 67, 75, 81], "v10": [23, 43, 67], "v11": [23, 43, 67], "v12": [23, 43, 67], "v13": [23, 43, 67], "v14": [23, 43, 67], "v15": [23, 43, 67], "v16": [23, 43, 67], "v17": [23, 43, 67], "v18": [23, 43, 67], "v19": [23, 43, 67], "v2": [13, 23, 31, 43, 51, 59, 67, 75, 81], "v20": [23, 43, 67], "v21": [23, 43, 67, 81], "v22": [23, 43, 67, 81], "v23": [23, 43, 67, 81], "v24": [23, 43, 67, 81], "v25": [23, 43, 67, 81], "v26": [23, 43, 67, 81], "v27": [23, 43, 67, 81], "v28": [23, 43, 67, 81], "v3": [23, 43, 67, 81], "v4": [23, 43, 67, 81], "v5": [23, 43, 67, 81], "v6": [23, 43, 67, 81], "v7": [23, 43, 67, 81], "v8": [23, 43, 67, 81], "v9": [23, 43, 67, 81], "v_1": [16, 62], "v_2": [16, 62], "v_i": [16, 62], "v_n": [16, 62], "vacat": [21, 31, 51, 65, 75], "vaccin": [35, 55, 56, 79], "vada_pav": 52, "vain": [31, 51, 66, 75], "val": [30, 34, 50, 54, 74, 78], "valenc": [18, 22, 42, 62, 63, 66], "valid": [1, 14, 16, 19, 20, 24, 25, 26, 27, 28, 30, 32, 34, 35, 36, 39, 40, 41, 42, 44, 45, 46, 47, 50, 56, 60, 62, 64, 68, 69, 70, 71, 72, 74, 76, 78, 79, 80, 81, 85, 88, 89, 91, 94, 95, 97, 99], "valid_dir": 39, "valid_mat": [30, 50, 74], "valid_sample_df": [25, 45, 69], "valid_sample_i": [25, 45, 69], "valid_sample_x": [25, 45, 69], "valid_scor": [15, 38, 87, 93], "valid_x": [30, 50, 74], "validate_data": [18, 34], "validate_paramet": [45, 69], "validate_separ": [18, 34], "valu": [8, 9, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 38, 39, 40, 42, 43, 44, 45, 46, 47, 48, 50, 51, 52, 53, 54, 55, 56, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 82, 84, 85, 86, 87, 88, 90, 91, 92, 93, 94, 95, 96, 97], "valuabl": [5, 12, 29, 36, 71, 73, 80, 99], "value_count": [14, 15, 17, 19, 23, 25, 26, 34, 36, 38, 40, 41, 43, 45, 46, 53, 54, 57, 58, 59, 60, 64, 67, 69, 70, 77, 78, 80, 89, 91, 95, 97], "value_throttl": [16, 62, 87, 93], "valueerror": [9, 18, 19, 34, 54, 63, 64, 77, 78, 91, 97], "values_format": [23, 43, 67], "vampir": 20, "vancouv": [17, 31, 35, 51, 52, 56, 75, 79, 83], "vancouver_canuck": [31, 51, 52, 75], "vanilla": [21, 65], "vaniti": 20, "var": [46, 63, 70], "var_": [26, 46, 70], "varada": [0, 1, 14, 99], "vari": [12, 14, 22, 29, 34, 42, 54, 60, 66, 69, 73, 78, 87, 93], "variabl": [8, 9, 14, 18, 19, 21, 22, 24, 26, 27, 31, 33, 34, 35, 38, 44, 46, 53, 56, 60, 63, 64, 65, 66, 68, 70, 71, 77, 78, 79, 90, 91, 93, 96, 97], "varianc": [24, 26, 29, 33, 38, 44, 46, 53, 68, 70, 73, 77, 87, 93], "variant": [26, 29, 46, 70, 73], "variat": [15, 21, 24, 27, 44, 61, 65, 67, 68, 81, 82], "varieti": [13, 25, 31, 52, 59, 69, 75], "variou": [12, 13, 16, 24, 26, 32, 33, 34, 35, 36, 39, 44, 53, 54, 56, 57, 58, 59, 62, 68, 70, 76, 77, 78, 79, 80, 85, 87, 93], "vastli": 59, "vault": [15, 59, 61], "ve": [8, 9, 13, 16, 17, 23, 24, 26, 30, 31, 32, 35, 36, 38, 39, 40, 43, 44, 46, 50, 51, 52, 53, 56, 57, 58, 59, 61, 62, 67, 68, 70, 74, 75, 76, 77, 79, 80, 81, 83, 84, 91, 97], "vec": [19, 20, 31, 32, 41, 51, 52, 64, 75, 76], "vec1": [31, 52, 75], "vec1_i": [31, 52, 75], "vec2": [31, 52, 75], "vec2_i": [31, 52, 75], "vec8": [19, 64], "vec8_binari": [19, 64], "vec_binari": [19, 64], "vecom": [22, 66], "vector": [14, 18, 21, 30, 32, 35, 39, 40, 48, 50, 51, 56, 60, 65, 74, 76, 79, 81, 83, 87, 89, 93, 95], "vener": 59, "verb": [31, 51, 52, 75, 83], "verbal": 85, "verbos": [13, 25, 26, 35, 40, 41, 42, 43, 45, 46, 56, 59, 63, 64, 66, 67, 68, 69, 70, 76, 79, 95], "verbose_feature_names_out": [40, 42, 45, 46, 54, 64, 66, 68, 69, 70, 78, 95], "veri": [2, 4, 6, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 40, 41, 42, 43, 44, 45, 46, 47, 48, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 82, 83, 87, 91, 92, 93, 97, 99], "verneuil": 41, "versa": [24, 44, 68, 87, 93], "version": [1, 4, 5, 6, 8, 9, 11, 14, 15, 17, 21, 24, 26, 29, 31, 33, 40, 44, 46, 51, 52, 53, 54, 63, 65, 66, 68, 70, 73, 75, 77, 78, 84, 91, 97], "versu": 10, "vert": [26, 46, 70], "vertic": [14, 33, 53, 60, 77, 81], "vgg": [32, 76], "vgg16": [32, 39, 76], "via": [8, 13, 27, 71, 81, 99], "vibe": [17, 40], "vice": [24, 44, 59, 68, 87, 93], "victim": 59, "victor": 59, "video": [1, 5, 8, 9, 10, 11, 30, 31, 32, 34, 35, 36, 38, 51, 55, 56, 57, 58, 74, 75, 76, 78, 79, 80, 99], "vietnames": [17, 18, 63], "view": [7, 8, 15, 17, 26, 29, 32, 33, 34, 35, 38, 46, 55, 56, 59, 60, 70, 73, 76, 77, 78, 79], "viewer": 59, "viewform": 22, "viewpoint": [30, 74], "vif": [26, 46, 70], "vikski": 52, "villain": 59, "violat": [18, 19, 34, 36, 40, 63, 64, 78, 80, 99], "virginia": [31, 32, 51, 75, 76], "viridi": [22, 42, 66], "virtu": 20, "virtual": [11, 13, 59], "vision": [1, 36, 48, 59, 80, 84], "visit": [9, 23, 43, 59, 99], "visitor": 59, "visual": [1, 11, 12, 14, 15, 16, 19, 20, 21, 23, 24, 25, 26, 28, 29, 32, 33, 34, 38, 41, 43, 45, 46, 54, 59, 60, 61, 62, 64, 65, 67, 68, 69, 70, 72, 73, 76, 77, 78, 85, 88, 90, 94, 96], "visualize_coeffici": [20, 41], "vittorio": 59, "viu": [31, 51, 52, 75], "vivid": [20, 41], "viz": [35, 55, 56, 79], "voc": [25, 26, 45, 46, 67, 69, 70], "vocab": [20, 31, 41, 51, 52, 75], "vocabulari": [19, 21, 31, 42, 51, 52, 64, 65, 66, 75, 83], "vocabulary_": [19, 64], "voic": [13, 31, 59, 75], "volcano": 59, "volum": [36, 80], "vote": [16, 18, 25, 45, 62, 63, 69, 84, 89, 95], "voting_ndt": [25, 45, 69], "votingclassifi": [25, 45, 69, 89, 95], "votingclassifierifit": 95, "votingclassifierinot": [25, 45, 69], "votingregressor": [25, 45, 69], "vulner": 20, "w": [6, 19, 21, 24, 28, 31, 35, 36, 41, 42, 44, 50, 51, 52, 53, 56, 57, 58, 64, 65, 66, 68, 72, 75, 77, 79, 80, 97], "w_0": [21, 65], "w_1": [21, 65], "w_1x_1": [21, 65], "w_2x_2": [21, 65], "w_3x_3": [21, 65], "w_4x_4": [21, 65], "w_d": [21, 65], "w_dx_d": [21, 65], "w_i": 50, "w_j": [20, 21, 41, 65], "wa": [4, 6, 13, 14, 15, 17, 18, 20, 21, 25, 26, 30, 31, 32, 34, 35, 40, 41, 45, 46, 50, 51, 52, 54, 56, 59, 60, 61, 63, 65, 67, 69, 70, 74, 75, 76, 78, 79, 83, 84, 86, 87, 90, 91, 92, 93, 96, 97, 99], "wa_fn": [34, 54, 78], "waggawagga": 97, "wai": [0, 2, 5, 7, 9, 13, 14, 15, 16, 17, 18, 19, 20, 21, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33, 34, 36, 40, 41, 43, 44, 45, 46, 48, 50, 51, 52, 53, 57, 58, 59, 60, 61, 62, 63, 64, 65, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 80, 81, 83, 84, 85, 87, 91, 92, 93, 94, 97, 99], "wait": [4, 5, 14, 16, 17, 19, 34, 36, 59, 60, 62, 64, 78, 80, 99], "waitlist": 99, "walk": [16, 31, 36, 39, 51, 57, 58, 59, 62, 75, 80, 81, 87, 93], "walker": [32, 59, 76], "wallabi": [32, 76], "walpol": 97, "walru": [31, 41, 51, 75], "want": [4, 5, 7, 8, 9, 11, 13, 14, 15, 16, 17, 18, 20, 22, 23, 24, 25, 27, 28, 29, 30, 31, 32, 33, 35, 36, 39, 40, 42, 43, 44, 45, 47, 50, 51, 52, 53, 54, 56, 57, 58, 59, 60, 61, 62, 63, 66, 67, 68, 69, 71, 72, 73, 74, 75, 76, 77, 79, 80, 81, 83, 85, 88, 90, 91, 94, 96, 97], "war": [30, 50, 59, 74], "ward": [29, 49, 59, 73], "warlik": 59, "warm": [18, 63], "warm_start": [35, 41, 43, 45, 56, 67, 69, 76, 79, 95], "warn": [7, 13, 15, 16, 19, 23, 24, 25, 26, 28, 29, 31, 34, 43, 44, 45, 46, 54, 61, 62, 64, 68, 69, 70, 78, 84, 89, 95], "warn_on_unknown": 64, "warranti": 0, "washroom": 99, "wasn": [17, 20, 40, 52, 83], "wast": [4, 19, 20, 35, 41, 56, 64, 79, 94], "watch": [1, 5, 13, 20, 21, 30, 41, 50, 52, 59, 62, 65, 74, 85], "watchfil": 39, "water": [17, 35, 55, 56, 79], "waterfal": [26, 46, 70], "waterfront": [15, 38, 59, 60], "watsonia": 97, "wavelet": [27, 71], "wax": 59, "waxwork": 20, "wb": [36, 57, 58, 80], "wd": [24, 26, 35, 44, 46, 55, 56, 68, 70, 79], "we": [1, 4, 6, 7, 8, 11, 13, 14, 16, 17, 20, 23, 29, 31, 32, 33, 39, 40, 41, 42, 43, 44, 48, 51, 52, 53, 55, 57, 58, 59, 60, 62, 73, 75, 76, 77, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 99], "weak": [20, 59, 85], "weapon": 59, "wear": 59, "weather": [14, 33, 36, 60, 77, 80], "weatherau": [53, 77, 91, 97], "weav": 59, "web": [6, 13, 52, 83, 85], "web_api": [36, 57, 58, 80], "web_appl": [36, 57, 58, 80], "weblog": 52, "websit": [4, 5], "wed": [33, 77], "wednesdai": [1, 33, 77, 99], "week": [1, 7, 13, 16, 18, 19, 24, 25, 26, 28, 31, 33, 35, 44, 45, 46, 51, 52, 56, 61, 62, 63, 64, 67, 68, 69, 70, 74, 75, 77, 79, 87, 93], "weekdai": [33, 77, 93], "weekend": [9, 20, 33, 35, 41, 56, 77, 79, 93], "weekli": 5, "weigh": [31, 51, 75], "weight": [13, 16, 23, 25, 30, 31, 32, 34, 39, 40, 43, 45, 46, 48, 49, 50, 51, 52, 62, 63, 64, 67, 69, 71, 74, 75, 76, 95, 99], "weighted_averag": 81, "weinberg": [26, 46, 70], "weird": [24, 44, 68], "welcom": [5, 92, 99], "well": [4, 6, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 32, 33, 34, 35, 36, 43, 45, 46, 51, 52, 53, 54, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 75, 76, 77, 78, 79, 80, 81, 83, 85, 90, 93, 96, 99], "wellyanto": [1, 99], "welsh": [32, 59, 76], "went": [24, 25, 44, 68, 89, 95], "were": [0, 7, 13, 17, 20, 21, 23, 24, 31, 32, 33, 34, 35, 40, 43, 44, 51, 52, 53, 56, 59, 64, 65, 68, 75, 76, 77, 78, 79, 83, 89, 93, 95, 99], "weren": [52, 83], "werther\u00f5": 96, "what": [6, 8, 9, 10, 11, 14, 16, 17, 20, 22, 29, 32, 33, 38, 39, 40, 41, 42, 44, 53, 57, 58, 60, 62, 66, 73, 76, 77, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97], "whatev": [27, 59, 71], "when": [1, 4, 5, 7, 8, 13, 14, 15, 16, 17, 19, 21, 23, 24, 25, 26, 27, 28, 29, 31, 32, 33, 34, 36, 38, 39, 40, 42, 43, 44, 45, 46, 48, 50, 51, 52, 53, 54, 57, 58, 59, 60, 61, 62, 64, 65, 67, 68, 69, 70, 72, 73, 74, 75, 76, 77, 78, 80, 81, 82, 83, 84, 85, 86, 88, 89, 91, 92, 94, 95, 97, 99], "where": [0, 1, 6, 8, 13, 14, 15, 16, 17, 18, 20, 21, 22, 23, 24, 25, 26, 28, 30, 31, 32, 33, 35, 36, 38, 39, 40, 41, 42, 43, 44, 45, 46, 50, 51, 52, 53, 55, 56, 57, 58, 59, 60, 61, 62, 65, 66, 67, 68, 69, 70, 72, 74, 75, 76, 77, 79, 80, 81, 83, 85, 87, 91, 93, 97], "wherea": [2, 14, 17, 21, 22, 24, 26, 29, 35, 40, 42, 46, 56, 60, 65, 66, 68, 70, 73, 79], "whether": [0, 4, 8, 9, 14, 15, 17, 18, 19, 21, 24, 25, 26, 27, 29, 33, 34, 36, 40, 44, 45, 46, 47, 52, 53, 54, 60, 61, 63, 64, 65, 67, 68, 69, 70, 71, 73, 77, 78, 80, 81, 82, 83, 86, 89, 91, 92, 95, 97, 99], "which": [4, 6, 7, 9, 14, 15, 16, 17, 18, 19, 20, 21, 22, 24, 26, 27, 31, 32, 33, 34, 35, 36, 38, 39, 40, 41, 42, 44, 46, 47, 51, 52, 54, 55, 56, 57, 58, 59, 61, 62, 63, 64, 65, 66, 68, 70, 71, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 92, 93, 94, 95, 96, 99], "whichev": [25, 45, 69], "while": [14, 15, 18, 20, 21, 22, 23, 25, 26, 28, 30, 31, 34, 43, 45, 46, 50, 51, 52, 59, 60, 61, 65, 66, 67, 69, 70, 72, 74, 75, 78, 83], "whilst": 59, "white": [25, 26, 29, 45, 46, 52, 59, 67, 69, 70, 73, 83], "whitespac": [34, 52, 54, 78, 83], "who": [4, 7, 13, 25, 26, 28, 29, 31, 33, 34, 35, 36, 46, 51, 52, 54, 56, 59, 70, 72, 73, 75, 77, 78, 79, 80, 81, 83, 85, 99], "whole": [8, 15, 22, 24, 26, 30, 31, 36, 42, 44, 46, 51, 59, 61, 66, 68, 70, 74, 75, 80], "whom": [0, 31, 51, 52, 75, 83], "whose": [4, 20], "why": [9, 14, 16, 17, 24, 25, 28, 29, 31, 33, 34, 38, 40, 42, 44, 45, 50, 51, 52, 61, 62, 67, 68, 69, 72, 73, 75, 77, 78, 83, 85, 86, 87, 88, 92, 93, 94], "wid": [36, 57, 58, 80, 81], "wide": [6, 21, 22, 25, 27, 30, 31, 32, 35, 42, 45, 55, 56, 65, 66, 69, 71, 74, 75, 76, 79, 99], "wider": [16, 39, 62, 87, 93], "widescreen": 59, "widespread": [31, 51, 52, 59, 75], "widget": [16, 23, 28, 29, 39, 43, 62, 67, 72, 73, 87, 93], "width": [14, 15, 16, 31, 39, 51, 52, 60, 61, 62, 67, 75, 86, 87, 92, 93], "width_ratio": [86, 92], "wife": [20, 25, 26, 45, 46, 59, 67, 69, 70], "wiggl": 99, "wiki": [31, 35, 51, 52, 56, 75, 79], "wiki_df": [31, 51, 52, 75], "wiki_dict": [31, 51, 52, 75], "wikipedia": [31, 32, 35, 51, 52, 56, 75, 76, 79], "wikipedia2vec": [31, 51, 52, 75], "wilcox": 41, "wild": [13, 15, 39, 59, 61], "william": 59, "williamtown": 97, "willing": [23, 43, 67], "win": [16, 19, 20, 25, 26, 27, 30, 41, 46, 47, 50, 62, 64, 69, 70, 71, 74, 84, 90, 96], "wind": [14, 59, 60], "winddir3pm": [53, 77, 91, 97], "winddir3pm_miss": [53, 77, 97], "winddir3pm_ss": [53, 77, 97], "winddir3pm_ssw": [53, 77, 97], "winddir3pm_sw": [53, 77, 97], "winddir3pm_w": [53, 77, 97], "winddir3pm_wnw": [53, 77, 97], "winddir3pm_wsw": [53, 77, 97], "winddir9am": [53, 77, 91, 97], "windgustdir": [53, 77, 91, 97], "windgustspe": [53, 77, 91, 97], "window": [11, 31, 34, 75, 78], "windspeed3pm": [53, 77, 91, 97], "windspeed9am": [53, 77, 91, 97], "wine_1": 9, "wink": 59, "winperc": [90, 96], "winter": [53, 77, 97], "winter_month": [53, 77, 97], "wipeout": 59, "wire": [30, 50, 74], "wisdom": [25, 69], "wish": [4, 13, 14, 20, 28, 56, 59, 60, 72, 79, 99], "wit": 59, "witchcliff": 97, "with_mean": [40, 42, 43, 45, 46, 63, 64, 66, 68, 69, 70, 95], "with_std": [40, 42, 43, 45, 46, 63, 64, 66, 68, 69, 70, 95], "within": [14, 18, 20, 21, 27, 28, 29, 34, 36, 39, 42, 45, 47, 54, 59, 60, 63, 65, 66, 69, 71, 72, 73, 77, 78, 80, 85, 91, 97], "without": [0, 5, 6, 8, 13, 14, 23, 25, 26, 27, 30, 32, 33, 34, 35, 36, 40, 43, 45, 46, 47, 54, 56, 57, 58, 59, 60, 67, 69, 70, 71, 74, 76, 77, 78, 79, 80, 82, 99], "wnw": [53, 77, 97], "wolf": 20, "wollongong": 97, "wolv": [29, 73], "woman": [31, 51, 52, 59, 75], "wombat": [32, 76], "women": [31, 51, 75], "won": [13, 14, 15, 16, 19, 20, 21, 25, 27, 30, 31, 32, 33, 34, 36, 47, 50, 51, 52, 54, 57, 58, 60, 61, 62, 64, 65, 71, 74, 75, 76, 77, 78, 80, 83], "wonder": [13, 20, 41, 59, 61], "woo": 59, "wooddecksf": [24, 26, 35, 44, 46, 55, 56, 68, 70, 79], "woomera": 97, "word": [12, 13, 15, 17, 20, 21, 22, 23, 27, 28, 29, 30, 32, 33, 34, 35, 38, 40, 41, 42, 43, 47, 56, 59, 65, 66, 67, 71, 72, 73, 74, 76, 77, 78, 79, 83, 85, 99], "word1": [31, 51, 52, 75], "word2": [31, 51, 52, 75], "word2vec": [12, 31, 32, 51, 52, 75, 76, 83], "word3": [31, 51, 52, 75], "word_coeff_df": [20, 41], "word_pair": [31, 51, 52, 75], "word_token": [31, 51, 52, 75, 83], "wordnet": [52, 83], "wordnetlemmat": [52, 83], "words_in_ex": [20, 41], "work": [0, 4, 5, 6, 8, 9, 11, 13, 16, 17, 18, 19, 20, 21, 22, 23, 24, 26, 27, 28, 30, 31, 33, 34, 36, 40, 42, 43, 44, 46, 47, 50, 51, 52, 53, 54, 55, 57, 58, 62, 63, 64, 65, 66, 67, 68, 70, 71, 72, 74, 75, 77, 78, 80, 82, 85, 89, 90, 91, 94, 95, 96, 97, 99], "workclass": [25, 26, 45, 46, 67, 69, 70], "workclass_feder": [25, 26, 45, 46, 69, 70], "workclass_loc": [25, 26, 45, 46, 69, 70], "workclass_miss": [26, 45, 46, 70], "workclass_nev": [25, 26, 45, 46, 69, 70], "workclass_priv": [25, 26, 45, 46, 69, 70], "workclass_self": [26, 45, 70], "workclass_st": [26, 45, 70], "workclass_without": [26, 45, 70], "workflow": [14, 31, 36, 51, 60, 75, 80, 99], "workhors": [13, 59], "world": [15, 16, 18, 19, 21, 22, 25, 26, 27, 28, 29, 30, 31, 32, 46, 47, 50, 51, 52, 59, 62, 63, 64, 65, 66, 67, 70, 71, 72, 73, 74, 75, 76, 82, 83, 85], "worm": [32, 76], "worri": [13, 29, 30, 50, 59, 72, 73, 74, 89, 95], "wors": [14, 17, 22, 24, 25, 32, 34, 44, 45, 54, 60, 66, 68, 69, 76, 78, 86, 92], "worst": [20, 23, 27, 28, 41, 43, 47, 59, 67, 71, 72], "worth": [14, 16, 24, 44, 59, 60, 62, 67, 68, 81], "worthi": [21, 65], "would": [4, 13, 14, 16, 17, 18, 19, 20, 21, 22, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 38, 39, 44, 45, 46, 47, 50, 51, 52, 53, 54, 56, 57, 58, 59, 60, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 84, 85, 87, 88, 89, 91, 93, 94, 95, 97, 99], "wouldn": [19, 22, 34, 42, 52, 59, 64, 66, 78, 83], "wow": [26, 46, 59, 70], "wrangl": [17, 40], "wrap": [19, 34, 64], "wrapper": [18, 27, 82, 96], "wrist": 59, "write": [4, 8, 12, 13, 22, 25, 28, 30, 31, 35, 36, 42, 51, 52, 56, 57, 58, 59, 66, 71, 72, 75, 79, 80, 83, 87, 89, 90, 93, 95, 99], "writer": 59, "written": [8, 19, 26, 31, 35, 46, 51, 53, 56, 64, 70, 75, 77, 79, 91, 97], "wrong": [15, 17, 21, 24, 27, 28, 34, 35, 40, 44, 54, 56, 59, 61, 65, 68, 72, 78, 79, 82, 96], "wrote": [31, 51, 52, 53, 75, 99], "wsw": [53, 77, 97], "wtf": [36, 57, 58, 80], "wvxp_oakj1i": [31, 51, 75], "www": [10, 13, 21, 65], "x": [4, 9, 11, 15, 16, 17, 18, 19, 21, 23, 25, 27, 28, 29, 30, 31, 32, 33, 34, 36, 38, 39, 40, 43, 45, 47, 50, 51, 52, 53, 57, 58, 61, 62, 63, 64, 65, 67, 69, 71, 72, 73, 74, 75, 76, 77, 80, 81, 84, 85, 86, 87, 90, 92, 93, 96, 97, 98], "x0": [27, 47, 71], "x0_male": 67, "x1": [27, 30, 47, 50, 71, 74], "x150": 1, "x153": 1, "x1x2": [27, 47, 71], "x2": [27, 29, 30, 47, 50, 71, 73, 74], "x27": [17, 18, 19, 20, 22, 23, 24, 25, 27, 35, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 55, 56, 63, 64, 66, 67, 68, 69, 70, 71, 76, 79, 95], "x337": 1, "x_": [20, 21, 41, 50, 65], "x_1": [21, 27, 28, 47, 65, 71, 72], "x_1x_2": [27, 47, 71], "x_2": [21, 27, 28, 47, 65, 71, 72], "x_anim_train": 39, "x_anim_valid": 39, "x_binari": [14, 60], "x_bird": 48, "x_citi": [16, 62], "x_coord": [90, 96], "x_count": [19, 64], "x_d": [21, 65], "x_femal": 67, "x_food": [48, 49], "x_hour": [33, 77], "x_hour_week": [33, 77], "x_hour_week_onehot": [33, 77], "x_hour_week_onehot_poli": [33, 77], "x_hour_week_onehot_poly_lag": [33, 77], "x_i": [21, 30, 65, 74], "x_imp_ohe_train": [18, 63], "x_init": [28, 72], "x_int": [19, 64], "x_label": [14, 15, 16, 42, 60, 61, 62, 66, 86, 92], "x_lag_featur": [33, 77], "x_lag_features_imp": [33, 77], "x_male": 67, "x_mask": [19, 64], "x_multi": 84, "x_n": [27, 47, 71], "x_orig": [29, 73], "x_re": 81, "x_small_citi": [16, 62], "x_spotifi": [22, 42, 62, 66], "x_subset": [14, 15, 60, 61], "x_test": [13, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 32, 33, 34, 35, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 54, 55, 56, 59, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 76, 77, 78, 79, 81, 84, 87, 88, 89, 93, 94, 95], "x_test_big": [22, 66], "x_test_cat": [17, 40], "x_test_cat_oh": [17, 40], "x_test_enc": [26, 34, 35, 46, 53, 54, 55, 56, 70, 77, 78, 79, 91, 97], "x_test_happi": [36, 57, 58, 80, 81], "x_test_imp": [18, 63], "x_test_multi": 84, "x_test_num": [17, 40], "x_test_num_imp": [17, 40], "x_test_num_imp_sc": [17, 40], "x_test_pr": [33, 77], "x_test_predict": [17, 18, 63], "x_test_scal": [18, 63], "x_test_transform": [17, 18, 63], "x_toi": [16, 18, 19, 33, 62, 63, 64, 77], "x_toy_oh": [18, 63], "x_toy_ord": [18, 19, 63, 64], "x_tr": [15, 38, 87, 93], "x_train": [13, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 30, 32, 33, 34, 35, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 50, 54, 55, 56, 59, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 74, 76, 77, 78, 79, 81, 82, 84, 87, 88, 89, 93, 94, 95], "x_train_big": [23, 43, 67, 81], "x_train_cat": [17, 40], "x_train_cat_oh": [17, 40], "x_train_enc": [24, 26, 34, 35, 44, 46, 53, 54, 55, 56, 67, 68, 70, 77, 78, 79, 91, 97], "x_train_happi": [36, 57, 58, 80, 81], "x_train_hous": [27, 47, 71], "x_train_imp": [17, 18, 63], "x_train_imp_sc": [17, 18, 63], "x_train_multi": 84, "x_train_num": [17, 40], "x_train_num_imp": [17, 40], "x_train_num_imp_sc": [17, 40], "x_train_ord": 17, "x_train_oversampl": 81, "x_train_perm": [26, 46, 70], "x_train_pp": [64, 94], "x_train_predict": [17, 18, 63], "x_train_scal": [18, 27, 47, 63, 71], "x_train_subsampl": 81, "x_train_tini": [22, 66], "x_train_transform": [17, 18, 63], "x_train_usr": [30, 50, 74], "x_transform": [19, 40, 64], "x_valid": [15, 23, 30, 38, 39, 43, 50, 67, 74, 81, 87, 93], "x_vari": [29, 73], "x_xor": [27, 47, 71], "xanni": [22, 42, 66], "xavier": [27, 30, 47, 50, 71, 74], "xcode": 6, "xferd": 36, "xgbclassifi": [25, 26, 45, 46, 69, 70], "xgbclassifierxgbclassifi": 25, "xgboost": [26, 46, 70], "xgboostcolumntransform": [25, 45, 69], "xgbregressor": [13, 25, 45, 59, 69], "xlabel": [9, 14, 15, 16, 21, 22, 23, 24, 26, 29, 32, 33, 34, 35, 39, 42, 43, 44, 46, 49, 53, 54, 55, 56, 60, 61, 62, 65, 66, 67, 68, 70, 73, 76, 77, 78, 79, 84, 86, 90, 91, 92, 96, 97, 98], "xlim": [34, 54, 78], "xor": [21, 27, 47, 65, 71], "xp": [18, 34], "xscale": [42, 66], "xt": [19, 64], "xtick": [23, 33, 39, 43, 53, 61, 67, 77, 86, 91, 92, 97], "xtick_label": 77, "xticklabel": [22, 42, 66], "xticks_rot": 81, "xwm\u0259\u03b8kw\u0259y": 99, "xx": [27, 28, 47, 71, 72], "xxxxviii": 41, "y": [9, 15, 16, 17, 18, 19, 21, 22, 23, 25, 27, 28, 29, 30, 32, 33, 34, 38, 39, 40, 42, 43, 45, 47, 50, 52, 53, 54, 61, 62, 63, 64, 65, 66, 67, 69, 71, 72, 73, 74, 76, 77, 78, 81, 83, 84, 85, 86, 87, 90, 91, 92, 93, 95, 96, 97, 98], "y_": [30, 74], "y_citi": [16, 62], "y_coord": [90, 96], "y_femal": 67, "y_hat": [21, 45, 65, 69], "y_i": [24, 27, 30, 44, 45, 47, 68, 69, 71, 74, 82], "y_init": [28, 72], "y_label": [14, 15, 16, 42, 60, 61, 62, 66, 86, 92], "y_male": 67, "y_mat": [30, 50, 74], "y_multi": 84, "y_numer": 18, "y_pred": [23, 33, 43, 67, 77], "y_pred_lower_threshold": [23, 43, 67], "y_pred_toi": 81, "y_pred_train": [33, 77], "y_re": 81, "y_small_citi": [16, 62], "y_spotifi": [22, 42, 66], "y_test": [13, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 32, 33, 34, 35, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 53, 54, 55, 56, 59, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 76, 77, 78, 79, 81, 84, 87, 88, 89, 91, 93, 94, 95, 97], "y_test_big": [22, 66], "y_test_happi": [36, 57, 58, 80, 81], "y_test_multi": 84, "y_test_num": [25, 26, 45, 46, 69, 70], "y_toi": [16, 33, 62, 77], "y_tr": [15, 38, 87, 93], "y_train": [13, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 30, 32, 33, 34, 35, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 50, 53, 54, 55, 56, 59, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 74, 76, 77, 78, 79, 81, 82, 84, 87, 88, 89, 91, 93, 94, 95, 97], "y_train_big": [23, 43, 67, 81], "y_train_happi": [36, 57, 58, 80, 81], "y_train_hous": [27, 47, 71], "y_train_multi": 84, "y_train_num": [25, 26, 45, 46, 69, 70], "y_train_ord": [53, 77, 91, 97], "y_train_oversampl": 81, "y_train_subsampl": 81, "y_train_tini": [22, 66], "y_train_usr": [30, 50, 74], "y_true": [35, 56, 79], "y_true_toi": 81, "y_valid": [15, 23, 30, 32, 38, 39, 43, 50, 67, 74, 76, 81, 87, 93], "y_vari": [29, 73], "y_xor": [27, 47, 71], "yah": 59, "yale": [31, 51, 52, 75], "yann": [26, 46, 70], "yawn": 59, "ycxmx": [34, 78], "ye": [4, 13, 14, 17, 18, 19, 26, 27, 28, 29, 30, 32, 33, 35, 36, 40, 46, 50, 53, 54, 56, 59, 60, 63, 64, 70, 72, 73, 74, 76, 77, 79, 80, 85, 90, 91, 94, 96, 97], "year": [5, 13, 14, 20, 27, 28, 30, 31, 32, 34, 50, 52, 53, 54, 59, 60, 74, 75, 76, 77, 78], "yearbuilt": [24, 26, 35, 44, 46, 55, 56, 68, 70, 79], "yearremodadd": [24, 26, 35, 44, 46, 55, 56, 68, 70, 79], "yeb4": 16, "yeild": 17, "yellow": [22, 31, 42, 51, 66, 75], "yellowbrick": [28, 29, 72, 73, 90, 96], "yesterdai": [53, 77, 91, 97], "yet": [12, 17, 18, 21, 26, 30, 33, 34, 40, 46, 50, 54, 59, 65, 70, 74, 77, 78, 87, 93], "yield": 17, "ylabel": [9, 14, 15, 16, 21, 22, 23, 24, 29, 32, 33, 34, 35, 38, 39, 42, 43, 44, 49, 53, 54, 55, 56, 60, 61, 62, 65, 66, 67, 68, 73, 76, 77, 78, 79, 84, 86, 87, 90, 91, 92, 93, 96, 97, 98], "ylim": [34, 35, 54, 55, 56, 78, 79], "yml": 11, "yolo": [32, 76], "yolo8": [32, 76], "yolo_input": [32, 76], "yolo_result": [32, 76], "yolo_test": [32, 76], "yolov8n": [32, 76], "york": [33, 77], "you": [0, 1, 4, 5, 6, 7, 8, 9, 11, 17, 23, 26, 31, 39, 42, 43, 44, 46, 47, 48, 49, 51, 52, 54, 55, 57, 58, 70, 75, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 99], "young": [20, 59], "your": [0, 1, 2, 4, 5, 7, 8, 9, 16, 17, 18, 19, 21, 22, 23, 24, 25, 26, 27, 28, 30, 31, 32, 33, 34, 36, 38, 40, 42, 43, 44, 45, 46, 50, 51, 52, 53, 54, 57, 58, 59, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 74, 75, 76, 77, 78, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 93, 94, 95, 96, 97, 99], "yourself": [4, 12, 19, 30, 35, 50, 52, 56, 64, 67, 74, 79, 83, 85, 90, 93, 96, 99], "yourselv": [52, 83], "yourusernam": 11, "youtub": [1, 13, 30, 31, 51, 52, 56, 74, 75, 79, 99], "yr_built": [15, 38, 59, 60], "yr_renov": [15, 38, 59, 60], "yrpxn": [34, 54, 78], "yrsold": [24, 26, 35, 44, 46, 55, 56, 68, 70, 79], "ytick": [23, 39, 43, 61, 67, 86, 92], "yticklabel": [22, 42, 66], "yy": [27, 47, 53, 71, 77, 91, 97], "yyyi": [53, 77, 91, 97], "z": [9, 21, 27, 28, 29, 30, 32, 34, 39, 47, 48, 49, 65, 71, 72, 73, 74, 76, 78], "z_bird": 48, "z_food": [48, 49], "z_hrch": 49, "z_i": [32, 76], "z_j": [32, 76], "z_km": [28, 72], "z_train": [32, 39, 76], "z_valid": [32, 39, 76], "zachari": [34, 54, 78], "zero": [9, 15, 19, 22, 30, 31, 35, 50, 51, 52, 55, 56, 64, 66, 74, 75, 79], "zero_divis": [23, 43, 67], "zheng": [1, 99], "zip": [16, 21, 30, 39, 50, 62, 65, 74, 87, 93], "zipcod": [15, 38, 59, 60], "zoe": [1, 99], "zombi": [20, 41], "zone": [20, 41, 53, 77, 91, 97], "zoo": [20, 41], "zoom": [8, 99], "zorro": [20, 41], "zu": [20, 41], "zucco": [20, 41], "\u0259m": 99, "\u03bc": 84}, "titles": ["LICENSE", "UBC CPSC 330: Applied Machine Learning (2025W1)", "CPSC 330 vs. CPSC 340", "CPSC 330 Documents", "How to ask for help", "Frequently Asked Questions", "Git and GitHub: Getting Started", "CPSC 330 grading policies", "Homework info &amp; submission guidelines", "CPSC 330 Python notes", "Reference material", "Setting up your coding environment", "Course Learning Objectives", "Lecture 1: Course Introduction", "Lecture 2: Terminology, Baselines, Decision Trees", "Lecture 3: Machine Learning Fundamentals", "Lecture 4: <span class=\"math notranslate nohighlight\">\\(k\\)</span>-Nearest Neighbours and SVM RBFs", "Lecture 5 and 6: Class demo", "Lecture 5: Preprocessing and <code class=\"docutils literal notranslate\"><span class=\"pre\">sklearn</span></code> pipelines", "Lecture 6: <code class=\"docutils literal notranslate\"><span class=\"pre\">sklearn</span></code> <code class=\"docutils literal notranslate\"><span class=\"pre\">ColumnTransformer</span></code> and Text Features", "Lecture 7: Class demo", "Lecture 7: Linear Models", "Lecture 8: Hyperparameter Optimization and Optimization Bias", "Lecture 9: Class demo", "Lecture 10: Regression metrics", "Lecture 11: Ensembles", "Lecture 12: Feature importances and model transparency", "Lecture 13: Feature engineering and feature selection", "Lecture 14: K-Means Clustering", "Lecture 16: More Clustering", "Lecture 16: Recommender Systems", "Lecture 17: Introduction to natural language processing", "Lecture 18: Multi-class classification and introduction to computer vision", "Lecture 19: Time series", "Lecture 20: Survival analysis", "Lecture 21: Communication", "Lecture 23: Deployment and conclusion", "Section 102", "Lecture 3: ML Fundamentals Class Demo", "Lecture 4: Class demo", "Lecture 5 and 6: Class demo", "Lectures 7: Class demo", "Lectures 8: Class demo", "Lecture 9: Class demo", "Lecture 10: Class demo", "Lecture 11: Ensembles", "Lecture 12: Class demo", "Lecture 13: Class demo", "Lecture 15: Clustering class demo", "Lecture 15: Class demo", "Lecture 16: Class demo", "Lecture 17: Class demo", "Lecture 18: Class demo", "Lecture 19: Class demo", "Lecture 20: Class demo", "Lecture 21: Class demo (Based on the lecture notes)", "Lecture 22: Class demo (Based on the lecture notes)", "Lecture 23: Class demo (Based on the lecture notes)", "Lecture 24: Class demo (Based on the lecture notes)", "Lecture 1: Course Introduction", "Lecture 2: Terminology, Baselines, Decision Trees", "Lecture 3: Machine Learning Fundamentals", "Lecture 4: <span class=\"math notranslate nohighlight\">\\(k\\)</span>-Nearest Neighbours and SVM RBFs", "Lecture 5: Preprocessing and <code class=\"docutils literal notranslate\"><span class=\"pre\">sklearn</span></code> pipelines", "Lecture 6: <code class=\"docutils literal notranslate\"><span class=\"pre\">sklearn</span></code> <code class=\"docutils literal notranslate\"><span class=\"pre\">ColumnTransformer</span></code> and Text Features", "Lecture 7: Linear Models", "Lecture 8: Hyperparameter Optimization and Optimization Bias", "Lecture 9: Classification metrics", "Lecture 10: Regression metrics", "Lecture 11: Ensembles", "Lecture 12: Feature importances and model transparency", "Lecture 13: Feature engineering and feature selection", "Lecture 14: K-Means Clustering", "Lecture 15: More Clustering", "Lecture 16: Recommender Systems", "Lecture 17: Introduction to natural language processing", "Lecture 18: Multi-class classification and introduction to computer vision", "Lecture 19: Time series", "Lecture 20: Survival analysis", "Lecture 21: Communication", "Lecture 23: Deployment and conclusion", "Appendix A: Handling class imbalance", "Appendix B: Feature Selection", "Appendix C: Basic text preprocessing [video]", "Appendix D: Multi-class, meta-strategies", "Final exam preparation: guiding questions", "Tutorial 1", "Tutorial 2", "Tutorial 3", "Tutorial 6", "Tutorial 6", "Tutorial 8", "Tutorial 1", "Tutorial 2", "Tutorial 3", "Tutorial 6", "Tutorial 6", "Tutorial 8", "&lt;no title&gt;", "Syllabus"], "titleterms": {"": [5, 13, 16, 17, 18, 19, 23, 24, 26, 35, 40, 43, 44, 46, 48, 53, 54, 55, 56, 59, 61, 62, 63, 64, 67, 68, 70, 77, 78, 79], "0": [69, 88], "1": [6, 11, 13, 14, 15, 16, 18, 19, 21, 22, 24, 25, 27, 28, 29, 30, 34, 35, 42, 45, 56, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 71, 72, 73, 78, 79, 85, 86, 87, 88, 89, 91, 92, 93, 94, 95, 97], "10": [24, 44, 68, 89, 95], "102": 37, "11": [25, 45, 69], "12": [25, 26, 46, 70], "13": [27, 47, 71], "14": [27, 28, 71, 72], "15": [28, 35, 36, 48, 49, 56, 73, 79, 80], "16": [29, 30, 50, 73, 74], "17": [30, 31, 51, 75], "18": [32, 52, 76], "19": [33, 53, 77], "2": [6, 11, 13, 14, 15, 16, 18, 19, 21, 22, 24, 28, 29, 30, 34, 35, 44, 56, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 72, 73, 78, 79, 85, 86, 87, 88, 89, 91, 92, 93, 94, 95, 97], "20": [34, 35, 36, 54, 56, 78, 79, 80], "2025w1": 1, "21": [34, 35, 55, 79], "22": 56, "23": [36, 57, 80], "24": 58, "3": [6, 11, 13, 14, 15, 18, 21, 28, 29, 34, 35, 38, 59, 60, 61, 63, 71, 73, 78, 86, 87, 88, 89, 91, 92, 93, 94, 95, 97], "330": [1, 2, 3, 7, 9, 13, 36, 80], "340": [2, 5, 13, 36, 80], "4": [11, 13, 14, 15, 16, 35, 39, 46, 56, 59, 60, 61, 62, 79, 86, 87, 88, 89, 91, 92, 93, 94, 95, 97], "5": [9, 11, 13, 14, 15, 16, 17, 18, 19, 26, 28, 32, 34, 35, 40, 51, 52, 56, 60, 61, 62, 63, 64, 70, 71, 72, 75, 76, 78, 79, 87, 88, 89, 91, 93, 94, 95, 97], "6": [11, 17, 19, 40, 64, 87, 89, 90, 91, 93, 95, 96, 97], "7": [11, 20, 21, 41, 65, 89, 95], "8": [22, 42, 66, 89, 91, 95, 97], "9": [23, 43, 67, 89, 95], "A": [4, 11, 23, 29, 31, 43, 51, 53, 67, 73, 75, 77, 81], "No": 9, "Not": 85, "One": [18, 53, 63, 77, 84], "The": [1, 15, 21, 22, 25, 28, 31, 42, 45, 51, 61, 65, 66, 69, 71, 72, 75, 89, 90, 95, 96], "__": [22, 42, 66], "about": [9, 13, 27, 30, 35, 47, 56, 71, 74, 79, 82], "academ": 99, "access": [8, 21, 65, 99], "accommod": 99, "acknowledg": 99, "activ": [13, 15, 26, 27, 28, 31, 35, 46, 51, 52, 56, 67, 70, 71, 72, 75, 79], "actual": 64, "ad": 9, "addit": [8, 26, 46, 70], "address": [23, 43, 67], "advantag": [22, 42, 66], "advic": [27, 71], "after": [31, 51, 75], "ai": [5, 13, 59, 99], "aka": [35, 56, 79], "algorithm": [14, 16, 27, 28, 47, 60, 62, 71, 72], "all": [13, 21, 23, 28, 29, 30, 35, 43, 50, 56, 60, 63, 65, 67, 72, 73, 74, 79], "alpha": [21, 24, 44, 65, 68], "alreadi": [36, 57, 58, 80], "altern": [11, 14, 17, 18, 40, 60, 63], "am": 5, "an": [25, 35, 45, 56, 69, 79], "analogi": 62, "analysi": [15, 17, 31, 34, 36, 38, 40, 51, 53, 75, 77, 78, 80, 85, 87, 91, 93, 97], "angl": [35, 56, 79], "announc": [16, 19, 21, 25, 60, 62, 64, 65, 69], "answer": [34, 78], "ap": [23, 43, 67], "api": [17, 18, 36, 57, 58, 63, 80], "app": [36, 57, 58, 80], "appendix": [81, 82, 83, 84], "appli": [1, 9, 18, 19, 24, 35, 44, 55, 56, 63, 64, 68, 79], "applic": [28, 72], "applymap": 9, "approach": [30, 33, 34, 35, 36, 50, 53, 54, 56, 74, 77, 78, 79, 80, 84], "approxim": [15, 61], "ar": [5, 13, 18, 21, 28, 29, 30, 31, 50, 51, 59, 60, 63, 65, 67, 72, 73, 74, 75], "architectur": [31, 51, 75], "area": [23, 43, 67], "argument": [16, 61, 62], "around": [35, 56, 79], "arrai": 9, "articl": 10, "asap": [35, 56, 79], "ask": [4, 5], "assess": 38, "assign": [5, 8, 99], "associ": [21, 65], "assum": [34, 78], "attend": [5, 26], "attent": [14, 16, 60, 62], "attribut": [26, 35, 46, 56, 70, 79], "auc": [23, 43, 67], "audit": 5, "authent": 6, "autom": [22, 66], "averag": [25, 30, 45, 50, 69, 74, 81, 89, 95], "avoid": [15, 61], "b": [11, 28, 72, 82], "backward": [27, 82], "bad": [22, 42, 66], "bag": [19, 64], "balanc": 67, "bank": [23, 43], "base": [25, 27, 30, 33, 47, 50, 53, 55, 56, 57, 58, 62, 69, 71, 74, 77, 91, 97], "baselin": [14, 15, 18, 23, 25, 26, 30, 38, 43, 45, 46, 50, 60, 63, 67, 69, 70, 74, 87, 93], "basic": [52, 83], "been": [54, 78], "befor": [13, 18, 31, 51, 63, 75], "best": 71, "better": [15, 22, 23, 27, 35, 42, 43, 55, 56, 61, 66, 67, 71, 79], "between": [16, 31, 36, 60, 62, 75, 80, 86, 92], "beyond": [26, 30, 31, 46, 50, 51, 70, 74, 75], "bia": [15, 22, 61, 66], "big": [14, 15, 18, 60, 61, 63], "binari": [23, 43, 67], "book": 1, "boost": [25, 35, 45, 55, 56, 69, 79], "bootstrap": [25, 69], "bottom": [35, 56, 79], "boundari": [14, 16, 21, 39, 60, 62, 65, 86, 92], "bow": [19, 64], "box": [32, 76], "break": [9, 13, 14, 15, 16, 19, 32, 34, 35, 36, 51, 52, 56, 60, 61, 62, 63, 64, 71, 75, 76, 78, 79, 80], "broadcast": 9, "browser": 13, "build": [13, 14, 20, 24, 30, 36, 38, 41, 44, 50, 57, 58, 59, 60, 68, 74, 80], "c": [16, 22, 42, 62, 66, 83], "calcul": [21, 65], "california": [21, 64, 65, 88, 94], "can": [5, 9, 15, 18, 25, 26, 28, 45, 46, 61, 63, 69, 70, 71, 72], "canada": [60, 86, 92], "care": [30, 35, 56, 74, 79], "carri": [18, 27, 47, 63, 71], "case": [19, 21, 29, 64, 65, 73], "catboost": [25, 45, 69], "categor": [17, 18, 19, 26, 33, 40, 46, 63, 64, 70, 77], "categori": [19, 64], "censor": [34, 54, 78], "centr": 99, "certain": 64, "cfa": 99, "chang": [67, 81], "charact": [13, 59], "characterist": [23, 43, 67], "cheatsheet": 9, "checklist": 13, "choos": [16, 28, 62, 72], "chunk": [35, 56, 79], "churn": [34, 78], "cite": 8, "citi": [21, 65], "claim": [35, 56, 79], "class": [5, 13, 17, 20, 22, 23, 24, 25, 26, 30, 32, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 66, 67, 68, 69, 70, 74, 76, 81, 84, 99], "class_attend": [19, 64], "class_weight": 67, "classif": [14, 23, 32, 36, 39, 43, 57, 58, 60, 67, 76, 80, 81, 85], "classifi": [14, 17, 20, 21, 25, 40, 41, 45, 60, 65, 69], "clearli": [27, 82], "cluster": [28, 29, 48, 49, 72, 73, 85, 90, 96], "cnn": [32, 76], "co": [1, 99], "code": [5, 11, 99], "coeffici": [20, 21, 26, 41, 46, 65, 70], "color": [86, 87, 88, 89, 91, 92, 93, 94, 95, 97], "column": [9, 18, 19, 33, 63, 64, 77], "columntransform": [19, 64, 88, 94], "combin": [25, 45, 69], "come": [15, 16, 61, 62], "command": 6, "comment": [14, 22, 23, 24, 28, 29, 30, 43, 50, 60, 66, 67, 68, 72, 73, 74], "common": [18, 28, 31, 51, 63, 72, 75], "commonli": [52, 83], "commun": [13, 35, 56, 79, 85], "compact": [17, 18, 63], "companion": 10, "complet": [30, 50, 74], "complex": [15, 61], "complic": [53, 77, 91, 97], "compon": [21, 65], "comprehens": [88, 94], "comput": [13, 32, 76, 85], "con": [16, 29, 62, 73, 85], "concept": [35, 38, 56, 79], "concern": 7, "concess": 99, "conclus": [36, 80], "conda": 11, "conduct": 99, "confid": [21, 35, 56, 65, 79], "configur": 11, "confus": [23, 35, 43, 55, 56, 67, 79], "consid": [34, 78], "construct": [25, 45, 69], "content": [30, 50, 74], "context": 52, "continu": [14, 60], "conveni": [19, 64], "convolut": [32, 76], "corpu": [36, 57, 58, 80], "correct": [11, 28, 72], "correl": [26, 46, 70], "countri": [60, 86, 92], "countvector": [19, 64], "cours": [1, 5, 10, 11, 12, 13, 36, 59, 80, 99], "cover": [30, 34, 36, 50, 54, 57, 58, 74, 78, 80], "cox": [34, 54, 78], "cpsc": [1, 2, 3, 5, 7, 9, 13], "creat": [8, 11, 14, 19, 30, 36, 50, 57, 58, 60, 61, 64, 74, 80], "credit": 11, "critic": [23, 43], "cross": [15, 17, 18, 23, 27, 33, 38, 43, 47, 53, 61, 63, 67, 71, 77, 87, 93], "cross_val_scor": 61, "cross_valid": [15, 24, 44, 61, 68], "csv": 9, "curs": [16, 62], "curv": [23, 34, 43, 54, 67, 78], "custom": [28, 34, 54, 72, 78], "cv": [22, 66], "d": 84, "dai": [33, 77], "data": [13, 14, 15, 16, 17, 18, 19, 21, 22, 24, 25, 26, 28, 30, 33, 35, 36, 38, 40, 44, 45, 46, 53, 54, 55, 56, 59, 60, 61, 62, 63, 64, 65, 66, 68, 69, 70, 71, 72, 74, 77, 79, 80, 81, 87, 91, 93, 97], "datafram": [9, 19, 64], "dataset": [8, 14, 18, 20, 21, 22, 23, 24, 32, 33, 35, 41, 43, 44, 53, 55, 56, 60, 63, 64, 65, 66, 67, 68, 76, 77, 79, 88, 89, 90, 91, 94, 95, 96, 97], "date": [1, 33, 53, 77], "datetim": [53, 77, 91, 97], "dbscan": [29, 49, 73], "deal": [19, 64, 67], "decis": [14, 15, 16, 21, 26, 38, 39, 46, 56, 60, 62, 65, 70, 79, 87, 93], "decisiontreeclassifi": [14, 25, 45, 60, 69], "decreas": [23, 43, 67], "deep": [32, 33, 53, 76, 77], "defin": [27, 82], "definit": [13, 59], "deliver": [1, 13], "demo": [15, 17, 20, 23, 27, 36, 38, 39, 40, 41, 42, 43, 44, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 71, 77, 80], "demonstr": [23, 43, 67], "dendrogram": [29, 73], "depend": 71, "deploi": [36, 57, 58, 80], "deploy": [15, 36, 57, 58, 61, 80, 85], "descript": 99, "desktop": 6, "detail": [15, 24, 29, 43, 44, 67, 68, 73], "detect": [32, 76], "df": 9, "did": [15, 18, 19, 24, 30, 34, 35, 36, 50, 54, 56, 57, 58, 61, 63, 64, 67, 68, 74, 78, 79, 80], "differ": [5, 18, 22, 23, 24, 26, 36, 42, 43, 44, 46, 63, 66, 68, 70, 80, 85], "dimens": [16, 62], "dimension": [16, 62], "directori": [36, 57, 58, 80], "discuss": [15, 17, 22, 30, 31, 35, 36, 52, 56, 57, 58, 66, 67, 74, 75, 79, 80], "diseas": [13, 59], "distanc": [16, 28, 62, 72], "distribut": [22, 31, 42, 51, 66, 75], "dl": [13, 59], "do": [5, 17, 18, 22, 23, 25, 26, 27, 35, 40, 43, 45, 46, 47, 56, 63, 64, 66, 67, 69, 70, 71, 79], "document": [3, 9, 28, 72], "doe": [5, 14, 15, 21, 29, 32, 35, 56, 60, 65, 73, 76, 79], "domain": [27, 71], "dr": 11, "drop": 9, "due": 1, "dummi": [17, 39, 40], "dummyclassifi": [14, 25, 34, 45, 53, 60, 69, 77, 78], "dummyregressor": [14, 18, 24, 44, 60, 63, 68], "easiest": 6, "eda": [18, 23, 24, 36, 43, 44, 63, 67, 68, 80, 87, 88, 90, 93, 96], "effect": [25, 35, 45, 56, 69, 79], "elbow": [28, 72], "element": 9, "elimin": [27, 47, 71], "embed": [31, 51, 52, 75], "encod": [18, 19, 27, 33, 47, 53, 63, 64, 71, 77], "engin": [27, 33, 47, 53, 71, 77, 85], "ensembl": [25, 45, 69, 85], "enter": [17, 40], "environ": [5, 11, 36, 57, 58, 80], "equal": [35, 55, 56, 79], "error": [11, 15, 22, 23, 24, 30, 43, 44, 50, 61, 66, 67, 68, 74], "estim": [17, 18, 25, 40, 45, 63, 69], "ethic": 85, "euclidean": [16, 62], "eva": [13, 59, 61], "evalu": [23, 29, 30, 34, 43, 50, 54, 67, 73, 74, 78, 81, 85], "evalut": 43, "event": [34, 78], "everyon": [34, 78], "exactli": [21, 65], "exam": [5, 85, 99], "examin": [19, 20, 24, 35, 41, 44, 55, 56, 64, 68, 79, 85], "exampl": [13, 14, 16, 18, 19, 21, 22, 23, 25, 26, 27, 28, 31, 32, 34, 35, 43, 45, 46, 51, 52, 56, 59, 60, 61, 62, 63, 64, 65, 66, 67, 69, 70, 72, 75, 76, 78, 79, 82], "exercis": [14, 15, 16, 18, 19, 21, 22, 24, 25, 27, 30, 32, 34, 45, 50, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 71, 76, 78, 86, 92], "exhaust": [22, 42, 66], "experi": [35, 56, 79], "explain": [26, 35, 46, 56, 70, 79], "explan": [26, 35, 46, 56, 70, 79], "explor": [16, 28, 62, 72], "exploratori": [15, 17, 38, 40, 53, 77, 87, 91, 93, 97], "express": [13, 59], "extract": [19, 33, 64, 77], "extractor": [32, 76], "f1": [23, 43, 67], "failur": [29, 73], "fair": 67, "fancier": [22, 42, 66], "farewel": [36, 80], "faster": 9, "fastest": 9, "featur": [13, 14, 16, 17, 18, 19, 21, 24, 26, 27, 30, 32, 33, 35, 40, 44, 46, 47, 50, 53, 55, 56, 59, 60, 62, 63, 64, 65, 68, 70, 71, 74, 76, 77, 79, 82, 85, 91, 97], "feature_importances_": [26, 46, 70], "few": [23, 29, 43, 56, 67, 73, 79], "fictiti": [13, 59], "figur": 8, "filter": [9, 30, 50, 74], "final": [14, 22, 28, 29, 30, 33, 50, 53, 60, 66, 72, 73, 74, 77, 85, 87, 93, 99], "find": [14, 16, 27, 62, 71], "first": [13, 18, 63], "fit": [14, 18, 45, 60, 63, 69], "follow": [13, 15, 28, 29, 30, 50, 60, 61, 72, 73, 74], "font": [86, 87, 88, 89, 91, 92, 93, 94, 95, 97], "forecast": [33, 77], "forest": [25, 26, 35, 45, 46, 55, 56, 69, 70, 79], "forg": 11, "format": [8, 9, 13], "formul": [30, 50, 74], "forward": [27, 82], "frequent": 5, "from": [5, 9, 31, 35, 51, 56, 75, 79], "full": [36, 57, 58, 80], "function": [9, 21, 24, 44, 65, 68], "fundament": [15, 16, 25, 38, 45, 61, 62, 69, 85], "further": [33, 77], "futur": [33, 77], "gamma": [16, 62], "garbag": [27, 71], "gaussian": [42, 66], "gb": [35, 55, 56, 79], "genai": 13, "gener": [4, 5, 7, 15, 16, 21, 25, 27, 45, 61, 62, 65, 69, 71, 82, 99], "geometr": [16, 62], "get": [5, 6, 46, 70], "git": [6, 11], "github": 6, "given": [13, 14, 54, 59, 60, 78], "global": [30, 50, 74], "goal": [15, 61], "golden": [15, 18, 19, 61, 63, 64], "good": [35, 55, 56, 67, 79], "grade": [4, 7, 13, 14, 60, 99], "gradescop": 8, "gradient": [25, 35, 45, 55, 56, 69, 79], "grid": [22, 35, 42, 56, 66, 79], "gridsearchcv": [22, 24, 35, 42, 44, 56, 66, 68, 79], "group": [15, 28, 67, 72], "guid": 85, "guidelin": [4, 7, 8], "ha": [13, 54, 59, 78], "halv": [22, 42, 66], "handl": [67, 81], "have": [25, 26, 35, 45, 46, 56, 69, 70, 79], "hazard": [34, 54, 78], "heatmap": [22, 42, 66], "help": [4, 27, 71], "here": [15, 54, 61, 78], "hierarch": [29, 49, 73], "high": [32, 76], "home": [29, 73], "homework": [5, 8, 13], "hot": [18, 27, 47, 53, 63, 71, 77], "hous": [13, 15, 18, 21, 59, 60, 63, 64, 65, 88, 94], "how": [4, 5, 8, 14, 15, 16, 17, 18, 21, 25, 26, 27, 29, 32, 35, 40, 45, 46, 47, 56, 60, 61, 62, 63, 65, 69, 70, 71, 73, 76, 79], "hyper": [22, 66], "hyperparamet": [14, 15, 16, 19, 21, 22, 24, 25, 28, 38, 42, 44, 45, 60, 62, 64, 65, 66, 68, 69, 72, 85, 87, 93], "hypothesi": [31, 51, 75], "i": [5, 13, 15, 18, 19, 22, 23, 25, 26, 27, 28, 30, 31, 35, 36, 43, 45, 46, 47, 52, 56, 57, 58, 59, 61, 63, 64, 66, 67, 69, 70, 71, 72, 74, 75, 79, 80, 82], "iclcik": 50, "iclick": [13, 14, 15, 16, 18, 19, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 32, 34, 35, 45, 50, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 71, 72, 73, 74, 76, 78, 99], "idea": [16, 25, 27, 31, 35, 45, 51, 56, 62, 67, 69, 75, 79, 81, 82], "identifi": [19, 26, 46, 64, 70], "imag": [13, 39, 48, 59], "imbal": [24, 25, 26, 45, 46, 67, 68, 69, 70, 81], "import": [1, 6, 13, 14, 15, 16, 17, 18, 19, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 85, 86, 87, 91, 92, 93, 97], "imput": [18, 30, 50, 63, 74], "incorpor": [17, 19, 40, 64], "increas": [23, 43, 67], "index": 9, "inertia": [28, 72], "info": 8, "inform": [26, 33, 46, 70, 77], "initi": [28, 36, 72, 80], "inject": [25, 45, 69], "input": [13, 28, 59, 72], "instal": [6, 11], "instruct": [0, 8], "instructor": 1, "interact": [27, 47, 71], "intercept": [21, 65], "interest": [35, 56, 79], "interim": [23, 26, 27, 33, 43, 46, 47, 67, 70, 71, 77], "interpret": [20, 21, 26, 28, 36, 41, 46, 65, 70, 80], "intra": [28, 72], "intro": [30, 74], "introduct": [9, 13, 26, 27, 28, 29, 31, 32, 35, 46, 47, 51, 56, 59, 70, 71, 72, 73, 75, 76, 79, 85], "intuit": [21, 38, 65], "involv": [33, 53, 56, 77, 79], "issu": [35, 56, 79], "jupyt": 13, "jupyterlab": 11, "k": [16, 18, 28, 29, 30, 50, 62, 63, 72, 73, 74, 90, 96], "kaplan": [34, 54, 78], "kei": [26, 36, 46, 56, 70, 79, 80], "kernel": [16, 62], "kind": [25, 45, 69], "kneighborsclassifi": [16, 39, 62], "knn": [17, 39, 40], "label": [13, 28, 35, 56, 59, 72, 79], "lag": [33, 53, 77, 91, 97], "land": 99, "languag": [5, 31, 51, 52, 75], "larg": [22, 31, 51, 66, 75], "late": 8, "latitud": [60, 86, 92], "lda": [31, 51, 52, 75], "learn": [1, 6, 11, 12, 13, 14, 15, 16, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 38, 41, 43, 44, 53, 56, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80], "least": [21, 65], "lectur": [1, 5, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 99], "let": [13, 16, 17, 18, 19, 23, 24, 26, 35, 40, 43, 44, 46, 48, 55, 56, 62, 63, 64, 67, 68, 70, 79], "level": [32, 76], "licens": [0, 1], "lightgbm": [25, 45, 69], "like": 5, "limit": [7, 21, 29, 65, 73], "line": 6, "linear": [20, 21, 24, 26, 41, 44, 46, 65, 68, 70], "link": 1, "list": 10, "liver": [13, 59], "ll": [15, 61], "llm": [31, 51, 75], "lo": [15, 16, 18, 19, 21, 22, 24, 25, 26, 30, 32, 33, 36, 46, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 74, 76, 77, 80], "load": [36, 57, 58, 80], "local": [36, 57, 58, 80], "localhost": [36, 57, 58, 80], "logist": [21, 23, 43, 65, 67], "logisticregress": [34, 35, 53, 56, 67, 77, 78, 79], "longitud": [60, 86, 92], "look": [5, 23, 28, 43, 67, 72], "loop": 9, "loss": [35, 56, 79], "lower": [22, 66], "m": 5, "machin": [1, 13, 14, 15, 16, 23, 28, 36, 38, 43, 59, 60, 61, 62, 67, 72, 80], "maco": 6, "macro": 81, "magnitud": [21, 65], "mai": 71, "main": [21, 30, 35, 56, 65, 74, 79], "make": [9, 21, 35, 56, 65, 79], "make_column_transform": [19, 64], "make_pipelin": [17, 18, 63], "mani": [22, 64, 66], "manual": [22, 66], "mape": [24, 44, 68], "markov": [31, 51, 75], "materi": [0, 1, 10], "matplotlib": 9, "matric": [19, 64], "matrix": [23, 30, 43, 50, 67, 74], "matter": 15, "max_depth": [14, 60], "mean": [24, 28, 29, 31, 35, 44, 51, 52, 56, 68, 72, 73, 75, 79, 90, 96], "measur": [31, 71, 75], "media": [31, 51, 52, 75], "meet": [13, 59, 99], "meier": [34, 54, 78], "messag": [13, 29, 59, 73], "meta": 84, "method": [9, 17, 22, 27, 28, 40, 42, 66, 72, 82], "metric": [23, 24, 43, 44, 67, 68, 81, 85], "midterm": [72, 99], "might": [34, 78], "min": [9, 13, 14, 15, 16, 19, 26, 28, 32, 34, 35, 36, 46, 51, 52, 56, 60, 61, 62, 63, 64, 70, 71, 72, 75, 76, 78, 79, 80], "miniconda": 11, "miniforg": 11, "minor": 81, "misc": [1, 10], "miscellan": [30, 50, 74], "mislead": [35, 55, 56, 79], "ml": [13, 15, 16, 26, 35, 38, 46, 56, 59, 61, 62, 67, 70, 79, 85], "model": [13, 14, 15, 17, 18, 19, 20, 21, 23, 24, 25, 26, 27, 31, 32, 34, 36, 38, 39, 40, 41, 43, 44, 45, 46, 47, 51, 52, 54, 57, 58, 59, 60, 61, 62, 63, 64, 65, 68, 69, 70, 71, 75, 76, 78, 80, 85, 87, 93], "model_select": [22, 42, 66], "moment": [36, 57, 58, 80], "month": [53, 54, 77, 78], "more": [14, 15, 16, 17, 18, 19, 21, 24, 27, 29, 43, 53, 60, 62, 63, 64, 65, 67, 68, 71, 73, 77, 91, 97], "most": [20, 21, 23, 41, 43, 65], "motiv": [15, 16, 18, 21, 22, 23, 25, 26, 27, 28, 29, 30, 31, 33, 35, 43, 46, 47, 51, 52, 56, 61, 62, 63, 65, 66, 67, 69, 70, 71, 72, 73, 74, 75, 77, 79], "movi": [13, 30, 50, 59, 74], "mse": [24, 44, 68], "much": [22, 66], "multi": [32, 76, 81, 84], "multiclass": 85, "multipl": [16, 19, 24, 44, 62, 64, 68], "multipli": 9, "n": [54, 78], "n_estim": [25, 45, 69], "n_iter": [22, 42, 66], "n_job": [22, 42, 66], "n_neighbor": [16, 62], "name": [15, 24, 30, 44, 61, 68, 74], "natur": [31, 52, 75], "nearest": [16, 18, 28, 30, 50, 62, 63, 72, 74], "need": [18, 22, 63, 66], "neg": [20, 23, 41, 43, 67], "neighbour": [16, 18, 30, 50, 62, 63, 74], "nest": 9, "netflix": [25, 69], "network": [32, 76], "neural": [32, 76], "new": [35, 36, 56, 57, 58, 79, 80], "next": [13, 36, 80], "nlp": [31, 51, 52, 75, 83, 85], "nn": [16, 62], "node": 14, "non": [16, 19, 46, 62, 64, 70], "notat": 9, "note": [9, 33, 55, 56, 57, 58, 61, 77, 87, 93], "notebook": [11, 13], "now": [34, 78], "number": [25, 28, 45, 53, 69, 72, 77], "numer": [26, 27, 46, 47, 70, 71], "numpi": 9, "object": [12, 14, 25, 31, 32, 33, 34, 35, 36, 60, 69, 75, 76, 77, 78, 79, 80], "observ": [23, 43, 67], "occasion": [18, 63], "off": [15, 16, 25, 45, 61, 62, 69], "oh": [18, 19, 63, 64], "ok": [18, 19, 63, 64], "onc": [23, 43, 67], "one": [19, 27, 47, 64, 71], "onehotencod": [19, 64], "onli": [11, 19, 34, 64, 78], "onlin": [1, 10], "open": 11, "oper": [23, 43, 67], "optim": [15, 22, 38, 42, 66, 85], "option": [6, 11, 16, 18, 22, 27, 32, 34, 36, 42, 43, 45, 54, 57, 58, 62, 63, 66, 67, 69, 76, 78, 80, 82], "ordin": [1, 17, 18, 19, 26, 40, 46, 63, 64, 70, 99], "other": [9, 16, 24, 27, 28, 33, 34, 35, 44, 47, 52, 53, 54, 56, 62, 68, 72, 77, 78, 79, 82, 83], "our": [8, 17, 18, 35, 36, 56, 57, 58, 61, 63, 79, 80], "out": [18, 27, 32, 35, 36, 47, 55, 56, 63, 71, 76, 79, 80], "outcom": [13, 14, 15, 16, 18, 19, 21, 22, 24, 26, 27, 28, 29, 30, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 70, 71, 72, 73, 74], "outlin": [86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97], "outlook": [54, 78], "output": [28, 72], "over": [9, 16, 21, 62, 65, 81], "overfit": [15, 22, 61, 66], "overlap": 5, "oversampl": 81, "overview": [16, 43, 62], "ovo": 84, "ovr": 84, "packag": [33, 53, 77], "panda": 9, "pandas_profil": [24, 44, 68], "paper": [25, 45, 67, 69], "paradigm": [18, 63], "paramet": [14, 21, 22, 42, 60, 65, 66, 67, 85], "parametr": [16, 62], "pars": [53, 77, 91, 97], "part": 85, "pass": [22, 42, 66], "patient": [13, 59], "paus": 17, "perfect": [28, 72], "perhap": [35, 55, 56, 79], "permut": 46, "permutation_import": [26, 46, 70], "persona": [13, 59], "piazza": 4, "pick": [15, 22, 61, 66], "pictur": [14, 15, 18, 60, 61, 63], "piec": [56, 79], "pipelin": [17, 18, 31, 40, 51, 52, 63, 75], "plan": [29, 73], "playground": [16, 39, 62, 87, 93], "plot": [9, 26, 28, 34, 46, 54, 70, 72, 78], "point": [16, 23, 26, 28, 33, 43, 46, 53, 62, 67, 70, 72, 77], "polici": 7, "poll": 72, "ponder": [20, 41], "popular": [13, 59], "posit": [20, 23, 41, 43, 67], "posix": [33, 77], "possibl": [19, 24, 28, 44, 64, 68, 72], "post": 10, "pr": [23, 43, 67], "practic": [14, 60, 62], "pre": [31, 32, 51, 75, 76], "precis": [23, 43, 67], "predict": [13, 14, 21, 26, 30, 31, 32, 34, 45, 46, 50, 51, 54, 59, 60, 64, 65, 69, 70, 74, 75, 76, 78, 84, 86, 92], "predict_proba": [21, 35, 56, 65, 79], "predictor": [36, 80], "prefer": [35, 56, 79], "prepar": [8, 85], "preprocess": [18, 19, 24, 35, 36, 44, 52, 53, 55, 56, 63, 64, 68, 77, 79, 80, 83, 85, 90, 91, 96, 97], "prerequisit": [5, 13], "pretrain": [31, 51, 75], "preval": [13, 59], "price": [13, 59, 60], "principl": [35, 56, 79], "prize": [25, 69], "pro": [16, 29, 62, 73, 85], "probabl": [21, 22, 42, 65, 66], "problem": [14, 15, 16, 18, 22, 27, 30, 33, 36, 42, 50, 53, 60, 61, 62, 63, 66, 74, 77, 80, 82], "procedur": 67, "process": [31, 52, 75], "product": [13, 59], "profil": [30, 50, 74], "program": [14, 60], "properli": [17, 40], "proport": [34, 54, 78], "python": [9, 10, 11, 13], "q": 4, "qualiti": 71, "queri": [9, 16, 62], "question": [4, 5, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 24, 25, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 38, 40, 41, 45, 50, 52, 53, 56, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 85, 86, 87, 88, 89, 91, 92, 93, 94, 95, 97], "quick": [11, 62], "quiz": [14, 60], "quiz2": [14, 60], "quot": [27, 71], "r": [24, 44, 68], "random": [22, 25, 26, 35, 42, 45, 46, 55, 56, 66, 69, 70, 79], "random_st": 61, "randomforestclassifi": [25, 34, 45, 69, 78], "randomizedsearchcv": [22, 24, 42, 44, 66, 68], "rang": [22, 42, 66], "rate": [30, 50, 74], "raw": [21, 65], "rbf": [16, 39, 62], "re": [35, 56, 79], "read": [9, 14, 22, 60, 66], "reader": [35, 56, 79], "real": [36, 57, 58, 60, 80, 86, 92], "realist": [19, 64], "reason": 7, "recal": [23, 43, 67], "recap": [14, 16, 29, 34, 56, 60, 62, 73, 78, 79, 86, 88, 92, 94], "receiv": [23, 43, 67], "recip": [36, 80], "recommend": [6, 11, 13, 18, 30, 50, 63, 74, 85], "record": 99, "recurs": [27, 47, 71], "red": [86, 87, 88, 89, 91, 92, 93, 94, 95, 97], "refer": [1, 10, 34, 54, 78], "reflect": [14, 15, 28, 29, 60, 61, 72, 73], "registr": [13, 99], "regress": [14, 16, 21, 23, 24, 38, 43, 44, 45, 60, 62, 65, 67, 68, 69], "regressor": [16, 62], "relat": [4, 14, 16, 35, 56, 60, 62, 67, 79], "relev": [10, 25, 27, 45, 67, 69, 71, 82], "remark": [33, 53, 77], "rememb": [28, 72], "remind": [30, 50, 60, 74], "remov": 9, "renam": 9, "render": [36, 57, 58, 80], "repo": 11, "report": [8, 23, 43], "repositori": 8, "represent": [19, 31, 51, 64, 75], "request": [36, 57, 58, 80], "requir": [13, 36, 80], "rescu": [15, 61], "resourc": [10, 13, 22, 27, 28, 29, 30, 50, 66, 67, 71, 72, 73, 74], "rest": 84, "result": [22, 28, 35, 42, 55, 56, 66, 79], "retail": [33, 77], "reus": [35, 56, 79], "review": [13, 20, 36, 41, 59, 80], "revis": 38, "rf": [35, 55, 56, 79], "rfe": [27, 47, 71], "ridg": [21, 24, 44, 65, 68], "ridgecv": [24, 44, 68], "right": [34, 78], "rmse": [24, 44, 68], "roc": [23, 43, 67], "root": [14, 24, 44, 68], "row": 9, "rule": [15, 18, 19, 61, 63, 64], "run": [11, 18, 35, 56, 63, 79], "same": 9, "sampl": [25, 28, 69, 72, 81], "sauc": [28, 72], "save": [13, 36, 57, 58, 59, 80], "scale": [13, 17, 18, 21, 26, 40, 46, 59, 63, 65, 70], "scenario": [23, 43], "schedul": 1, "scheme": 99, "scikit": [15, 18, 19, 24, 44, 61, 63, 64, 68], "score": [14, 21, 22, 23, 24, 27, 28, 43, 44, 60, 61, 65, 66, 67, 68, 72, 82], "search": [16, 22, 27, 35, 42, 47, 56, 62, 66, 79, 82], "season": [33, 53, 77], "section": [5, 37], "segment": [28, 72], "select": [11, 13, 27, 28, 29, 30, 47, 50, 60, 71, 72, 73, 74, 82, 85], "send": [36, 57, 58, 80], "sentenc": [31, 51, 75], "sentiment": [13, 31, 51, 59, 75], "separ": [24, 26, 35, 44, 46, 55, 56, 68, 70, 79], "seri": [9, 33, 53, 77, 85, 91, 97], "server": [36, 57, 58, 80], "servic": [36, 57, 58, 80], "set": [11, 13, 22, 36, 38, 57, 58, 61, 66, 67, 80], "set_config": [19, 64], "shap": [26, 46, 70], "shape": [9, 29, 73], "shaplei": [26, 46, 70], "short": 10, "should": [25, 30, 35, 45, 56, 69, 74, 79], "show": [26, 35, 46, 56, 70, 79], "sigmoid": [21, 32, 65, 76], "sign": [21, 65], "silhouett": [28, 72], "similar": [16, 31, 62, 75], "simpl": [15, 31, 51, 61, 75], "simplefeatur": [26, 70], "simpleimput": [17, 40], "simul": [89, 95], "singl": [15, 38, 61], "size": 9, "sklearn": [14, 17, 18, 19, 22, 25, 26, 40, 42, 45, 46, 60, 63, 64, 66, 67, 69, 70], "slowest": 9, "small": [35, 56, 79], "smote": 81, "social": [31, 51, 52, 75], "softmax": [32, 76], "softwar": [0, 32, 33, 53, 76, 77], "solut": 25, "solv": [22, 66], "some": [14, 22, 25, 27, 36, 43, 45, 60, 66, 67, 69, 71, 80], "sort": 9, "sort_valu": 9, "sourc": [8, 26], "space": [33, 53, 77], "spaci": 52, "spaghetti": [28, 72], "spam": [13, 19, 59, 64], "spars": [19, 64], "specif": [4, 27, 71], "split": [15, 17, 18, 33, 38, 40, 53, 61, 63, 67, 77, 87, 93], "spotifi": [18, 22, 63, 66], "squar": [24, 44, 68], "stack": [25, 45, 69, 89, 95], "standardscal": [18, 63], "start": [6, 11, 16], "statement": [13, 28, 29, 30, 50, 60, 72, 73, 74], "statist": [36, 80], "step": [6, 11, 14, 38, 52, 60, 83, 88, 94], "strategi": [25, 45, 69, 84], "stratifi": 67, "strength": [21, 25, 45, 65, 69], "structur": [36, 57, 58, 80], "studi": 85, "style": 13, "submiss": 8, "submit": [5, 8], "success": [22, 42, 66], "summari": [9, 13, 14, 15, 16, 17, 18, 21, 22, 23, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 43, 45, 46, 47, 50, 51, 52, 54, 59, 60, 61, 62, 63, 65, 66, 67, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78], "supervis": [13, 14, 15, 16, 28, 30, 36, 38, 50, 59, 60, 61, 62, 72, 74, 80], "support": [16, 62], "surviv": [34, 54, 78, 85], "svc": [23, 43, 67], "svm": [16, 21, 39, 62, 65], "syllabu": [1, 99], "syntax": [17, 18, 19, 22, 42, 63, 64, 66], "synthet": 81, "system": [30, 50, 74, 85], "ta": [1, 99], "tabular": [14, 16, 36, 60, 62, 80], "tackl": [24, 68], "take": [5, 29, 73], "takeawai": [36, 80], "talk": 13, "target": [13, 14, 19, 24, 28, 44, 59, 60, 64, 68, 72], "task": [52, 83], "teach": [1, 99], "team": [1, 99], "techniqu": [18, 63, 81], "templat": 8, "tempor": [33, 77], "tent": 1, "terminologi": [14, 32, 60, 76], "test": [6, 15, 22, 33, 38, 53, 61, 66, 77], "test_df": 61, "test_siz": 61, "text": [17, 19, 31, 40, 51, 52, 64, 75, 83], "than": [19, 22, 27, 35, 55, 56, 64, 66, 71, 79], "thei": [25, 45, 69], "them": 9, "thi": [5, 9, 13, 17, 18, 19, 23, 26, 35, 36, 38, 40, 43, 46, 56, 59, 63, 64, 70, 79, 80], "thing": [18, 35, 55, 56, 63, 79], "threshold": [23, 43, 67], "time": [7, 13, 33, 34, 53, 59, 77, 78, 85, 91, 97], "tip": 85, "tl": 11, "todai": [15, 18, 19, 24, 35, 56, 61, 63, 64, 67, 68, 79], "toi": [14, 19, 23, 31, 43, 51, 52, 60, 64, 67, 75], "token": [52, 83], "tool": [52, 83], "topic": [31, 51, 52, 75], "trade": [15, 16, 25, 45, 61, 62, 69], "tradeoff": [15, 23, 25, 43, 45, 61, 67, 69], "tradit": [14, 33, 53, 60, 77], "train": [13, 14, 15, 19, 21, 31, 32, 33, 35, 36, 51, 53, 55, 56, 57, 58, 59, 60, 61, 64, 65, 67, 75, 76, 77, 79, 80], "train_df": 61, "train_siz": 61, "transfer": [32, 76], "transform": [17, 18, 19, 24, 27, 31, 35, 40, 44, 51, 55, 56, 63, 64, 68, 71, 75, 79], "transpar": [26, 36, 46, 70, 80], "tree": [14, 15, 25, 26, 35, 38, 45, 46, 55, 56, 60, 69, 70, 79, 87, 93], "trend": [33, 77], "troubleshoot": 11, "true": [13, 28, 29, 30, 50, 72, 73, 74], "try": [17, 18, 24, 35, 36, 40, 44, 56, 63, 68, 79, 80], "tune": [24, 28, 44, 68, 72, 87, 93], "tutori": [16, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97], "two": [19, 64], "type": [13, 15, 23, 24, 26, 28, 33, 34, 35, 43, 44, 46, 53, 54, 55, 56, 59, 61, 67, 68, 70, 72, 77, 78, 79], "typic": [5, 38, 52, 61, 83], "u": [35, 56, 79], "ubc": 1, "ubuntu": 6, "under": [23, 43, 67], "underfit": [15, 61], "undersampl": 81, "understand": [36, 80], "unequ": [33, 53, 77], "uniform": [42, 66], "unknown": [19, 64], "unlabel": [28, 72], "unseen": [13, 59, 61], "unsupervis": [14, 28, 60, 72], "up": [11, 13, 15, 16, 35, 36, 56, 57, 58, 61, 62, 79, 80], "updat": 8, "url": 9, "us": [5, 8, 9, 11, 13, 14, 15, 16, 18, 19, 24, 25, 28, 31, 32, 35, 39, 44, 45, 51, 52, 56, 59, 60, 61, 62, 63, 64, 68, 69, 71, 72, 75, 76, 79, 81, 83, 84, 86, 92, 99], "usa": [60, 86, 92], "user": [6, 30, 50, 74], "usual": [27, 71], "util": [30, 50, 74], "v": [2, 11, 13, 14, 15, 16, 23, 26, 28, 32, 36, 40, 43, 46, 60, 61, 62, 67, 70, 72, 76, 80, 84], "valid": [15, 17, 18, 22, 23, 33, 38, 43, 53, 61, 63, 66, 67, 77, 87, 93], "varianc": [15, 61], "vector": [9, 16, 31, 52, 62, 75], "verifi": 11, "video": [13, 14, 15, 16, 18, 21, 22, 24, 25, 26, 28, 29, 44, 45, 52, 59, 60, 61, 62, 63, 65, 67, 68, 69, 72, 73, 83], "view": [16, 19, 62, 64], "violat": [15, 61], "vision": [32, 76, 85], "visual": [10, 22, 35, 42, 55, 56, 66, 79], "vocabulari": [20, 41], "wai": [22, 27, 35, 47, 56, 66, 79, 82], "waitlist": [5, 13], "want": [19, 26, 34, 46, 64, 70, 78], "warn": [14, 27, 47, 60, 71, 82], "watch": [35, 55, 56, 79], "we": [5, 9, 15, 18, 19, 21, 22, 24, 25, 26, 27, 28, 30, 34, 35, 36, 38, 45, 46, 47, 50, 54, 56, 61, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 74, 78, 79, 80], "weak": [25, 45, 69], "web": [36, 57, 58, 80], "websit": 13, "week": 5, "weight": [21, 65, 81], "what": [5, 13, 15, 18, 19, 21, 23, 24, 25, 26, 27, 28, 30, 31, 34, 35, 36, 43, 45, 46, 47, 50, 51, 52, 54, 56, 59, 61, 63, 64, 65, 67, 68, 69, 70, 71, 72, 74, 75, 78, 79, 80], "when": [9, 11, 18, 22, 35, 56, 63, 66, 79], "where": [19, 34, 64, 78], "whether": [13, 59], "which": [13, 23, 25, 28, 29, 30, 43, 45, 50, 60, 67, 69, 72, 73, 74], "who": 5, "why": [13, 15, 19, 22, 26, 27, 30, 32, 35, 46, 47, 56, 59, 64, 66, 70, 71, 74, 76, 79], "window": 6, "wise": 9, "without": [28, 72], "word": [19, 31, 51, 52, 64, 75], "work": [14, 25, 29, 32, 35, 45, 56, 60, 69, 73, 76, 79], "workflow": [13, 15, 23, 43, 59, 61, 67], "workload": 5, "would": [15, 23, 40, 43, 61], "wrapper": 84, "write": [14, 60], "x": [13, 14, 24, 26, 35, 44, 46, 55, 56, 59, 60, 68, 70, 79], "xgboost": [25, 45, 69], "y": [13, 14, 24, 26, 35, 44, 46, 55, 56, 59, 60, 68, 70, 79], "ye": [34, 78], "yield": [22, 42, 66], "you": [13, 14, 15, 16, 18, 19, 20, 21, 22, 24, 25, 27, 28, 29, 30, 32, 33, 34, 35, 36, 38, 40, 41, 45, 50, 53, 56, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 71, 72, 73, 74, 76, 77, 78, 79, 80], "your": [6, 11, 13, 14, 15, 35, 55, 56, 60, 79]}})